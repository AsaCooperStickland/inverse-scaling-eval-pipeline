{"prompt": "  Dots are ideal systems to study fundamentals on heat transfer at the\nnanoscale and promising nanoscale heat-engines and thermal devices. Here, we\nreport on the validation of our theoretical model on the thermal conductance of\na metallic dot single-electron transistor (md-SET) by a recent experiment on\nthe low-T thermal conductance. We compare with the experiment, we emphasize the\nphysics interpretation and characteristic values and we apply the model to\nevaluate the operation the md-SET as heat-switch. Perfect agreement is shown\nbetween the calculated and the measured charge conductance G, heat conductance\n\\k{appa} and the ratio \\k{appa}/GT. The experimental findings confirm the\ntheoretical predictions on the periodicity of the Coulomb oscillations in the\nclassical regime, the low-T extreme values and the high-T limits of G and\n\\k{appa}. The calculated conductances of the md-SET are presented in universal\ncurves from low-T to high-T. It is shown that the md-SET can efficiently\noperate as a heat switch at temperatures , Ec being the charging energy of the\ndot.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  The phenomenon of subpulse drifting offers unique insights into the emission\ngeometry of pulsars, and is commonly interpreted in terms of a rotating\ncarousel of \"spark\" events near the stellar surface. We develop a detailed\ngeometric model for the emission columns above a carousel of sparks that is\nentirely calculated in the observer's inertial frame, and which is consistent\nwith the well-understood rotational effects of aberration and retardation. We\nexplore the observational consequences of the model, including (1) the\nappearance of the reconstructed beam pattern via the cartographic transform and\n(2) the morphology of drift bands and how they might evolve as a function of\nfrequency. The model, which is implemented in the software package PSRGEOM, is\napplicable to a wide range of viewing geometries, and we illustrate its\nimplications using PSRs B0809+74 and B2034+19 as examples. Some specific\npredictions are made with respect to the difference between subpulse evolution\nand microstructure evolution, which provides a way to further test our model.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We show that a small cover of dimension $3$ is atorodal if and only if there\nis no $4$-belt in the corresponding simple polytope.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  We develop a family of techniques to align word embeddings which are derived\nfrom different source datasets or created using different mechanisms (e.g.,\nGloVe or word2vec). Our methods are simple and have a closed form to optimally\nrotate, translate, and scale to minimize root mean squared errors or maximize\nthe average cosine similarity between two embeddings of the same vocabulary\ninto the same dimensional space. Our methods extend approaches known as\nAbsolute Orientation, which are popular for aligning objects in\nthree-dimensions, and generalize an approach by Smith etal (ICLR 2017). We\nprove new results for optimal scaling and for maximizing cosine similarity.\nThen we demonstrate how to evaluate the similarity of embeddings from different\nsources or mechanisms, and that certain properties like synonyms and analogies\nare preserved across the embeddings and can be enhanced by simply aligning and\naveraging ensembles of embeddings.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  A package for the Sage computer algebra system is developed for checking\nfeasibility of a given intersection array for a distance-regular graph. We use\nthis tool to show that there is no distance-regular graph with intersection\narray $\\{(2r+1)(4r+1)(4t-1), 8r(4rt-r+2t), (r+t)(4r+1); 1, (r+t)(4r+1),\n4r(2r+1)(4t-1)\\}$ ($r, t \\ge 1$), $\\{135, 128, 16; 1, 16, 120\\}$, $\\{234, 165,\n12; 1, 30, 198\\}$ or $\\{55, 54, 50, 35, 10; 1, 5, 20, 45, 55\\}$. In all cases,\nthe proofs rely on equality in the Krein condition, from which triple\nintersection numbers are determined. Further combinatorial arguments are then\nused to derive nonexistence.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  The magneto-Rayleigh-Taylor (MRT) instability has been investigated in great\ndetail in previous work using magnetohydrodynamic and kinetic models for\nlow-beta plasmas. The work presented here extends previous studies of this\ninstability to regimes where finite-Larmor-Radius (FLR) effects may be\nimportant. Comparisons of the MRT instability are made using a 5-moment and a\n10-moment two-fluid model, the two fluids being ions and electrons. The\n5-moment model includes Hall stabilization whereas the 10-moment model includes\nHall and FLR stabilization. Results are presented for these two models using\ndifferent electron mass to understand the role of electron inertia in the\nlate-time nonlinear evolution of the MRT instability. For the 5-moment model,\nthe late-time nonlinear MRT evolution does not significantly depend on the\nelectron inertia. However, when FLR stabilization is important, the 10-moment\nresults show that a lower ion-to-electron mass ratio (i.e. larger electron\ninertia) under-predicts the energy in high-wavenumber modes due to larger FLR\nstabilization.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  The experimentally observed swelling and collapse response of weakly charged\npolymers to the addition of specific salts displays quite convoluted behavior\nthat is not easy to categorize. Here we use a minimalistic implicit solvent /\nexplicit salt simulation model with a focus on ion-specific interactions\nbetween ions and a single weakly charged polyelectrolyte to qualitatively\nexplain the observed effects. In particular, we demonstrate ion-specific\nscreening and bridging effects cause collapse at low salt concentrations\nwhereas the same strong ion-specific direct interactions drive re-entrant\nswelling at high concentrations. Consistently with experiments, a distinct salt\nconcentration at which the salting-out power of anions inverts from the reverse\nto direct Hofmeister series is observed. At this, so called 'isospheric point',\nthe ion-specific effects vanish. Furthermore, with additional simplifying\nassumptions, an ion-specific mean-field model is developed for the collapse\ntransition which quantitatively agrees with the simulations. Our work\ndemonstrates the sensitivity of the structural behavior of charged polymers to\nthe addition of specific salt and shall be useful for further guidance of\nexperiments.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We study the problem of writing Gaussian primes as the sum of two squares,\nboth of which are interesting arithmetically, in particular, when one is the\nsquare of a prime and the other the square of an almost-prime.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  We discuss the Standard Model Effective Field Theory (SM-EFT) contributions\nto neutral- and charge-current Drell-Yan production, associated production of\nthe Higgs and a vector boson, and Higgs boson production via vector boson\nfusion. We consider all the dimension-six SM-EFT operators that contribute to\nthese processes at leading order, include next-to-leading order QCD\ncorrections, and interface them with parton showering and hadronization in\nPythia8 according to the POWHEG method. We discuss existing constraints on the\ncoefficients of dimension-six operators and identify differential and angular\ndistributions that can differentiate between different effective operators,\npointing to specific features of Beyond-the-Standard-Model physics.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  As of today, abuse is a pressing issue to participants and administrators of\nOnline Social Networks (OSN). Abuse in Twitter can spawn from arguments\ngenerated for influencing outcomes of a political election, the use of bots to\nautomatically spread misinformation, and generally speaking, activities that\ndeny, disrupt, degrade or deceive other participants and, or the network. Given\nthe difficulty in finding and accessing a large enough sample of abuse ground\ntruth from the Twitter platform, we built and deployed a custom crawler that we\nuse to judiciously collect a new dataset from the Twitter platform with the aim\nof characterizing the nature of abusive users, a.k.a abusive birds, in the\nwild. We provide a comprehensive set of features based on users' attributes, as\nwell as social-graph metadata. The former includes metadata about the account\nitself, while the latter is computed from the social graph among the sender and\nthe receiver of each message. Attribute-based features are useful to\ncharacterize user's accounts in OSN, while graph-based features can reveal the\ndynamics of information dissemination across the network. In particular, we\nderive the Jaccard index as a key feature to reveal the benign or malicious\nnature of directed messages in Twitter. To the best of our knowledge, we are\nthe first to propose such a similarity metric to characterize abuse in Twitter.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  While many recent advances in deep reinforcement learning (RL) rely on\nmodel-free methods, model-based approaches remain an alluring prospect for\ntheir potential to exploit unsupervised data to learn environment model. In\nthis work, we provide an extensive study on the design of deep generative\nmodels for RL environments and propose a sample efficient and robust method to\nlearn the model of Atari environments. We deploy this model and propose\ngenerative adversarial tree search (GATS) a deep RL algorithm that learns the\nenvironment model and implements Monte Carlo tree search (MCTS) on the learned\nmodel for planning. While MCTS on the learned model is computationally\nexpensive, similar to AlphaGo, GATS follows depth limited MCTS. GATS employs\ndeep Q network (DQN) and learns a Q-function to assign values to the leaves of\nthe tree in MCTS. We theoretical analyze GATS vis-a-vis the bias-variance\ntrade-off and show GATS is able to mitigate the worst-case error in the\nQ-estimate. While we were expecting GATS to enjoy a better sample complexity\nand faster converges to better policies, surprisingly, GATS fails to outperform\nDQN. We provide a study on which we show why depth limited MCTS fails to\nperform desirably.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  This paper considers links between the original risk-sensitive performance\ncriterion for quantum control systems and its recent quadratic-exponential\ncounterpart. We discuss a connection between the minimization of these cost\nfunctionals and robustness with respect to uncertainty in system-environment\nquantum states whose deviation from a nominal state is described in terms of\nthe quantum relative entropy. These relations are similar to those in minimax\nLQG control for classical systems. The results of the paper can be of use in\nproviding a rational choice of the risk-sensitivity parameter in the context of\nrobust quantum control with entropy theoretic quantification of statistical\nuncertainty in the system-field state.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  Entangled photon sources with simultaneously near-unity heralding efficiency\nand indistinguishability are the fundamental elements for scalable photonic\nquantum technologies. We design and realize a degenerate entangled-photon\nsource from an ultrafast pulsed laser pumped spontaneous parametric\ndown-conversion (SPDC), which show simultaneously ~97% heralding efficiency and\n~96% indistinguishability between independent single photons. Such a\nhigh-efficiency and frequency-uncorrelated SPDC source allows generation of the\nfirst 12-photon genuine entanglement with a state fidelity of 0.572(24). We\nfurther demonstrate a blueprint of scalable scattershot boson sampling using 12\nSPDC sources and a 12*12-modes interferometer for three-, four-, and five-boson\nsampling, which yields count rates more than four orders of magnitudes higher\nthan all previous SPDC experiments. Our work immediately enables\nhigh-efficiency implementations of multiplexing, scattershot boson sampling,\nand heralded creation of remotely entangled photons, opening up a promising\npathway to scalable photonic quantum technologies.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We demonstrate the existence of an exactly marginal deformation, with\nderivative coupling, about the free theory of a $(2+1)$-dimensional charged,\nLifshitz scalar with dynamic critical exponent $z=4$ and particle-hole\nasymmetry. We show that the other classically scale invariant interactions\n(consistent with translational and rotational invariance) break the scale\nsymmetry at the quantum level and find a trace identity for the\nstress-energy-momentum tensor complex. We conjecture the existence of bound\nstates of $(N+1)$-particles, as a manifestation of broken scale invariance,\nwhen we turn on an attractive, classically scale invariant, polynomial\ninteraction in charged, scalar Lifshitz field theories with dynamic critical\nexponent $z=2N$, $n \\in \\mathbb{N}$.\n\n\n###\n\n", "completion": " 03"}
{"prompt": "  By inverting the distributions of galaxies' apparent ellipticities and\nmisalignment angles (measured around the projected half-light radius $R_{\\rm\ne}$) between their photometric and kinematic axes, we study the intrinsic shape\ndistribution of 189 slow rotator early-type galaxies with stellar masses\n$2\\times 10^{11} M_{\\odot}<M_\\ast<2\\times 10^{12} M_{\\odot}$, extracted from a\nsample of about 2200 galaxies with integral-field stellar kinematics from the\nDR14 of the SDSS-IV MaNGA IFU survey. Thanks to the large sample of slow\nrotators, Graham+18 showed that there is clear structure in the misalignment\nangle distribution, with two peaks at both $0^{\\circ}$ and $90^{\\circ}$\nmisalignment (characteristic of oblate and prolate rotation respectively). Here\nwe invert the observed distribution from Graham+18. The large sample allows us\nto go beyond the known fact that slow rotators are weakly triaxial and to place\nuseful constraints on their intrinsic triaxiality distribution (around $1R_{\\rm\ne}$) for the first time. The shape inversion is generally non-unique. However,\nwe find that, for a wide set of model assumptions, the observed distribution\nclearly requires a dominant triaxial-oblate population. For some of our models,\nthe data suggest a hint for a minor triaxial-prolate population, but a dominant\nprolate population is ruled out.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  The $\\Xi\\Xi$ interaction in the $^1$S$_0$ channel is studied to examine the\nconvergence of the derivative expansion of the non-local HAL QCD potential at\nthe next-to-next-to-leading order (N$^2$LO). We find that (i) the leading order\npotential from the N$^2$LO analysis gives the scattering phase shifts\naccurately at low energies, (ii) the full N$^2$LO potential gives only small\ncorrection to the phase shifts even at higher energies below the inelastic\nthreshold, and (iii) the potential determined from the wall quark source at the\nleading order analysis agrees with the one at the N$^2$LO analysis except at\nshort distances, and thus, it gives correct phase shifts at low energies. We\nalso study the possible systematic uncertainties in the HAL QCD potential such\nas the inelastic state contaminations and the finite volume artifact for the\npotential and find that they are well under control for this particular system.\n\n\n###\n\n", "completion": " 07"}
{"prompt": "  In this paper, we present error-correcting codes which are the results of our\nresearch on the sub-exceeding functions. For a short and medium distance data\ntransmission (wifi network, bluetooth, cable, ...), we see that these codes\nmentioned above present many advantages compared with the Hamming code which is\na 1 correcting code.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  The Sobol' indices are a recognized tool in global sensitivity analysis. When\nthe uncertain variables in a model are statistically independent, the Sobol'\nindices may be easily interpreted and utilized. However, their interpretation\nand utility is more challenging with statistically dependent variables. This\narticle develops an approximation theoretic perspective to interpret Sobol'\nindices in the presence of variable dependencies. The value of this perspective\nis demonstrated in the context of dimension reduction, a common application of\nthe Sobol' indices. Theoretical analysis and illustrative examples are\nprovided.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Using a kinetic model for the ions and adiabatic electrons, we solve a steady\nstate, electron-repelling magnetic presheath in which a uniform magnetic field\nmakes a small angle $\\alpha \\ll 1$ (in radians) with the wall. The presheath\ncharacteristic thickness is the typical ion gyroradius $\\rho_{\\text{i}}$. The\nDebye length $\\lambda_{\\text{D}}$ and the collisional mean free path of an ion\n$\\lambda_{\\text{mfp}}$ satisfy the ordering $\\lambda_{\\text{D}} \\ll\n\\rho_{\\text{i}} \\ll \\alpha \\lambda_{\\text{mfp}}$, so a quasineutral and\ncollisionless model is used. We assume that the electrostatic potential is a\nfunction only of distance from the wall, and it varies over the scale\n$\\rho_{\\text{i}}$. Using the expansion in $\\alpha \\ll 1$, we derive an\nanalytical expression for the ion density that only depends on the ion\ndistribution function at the entrance of the magnetic presheath and the\nelectrostatic potential profile. Importantly, we have added the crucial\ncontribution of the orbits in the region near the wall. By imposing the\nquasineutrality equation, we derive a condition that the ion distribution\nfunction must satisfy at the magnetic presheath entrance --- the kinetic\nequivalent of the Chodura condition. Using an ion distribution function at the\nentrance of the magnetic presheath that satisfies the kinetic Chodura\ncondition, we find numerical solutions for the self-consistent electrostatic\npotential, ion density and flow across the magnetic presheath for several\nvalues of $\\alpha$. Our numerical results also include the distribution of ion\nvelocities at the Debye sheath entrance. We find that at small values of\n$\\alpha$ there are substantially fewer ions travelling with a large normal\ncomponent of the velocity into the wall.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  This paper describes a data reduction technique in case of a markov chain of\nspecified order. Instead of observing all the transitions in a markov chain we\nrecord only a few of them and treat the remaining part as missing. The decision\nabout which transitions to be filtered is taken before the observation process\nstarts. Based on the filtered chain we try to estimate the parameters of the\nmarkov model using EM algorithm. In the first half of the paper we characterize\na class of filtering mechanism for which all the parameters remain\nidentifiable. In the later half we explain methods of estimation and testing\nabout the transition probabilities of the markov chain based on the filtered\ndata. The methods are first developed assuming a simple markov model with each\nprobability of transition positive, but then generalized for models with\nstructural zeroes in the transition probability matrix. Further extension is\nalso done for multiple markov chains. The performance of the developed method\nof estimation is studied using simulated data along with a real life data.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  It has been proposed that topological insulators can be best characterized\nnot as surface conductors, but as bulk magnetoelectrics that -- under the right\nconditions-- have a universal quantized magnetoelectric response coefficient\n$e^2/2h$. However, it is not clear to what extent these conditions are\nachievable in real materials that can have disorder, finite chemical potential,\nresidual dissipation, and even inversion symmetry. This has led to some\nconfusion and misconceptions. The primary goal of this work is to illustrate\nexactly under what real life scenarios and in what context topological\ninsulators can be described as magnetoelectrics. We explore analogies of the 3D\nmagnetoelectric response to electric polarization in 1D in detail, the formal\nvs. effective polarization and magnetoelectric susceptibility, the 1/2\nquantized surface quantum Hall effect, the multivalued nature of the\nmagnetoelectric susceptibility, the role of inversion symmetry, the effects of\ndissipation, and the necessity for finite frequency measurements. We present\nthese issues from the perspective of experimentalists who have struggled to\ntake the beautiful theoretical ideas and to try to measure their (sometimes\nsubtle) physical consequences in messy real material systems.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Medical research suggests that the anterior-posterior (AP)-diameter of the\ninferior vena cava (IVC) and its associated temporal variation as imaged by\nbedside ultrasound is useful in guiding fluid resuscitation of the\ncritically-ill patient. Unfortunately, indistinct edges and gaps in vessel\nwalls are frequently present which impede accurate estimation of the IVC\nAP-diameter for both human operators and segmentation algorithms. The majority\nof research involving use of the IVC to guide fluid resuscitation involves\nmanual measurement of the maximum and minimum AP-diameter as it varies over\ntime. This effort proposes using a time-varying circle fitted inside the\ntypically ellipsoid IVC as an efficient, consistent and novel approach to\ntracking and approximating the AP-diameter even in the context of poor image\nquality. In this active-circle algorithm, a novel evolution functional is\nproposed and shown to be a useful tool for ultrasound image processing. The\nproposed algorithm is compared with an expert manual measurement, and\nstate-of-the-art relevant algorithms. It is shown that the algorithm\noutperforms other techniques and performs very close to manual measurement.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  The Hipparcos catalog contains stars suspected to be {\\delta} Scuti variables\nfor which extensive ground-based observations and characterization of\nvariability are necessary. Our aim was to characterize variability of 13\ncandidates to {\\delta} Scuti type stars. We obtained 24 215 CCD images and\nanalyzed stellar light curves using the Period04 program. Twelve {\\delta} Scuti\ncandidate stars have been characterized as pulsating with frequencies intrinsic\nto {\\delta} Scuti stars: HIP 2923, HIP 5526, HIP 5659, HIP 11090, HIP 17585,\nHIP 74155, HIP 101473, HIP 106219, HIP 107786, HIP 113487, HIP 115093, HIP\n115856. Five of them (HIP 2923, HIP 5526, HIP 11090, HIP 115856 and HIP 106219)\nmay be hybrid {\\delta} Scuti-{\\gamma} Doradus pulsators. One more candidate,\nHIP 106223, is a variable star with longer periods of pulsations which are\nintrinsic to {\\gamma} Doradus.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We discuss herein the emergence of a large entropy change in metallic\nLi0.33VS2 derived from the orbitally assisted loose {\\sigma} bond formation.\nComprehensive structural studies based on synchrotron x-ray and neutron\ndiffraction analyses clarify the fabrication of ribbon chains at 375 K,\nconsisting of multiple three-centered two-electron {\\sigma} bonds based on the\nviewpoint of local chemical bonding. Although the metallic conductivity\npersists down to the lowest temperature measured, exceptionally large entropy\nchange as a metal, as much as {\\Delta}S = 6.6 J/mol K, appears at the\ntransition. Emergence of a large entropy change in a metallic state expects us\nthe possible novel functional materials, such as a heat-storage material with\nrapid thermal response.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  In these mini-proceedings we review the results of the workshop `Impact of\n$B\\to\\mu^+\\mu^-$ on New Physics Searches' that took place at the Paul Scherrer\nInstitute (PSI) on the 18th-19th December 2017.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  With the development of feature extraction technique, one sample always can\nbe represented by multiple features which locate in high-dimensional space.\nMultiple features can re ect various perspectives of one same sample, so there\nmust be compatible and complementary information among the multiple views.\nTherefore, it's natural to integrate multiple features together to obtain\nbetter performance. However, most multi-view dimension reduction methods cannot\nhandle multiple features from nonlinear space with high dimensions. To address\nthis problem, we propose a novel multi-view dimension reduction method named\nMulti-view Reconstructive Preserving Embedding (MRPE) in this paper. MRPE\nreconstructs each sample by utilizing its k nearest neighbors. The similarities\nbetween each sample and its neighbors are primely mapped into lower-dimensional\nspace in order to preserve the underlying neighborhood structure of the\noriginal manifold. MRPE fully exploits correlations between each sample and its\nneighbors from multiple views by linear reconstruction. Furthermore, MRPE\nconstructs an optimization problem and derives an iterative procedure to obtain\nthe low-dimensional embedding. Various evaluations based on the applications of\ndocument classification, face recognition and image retrieval demonstrate the\neffectiveness of our proposed approach on multi-view dimension reduction.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Solar Energetic Particles (SEPs) are an important aspect of space weather.\nSEP events posses a high destructive potential, since they may cause\ndisruptions of communication systems on Earth and be fatal to crew members\nonboard spacecrafts and, in extreme cases, harmful to people onboard high\naltitude flights. However, currently the research community lacks efficient\ntools to predict such hazardous threat and its potential impacts. Such a tool\nis a first step for mankind to improve its preparedness for SEP events and\nultimately to be able to mitigate their effects. The main goal of the presented\nresearch effort is to develop a computational tool that will have the\nforecasting capability and can be serve in operational system that will provide\nlive information on the current potential threats posed by SEP based on the\nobservations of the Sun. In the present paper the fundamentals of\nmagneto-hydrodynamical (MHD) simulations are discussed to be employed as a\ncritical part of the desired forecasting system.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In this paper, a new spectrum sharing model referred to as riding on the\nprimary (ROP) is proposed for wireless-powered IoT devices with ambient\nbackscatter communication capabilities. The key idea of ROP is that the\nsecondary transmitter harvests energy from the primary signal, then modulates\nits information bits to the primary signal, and reflects the modulated signal\nto the secondary receiver without violating the primary system's interference\nrequirement. Compared with the conventional spectrum sharing model, the\nsecondary system in the proposed ROP not only utilizes the spectrum of the\nprimary system but also takes advantage of the primary signal to harvest energy\nand to carry its information. In this paper, we investigate the performance of\nsuch a spectrum sharing system under fading channels. To be specific, we\nmaximize the ergodic capacity of the secondary system by jointly optimizing the\ntransmit power of the primary signal and the reflection coefficient of the\nsecondary ambient backscatter. Different (ideal/practical) energy consumption\nmodels, different (peak/average) transmit power constraints, different types\n(fixed/dynamically adjustable) reflection coefficient, different primary\nsystem's interference requirements (rate/outage) are considered. Optimal power\nallocation and reflection coefficient are obtained for each scenario.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  The absence of large-angle correlations in the map of cosmic microwave\nbackground temperature fluctuations is among the well-established anomalies\nidentified in full-sky and cut-sky maps over the past three decades. Suppressed\nlarge-angle correlations are rare statistical flukes in standard inflationary\ncosmological models. One natural explanation could be that the underlying\nprimordial density perturbations lack correlations on large distance scales. To\ntest this idea, we replace Fourier modes by a wavelet basis with compact\nspatial support. While the angular correlation function of perturbations can\nreadily be suppressed, the observed monopole and dipole-subtracted correlation\nfunction is not generally suppressed. This suggests that suppression of\nlarge-angle temperature correlations requires a mechanism that has both\nreal-space and harmonic-space effects.\n\n\n###\n\n", "completion": " 04"}
{"prompt": "  We present an open access grid of 3930 calculations of externally evaporating\nprotoplanetary discs. This spans a range of disc sizes (1-400AU), disc masses,\nUV field strengths (10-10$^4$G$_0$) and stellar masses (0.05-1.9M$_\\odot$). The\ngrid is publicly available for download, and offers a means of cheaply\nincluding external photoevaporation in disc evolutionary calculations. It can\nalso be queried using an online tool for quick estimates of instantaneous mass\nloss rates (e.g for convenient evaluation of real observed systems). The\n`FRIED' grid itself illustrates that for discs around stars $\\leq0.3$M$_\\odot$\nexternal photoevaporation is effective down to small radii ($<50$AU) down to UV\nfields at least as weak as 10G$_0$. At the other end of the scale, in a\n$10^4$G$_0$ environment photoevaporation is effective down to 1AU even for\nstellar masses at least as high as 1.9M$_\\odot$. We also illustrate in which\nregimes CO survives in the photoevaporative outflow for significant mass loss\nrates; marking a system a good candidate to detect external photoevaporation in\nweak-intermediate UV environments through sub-Keplerian rotation. Finally we\nmake illustrative mass loss rate estimates for discs in Taurus based on the\nGuilloteau et al. (2011) star-disc parameters, finding that around half are\nexpected to have both significant mass loss and retain CO in the\nphotoevaporative outflow.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  We report a systematic study of thickness-dependent superconductivity and\ncarrier transport properties in exfoliated layered 2H-NbS2. Hall-effect\nmeasurements reveal 2H-NbS2 in its normal state to be a p-type metal with hole\nmobility of 1-3 cm2/Vs. The superconducting transition temperature is found to\ndecrease with thickness. We find that the suppression of superconductivity is\ndue to disorder resulting from the incorporation of atmospheric oxygen and a\nreduced hole density. Cross-section transmission electron microscope (TEM)\nimaging reveals a chemical change of NbS2 in ambient conditions, resulting in\nthe formation of amorphous oxide layers sandwiching crystalline layered NbS2.\nThough few-nm-thick 2H-NbS2 completely converts to amorphous oxide in ambient\nconditions, PMMA encapsulation prevents further chemical change and preserves\nsuperconductivity.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We study the homotopy category $\\mathrm{hef}(R,W)$ (and its\n$\\mathbb{Z}_2$-graded version $\\mathrm{HEF}(R,W)$) of elementary\nfactorizations, where $R$ is a B\\'ezout domain which has prime elements and\n$W=W_0 W_c$, where $W_0\\in R^\\times$ is a square-free element of $R$ and\n$W_c\\in R^\\times$ is a finite product of primes with order at least two. In\nthis situation, we give criteria for detecting isomorphisms in\n$\\mathrm{hef}(R,W)$ and $\\mathrm{HEF}(R,W)$ and formulas for the number of\nisomorphism classes of objects. We also study the full subcategory\n$\\mathbf{hef}(R,W)$ of the homotopy category $\\mathrm{hmf}(R,W)$ of finite rank\nmatrix factorizations of $W$ which is additively generated by elementary\nfactorizations. We show that $\\mathbf{hef}(R,W)$ is Krull-Schmidt and we\nconjecture that it coincides with $\\mathrm{hmf}(R,W)$. Finally, we discuss a\nfew classes of examples.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Time-evolving stream datasets exist ubiquitously in many real-world\napplications where their inherent hot keys often evolve over times.\nNevertheless, few existing solutions can provide efficient load balance on\nthese time-evolving datasets while preserving low memory overhead. In this\npaper, we present a novel grouping approach (named FISH), which can provide the\nefficient time-evolving stream processing at scale. The key insight of this\nwork is that the keys of time-evolving stream data can have a skewed\ndistribution within any bounded distance of time interval. This enables to\naccurately identify the recent hot keys for the real-time load balance within a\nbounded scope. We therefore propose an epoch-based recent hot key\nidentification with specialized intra-epoch frequency counting (for maintaining\nlow memory overhead) and inter-epoch hotness decaying (for suppressing\nsuperfluous computation). We also propose to heuristically infer the accurate\ninformation of remote workers through computation rather than communication for\ncost-efficient worker assignment. We have integrated our approach into Apache\nStorm. Our results on a cluster of 128 nodes for both synthetic and real-world\nstream datasets show that FISH significantly outperforms state-of-the-art with\nthe average and the 99th percentile latency reduction by 87.12% and 76.34% (vs.\nW-Choices), and memory overhead reduction by 99.96% (vs. Shuffle Grouping).\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Learning to follow human instructions is a long-pursued goal in artificial\nintelligence. The task becomes particularly challenging if no prior knowledge\nof the employed language is assumed while relying only on a handful of examples\nto learn from. Work in the past has relied on hand-coded components or manually\nengineered features to provide strong inductive biases that make learning in\nsuch situations possible. In contrast, here we seek to establish whether this\nknowledge can be acquired automatically by a neural network system through a\ntwo phase training procedure: A (slow) offline learning stage where the network\nlearns about the general structure of the task and a (fast) online adaptation\nphase where the network learns the language of a new given speaker. Controlled\nexperiments show that when the network is exposed to familiar instructions but\ncontaining novel words, the model adapts very efficiently to the new\nvocabulary. Moreover, even for human speakers whose language usage can depart\nsignificantly from our artificial training language, our network can still make\nuse of its automatically acquired inductive bias to learn to follow\ninstructions more effectively.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We study by Monte Carlo methods the thermodynamics of a spin polarized gas of\nnon-relativistic fermions in 1+1 dimensions. The main result of this work is\nthat our action suffers no significant sign problem for any spin polarization\nin the region relevant for dilute degenerate fermi gases. This lack of sign\nproblem allows us to study attractive spin polarized fermions\nnon-perturbatively at spin polarizations not previously explored. For some\nparameters values we verify results previously obtained by methods which\ninclude an uncontrolled step like complex Langevin and/or analytical\ncontinuation from imaginary chemical potential. For others, larger values of\nthe polarization, we deviate from these previous results.\n\n\n###\n\n", "completion": " 02"}
{"prompt": "  This work presents a depleted monolithic active pixel sensor (DMAPS)\nprototype manufactured in the LFoundry 150\\,nm CMOS process. DMAPS exploit high\nvoltage and/or high resistivity inclusion of modern CMOS technologies to\nachieve substantial depletion in the sensing volume. The described device,\nnamed LF-Monopix, was designed as a proof of concept of a fully monolithic\nsensor capable of operating in the environment of outer layers of the ATLAS\nInner Tracker upgrade in 2025 for the High Luminosity Large Hadron Collider\n(HL-LHC). This type of devices has a lower production cost and lower material\nbudget compared to presently used hybrid designs. In this work, the chip\narchitecture will be described followed by the characterization of the\ndifferent pre-amplifier and discriminator flavors with an external injection\nsignal and an iron source (5.9\\,keV x-rays).\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Several diseases of parkinsonian syndromes present similar symptoms at early\nstage and no objective widely used diagnostic methods have been approved until\nnow. Positron emission tomography (PET) with $^{18}$F-FDG was shown to be able\nto assess early neuronal dysfunction of synucleinopathies and tauopathies.\nTensor factorization (TF) based approaches have been applied to identify\ncharacteristic metabolic patterns for differential diagnosis. However, these\nconventional dimension-reduction strategies assume linear or multi-linear\nrelationships inside data, and are therefore insufficient to distinguish\nnonlinear metabolic differences between various parkinsonian syndromes. In this\npaper, we propose a Deep Projection Neural Network (DPNN) to identify\ncharacteristic metabolic pattern for early differential diagnosis of\nparkinsonian syndromes. We draw our inspiration from the existing TF methods.\nThe network consists of a (i) compression part: which uses a deep network to\nlearn optimal 2D projections of 3D scans, and a (ii) classification part: which\nmaps the 2D projections to labels. The compression part can be pre-trained\nusing surplus unlabelled datasets. Also, as the classification part operates on\nthese 2D projections, it can be trained end-to-end effectively with limited\nlabelled data, in contrast to 3D approaches. We show that DPNN is more\neffective in comparison to existing state-of-the-art and plausible baselines.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  We investigated the elongational flows of the weakly entangled linear polymer\nmelt using a coarse-grained molecular dynamics simulation. We extended the\nuniform extensional flow (UEF) method developed by Nicholson and Rutledge (D.\nA. Nicholson and G. C. Rutledge, J. Chem. Phys., 145, 244903 (2016)) for\napplication to Langevin dynamics. We succeeded in observing the elongational\nviscosity of the weakly entangled linear polymer melt from the equilibrium\nstate to the steady state using the extended UEF method, whereas the\nconventional rectangular parallelepiped shape technique for extensional flows\nhas failed to do so for over 20 years.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Although reinforcement learning methods can achieve impressive results in\nsimulation, the real world presents two major challenges: generating samples is\nexceedingly expensive, and unexpected perturbations or unseen situations cause\nproficient but specialized policies to fail at test time. Given that it is\nimpractical to train separate policies to accommodate all situations the agent\nmay see in the real world, this work proposes to learn how to quickly and\neffectively adapt online to new tasks. To enable sample-efficient learning, we\nconsider learning online adaptation in the context of model-based reinforcement\nlearning. Our approach uses meta-learning to train a dynamics model prior such\nthat, when combined with recent data, this prior can be rapidly adapted to the\nlocal context. Our experiments demonstrate online adaptation for continuous\ncontrol tasks on both simulated and real-world agents. We first show simulated\nagents adapting their behavior online to novel terrains, crippled body parts,\nand highly-dynamic environments. We also illustrate the importance of\nincorporating online adaptation into autonomous agents that operate in the real\nworld by applying our method to a real dynamic legged millirobot. We\ndemonstrate the agent's learned ability to quickly adapt online to a missing\nleg, adjust to novel terrains and slopes, account for miscalibration or errors\nin pose estimation, and compensate for pulling payloads.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Selected configuration interaction (sCI) methods including second-order\nperturbative corrections provide near full CI (FCI) quality energies with only\na small fraction of the determinants of the FCI space. Here, we introduce both\na state-specific and a multi-state sCI method based on the CIPSI (Configuration\nInteraction using a Perturbative Selection made Iteratively) algorithm. The\npresent method revises the reference (internal) space under the effect of its\ninteraction with the outer space via the construction of an effective\nHamiltonian, following the shifted-Bk philosophy of Davidson and coworkers. In\nparticular, the multi-state algorithm removes the storage bottleneck of the\neffective Hamiltonian via a low-rank factorization of the dressing matrix.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Large-scale quantum technologies require exquisite control over many\nindividual quantum systems. Typically, such systems are very sensitive to\nenvironmental fluctuations, and diagnosing errors via measurements causes\nunavoidable perturbations. In this work we present an in situ frequency locking\ntechnique that monitors and corrects frequency variations in single photon\nsources based on microring resonators. By using the same classical laser fields\nrequired for photon generation as a probe to diagnose variations in the\nresonator frequency, our protocol applies feedback control to correct photon\nfrequency errors in parallel to the optical quantum computation without\ndisturbing the physical qubit. We implement our technique on a silicon photonic\ndevice and demonstrate sub 1 pm frequency stabilization in the presence of\napplied environmental noise, corresponding to a fractional frequency drift of\n<1 % of a photon linewidth. Using these methods we demonstrate feedback\ncontrolled quantum state engineering. By distributing a single local oscillator\nacross a single chip or network of chips, our approach enables frequency\nlocking of many single photon sources for large-scale photonic quantum\ntechnologies.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Adam is shown not being able to converge to the optimal solution in certain\ncases. Researchers recently propose several algorithms to avoid the issue of\nnon-convergence of Adam, but their efficiency turns out to be unsatisfactory in\npractice. In this paper, we provide new insight into the non-convergence issue\nof Adam as well as other adaptive learning rate methods. We argue that there\nexists an inappropriate correlation between gradient $g_t$ and the\nsecond-moment term $v_t$ in Adam ($t$ is the timestep), which results in that a\nlarge gradient is likely to have small step size while a small gradient may\nhave a large step size. We demonstrate that such biased step sizes are the\nfundamental cause of non-convergence of Adam, and we further prove that\ndecorrelating $v_t$ and $g_t$ will lead to unbiased step size for each\ngradient, thus solving the non-convergence problem of Adam. Finally, we propose\nAdaShift, a novel adaptive learning rate method that decorrelates $v_t$ and\n$g_t$ by temporal shifting, i.e., using temporally shifted gradient $g_{t-n}$\nto calculate $v_t$. The experiment results demonstrate that AdaShift is able to\naddress the non-convergence issue of Adam, while still maintaining a\ncompetitive performance with Adam in terms of both training speed and\ngeneralization.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We derive and study the effective spin model that explains the anomalous spin\ndynamics in the one-dimensional Hubbard model with strong potential disorder.\nAssuming that charges are localized, we show that spins are delocalized and\ntheir subdiffusive transport originates from a singular random distribution of\nspin exchange interactions. The exponent relevant for the subdiffusion is\ndetermined by the Anderson localization length and the density of electrons.\nWhile the analytical derivations are valid for low particle density, numerical\nresults for the full model reveal a qualitative agreement up to half-filling.\n\n\n###\n\n", "completion": " 04"}
{"prompt": "  We study diffusion on a multilayer network where the contact dynamics between\nthe nodes is governed by a random process and where the waiting time\ndistribution differs for edges from different layers. We study the impact on a\nrandom walk of the competition that naturally emerges between the edges of the\ndifferent layers. In opposition to previous studies which have imposed a priori\ninter-layer competition, the competition is here induced by the heterogeneity\nof the activity on the different layers. We first study the precedence relation\nbetween different edges and by extension between different layers, and show\nthat it determines biased paths for the walker. We also discuss the emergence\nof cyclic, rock-paper-scissors random walks, when the precedence between layers\nis non-transitive. Finally, we numerically show the slowing-down effect due to\nthe competition on a heterogeneous multilayer as the walker is likely to be\ntrapped for a longer time either on a single layer, or on an oriented cycle .\n  Keywords: random walks; multilayer networks; dynamical systems on networks;\nmodels of networks; simulations of networks; competition between layers.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We experimentally investigate a strongly driven GaAs double quantum dot\ncharge qubit weakly coupled to a superconducting microwave resonator. The\nFloquet states emerging from strong driving are probed by tracing the qubit -\nresonator resonance condition. This way we probe the resonance of a qubit that\nis driven in an adiabatic, a non-adiabatic, or an intermediate rate showing\ndistinct quantum features of multi-photon processes and\nLandau-Zener-St\\\"uckelberg interference pattern. Our resonant detection scheme\nenables the investigation of novel features when the drive frequency is\ncomparable to the resonator frequency. Models based on adiabatic approximation,\nrotating wave approximation, and Floquet theory explain our experimental\nobservations.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  A fundamental challenge in neuroscience is to understand what structure in\nthe world is represented in spatially distributed patterns of neural activity\nfrom multiple single-trial measurements. This is often accomplished by learning\na simple, linear transformations between neural features and features of the\nsensory stimuli or motor task. While successful in some early sensory\nprocessing areas, linear mappings are unlikely to be ideal tools for\nelucidating nonlinear, hierarchical representations of higher-order brain areas\nduring complex tasks, such as the production of speech by humans. Here, we\napply deep networks to predict produced speech syllables from cortical surface\nelectric potentials recorded from human sensorimotor cortex. We found that deep\nnetworks had higher decoding prediction accuracy compared to baseline models,\nand also exhibited greater improvements in accuracy with increasing dataset\nsize. We further demonstrate that deep network's confusions revealed\nhierarchical latent structure in the neural data, which recapitulated the\nunderlying articulatory nature of speech motor control. Finally, we used deep\nnetworks to compare task-relevant information in different neural frequency\nbands, and found that the high-gamma band contains the vast majority of\ninformation relevant for the speech prediction task, with little-to-no\nadditional contribution from lower-frequencies. Together, these results\ndemonstrate the utility of deep networks as a data analysis tool for\nneuroscience.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Underwater optical wireless links have limited range and intermittent\nconnectivity due to the hostile aquatic channel impairments and misalignment\nbetween the optical transceivers. Therefore, multi-hop communication can expand\nthe communication range, enhance network connectivity, and provide a more\nprecise network localization scheme. In this regard, this paper investigates\nthe connectivity of underwater optical wireless sensor networks (UOWSNs) and\nits impacts on the network localization performance. Firstly, we model UOWSNs\nas randomly scaled sector graphs where the connection between sensors is\nestablished by point-to-point directed links. Thereafter, the probability of\nnetwork connectivity is analytically derived as a function of network density,\ncommunication range, and optical transmitters' divergence angle. Secondly, the\nnetwork localization problem is formulated as an unconstrained optimization\nproblem and solved using the conjugate gradient technique. Numerical results\nshow that different network parameters such as the number of nodes, divergence\nangle, and transmission range significantly influence the probability of a\nconnected network. Furthermore, the performance of the proposed localization\ntechnique is compared to well-known network localization schemes and the\nresults show that the localization accuracy of the proposed technique\noutperforms the literature in terms of network connectivity, ranging error, and\nnumber of anchors.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  In this paper by making use of the \"Complexity=Action\" proposal, we study the\ncomplexity growth after shock waves in holographic field theories. We consider\nboth double black hole-Vaidya and AdS-Vaidya with multiple shocks geometries.\nWe find that the Lloyd's bound is respected during the thermalization process\nin each of these geometries and at the late time, the complexity growth\nsaturates to the value which is proportional to the energy of the final state.\nWe conclude that the saturation value of complexity growth rate is independent\nof the initial temperature and in the case of thermal initial state, the rate\nof complexity is always less than the value for the vacuum initial state such\nthat considering multiple shocks it gets more smaller. Our results indicate\nthat by increasing the temperature of the initial state, the corresponding rate\nof complexity growth starts far from final saturation rate value.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  The Laplace equation in the two-dimensional Euclidean plane is considered in\nthe context of the inverse stereographic projection. The Lie algebra of the\nconformal group as the symmetry group of the Laplace equation can be\nrepresented solely in terms of the solutions and derivatives of the solutions\nof the Laplace equation. It is then possible to put contents from differential\ngeometry and quantum systems, like the Hopf bundle, relativistic spin,\nbicomplex numbers, and the Fock space into a common context. The basis elements\nof the complex numbers, considered as a Clifford paravector algebra, are\nreinterpreted as differential tangent vectors referring to dilations and\nrotations. In relation to this a homogeneous space is defined with the Lie\nalgebra of the conformal group, where dilations and rotations are the coset\nrepresentatives. Potential applications in physics are discussed.\n\n\n###\n\n", "completion": " 00"}
{"prompt": "  Let $f(x)$ be a nonconstant polynomial with integer coefficients and nonzero\ndiscriminant. We study the distribution modulo primes of the set of squarefree\nintegers $d$ such that the curve $dy^2=f(x)$ has a nontrivial rational or\nintegral point.\n\n\n###\n\n", "completion": " 06"}
{"prompt": "  Topological quantum computation employs two-dimensional quasiparticles called\nanyons. The generally accepted mathematical basis for the theory of anyons is\nthe framework of modular tensor categories. That framework involves a\nsubstantial amount of category theory and is, as a result, considered rather\ndifficult to understand. Is the complexity of the present framework necessary?\nThe computations of associativity and braiding matrices can be based on a much\nsimpler framework, which looks less like category theory and more like familiar\nalgebra. We introduce that framework here.\n\n\n###\n\n", "completion": " 01"}
{"prompt": "  In this paper we define an interesting family of perfect ideals of\ncodimension three, with five generators, of Cohen-Macaulay type two with\ntrivial multiplication on the Tor algebra. This family is likely to play a key\nrole in classifying perfect ideals with five generators of type two.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  In this paper, we apply different NMT models to the problem of historical\nspelling normalization for five languages: English, German, Hungarian,\nIcelandic, and Swedish. The NMT models are at different levels, have different\nattention mechanisms, and different neural network architectures. Our results\nshow that NMT models are much better than SMT models in terms of character\nerror rate. The vanilla RNNs are competitive to GRUs/LSTMs in historical\nspelling normalization. Transformer models perform better only when provided\nwith more training data. We also find that subword-level models with a small\nsubword vocabulary are better than character-level models for low-resource\nlanguages. In addition, we propose a hybrid method which further improves the\nperformance of historical spelling normalization.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  In the mentioned paper we presented results of the estimation of Kolmogorov\ncomplexity of sequences of random numbers generated in a famous Bell's\nexperiment, aimed to study the security of QKD. We focused on series of time\ndifferences between successive detections of coincidences, and found that\nrandomness cannot be taken for granted. It was then criticized that the\ntheorems that demonstrate the randomness of series produced in Bell's\nexperiments involve series of measurement outcomes, not of measurement times.\nHere we reply to this objection and present data of series of outcomes, showing\nthat the conclusions in the mentioned paper are valid also in this case.\n\n\n###\n\n", "completion": " 00"}
{"prompt": "  Models that accurately predict the output voltage ripple magnitude are\nessential for applications with stringent performance target for it. Impact of\ndc input ripple on the output ripple for a Series Resonant Converter (SRC)\nusing discrete domain exact discretization modelling method is analysed in this\npaper. A novel discrete state space model along with a small signal model for\nSRC considering 3 state variables is presented. The audiosusceptibility (AS)\ntransfer function which relates the input to output ripple is derived from the\nsmall signal model. Analysis of the AS transfer function indicates a resonance\npeak and an expression is derived connecting the AS resonance frequency for\ninput ripple with different SRC component values. Further analysis is done to\nshow that a set of values for SRC parameter exists, which forms a design\nregion, for which the normalized gain offered by the SRC for input ripple is\nless than unity at any input ripple frequency. A test setup to introduce the\nvariable frequency ripple at the input of SRC for the experimental evaluation\nof AS transfer function is also proposed. Influence of stray parameters on AS\ngain, AS resonance frequency and on SRC tank resonance frequency is addressed.\nAn SRC is designed at a power level of 10kW. The analysis using the derived\nmodel, simulations, and experimental results are found to be closely matching.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We consider the problem of maximizing the sum of a monotone submodular\nfunction and a linear function subject to a general solvable polytope\nconstraint. Recently, Sviridenko et al. (2017) described an algorithm for this\nproblem whose approximation guarantee is optimal in some intuitive and formal\nsenses. Unfortunately, this algorithm involves a guessing step which makes it\nless clean and significantly affects its time complexity. In this work we\ndescribe a clean alternative algorithm that uses a novel weighting technique in\norder to avoid the problematic guessing step while keeping the same\napproximation guarantee as the algorithm of Sviridenko et al.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  If the extremely low surface brightness galaxy Coma P lies at $5.5\\pm0.3$ Mpc\nas recently proposed then it would have an extraordinarily deviant peculiar\nvelocity of $\\sim900$ km $\\mathrm{s^{-1}}$ at a location where differential\nvelocities between galaxies are low. We have accessed the images from the HST\narchives used to derive the literature distance from the magnitude of the tip\nof the red giant branch. Our analysis gives the distance to be $10.9\\pm1.0$\nMpc. At this location the galaxy lies within the infall region of the Virgo\nCluster, such that its still considerable peculiar velocity of $\\sim500$ km\n$\\mathrm{s^{-1}}$ is consistent with an established model. Coma P has an\nunusually pronounced asymptotic giant branch relative to its red giant branch.\nThe dominant stellar population is just a few Gyr old.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  The presence of massive neutrinos affects structure formation, leaving\nimprints on large-scale structure observables such as the weak lensing field.\nThe common lensing analyses with two-point statistics are insensitive to the\nlarge amount of non-Gaussian information in the density field. We investigate\nnon-Gaussian tools, in particular the Minkowski Functionals\n(MFs)---morphological descriptors including area, perimeter, and genus---in an\nattempt to recover the higher-order information. We use convergence maps from\nthe Cosmological Massive Neutrino Simulations (\\texttt{MassiveNus}) and assume\ngalaxy noise, density, and redshift distribution for an LSST-like survey. We\nshow that MFs are sensitive to the neutrino mass sum, and the sensitivity is\nredshift dependent and is non-Gaussian. We find that redshift tomography\nsignificantly improves the constraints on neutrino mass for MFs, compared to\nthe improvements for the power spectrum. We attribute this to the stronger\nredshift dependence of neutrino effects on small scales. We then build an\nemulator to model the power spectrum and MFs, and study the constraints on\n$[M_{\\nu}$, $\\Omega_{m}$, $A_{s}]$ from the power spectrum, MFs, and their\ncombination. We show that MFs significantly outperform the power spectrum in\nconstraining neutrino mass, by more than a factor of four. However, a thorough\nstudy of the impact from systematics such as baryon physics and galaxy shape\nand redshift biases will be important to realize the full potential of MFs.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In arXiv:1807.09038 we formulated a conjecture describing the derived\ncategory D-mod(Gr$_{GL(n)}$) of (all) D-modules on the affine Grassmannian of\nthe group $GL(n)$ as the category of quasi-coherent sheaves on a certain stack\n(it is explained in loc. cit. that this conjecture \"follows\" naturally from\nsome heuristic arguments involving 3-dimensional quantum field theory). In this\npaper we prove a weaker version of this conjecture for the case $n=2$.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Within the context of an extended Nambu - Jona-Lasinio model, we analyze the\nrole of the axial-vector $a_1(1260)$ and $a_1(1640)$ mesons in the decay\n$\\tau\\to\\nu_\\tau \\rho^0\\pi^-$. The contributions of pseudoscalar $\\pi$ and $\\pi\n(1300)$ states are also considered. The form factors for the decay amplitude\nare determined in terms of the masses and widths of these states. To describe\nthe radial excited states $\\pi (1300)$ and $a_1(1640)$ we introduce two\nadditional parameters which can be estimated theoretically, or fixed from\nexperiment. The decay rate and $\\rho\\pi$ mass spectrum are calculated.\n\n\n###\n\n", "completion": " 98"}
{"prompt": "  Despite decades of efforts, achieving $p$-type conductivity in the wide band\ngap ZnO in its ground-state wurtzite structure continues to be a challenge.\nHere we detail how $p$-type ZnO can be realized in the metastable,\nhigh-pressure rocksalt phase (also wide-gap) with Li as an external dopant.\nUsing modern first-principles defect theory, we predict Li to dope the rocksalt\nphase $p$-type by preferentially substituting for Zn and introducing shallow\nacceptor levels. Formation of compensating donors like interstitial Li and/or\nhydrogen, ubiqutous in the wurtzite phase, is inhibited by the close-packed\nnature of the rocksalt structure, which also exhibits relatively high absolute\nvalence band edge that promotes low hole effective mass and hole\ndelocalization. Resulting concentrations of free holes are predicted to exceed\n$\\sim10^{19}$ cm$^{-3}$ under O-rich synthesis conditions while under O-poor\nconditions the system remains $n$-type dopable. In addition to revealing\ncompelling opportunities offered by the metastable rocksalt structure in\nrealizing a long-sought $p$-type ZnO our results present polymorphism as a\npromising route to overcoming strong doping asymmetry of wide-band gap oxides.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Standard evaluations of deep learning models for semantics using naturalistic\ncorpora are limited in what they can tell us about the fidelity of the learned\nrepresentations, because the corpora rarely come with good measures of semantic\ncomplexity. To overcome this limitation, we present a method for generating\ndata sets of multiply-quantified natural language inference (NLI) examples in\nwhich semantic complexity can be precisely characterized, and we use this\nmethod to show that a variety of common architectures for NLI inevitably fail\nto encode crucial information; only a model with forced lexical alignments\navoids this damaging information loss.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Collecting flow records is a common practice of network operators and\nresearchers for monitoring, diagnosing and understanding a network. Traditional\ntools like NetFlow face great challenges when both the speed and the complexity\nof the network traffic increase. To keep pace up, we propose HashFlow, a tool\nfor more efficient and accurate collection and analysis of flow records. The\ncentral idea of HashFlow is to maintain accurate records for elephant flows,\nbut summarized records for mice flows, by applying a novel collision resolution\nand record promotion strategy to hash tables. The performance bound can be\nanalyzed with a probabilistic model, and with this strategy, HashFlow achieves\na better utilization of space, and also more accurate flow records, without\nbringing extra complexity. We have implemented HashFlow, as well as several\nlatest flow measurement algorithms such as FlowRadar, HashPipe and\nElasticSketch, in a P4 software switch. Then we use traces from different\noperational networks to evaluate them. In these experiments, for various types\nof traffic analysis applications, HashFlow consistently demonstrates a clearly\nbetter performance against its state-of-the-art competitors. For example, using\na small memory of 1 MB, HashFlow can accurately record around 55K flows, which\nis often 12.5% higher than the others. For estimating the sizes of 50K flows,\nHashFlow achieves a relative error of around 11.6%, while the estimation error\nof the best competitor is 42.9% higher. It detects 96.1% of the heavy hitters\nout of 250K flows with a size estimation error of 5.6%, which is 11.3% and\n73.7% better than the best competitor respectively. At last, we show these\nmerits of HashFlow come with almost no degradation of throughput.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  The aim of this note is to point out an interesting fact related to the\nelliptic genus of complex algebraic surfaces in the context of Mathieu\nmoonshine. We also discuss the case of 4-folds.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  Neutrinos emitted from a supernova may undergo flavor conversions almost\nimmediately above the core, with possible consequences for supernova dynamics\nand nucleosynthesis. However, the precise conditions for such fast conversions\ncan be difficult to compute and require knowledge of the full angular\ndistribution of the flavor-dependent neutrino fluxes, that is not available in\ntypical supernova simulations. In this paper, we show that the overall flavor\nevolution is qualitatively similar to the growth of a so-called `zero mode',\ndetermined by the background matter and neutrino densities, which can be\nreliably predicted using only the second angular moments of the electron lepton\nnumber distribution, i.e., the difference in the angular distributions of\n$\\nu_e$ and $\\bar{\\nu}_e$ fluxes. We propose that this zero mode, which neither\nrequires computing the full Green's function nor a detailed knowledge of the\nangular distributions, may be useful for a preliminary diagnosis of possible\nfast flavor conversions in supernova simulations with modestly resolved angular\ndistributions\n\n\n###\n\n", "completion": " 99"}
{"prompt": "  Nonclassicality of temporal correlations pertaining to noncommutative\nsequential measurements is defined through the violation of macrorealistic\ninequalities, known as Leggett-Garg inequalities (LGI). We investigate the\nenergy cost of the process associated with the Leggett-Garg test in the context\nof noiseless and Markovian noise for arbitrary initial states. We prove that in\nnoiseless and in certain noisy scenarios, the maximal violations of LGI under\nthe energy constraint occurs when the average energy of the process is equal to\nthe negative of the energy of the initial state. Such a dependence of LGI on\nthe choice of the initial state is not seen in the unconstrained case.\nMoreover, we find that in the presence of a moderate amount of Markovian noise,\nthe amount of violation of LGI remains almost unaltered with a suitable choice\nof the evolution and dephasing operators in the neighborhood of the maximal\nviolation line, thereby showing the robustness of temporal correlations under\nenvironmental effects.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We study heat transfer mediated by near-field fluctuations of the\nelectromagnetic field. In case of metals the latter are dominated by Coulomb\ninteractions between thermal fluctuations of electronic density. We show that\nan elastic scattering of electrons, leading to diffusive propagation of density\nfluctuations, results in a qualitative change of the radiation law. While the\nheat flux between clean metals follows the Stefan-Boltzmann-like $T^4$\ndependence, the heat exchange between disordered conductors is significantly\nenhanced and scales as $T^3$ at low temperatures.\n\n\n###\n\n", "completion": " 06"}
{"prompt": "  We introduce forest straight-line programs (FSLPs) as a compressed\nrepresentation of unranked ordered node-labelled trees. FSLPs are based on the\noperations of forest algebra and generalize tree straight-line programs. We\ncompare the succinctness of FSLPs with two other compression schemes for\nunranked trees: top dags and tree straight-line programs of first-child/next\nsibling encodings. Efficient translations between these formalisms are\nprovided. Finally, we show that equality of unranked trees in the setting where\ncertain symbols are associative or commutative can be tested in polynomial\ntime. This generalizes previous results for testing isomorphism of compressed\nunordered ranked trees.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  It has been recently suggested that oscillons produced in the early universe\nfrom certain asymmetric potentials continue to emit gravitational waves for a\nnumber of $e$-folds of expansion after their formation, leading to potentially\ndetectable gravitational wave signals. We revisit this claim by conducting a\nconvergence study using graphics processing unit (GPU)-accelerated lattice\nsimulations and show that numerical errors accumulated with time are\nsignificant in low-resolution scenarios, or in scenarios where the run-time\ncauses the resolution to drop below the relevant scales in the problem. Our\nstudy determines that the dominant, growing high frequency peak of the\ngravitational wave signals in the fiducial \"hill-top model\" in\n[arXiv:1607.01314] is a numerical artifact. This finding prompts the need for a\nmore careful analysis of the numerical validity of other similar results\nrelated to gravitational waves from oscillon dynamics.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  In this second paper of the series we specify general theory developed in the\nfirst paper. Here we study the structure of Jacobi fields in the case of an\nanalytic system and piece-wise analytic control. Moreover, we consider only\n1-dimensional control variations. Jacobi fields are piece-wise analytic in this\ncase but may have much more singularities than the control. We derive ODEs that\nthese fields satisfy on the intervals of regularity and study behavior of the\nfields in a neighborhood of a singularity where the ODE becomes singular and\nthe Jacobi fields may have jumps.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  The evolution of surface gravity waves is driven by nonlinear interactions\nthat trigger an energy cascade similarly to the one observed in hydrodynamic\nturbulence. This process, known as wave turbulence, has been found to display\nanomalous scaling with deviation from classical turbulent predictions due to\nthe emergence of coherent and intermittent structures on the water surface. In\nrealistic oceanic sea states, waves are spread over a wide range of directions,\nwith a consequent attenuation of the nonlinear properties. A laboratory\nexperiment in a large wave facility is presented to discuss the effect of wave\ndirectionality on wave turbulence. Results show that the occurrence of coherent\nand intermitted structures become less likely with the broadening of the wave\ndirectional spreading. There is no evidence, however, that intermittency\ncompletely vanishes.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  Unconventional superconductivity typically emerges in the presence of\nquasi-degenerate ground states, and the associated intense fluctuations are\nlikely responsible for generating the superconducting state. Here we use\npolarized neutron scattering to study the spin space anisotropy of spin\nexcitations in Fe$_{1.07}$Te exhibiting bicollinear antiferromagnetic (AF)\norder, the parent compound of FeTe$_{1-x}$Se$_x$ superconductors. We confirm\nthat the low energy spin excitations are transverse spin waves, consistent with\na local-moment origin of the bicollinear AF order. While the ordered moments\nlie in the $ab$-plane in Fe$_{1.07}$Te, it takes less energy for them to\nfluctuate out-of-plane, similar to BaFe$_2$As$_2$ and NaFeAs. At energies above\n$E\\gtrsim20$ meV, we find magnetic scattering to be dominated by an isotropic\ncontinuum that persists up to at least 50 meV. Although the isotropic spin\nexcitations cannot be ascribed to spin waves from a long-range ordered local\nmoment antiferromagnet, the continuum can result from the bicollinear magnetic\norder ground state of Fe$_{1.07}$Te being quasi-degenerate with plaquette\nmagnetic order.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Several theoretical motivations point to ultralight QCD axions with large\ndecay constants $f_a \\simeq \\mathcal{O}(10^{16}-10^{17})$ GeV, to which\nexperimental proposals are dedicated. This regime is known to face the problem\nof overproduction of axion dark matter from the misalignment mechanism unless\nthe misalignment angle $\\theta_{\\rm mis}$ is as small as\n$\\mathcal{O}(10^{-3}-10^{-4})$, which is generally considered a fine-tuning\nproblem. We investigate a dynamical explanation for a small $\\theta_{\\rm mis}$.\nThe axion mass arises from strong dynamics and may be sufficiently enhanced by\nearly dynamics so as to overcome Hubble friction and drive the field value to\nthe bottom of the potential long before the QCD phase transition. Together with\nan approximate CP symmetry in the theory, this minimum is very closely related\nto today's value and thus $\\theta_{\\rm mis}$ can automatically be well under\nunity. Owing to such efficient relaxation, the isocurvature perturbations are\nessentially damped. As an existence proof, using supersymmetric theories we\nillustrate that the Higgs coupling with the inflaton energy can successfully\nachieve this axion damping in a consistent inflationary cosmology.\n\n\n###\n\n", "completion": " 98"}
{"prompt": "  The tabu and restart are two fundamental strategies for local search. In this\npaper, we improve the local search algorithms for solving the Maximum Weight\nClique (MWC) problem by introducing new tabu and restart strategies. Both the\ntabu and restart strategies proposed are based on the notion of a local search\nscenario, which involves not only a candidate solution but also the tabu status\nand unlocking relationship. Compared to the strategy of configuration checking,\nour tabu mechanism discourages forming a cycle of unlocking operations. Our new\nrestart strategy is based on the re-occurrence of a local search scenario\ninstead of that of a candidate solution. Experimental results show that the\nresulting MWC solver outperforms several state-of-the-art solvers on the\nDIMACS, BHOSLIB, and two benchmarks from practical applications.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We experimentally investigate charge transport through the interface between\na niobium superconductor and a three-dimensional WTe$_2$ Weyl semimetal. In\naddition to classical Andreev reflection, we observe sharp non-periodic subgap\nresistance resonances. From an analysis of their positions, magnetic field and\ntemperature dependencies, we can interpret them as an analog of Tomasch\noscillations for transport along the topological surface state across the\nregion of proximity-induced superconductivity at the Nb-WTe$_2$ interface.\nObservation of distinct geometrical resonances implies a specific transmission\ndirection for carriers, which is a hallmark of the Fermi arc surface states.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  This paper presents a study on detecting cyberattacks on industrial control\nsystems (ICS) using unsupervised deep neural networks, specifically,\nconvolutional neural networks. The study was performed on a SecureWater\nTreatment testbed (SWaT) dataset, which represents a scaled-down version of a\nreal-world industrial water treatment plant. e suggest a method for anomaly\ndetection based on measuring the statistical deviation of the predicted value\nfrom the observed value.We applied the proposed method by using a variety of\ndeep neural networks architectures including different variants of\nconvolutional and recurrent networks. The test dataset from SWaT included 36\ndifferent cyberattacks. The proposed method successfully detects the vast\nmajority of the attacks with a low false positive rate thus improving on\nprevious works based on this data set. The results of the study show that 1D\nconvolutional networks can be successfully applied to anomaly detection in\nindustrial control systems and outperform more complex recurrent networks while\nbeing much smaller and faster to train.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Edge detection has made significant progress with the help of deep\nConvolutional Networks (ConvNet). These ConvNet based edge detectors have\napproached human level performance on standard benchmarks. We provide a\nsystematical study of these detectors' outputs. We show that the detection\nresults did not accurately localize edge pixels, which can be adversarial for\ntasks that require crisp edge inputs. As a remedy, we propose a novel\nrefinement architecture to address the challenging problem of learning a crisp\nedge detector using ConvNet. Our method leverages a top-down backward\nrefinement pathway, and progressively increases the resolution of feature maps\nto generate crisp edges. Our results achieve superior performance, surpassing\nhuman accuracy when using standard criteria on BSDS500, and largely\noutperforming state-of-the-art methods when using more strict criteria. More\nimportantly, we demonstrate the benefit of crisp edge maps for several\nimportant applications in computer vision, including optical flow estimation,\nobject proposal generation and semantic segmentation.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We present Atacama Large Millimeter/Submillimeter Array observations of the\nrest-frame far-infrared (FIR) dust continuum emission of six bright Lyman-break\ngalaxies (LBGs) at $z \\simeq 7$. One LBG is detected ($5.2\\sigma$ at peak\nemission), while the others remain individually undetected at the $3\\sigma$\nlevel. The average FIR luminosity of the sample is found to be $L_{\\rm FIR}\n\\simeq 2 \\times 10^{11}\\,{\\rm L}_{\\odot}$, corresponding to an obscured\nstar-formation rate (SFR) that is comparable to that inferred from the\nunobscured UV emission. In comparison to the infrared excess (IRX$\\,=L_{\\rm\nFIR}/L_{\\rm UV}$)-$\\beta$ relation, our results are consistent with a\nCalzetti-like attenuation law (assuming a dust temperature of T = 40-50 K). We\nfind a physical offset of 3 kpc between the dust continuum emission and the\nrest-frame UV light probed by Hubble Space Telescope imaging for galaxy ID65666\nat $z = 7.17^{+0.09}_{-0.06}$. The offset is suggestive of an inhomogeneous\ndust distribution, where 75% of the total star formation activity (SFR$\n\\,\\simeq 70\\,{\\rm M}_{\\odot}/{\\rm yr}$) of the galaxy is completely obscured.\nOur results provide direct evidence that dust obscuration plays a key role in\nshaping the bright-end of the observed rest-frame UV luminosity function at $z\n\\simeq 7$, in agreement with cosmological galaxy formation simulations. The\nexistence of a heavily-obscured component of galaxy ID65666 indicates that\ndusty star-forming regions, or even entire galaxies, that are \"UV-dark\" are\nsignificant even in the $z \\simeq 7$ galaxy population.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Optimal transport (OT) and maximum mean discrepancies (MMD) are now routinely\nused in machine learning to compare probability measures. We focus in this\npaper on \\emph{Sinkhorn divergences} (SDs), a regularized variant of OT\ndistances which can interpolate, depending on the regularization strength\n$\\varepsilon$, between OT ($\\varepsilon=0$) and MMD ($\\varepsilon=\\infty$).\nAlthough the tradeoff induced by that regularization is now well understood\ncomputationally (OT, SDs and MMD require respectively $O(n^3\\log n)$, $O(n^2)$\nand $n^2$ operations given a sample size $n$), much less is known in terms of\ntheir \\emph{sample complexity}, namely the gap between these quantities, when\nevaluated using finite samples \\emph{vs.} their respective densities. Indeed,\nwhile the sample complexity of OT and MMD stand at two extremes, $1/n^{1/d}$\nfor OT in dimension $d$ and $1/\\sqrt{n}$ for MMD, that for SDs has only been\nstudied empirically. In this paper, we \\emph{(i)} derive a bound on the\napproximation error made with SDs when approximating OT as a function of the\nregularizer $\\varepsilon$, \\emph{(ii)} prove that the optimizers of regularized\nOT are bounded in a Sobolev (RKHS) ball independent of the two measures and\n\\emph{(iii)} provide the first sample complexity bound for SDs, obtained,by\nreformulating SDs as a maximization problem in a RKHS. We thus obtain a scaling\nin $1/\\sqrt{n}$ (as in MMD), with a constant that depends however on\n$\\varepsilon$, making the bridge between OT and MMD complete.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Construction of capacity achieving deletion correcting codes has been a\nbaffling challenge for decades. A recent breakthrough by Brakensiek $et~al$.,\nalongside novel applications in DNA storage, have reignited the interest in\nthis longstanding open problem. In spite of recent advances, the amount of\nredundancy in existing codes is still orders of magnitude away from being\noptimal. In this paper, a novel approach for constructing binary two-deletion\ncorrecting codes is proposed. By this approach, parity symbols are computed\nfrom indicator vectors (i.e., vectors that indicate the positions of certain\npatterns) of the encoded message, rather than from the message itself. Most\ninterestingly, the parity symbols and the proof of correctness are a direct\ngeneralization of their counterparts in the Varshamov-Tenengolts construction.\nOur techniques require $7\\log(n)+o(\\log(n)$ redundant bits to encode an~$n$-bit\nmessage, which is near-optimal.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  When generating adversarial examples to attack deep neural networks (DNNs),\nLp norm of the added perturbation is usually used to measure the similarity\nbetween original image and adversarial example. However, such adversarial\nattacks perturbing the raw input spaces may fail to capture structural\ninformation hidden in the input. This work develops a more general attack\nmodel, i.e., the structured attack (StrAttack), which explores group sparsity\nin adversarial perturbations by sliding a mask through images aiming for\nextracting key spatial structures. An ADMM (alternating direction method of\nmultipliers)-based framework is proposed that can split the original problem\ninto a sequence of analytically solvable subproblems and can be generalized to\nimplement other attacking methods. Strong group sparsity is achieved in\nadversarial perturbations even with the same level of Lp norm distortion as the\nstate-of-the-art attacks. We demonstrate the effectiveness of StrAttack by\nextensive experimental results onMNIST, CIFAR-10, and ImageNet. We also show\nthat StrAttack provides better interpretability (i.e., better correspondence\nwith discriminative image regions)through adversarial saliency map (Papernot et\nal., 2016b) and class activation map(Zhou et al., 2016).\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  On-demand video accounts for the majority of wireless data traffic. Video\ndistribution schemes based on caching combined with device-to-device (D2D)\ncommunications promise order-of-magnitude greater spectral efficiency for video\ndelivery, but hinge on the principle of `concentrated demand distributions.'\nThis paper presents, for the first time, the analysis and evaluations of the\nthroughput--outage tradeoff of such schemes based on measured cellular demand\ndistributions. In particular, we use a dataset with more than 100 million\nrequests from the BBC iPlayer, a popular video streaming service in the U.K.,\nas the foundation of the analysis and evaluations. We present an achievable\nscaling law based on the practical popularity distribution, and show that such\nscaling law is identical to those reported in the literature. We find that also\nfor the numerical evaluations based on a realistic setup, order-of-magnitude\nimprovements can be achieved. Our results indicate that the benefits promised\nby the caching-based D2D in the literature could be retained for cellular\nnetworks in practice.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We prove that any finite system of interacted automata can not leave some\nfinite arrear of Calley graph of periodic group. If group has non-periodic\nelement, then its Calley graph can be explored by some finite automata with 3\npebbles. If group is finitelly generated and aperiodic then it can not be\nexplored by any system of finite automata.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Consider $L$ groups of point sources or spike trains, with the\n$l^{\\text{th}}$ group represented by $x_l(t)$. For a function $g:\\mathbb{R}\n\\rightarrow \\mathbb{R}$, let $g_l(t) = g(t/\\mu_l)$ denote a point spread\nfunction with scale $\\mu_l > 0$, and with $\\mu_1 < \\cdots < \\mu_L$. With $y(t)\n= \\sum_{l=1}^{L} (g_l \\star x_l)(t)$, our goal is to recover the source\nparameters given samples of $y$, or given the Fourier samples of $y$. This\nproblem is a generalization of the usual super-resolution setup wherein $L =\n1$; we call this the multi-kernel unmixing super-resolution problem. Assuming\naccess to Fourier samples of $y$, we derive an algorithm for this problem for\nestimating the source parameters of each group, along with precise\nnon-asymptotic guarantees. Our approach involves estimating the group\nparameters sequentially in the order of increasing scale parameters, i.e., from\ngroup $1$ to $L$. In particular, the estimation process at stage $1 \\leq l \\leq\nL$ involves (i) carefully sampling the tail of the Fourier transform of $y$,\n(ii) a \\emph{deflation} step wherein we subtract the contribution of the groups\nprocessed thus far from the obtained Fourier samples, and (iii) applying\nMoitra's modified Matrix Pencil method on a deconvolved version of the samples\nin (ii).\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  In this paper we present the results of the spectral studies of erosive\ndischarge with tin alloy electrodes and of the generated JFs, and\nexperimentally determine internal energy of JFs using the calorimetric\ntechnique.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  Current face recognition systems robustly recognize identities across a wide\nvariety of imaging conditions. In these systems recognition is performed via\nclassification into known identities obtained from supervised identity\nannotations. There are two problems with this current paradigm: (1) current\nsystems are unable to benefit from unlabelled data which may be available in\nlarge quantities; and (2) current systems equate successful recognition with\nlabelling a given input image. Humans, on the other hand, regularly perform\nidentification of individuals completely unsupervised, recognising the identity\nof someone they have seen before even without being able to name that\nindividual. How can we go beyond the current classification paradigm towards a\nmore human understanding of identities? We propose an integrated Bayesian model\nthat coherently reasons about the observed images, identities, partial\nknowledge about names, and the situational context of each observation. While\nour model achieves good recognition performance against known identities, it\ncan also discover new identities from unsupervised data and learns to associate\nidentities with different contexts depending on which identities tend to be\nobserved together. In addition, the proposed semi-supervised component is able\nto handle not only acquaintances, whose names are known, but also unlabelled\nfamiliar faces and complete strangers in a unified framework.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Exact recovery of tensor decomposition (TD) methods is a desirable property\nin both unsupervised learning and scientific data analysis. The numerical\ndefects of TD methods, however, limit their practical applications on\nreal-world data. As an alternative, convex tensor decomposition (CTD) was\nproposed to alleviate these problems, but its exact-recovery property is not\nproperly addressed so far. To this end, we focus on latent convex tensor\ndecomposition (LCTD), a practically widely-used CTD model, and rigorously prove\na sufficient condition for its exact-recovery property. Furthermore, we show\nthat such property can be also achieved by a more general model than LCTD. In\nthe new model, we generalize the classic tensor (un-)folding into reshuffling\noperation, a more flexible mapping to relocate the entries of the matrix into a\ntensor. Armed with the reshuffling operations and exact-recovery property, we\nexplore a totally novel application for (generalized) LCTD, i.e., image\nsteganography. Experimental results on synthetic data validate our theory, and\nresults on image steganography show that our method outperforms the\nstate-of-the-art methods.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We propose a class of numerical schemes for nonlocal HJB variational\ninequalities (HJBVIs) with monotone drivers. The solution and free boundary of\nthe HJBVI are constructed from a sequence of penalized equations, for which a\ncontinuous dependence result is derived and the penalization error is\nestimated. The penalized equation is then discretized by a class of\nsemi-implicit monotone approximations. We present a novel analysis technique\nfor the well-posedness of the discrete equation, and demonstrate the\nconvergence of the scheme, which subsequently gives a constructive proof for\nthe existence of a solution to the penalized equation and variational\ninequality. We further propose an efficient iterative algorithm with local\nsuperlinear convergence for solving the discrete equation. Numerical\nexperiments are presented for an optimal investment problem under ambiguity and\na recursive consumption-portfolio allocation problem.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We analyze hydrodynamic simulations of turbulent, star-forming molecular\nclouds that are post-processed with the photo-dissociation region\nastrochemistry code 3D-PDR. We investigate the sensitivity of 15 commonly\napplied turbulence statistics to post-processing assumptions, namely variations\nin gas temperature, abundance and external radiation field. We produce\nsynthetic $^{12}$CO(1-0) and CI($^{3}$P$_{1}$-$^{3}$P$_{0}$) observations and\nexamine how the variations influence the resulting emission distributions. To\ncharacterize differences between the datasets, we perform statistical\nmeasurements, identify diagnostics sensitive to our chemistry parameters, and\nquantify the statistic responses by using a variety of distance metrics. We\nfind that multiple turbulent statistics are sensitive not only to the chemical\ncomplexity but also to the strength of the background radiation field. The\nstatistics with meaningful responses include principal component analysis,\nspatial power spectrum and bicoherence. A few of the statistics, such as the\nvelocity coordinate spectrum, are primarily sensitive to the type of tracer\nbeing utilized, while others, like the delta-variance, strongly respond to the\nbackground radiation field. Collectively, these findings indicate that more\nrealistic chemistry impacts the responses of turbulent statistics and is\nnecessary for accurate statistical comparisons between models and observed\nmolecular clouds.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  The present paper is a continuation of our recent paper \\cite{DaoReissig}. We\nwill consider the following Cauchy problems for semi-linear structurally damped\n$\\sigma$-evolution models: \\begin{equation*} u_{tt}+ (-\\Delta)^\\sigma u+ \\mu\n(-\\Delta)^\\delta u_t = f(u,u_t),\\, u(0,x)= u_0(x),\\, u_t(0,x)=u_1(x)\n\\end{equation*} with $\\sigma \\ge 1$, $\\mu>0$ and $\\delta \\in\n(\\frac{\\sigma}{2},\\sigma]$. Our aim is to study two main models including\n$\\sigma$-evolution models with structural damping $\\delta \\in\n(\\frac{\\sigma}{2},\\sigma)$ and those with visco-elastic damping\n$\\delta=\\sigma$. Here the function $f(u,u_t)$ stands for power nonlinearities\n$|u|^{p}$ and $|u_t|^{p}$ with a given number $p>1$. We are interested in\ninvestigating the global (in time) existence of small data solutions to the\nabove semi-linear models from suitable spaces basing on $L^q$ space by assuming\nadditional $L^{m}$ regularity on the initial data, with $q\\in (1,\\infty)$ and\n$m\\in [1,q)$.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  By local measurements on party $A$ of a system $AB$ and classical\ncommunication between its two parties, one can achieve a nonlocal advantage of\nquantum coherence (NAQC) on party $B$. For the $l_1$ norm of coherence and the\nrelative entropy of coherence, we generalized the framework of NAQC for two\nqubits and derived the criteria which capture NAQC in the $(d\\times\nd)$-dimensional states when $d$ is a power of a prime. We also presented a new\nframework for formulating NAQC, and showed through explicit examples its\ncapacity on capturing the NAQC states. Moreover, we proved that any bipartite\nstate with NAQC is quantum entangled, thus the obtained criteria can also be\nused as an entanglement witness.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Maximum likelihood estimation is an important statistical technique for\nestimating missing data, for example in climate and environmental applications,\nwhich are usually large and feature data points that are irregularly spaced. In\nparticular, the Gaussian log-likelihood function is the \\emph{de facto} model,\nwhich operates on the resulting sizable dense covariance matrix. The advent of\nhigh performance systems with advanced computing power and memory capacity have\nenabled full simulations only for rather small dimensional climate problems,\nsolved at the machine precision accuracy. The challenge for high dimensional\nproblems lies in the computation requirements of the log-likelihood function,\nwhich necessitates ${\\mathcal O}(n^2)$ storage and ${\\mathcal O}(n^3)$\noperations, where $n$ represents the number of given spatial locations. This\nprohibitive computational cost may be reduced by using approximation techniques\nthat not only enable large-scale simulations otherwise intractable but also\nmaintain the accuracy and the fidelity of the spatial statistics model. In this\npaper, we extend the Exascale GeoStatistics software framework (i.e.,\nExaGeoStat) to support the Tile Low-Rank (TLR) approximation technique, which\nexploits the data sparsity of the dense covariance matrix by compressing the\noff-diagonal tiles up to a user-defined accuracy threshold. The underlying\nlinear algebra operations may then be carried out on this data compression\nformat, which may ultimately reduce the arithmetic complexity of the maximum\nlikelihood estimation and the corresponding memory footprint. Performance\nresults of TLR-based computations on shared and distributed-memory systems\nattain up to 13X and 5X speedups, respectively, compared to full accuracy\nsimulations using synthetic and real datasets (up to 2M), while ensuring\nadequate prediction accuracy.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We describe an exact simulation algorithm for the increments of Brownian\nmotion on a sphere of arbitrary dimension, based on the skew-product\ndecomposition of the process with respect to the standard geodesic distance.\nThe radial process is closely related to a Wright-Fisher diffusion, increments\nof which can be simulated exactly using the recent work of Jenkins & Span\\`{o}\n(2017) [JS17]. The rapid spinning phenomenon of the skew-product decomposition\nthen yields the algorithm for the increments of the process on the sphere.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Dynamical sampling, as introduced by Aldroubi et al., deals with frame\nproperties of sequences of the form $\\{T^i f_1\\}_{i\\in \\mathbb{N}}$, where\n$f_1$ belongs to Hilbert space $\\h$ and $T:\\h\\rightarrow\\h$ belongs to certain\nclasses of the bounded operators. Christensen et al., study frames for $\\h$\nwith index set $\\mathbb{N}$ (or $\\mathbb{Z}$), that have representations in the\nform $\\{T^{i-1}f_1\\}_{i\\in \\mathbb{N}}$ (or $\\{T^if_0\\}_{i\\in \\mathbb{Z}}$). As\nframes of subspaces, fusion frames and generalized translation invariant\nsystems are the spacial cases of $g$-frames, the purpose of this paper is to\nstudy $g$-frames $\\Lambda=\\{\\Lambda_i\\in B(\\h,\\K): i\\in I\\}$ $(I=\\mathbb{N}$ or\n$\\mathbb{Z}$) having the form $\\Lambda_{i+1}=\\Lambda_1 T^{i},$ for $T\\in\nB(\\h).$\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We discuss our recent results regarding chiral and $U(1)_A$ restoration, both\nfrom the formal point of view of QCD Ward Identities (WI) and from an Effective\nTheory analysis provided by $U(3)$ Chiral Perturbation Theory (ChPT) at finite\ntemperature. Our results lead to relevant conclusions regarding the behavior of\nchiral partners (in terms of susceptibilities) in the limit of exact\nrestoration and provide useful results for lattice analysis. In addition, it\nhelps to understand the temperature dependence of lattice screening masses in\nterms of quark condensate combinations. The U(3) ChPT calculation supports the\nconclusions obtained within the WI analysis. Finally, the role of the thermal\n$f_0(500)$ state in chiral symmetry restoration, regarding the scalar\nsusceptibility, is also discussed.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  Photon operators with the proper $J^{PC}$ quantum numbers are constructed,\nincluding one made of elementary plaquettes. In compact U(1) lattice gauge\ntheory, these explicit photon operators are shown to permit direct confirmation\nof the massive and massless states on each side of the phase transition. In the\nabelian Higgs model, these explicit photon operators avoid some excited state\ncontamination seen with the traditional composite operator, and allow more\ndetailed future studies of the Higgs mechanism.\n\n\n###\n\n", "completion": " 98"}
{"prompt": "  A basic result is that the sample variance for i.i.d. observations is an\nunbiased estimator of the variance of the underlying distribution (see for\ninstance Casella and Berger (2002)). But what happens if the observations are\nneither independent nor identically distributed. What can we say? Can we in\nparticular compute explicitly the first two moments of the sample mean and\nhence generalize formulae provided in Tukey (1957a), Tukey (1957b) for the\nfirst two moments of the sample variance? We also know that the sample mean and\nvariance are independent if they are computed on an i.i.d. normal distribution.\nThis is one of the underlying assumption to derive the Student distribution\nStudent alias W. S. Gosset (1908). But does this result hold for any other\nunderlying distribution? Can we still have independent sample mean and variance\nif the distribution is not normal? This paper precisely answers these questions\nand extends previous work of Cho, Cho, and Eltinge (2004). We are able to\nderive a general formula for the first two moments and variance of the sample\nvariance under no specific assumption. We also provide a faster proof of a\nseminal result of Lukacs (1942) by using the log characteristic function of the\nunbiased sample variance estimator.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We investigate an ultracold and dilute Bose gas by taking into account a\nfinite-range two-body interaction. The coupling constants of the resulting\nLagrangian density are related to measurable scattering parameters by following\nthe effective-field-theory approach. A perturbative scheme is then developed up\nto the Gaussian level, where both quantum and thermal fluctuations are\ncrucially affected by finite-range corrections. In particular, the relation\nbetween spontaneous symmetry breaking and the onset of superfluidity is\nemphasized by recovering the renowned Landau's equation for the superfluid\ndensity in terms of the condensate one.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  The magnetoresistance of a three-dimensional Rashba material placed on top of\na ferromagnetic insulator is theoretically investigated. In addition to the\nintrinsic Rashba spin-orbit interaction, we also consider extrinsic spin-orbit\ncoupling via side-jump and skew scattering, and the Elliott-Yafet spin\nrelaxation mechanism. The latter is anisotropic due to the mass anisotropy\nwhich reflects the noncentrosymmetric crystal structure of three-dimensional\nRashba metals. A quasiclassical approach is employed to derive a set of coupled\nspin-diffusion equations, which are supplemented by boundary conditions that\naccount for the spin-transfer torque at the interface of the bilayer. The\nmagnetoresistance is fully determined by the current-induced spin polarization,\ni.e., it cannot in general be ascribed to a single (bulk) spin Hall angle. Our\ntheoretical results reproduce several features of the experiments, at least\nqualitatively, and contain established phenomenological results in the relevant\nlimiting cases. In particular, the anisotropy of the Elliott-Yafet spin\nrelaxation mechanism plays a major role for the interpretation of the observed\nmagnetoresistance.\n\n\n###\n\n", "completion": " 05"}
{"prompt": "  Low-Power Wide-Area Networks (LPWANs) are being successfully used for the\nmonitoring of large-scale systems that are delay-tolerant and which have\nlow-bandwidth requirements. The next step would be instrumenting these for the\ncontrol of Cyber-Physical Systems (CPSs) distributed over large areas which\nrequire more bandwidth, bounded delays and higher reliability or at least more\nrigorous guarantees therein. This paper presents LPWA-MAC, a novel Low Power\nWide-Area network MAC protocol, that ensures bounded end-to-end delays, high\nchannel utility and supports many of the different traffic patterns and\ndata-rates typical of CPS.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  This application of renormalization techniques offers a modern take on the\nclassical Arbelos geometry problem. Keeping within the context of the original\nproblem, two semicircles, meeting at chord T, are together circumscribed by a\nthird semicircle. Separate from the original Arbelos result, both circumscribed\nsemicircle areas are found in terms of chord T and the third circumscribing\nsemicircle radius R. This approach eliminates the additional variables of the\ncircumscribed semicircle radii.\n\n\n###\n\n", "completion": " 99"}
{"prompt": "  Magnitude homology was introduced by Hepworth and Willerton in the case of\ngraphs, and was later extended by Leinster and Shulman to metric spaces and\nenriched categories. Here we introduce the dual theory, magnitude cohomology,\nwhich we equip with the structure of an associative unital graded ring. Our\nfirst main result is a 'recovery theorem' showing that the magnitude cohomology\nring of a finite metric space completely determines the space itself. The\nmagnitude cohomology ring is non-commutative in general, for example when\napplied to finite metric spaces, but in some settings it is commutative, for\nexample when applied to ordinary categories. Our second main result explains\nthis situation by proving that the magnitude cohomology ring of an enriched\ncategory is graded-commutative whenever the enriching category is cartesian. We\nend the paper by giving complete computations of magnitude cohomology rings for\nseveral large classes of graphs.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We study geometric aspects of the Laughlin fractional quantum Hall (FQH)\nstates using a description of these states in terms of a matrix quantum\nmechanics model known as the Chern-Simons matrix model (CSMM). This model was\nproposed by Polychronakos as a regularization of the noncommutative\nChern-Simons theory description of the Laughlin states proposed earlier by\nSusskind. Both models can be understood as describing the electrons in a FQH\nstate as forming a noncommutative fluid, i.e., a fluid occupying a\nnoncommutative space. Here we revisit the CSMM in light of recent work on\ngeometric response in the FQH effect, with the goal of determining whether the\nCSMM captures this aspect of the physics of the Laughlin states. For this model\nwe compute the Hall viscosity, Hall conductance in a non-uniform electric\nfield, and the Hall viscosity in the presence of anisotropy (or intrinsic\ngeometry). Our calculations show that the CSMM captures the guiding center\ncontribution to the known values of these quantities in the Laughlin states,\nbut lacks the Landau orbit contribution. The interesting correlations in a\nLaughlin state are contained entirely in the guiding center part of the\nstate/wave function, and so we conclude that the CSMM accurately describes the\nmost important aspects of the physics of the Laughlin FQH states, including the\nHall viscosity and other geometric properties of these states which are of\ncurrent interest.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  In this paper, we implement an optical fiber communication system as an\nend-to-end deep neural network, including the complete chain of transmitter,\nchannel model, and receiver. This approach enables the optimization of the\ntransceiver in a single end-to-end process. We illustrate the benefits of this\nmethod by applying it to intensity modulation/direct detection (IM/DD) systems\nand show that we can achieve bit error rates below the 6.7\\% hard-decision\nforward error correction (HD-FEC) threshold. We model all componentry of the\ntransmitter and receiver, as well as the fiber channel, and apply deep learning\nto find transmitter and receiver configurations minimizing the symbol error\nrate. We propose and verify in simulations a training method that yields robust\nand flexible transceivers that allow---without reconfiguration---reliable\ntransmission over a large range of link dispersions. The results from\nend-to-end deep learning are successfully verified for the first time in an\nexperiment. In particular, we achieve information rates of 42\\,Gb/s below the\nHD-FEC threshold at distances beyond 40\\,km. We find that our results\noutperform conventional IM/DD solutions based on 2 and 4 level pulse amplitude\nmodulation (PAM2/PAM4) with feedforward equalization (FFE) at the receiver. Our\nstudy is the first step towards end-to-end deep learning-based optimization of\noptical fiber communication systems.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  The Dirac fermion is an important fundamental particle appearing in\nhigh-energy physics and topological insulator physics. In particular, a Dirac\nfermion in a one-dimensional lattice system exhibits the essential properties\nof topological physics. However, the system has not been quantum simulated in\nexperiments yet. Herein, we propose a one-dimensional generalized lattice\nWilson-Dirac fermion model and study its topological phase structure. We show\nthe experimental setups of an atomic quantum simulator for the model, in which\ntwo parallel optical lattices with the same tilt for trapping cold fermion\natoms and a laser-assisted hopping scheme are used. Interestingly, we find that\nthe model exhibits nontrivial topological phases characterized by gapless edge\nmodes and a finite winding number in the broad regime of the parameter space.\nSome of the phase diagrams closely resemble those of the Haldane model. We also\ndiscuss topological charge pumping and a lattice Gross-Neveu model in the\nsystem of generalized Wilson-Dirac fermions.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  The key issue in Dynamic Ensemble Selection (DES) is defining a suitable\ncriterion for calculating the classifiers' competence. There are several\ncriteria available to measure the level of competence of base classifiers, such\nas local accuracy estimates and ranking. However, using only one criterion may\nlead to a poor estimation of the classifier's competence. In order to deal with\nthis issue, we have proposed a novel dynamic ensemble selection framework using\nmeta-learning, called META-DES. An important aspect of the META-DES framework\nis that multiple criteria can be embedded in the system encoded as different\nsets of meta-features. However, some DES criteria are not suitable for every\nclassification problem. For instance, local accuracy estimates may produce poor\nresults when there is a high degree of overlap between the classes. Moreover, a\nhigher classification accuracy can be obtained if the performance of the\nmeta-classifier is optimized for the corresponding data. In this paper, we\npropose a novel version of the META-DES framework based on the formal\ndefinition of the Oracle, called META-DES.Oracle. The Oracle is an abstract\nmethod that represents an ideal classifier selection scheme. A meta-feature\nselection scheme using an overfitting cautious Binary Particle Swarm\nOptimization (BPSO) is proposed for improving the performance of the\nmeta-classifier. The difference between the outputs obtained by the\nmeta-classifier and those presented by the Oracle is minimized. Thus, the\nmeta-classifier is expected to obtain results that are similar to the Oracle.\nExperiments carried out using 30 classification problems demonstrate that the\noptimization procedure based on the Oracle definition leads to a significant\nimprovement in classification accuracy when compared to previous versions of\nthe META-DES framework and other state-of-the-art DES techniques.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  The seminal work \\cite{bm} by Brezis and Merle has been pioneering in\nstudying the bubbling phenomena of the mean field equation with singular\nsources. When the vortex points are not collapsing, the mean field equation\npossesses the property of the so-called \"bubbling implies mass concentration\".\nRecently, Lin and Tarantello in \\cite{lt} pointed out that the \"bubbling\nimplies mass concentration\" phenomena might not hold in general if the collapse\nof singularities occurs. In this paper, we shall construct the first concrete\nexample of non-concentrated bubbling solution of the mean field equation with\ncollapsing singularities.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  In this paper, we propose an improved version of the power index related to\nthe Banzhaf power index for weighted voting systems. This index now takes into\naccount the mutual persuasion power matrix(PPM) existing among the voters. This\nimproved index is calculated for European Union voting by basing the PPM on\nimmigration data among the EU countries. We also provide better approximation\nbounds for the Monte Carlo approximation method for computing power indices.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Accurate and efficient eye gaze estimation is important for emerging consumer\nelectronic systems such as driver monitoring systems and novel user interfaces.\nSuch systems are required to operate reliably in difficult, unconstrained\nenvironments with low power consumption and at minimal cost. In this paper a\nnew hardware friendly, convolutional neural network model with minimal\ncomputational requirements is introduced and assessed for efficient\nappearance-based gaze estimation. The model is tested and compared against\nexisting appearance based CNN approaches, achieving better eye gaze accuracy\nwith significantly fewer computational requirements. A brief updated literature\nreview is also provided.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  The paper is devoted to dynamic games. We consider a general enough\nframework, which is not limited to e.g. differential games and could\naccommodate both discrete and continuous time. Assuming common dynamics, we\nstudy two game families with total payoffs that are defined either as the\nCes\\`{a}ro average (long run average game family) or Abel average (discounting\ngame family) of the running costs. We study a robust strategy that would\nprovide a near-optimal total payoff for all sufficiently small discounts and\nfor all sufficiently large planning horizons. Assuming merely the Dynamic\nProgramming Principle, we prove the following Tauberian theorem: if a strategy\nis uniformly optimal for one of the families (when discount goes to zero for\ndiscounting games, when planning horizon goes to infinity in long run average\ngames) and its value functions converge uniformly, then, for the other family,\nthis strategy is also uniformly optimal and its value functions converge\nuniformly to the same limit.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Microscopic particles suspended in liquids are the prime example of an\noverdamped system because viscous forces dominate over inertial effects. Apart\nfrom their use as model systems, they receive considerable attention as\nsensitive probes from which forces on molecular scales can be inferred. The\ninterpretation of such experiments rests on the assumption, that, even if the\nparticles are driven, the liquid remains in equilibrium, and all modes are\noverdamped. Here, we experimentally demonstrate that this is no longer valid\nwhen a particle is forced through a viscoelastic fluid. Even at small driving\nvelocities where Stokes law remains valid, we observe particle oscillations\nwith periods up to several tens of seconds. We attribute these to\nnon-equilibrium fluctuations of the fluid, which are excited by the particle's\nmotion. The observed oscillatory dynamics is in quantitative agreement with an\noverdamped Langevin equation with negative friction-memory term and which is\nequivalent to the motion of a stochastically driven underdamped oscillator.\nThis fundamentally new oscillatory mode will largely expand the variety of\nmodel systems but has also considerable implications on how molecular forces\nare determined by colloidal probe particles under natural viscoelastic\nconditions.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We study several aspects of the $k$-th Cheeger constant of a complex X, a\nparameter that quantifies the distance of $X$ from a complex $Y$ with\nnontrivial $k$-th cohomology over $\\mathbb{Z}_2$. Our results include general\nmethods for bounding the cosystolic norm of a cochain and for bounding the\nCheeger constant of a complex, a discussion of expansion of pseudomanifolds and\ngeometric lattices, probabilistic upper bounds on Cheeger constants, and\napplication of non-Abelian expansion to random complexes.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Given a graph $G=(V,E)$, two vertices $s,t\\in V$, and two integers $k,\\ell$,\nthe Short Secluded Path problem is to find a simple $s$-$t$-path with at most\n$k$ vertices and $\\ell$ neighbors. We study the parameterized complexity of the\nproblem with respect to four structural graph parameters: the vertex cover\nnumber, treewidth, feedback vertex number, and feedback edge number. In\nparticular, we completely settle the question of the existence of problem\nkernels with size polynomial in these parameters and their combinations with\n$k$ and $\\ell$. We also obtain a $2^{O(w)}\\cdot \\ell^2\\cdot n$-time algorithm\nfor graphs of treewidth $w$, which yields subexponential-time algorithms in\nseveral graph classes.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Polydisperse linear polymer melts can be microscopically described by the\ntube model and fractal reptation dynamics, while on the macroscopic side the\ngeneralized Maxwell model is capable of correctly displaying most of the\nrheological behavior. In this paper, a Laplace transform method is derived and\ndifferent macroscopic starting points for molecular mass distribution\ncalculation are compared to a classical light scattering evaluation. The\nunderlying assumptions comprise the modern understanding on polymer dynamics in\nentangled systems but can be stated in a mathematically generalized way. The\nresulting method is very easy to use due to its mathematical structure and it\nis capable of calculating multimodal molecular mass distributions of linear\npolymer melts.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  The dust sub-millimetre polarisation of star-forming clouds carries\ninformation on dust and the role of magnetic fields in cloud evolution. With\nobservations of a dense filamentary cloud G035.39-00.33, we aim to characterise\nthe dust emission properties and the variations of the polarisation fraction.\nJCMT SCUBA-2/POL-2 data at 850um are combined with Planck 850um (353GHz) data\nto map polarisation fractions. With previous SCUBA-2 observations (450um and\n850um) and Herschel data, the column densities are determined via modified\nblackbody fits and via radiative transfer modelling. Models are constructed to\nexamine how the polarisation angles and fractions depend on potential magnetic\nfield geometries and grain alignment. POL-2 data show clear changes in the\nmagnetic field orientation. The filament has a peak column density of N(H2)~7\n10^22 cm-2, a minimum dust temperature of T~12 K, and a mass of some 4300Msun\nfor the area N(H2)> 5 10^21 cm-2. The estimated average value of the dust\nopacity spectral index is beta ~ 1.9. The ratio of sub-millimetre and J band\noptical depths is tau(250 um)/tau(J) ~ 2.5 10^-3, more than four times the\ntypical values for diffuse medium. The polarisation fraction decreases as a\nfunction of column density to p ~ 1% in the central filament. Because of noise,\nthe observed decrease of p(N) is significant only at N(H2)>2 10^22 cm-2. The\nobservations suggest that the grain alignment is not constant. Although the\ndata can be explained with a complete loss of alignment at densities above ~\n10^4 cm-3 or using the predictions of radiative torques alignment, the\nuncertainty of the field geometry and the spatial filtering of the SCUBA-2 data\nprevent strong conclusions. G035.39-00.33 shows strong signs of dust evolution\nand the low polarisation fraction is suggestive of a loss of polarised emission\nfrom its densest parts.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Typically, AI researchers and roboticists try to realize intelligent behavior\nin machines by tuning parameters of a predefined structure (body plan and/or\nneural network architecture) using evolutionary or learning algorithms. Another\nbut not unrelated longstanding property of these systems is their brittleness\nto slight aberrations, as highlighted by the growing deep learning literature\non adversarial examples. Here we show robustness can be achieved by evolving\nthe geometry of soft robots, their control systems, and how their material\nproperties develop in response to one particular interoceptive stimulus\n(engineering stress) during their lifetimes. By doing so we realized robots\nthat were equally fit but more robust to extreme material defects (such as\nmight occur during fabrication or by damage thereafter) than robots that did\nnot develop during their lifetimes, or developed in response to a different\ninteroceptive stimulus (pressure). This suggests that the interplay between\nchanges in the containing systems of agents (body plan and/or neural\narchitecture) at different temporal scales (evolutionary and developmental)\nalong different modalities (geometry, material properties, synaptic weights)\nand in response to different signals (interoceptive and external perception)\nall dictate those agents' abilities to evolve or learn capable and robust\nstrategies.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Hyperbolic transport-reaction equations are abundant in the description of\nmovement of motile organisms. Here, we focus on system of four coupled\ntransport-reaction equations that arises from an age-structuring of a species\nof turning individuals. The highlight consists of the explicit construction and\ncharacterization of counter-propagating traveling waves, patterns which have\nbeen observed in bacterial colonies. Stability analysis reveals conditions for\nthe wave formation as well as pulsating-in-time spatially constant solutions.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We study boundary properties of plurisubharmonic functions near real\nsubmanifolds of almost complex manifolds.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  We provide several extensions of the modular method which were motivated by\nthe problem of completing previous work to prove that, for any integer $n \\geq\n2$, the equation \\[ x^{13} + y^{13} = 3 z^n \\] has no non-trivial solutions. In\nparticular, we present four elimination techniques which are based on: (1)\nestablishing reducibility of certain residual Galois representations over a\ntotally real field; (2) generalizing image of inertia arguments to the setting\nof abelian surfaces; (3) establishing congruences of Hilbert modular forms\nwithout the use of often impractical Sturm bounds; and (4) a unit sieve\nargument which combines information from classical descent and the modular\nmethod.\n  The extensions are of broader applicability and provide further evidence that\nit is possible to obtain a complete resolution of a family of generalized\nFermat equations by remaining within the framework of the modular method. As a\nfurther illustration of this, we complete a theorem of Anni-Siksek to show\nthat, for $\\ell, m\\ge 5$, the only solutions to the equation $x^{2\\ell} +\ny^{2m} = z^{13}$ are the trivial ones.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Inner Oort Cloud objects (IOCs) are Trans-Plutonian for their entire orbits.\nThey are beyond the strong gravitational influences of the known planets yet\nclose enough to the Sun that outside forces are minimal. Here we report the\ndiscovery of the third known IOC after Sedna and 2012 VP113, called 2015 TG387.\n2015 TG387 has a perihelion of $65 \\pm 1$ au and semi-major axis of $1170 \\pm\n70$ au. The longitude of perihelion angle, $\\bar{\\omega}$, for 2015 TG387 is\nbetween that of Sedna and 2012 VP113, and thus similar to the main group of\nclustered extreme trans-Neptunian objects (ETNOs), which may be shepherded into\nsimilar orbital angles by an unknown massive distant planet, called Planet X or\nPlanet Nine. 2015 TG387's orbit is stable over the age of the solar system from\nthe known planets and Galactic tide. When including outside stellar encounters\nover 4 Gyrs, 2015 TG387's orbit is usually stable, but its dynamical evolution\ndepends on the stellar encounter scenarios used. Surprisingly, when including a\nmassive Planet X beyond a few hundred au on an eccentric orbit that is\nanti-aligned in longitude of perihelion with most of the known ETNOs, we find\n2015 TG387 is typically stable for Planet X orbits that render the other ETNOs\nstable as well. Notably, 2015 TG387's argument of perihelion is constrained and\nits longitude of perihelion librates about 180 degs from Planet X's longitude\nof perihelion, keeping 2015 TG387 anti-aligned with Planet X over the age of\nthe solar system. We find a power law slope near 3 for the semi-major axis\ndistribution of IOCs, meaning there are many more high than low semi-major axis\nIOCs. There are about 2 million IOCs larger than 40 km, giving a mass of\n$10^{22}$ kg. The IOCs inclination distribution is similar to the scattered\ndisk, with an average inclination of 19 degs.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We study in detail the recently proposed mechanism of generating superheavy\nDark Matter with the mass larger than the Hubble rate at the end of inflation.\nA real scalar field constituting Dark Matter linearly couples to the inflaton.\nAs a result of this interaction, the scalar gets displaced from its zero\nexpectation value. This offset feeds into the energy density of Dark Matter.\nThis mechanism is universal and can be implemented in a generic inflationary\nscenario. Phenomenology of the model is comprised of Dark Matter decay into\ninflatons, which in turn decay into Standard Model species triggering cascades\nof high energy particles contributing to the cosmic ray flux. We evaluate the\nlifetime of Dark Matter and obtain limits on the inflationary scenarios, where\nthis mechanism does not lead to the conflict with the Dark Matter stability\nconsiderations/studies of cosmic ray propagation.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  Privacy is a major concern in sharing human subject data to researchers for\nsecondary analyses. A simple binary consent (opt-in or not) may significantly\nreduce the amount of sharable data, since many patients might only be concerned\nabout a few sensitive medical conditions rather than the entire medical\nrecords. We propose event-level privacy protection, and develop a feature\nablation method to protect event-level privacy in electronic medical records.\nUsing a list of 13 sensitive diagnoses, we evaluate the feasibility and the\nefficacy of the proposed method. As feature ablation progresses, the\nidentifiability of a sensitive medical condition decreases with varying speeds\non different diseases. We find that these sensitive diagnoses can be divided\ninto 3 categories: (1) 5 diseases have fast declining identifiability (AUC\nbelow 0.6 with less than 400 features excluded); (2) 7 diseases with\nprogressively declining identifiability (AUC below 0.7 with between 200 and 700\nfeatures excluded); and (3) 1 disease with slowly declining identifiability\n(AUC above 0.7 with 1000 features excluded). The fact that the majority (12 out\nof 13) of the sensitive diseases fall into the first two categories suggests\nthe potential of the proposed feature ablation method as a solution for\nevent-level record privacy protection.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We resolved the hydrogen bond transition from the mode of ordinary water to\nits hydration in terms of its phonon stiffness (vibration frequency shift),\norder of fluctuation (line width), and number fraction (phonon abundance) upon\nchage injection by solvation.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  It is now well established that a Josephson junction made from conventional\nspin-singlet superconductors containing ferromagnetic layers can carry\nspin-triplet supercurrent under certain conditions. The first experimental\nsignature of that fact is the propagation of such supercurrent over long\ndistances through strong ferromagnetic materials. Surprisingly, one of the most\nsalient predictions of the theory has yet to be verified experimentally --\nnamely that a Josephson junction containing three magnetic layers with coplanar\nmagnetizations should exhibit a ground-state phase shift of either zero or pi\ndepending on the relative orientations of those magnetizations. Here we\ndemonstrate this property using Josephson junctions containing three different\ntypes of magnetic layers, chosen so that the magnetization of one layer can be\nswitched by 180 degrees without disturbing the other two. Phase-sensitive\ndetection is accomplished using a superconducting quantum interference device,\nor SQUID. Such a phase-controllable junction could be used as the memory\nelement in a fully-superconducting computer.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  Thermal Radiative Transfer (TRT) is the dominant energy transfer mechanism in\nhigh-energy density physics with applications in inertial confinement fusion\nand astrophysics. The stiff interactions between the material and radiation\nfields make TRT problems challenging to model. In this study, we propose a\nmulti-dimensional extension of the deterministic particle (DP) method. The DP\nmethod combines aspects from both particle and deterministic methods. If the\nemission source is known \\apriori, and no physical scattering is present, the\nintensity of a particle can be integrated analytically. This introduces no\nstatistical noise compared to Monte-Carlo methods, while maintaining the\nflexibility of particle methods. The method is closely related to the popular\nmethod of long characteristics. The combination of the DP-method with a\ndiscretely-consistent, nonlinear, gray low-order system enables an efficient\nsolution algorithm for multi-frequency TRT problems. We demonstrate with\nnumerical examples that the use of a linear-source approximation based on\nspatial moments improves the behavior of our method in the thick diffusion\nlimit significantly.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We consider a controlled evolution problem for a set\n$\\Omega(t)\\in\\mathbb{R}^d$, originally motivated by a model where a dog\ncontrols a flock of sheep. Necessary conditions and sufficient conditions are\ngiven, in order that the evolution be completely controllable. Similar\ntechniques are then applied to the approximation of a sweeping process. Under\nsuitable assumptions, we prove that there exists a control function such that\nthe corresponding evolution of the set $\\Omega(t)$ is arbitrarily close to the\none determined by the sweeping process.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Emerging reinforcement learning techniques using deep neural networks have\nshown great promise in control optimization. They harness non-local\nregularities of noisy control trajectories and facilitate transfer learning\nbetween tasks. To leverage these powerful capabilities for quantum control\noptimization, we propose a new control framework to simultaneously optimize the\nspeed and fidelity of quantum computation against both leakage and stochastic\ncontrol errors. For a broad family of two-qubit unitary gates that are\nimportant for quantum simulation of many-electron systems, we improve the\ncontrol robustness by adding control noise into training environments for\nreinforcement learning agents trained with trusted-region-policy-optimization.\nThe agent control solutions demonstrate a two-order-of-magnitude reduction in\naverage-gate-error over baseline stochastic-gradient-descent solutions and up\nto a one-order-of-magnitude reduction in gate time from optimal gate synthesis\ncounterparts.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We study ascending HNN-extensions $G$ of finitely generated free abelian\ngroups: examples of such $G$ include soluble Baumslag-Solitar groups and\nfundamental groups of orientable prime $3$-manifolds modelled on Sol geometry.\nIn particular, we study the elliptic subgroup $A \\leq G$, consisting of all\nelements that stabilise a point in the Bass-Serre tree of $G$. We consider the\ndensity of $A$ with respect to ball counting measures corresponding to finite\ngenerating sets of $G$, and we show that $A$ is exponentially negligible in $G$\nwith respect to such sequences of measures. As a consequence, we show that the\nset of tuples $(x_0,\\ldots,x_r) \\in G^{r+1}$, such that the $(r+1)$-fold simple\ncommutator $[x_0,\\ldots,x_r]$ vanishes, is exponentially negligible in\n$G^{r+1}$ with respect to sequences of ball counting measures.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In this note we show that the cosmological domain wall and the de Sitter\nquantum breaking problems complement each other in theories with discrete\nsymmetries that are spontaneously broken at low energies. Either the symmetry\nis exact and there is a domain wall problem, or it is approximate and there\nexists an inconsistent de Sitter minimum. This leaves no room for many\nextension of the Standard Model based on such discrete symmetries. We give some\nexamples that include NMSSM, spontaneous CP violation at the weak scale and\nsome versions of the Peccei-Quinn scenario with discrete symmetries.\n\n\n###\n\n", "completion": " 01"}
{"prompt": "  A star edge coloring of a graph $G$ is a proper edge coloring of $G$ such\nthat every path and cycle of length four in $G$ uses at least three different\ncolors. The star chromatic index of a graph $G$, is the smallest integer $k$\nfor which $G$ admits a star edge coloring with $k$ colors. In this paper, we\nfirst obtain some upper bounds for the star chromatic index of the Cartesian\nproduct of two graphs. We then determine the exact value of the star chromatic\nindex of $2$-dimensional grids. We also obtain some upper bounds on the star\nchromatic index of the Cartesian product of a path with a cycle,\n$d$-dimensional grids, $d$-dimensional hypercubes and $d$-dimensional toroidal\ngrids, for every positive integer $d$.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Dealing with Commercial off-the-shelf (COTS) com- ponents is a daily business\nfor avionic system manufacturers. They are necessary ingredients for hardware\ndesigns, but are not built in accordance with the avionics consensus standard\nDO- 254 for Airborne Electronic Hardware (AEH) design. Especially for complex\nCOTS hardware components used in safety critical AEH, like Microcontroller\nUnits (MCUs), additional assurance activities have to be performed. All of them\ntogether shall form a convincing confident, that the hardware is safe in its\nintended operation environment. The focus of DO-254 is one approach called\nDesign Assurance (DA). Its aim is to reduce design errors by adherence of\nprescribed process objectives for the entire design life cycle. The effort for\ncertain COTS assurance activities could be reduced if it is possible to\ndemonstrate, that the COTS design process is based on similar effective design\nprocess guide- lines to minimize desgin errors. In the last years,\nsemiconductor manufacturers released safety MCUs in compliance to the ISO 26262\nstandard, dedicated for the development of functional safe automotive systems.\nThese products are COTS components in the sense of avionics, but they are also\ndeveloped according to a process that focuses on reduction of design errors. In\nthis paper an evaluation is performed to figure out if the ISO 26262 prescribes\na similar DA approach as the DO-254, in order to reduce the COTS assurance\neffort for coming avionic systems.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Any germ of a complex analytic space is equipped with two natural metrics:\nthe outer metric induced by the hermitian metric of the ambient space and the\ninner metric, which is the associated riemannian metric on the germ. These two\nmetrics are in general nonequivalent up to bilipschitz homeomorphism. We give a\nnecessary and sufficient condition for a normal surface singularity to be\nLipschitz normally embedded (LNE), i.e., to have bilipschitz equivalent outer\nand inner metrics. In a partner paper [15] we apply it to prove that rational\nsurface singularities are LNE if and only if they are minimal.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Graph Drawing Beyond Planarity is a rapidly growing research area that\nclassifies and studies geometric representations of non-planar graphs in terms\nof forbidden crossing configurations. Aim of this survey is to describe the\nmain research directions in this area, the most prominent known results, and\nsome of the most challenging open problems.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  This paper presents the sparsifying preconditioner for the time-harmonic\nMaxwell's equations in the integral formulation. Following the work on\nsparsifying preconditioner for the Lippmann-Schwinger equation, this paper\ngeneralizes that approach from the scalar wave case to the vector case. The key\nidea is to construct a sparse approximation to the dense system by minimizing\nthe non-local interactions in the integral equation, which allows for applying\nsparse linear solvers to reduce the computational cost. When combined with the\nstandard GMRES solver, the number of preconditioned iterations remains small\nand essentially independent of the frequency. This suggests that, when the\nsparsifying preconditioner is adopted, solving the dense integral system can be\ndone as efficiently as solving the sparse system from PDE discretization.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  This paper presents a novel approach for indoor acoustic source localization\nusing microphone arrays and based on a Convolutional Neural Network (CNN). The\nproposed solution is, to the best of our knowledge, the first published work in\nwhich the CNN is designed to directly estimate the three dimensional position\nof an acoustic source, using the raw audio signal as the input information\navoiding the use of hand crafted audio features. Given the limited amount of\navailable localization data, we propose in this paper a training strategy based\non two steps. We first train our network using semi-synthetic data, generated\nfrom close talk speech recordings, and where we simulate the time delays and\ndistortion suffered in the signal that propagates from the source to the array\nof microphones. We then fine tune this network using a small amount of real\ndata. Our experimental results show that this strategy is able to produce\nnetworks that significantly improve existing localization methods based on\n\\textit{SRP-PHAT} strategies. In addition, our experiments show that our CNN\nmethod exhibits better resistance against varying gender of the speaker and\ndifferent window sizes compared with the other methods.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  A deep convolutional fuzzy system (DCFS) on a high-dimensional input space is\na multi-layer connection of many low-dimensional fuzzy systems, where the input\nvariables to the low-dimensional fuzzy systems are selected through a moving\nwindow across the input spaces of the layers. To design the DCFS based on\ninput-output data pairs, we propose a bottom-up layer-by-layer scheme.\nSpecifically, by viewing each of the first-layer fuzzy systems as a weak\nestimator of the output based only on a very small portion of the input\nvariables, we design these fuzzy systems using the WM Method. After the\nfirst-layer fuzzy systems are designed, we pass the data through the first\nlayer to form a new data set and design the second-layer fuzzy systems based on\nthis new data set in the same way as designing the first-layer fuzzy systems.\nRepeating this process layer-by-layer we design the whole DCFS. We also propose\na DCFS with parameter sharing to save memory and computation. We apply the DCFS\nmodels to predict a synthetic chaotic plus random time-series and the real Hang\nSeng Index of the Hong Kong stock market.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  We propose a novel mechanism for the production of gravitational waves in the\nearly Universe that originates from the relaxation processes induced by the QCD\nphase transition. While the energy density of the quark-gluon mean-field is\nmonotonously decaying in real time, its pressure undergoes a series of violent\noscillations at the characteristic QCD time scales that generates a primordial\nmulti-peaked gravitational waves' signal in the radio frequencies' domain. The\nsignal as an echo of the QCD phase transition, and is accessible by the FAST\nand SKA telescopes.\n\n\n###\n\n", "completion": " 07"}
{"prompt": "  We investigate the nonlocal dynamics of a single particle placed in an\ninfinite well with moving walls. It is shown that in this situation, the\nSchr\\\"odinger equation (SE) violates local causality by causing instantaneous\nchanges in the probability current everywhere inside the well. This violation\nis formalized by designing a gedanken faster-than-light communication device\nwhich uses an ensemble of long narrow cavities and weak measurements to resolve\nthe weak value of the momentum far away from the movable wall. Our system is\nfree from the usual features causing nonphysical violations of local causality\nwhen using the (nonrelativistic) SE, such as instantaneous changes in\npotentials or states involving arbitrarily high energies or velocities. We\nexplore in detail several possible artifacts that could account for the failure\nof the SE to respect local causality for systems involving time-dependent\nboundary conditions.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We propose a new recurrent generative model for generating images from text\ncaptions while attending on specific parts of text captions. Our model creates\nimages by incrementally adding patches on a \"canvas\" while attending on words\nfrom text caption at each timestep. Finally, the canvas is passed through an\nupscaling network to generate images. We also introduce a new method for\ngenerating visual-semantic sentence embeddings based on self-attention over\ntext. We compare our model's generated images with those generated Reed et.\nal.'s model and show that our model is a stronger baseline for text to image\ngeneration tasks.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  A recent laboratory experiment of ideal magnetohydrodynamic (MHD)\ninstabilities reveals four distinct eruption regimes readily distinguished by\nthe torus instability (TI) and helical kink instability (KI) parameters\n\\citep{Myers2015}. To establish its observational counterpart, we collect 38\nsolar flares (stronger than GOES class M5 in general) that took place within\n45$^{\\circ}$ of disk center during 2011$-$2017, 26 of which are associated with\na halo or partial halo coronal mass ejection (CME) (i.e., ejective events),\nwhile the others are CMEless (i.e., confined events). This is a complete sample\nof solar events satisfying our selection criteria detailed in the paper. For\neach event, we calculate decay index $n$ of the potential strapping field above\nthe magnetic flux rope (MFR) in and around the flaring magnetic polarity\ninversion line (a TI parameter), and the unsigned twist number $T_w$ of the\nnon-linear force-free (NLFF) field lines forming the same MFR (a KI parameter).\nWe then construct a $n-T_w$ diagram to investigate how the eruptiveness depends\non these parameters. We find: (1) $T_w$ appears to play little role in\ndiscriminating between confined and ejective events; (2) the events with\n$n\\gtrsim0.8$ are all ejective and all confined events have $n\\lesssim0.8$.\nHowever, $n\\gtrsim0.8$ is not a necessary condition for eruption, because some\nevents with $n\\lesssim0.8$ also erupted. In addition, we investigate the MFR's\ngeometrical parameters, apex height and distance between footpoints, as a\npossible factor for the eruptiveness. We briefly discuss the difference of the\npresent result for solar eruptions with that of the laboratory result in terms\nof the role played by magnetic reconnection.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  We study the spin transport phenomena in two-dimensional graphene-like\nmaterials with arbitrary tilted Dirac cones. The tilt arises due to\nnext-nearest hopping when the bottom of the conduction band and top of the\nvalence band does not simultaneously coincide at Dirac point. We consider\nnormal-ferromagnetic-normal (N-F-N) junction of the materials and using the\ngeneralized scattering approach calculate the spin current. Here, we show that\ntilting the Dirac cones can strongly change the transport properties by\nmodifying the period of oscillation of the spin current. The spin conductance\ncan be effectively tuned by the tilt with taking advantage of the modified\ninterference condition. A pure spin current reversal also possible with a\nsmooth variation of the tilting. We further study the spin current by the\nadiabatic precession of a doped ferromagnet on top of the material. It is shown\nthat the spin-mixing conductance and hence the spin current can become zero by\nturning the tilt of the Dirac cone. Our findings provide an efficient way\ntowards high controllability of spin transport by tuning the tilt of the\nferromagnetic junction and can be very useful in the field of spintronics. The\nmodel also presents a simplified way to measure the tilt of Dirac cone of those\nmaterials.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We prove q-analogues of two Ramanujan-type series for $1/\\pi$ from\n$q$-analogues of ordinary WZ pairs.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  We present an efficient quantum algorithm for some independent set problems\nin graph theory, based on non-abelian adiabatic mixing. We illustrate the\nperformance of our algorithm with analysis and numerical calculations for two\ndifferent types of graphs, with the number of edges proportional to the number\nof vertices or its square. The theoretical advantages of our quantum algorithm\nover classical algorithms are discussed. Non-abelian adiabatic mixing can be a\ngeneral technique to aid exploration in a landscape of near-degenerate ground\nstates.\n\n\n###\n\n", "completion": " 06"}
{"prompt": "  Convolutional neural networks(CNN) have been shown to perform better than the\nconventional stereo algorithms for stereo estimation. Numerous efforts focus on\nthe pixel-wise matching cost computation, which is the important building block\nfor many start-of-the-art algorithms. However, those architectures are limited\nto small and single scale receptive fields and use traditional methods for cost\naggregation or even ignore cost aggregation. Differently we take them both into\nconsideration. Firstly, we propose a new multi-scale matching cost computation\nsub-network, in which two different sizes of receptive fields are implemented\nparallelly. In this way, the network can make the best use of both variants and\nbalance the trade-off between the increase of receptive field and the loss of\ndetail. Furthermore, we show that our multi-dimension aggregation sub-network\nwhich containing 2D convolution and 3D convolution operations can provide rich\ncontext and semantic information for estimating an accurate initial disparity.\nFinally, experiments on challenging stereo benchmark KITTI demonstrate that the\nproposed method can achieve competitive results even without any additional\npost-processing.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We describe how the extension of a solver for linear differential equations\nby Kovacic's algorithm helps to improve a method to compute the inverse Mellin\ntransform of holonomic sequences. The method is implemented in the computer\nalgebra package HarmonicSums.\n\n\n###\n\n", "completion": " 00"}
{"prompt": "  One of the major goals of the NEXT-White (NEW) detector is to demonstrate the\nenergy resolution that an electroluminescent high pressure xenon TPC can\nachieve for high energy tracks. For this purpose, energy calibrations with\n137Cs and 232Th sources have been carried out as a part of the long run taken\nwith the detector during most of 2017. This paper describes the initial results\nobtained with those calibrations, showing excellent linearity and an energy\nresolution that extrapolates to approximately 1% FWHM at Q$_{\\beta\\beta}$.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Understanding phonon transport mechanisms in nanostructures is of great\nimportance for delicately tailoring thermal properties. Combining phonon\nparticle and wave effects through different strategies, previous studies have\nobtained ultra-low thermal conductivity in nanostructures. However, phonon\nparticle and wave effects are coupled together, that is their individual\ncontributions to phonon transport cannot be figured out. Here, we present how\nto quantify the particle and wave effects on phonon transport by combining\nMonte Carlo and atomic green function methods. We apply it to 1D silicon\nnanophononic metamaterial with cross-junctions, where it has been thought that\nthe wave effect was the main modulator to block phonon transport and the\nparticle effect was negligibly weak. Surprisingly, we find that the particle\neffect is quite significant as well and can contribute as much as 39% to the\ntotal thermal conductivity reduction. Moreover, the particle effect does not\ndecrease much as the cross section area (CSA) of the structure decreases and\nstill keeps quite strong even for CSA as small as 2.23 nm2. Further phonon\ntransmission analysis by reducing the junction leg length also qualitatively\ndemonstrates the strong particle effect. The results highlight the importance\nof mutually controlling particle and wave characteristics, and the\nmethodologies for quantifying phonon particle and wave effect are important for\nphonon engineering by nanostructuring.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Given a finite generating set $T=\\{g_0,\\dots, g_n\\}$ of a group $G$, and a\nrepresentation $\\rho$ of $G$ on a Hilbert space $V$, we investigate how the\ngeometry of the set $D(T,\\rho)=\\{ [x_0 : \\dots : x_n] \\in\\mathbb C\\mathbb P^n\n\\mid \\sum x_i\\rho(g_i) \\text{ not invertible} \\}$ reflects the properties of\n$\\rho$. When $V$ is finite-dimensional this is an algebraic hypersurface in\n$\\mathbb C\\mathbb P^n$. In the special case $T=G$ and $\\rho=$ the left regular\nrepresentation of $G$, this hypersurface is defined by the \\emph{group\ndeterminant}, an object studied extensively in the founding work of Frobenius\nthat lead to the creation of representation theory. We focus on the classic\ncase when $G$ is a finite Coxeter group, and make $T$ by adding the identity\nelement $1_G$ to a Coxeter generating set for $G$. Under these assumptions we\nshow in our first main result that if $\\rho$ is the left regular\nrepresentation, then $D(T,\\rho)$ determines the isomorphism class of $G$. Our\nsecond main result is that if $G$ is not of exceptional type, and $\\rho$ is any\nfinite dimensional representation, then $D(T,\\rho)$ determines $\\rho$.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  In the high-scale (split) MSSM, the measured Higgs mass sets an upper bound\non the supersymmetric scalar mass scale MSUSY around $10^{11}$ ($10^{8}$) GeV,\nfor $\\tan\\beta$ in the standard range and the central value of the top quark\nmass $m_t$. This article discusses how maximal MSUSY is affected by negative\nthreshold corrections to the quartic Higgs coupling arising from the sbottom\nand stop trilinear couplings. In the high-scale MSSM with very high\n$\\tan\\beta$, the electroweak vacuum decay due to the large bottom Yukawa\ncoupling rules out the possibility of raising MSUSY beyond the above limit. In\ncases with large $A_b$ or $A_t$, MSUSY as a common mass of the extra fermions\nand scalars can be as high as $10^{17}$ GeV remaining consistent with $m_h$ and\nthe vacuum longevity if $m_t$ is smaller than the central value by $2\\sigma$.\nFor the central value of $m_t$, the upper limit on MSUSY does not change very\nmuch owing to the metastability, which is the case also in the split MSSM even\nwith $\\pm 2\\sigma$ variations in $m_t$.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  We extend the injectivity theorem of Esnault and Viehweg to a class of\nnon-normal log varieties, which contains normal crossings log varieties, and is\nclosed under the operation of taking the $\\LCS$ locus.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  CO is commonly used as a tracer of the total gas mass in both the\ninterstellar medium and in protoplanetary disks. Recently there has been much\ndebate about the utility of CO as a mass tracer in disks. Observations of CO in\nprotoplanetary disks reveal a range of CO abundances, with measurements of low\nCO to dust mass ratios in numerous systems. One possibility is that carbon is\nremoved from CO via chemistry. However, the full range of physical conditions\nconducive to this chemical reprocessing is not well understood. We perform a\nsystematic survey of the time dependent chemistry in protoplanetary disks for\n198 models with a range of physical conditions. We varying dust grain size\ndistribution, temperature, comic ray and X-ray ionization rate, disk mass, and\ninitial water abundance, detailing what physical conditions are necessary to\nactivate the various CO depletion mechanisms in the warm molecular layer. We\nfocus our analysis on the warm molecular layer in two regions: the outer disk\n(100 au) well outside the CO snowline and the inner disk (19 au) just inside\nthe midplane CO snow line. After 1 Myr, we find that the majority of models\nhave a CO abundance relative to H$_2$ less than $10^{-4}$ in the outer disk,\nwhile an abundance less than $10^{-5}$ requires the presence of cosmic rays.\nInside the CO snow line, significant depletion of CO only occurs in models with\na high cosmic ray rate. If cosmic rays are not present in young disks it is\ndifficult to chemically remove carbon from CO. Additionally, removing water\nprior to CO depletion impedes the chemical processing of CO. Chemical\nprocessing alone cannot explain current observations of low CO abundances.\nOther mechanisms must also be involved.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  The Event Horizon Telescope is a millimeter VLBI array that aims to take the\nfirst pictures of the black holes in the center of the Milky Way and of the M87\ngalaxy, with horizon scale resolution. Measurements of the shape and size of\nthe shadows cast by the black holes on the surrounding emission can test the\ncosmic censorship conjecture and the no-hair theorem and may find evidence for\nclassical effects of the quantum structure of black holes. Observations of\ncoherent structures in the accretion flows may lead to accurate measurements of\nthe spins of the black holes and of other properties of their spacetimes. For\nSgr A*, the black hole in the center of the Milky Way, measurements of the\nprecession of stellar orbits and timing monitoring of orbiting pulsars offer\ncomplementary avenues to the gravitational tests with the Event Horizon\nTelescope.\n\n\n###\n\n", "completion": " 07"}
{"prompt": "  Given a compact set $K$ one may define a transfinite diameter for $K$ via a\nlimiting process involving maximising a Vandermonde determinant over $K$ with\nrespect to a monomial basis. Different transfinite diameters may be obtained by\nusing different polynomial bases in the Vandermonde determinant calculation. We\nshow that if these bases are sufficiently similar that the transfinite diameter\nof $K$ is unchanged. Utilising this result we show that the transfinite\ndiameters defined by Cox-Ma`u and Berman-Boucksom for algebraic varieties are\nequal.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  The Madelung transform is known to relate Schr\\\"odinger-type equations in\nquantum mechanics and the Euler equations for barotropic-type fluids. We prove\nthat, more generally, the Madelung transform is a K\\\"ahler map (i.e. a\nsymplectomorphism and an isometry) between the space of wave functions and the\ncotangent bundle to the density space equipped with the Fubini-Study metric and\nthe Fisher-Rao information metric, respectively. We also show that Fusca's\nmomentum map property of the Madelung transform is a manifestation of the\ngeneral approach via reduction for semi-direct product groups. Furthermore, the\nHasimoto transform for the binormal equation turns out to be the 1D case of the\nMadelung transform, while its higher-dimensional version is related to the\nproblem of conservation of the Willmore energy in binormal flows.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  User demand for blocking advertising and tracking online is large and\ngrowing. Existing tools, both deployed and described in research, have proven\nuseful, but lack either the completeness or robustness needed for a general\nsolution. Existing detection approaches generally focus on only one aspect of\nadvertising or tracking (e.g. URL patterns, code structure), making existing\napproaches susceptible to evasion.\n  In this work we present AdGraph, a novel graph-based machine learning\napproach for detecting advertising and tracking resources on the web. AdGraph\ndiffers from existing approaches by building a graph representation of the HTML\nstructure, network requests, and JavaScript behavior of a webpage, and using\nthis unique representation to train a classifier for identifying advertising\nand tracking resources. Because AdGraph considers many aspects of the context a\nnetwork request takes place in, it is less susceptible to the single-factor\nevasion techniques that flummox existing approaches.\n  We evaluate AdGraph on the Alexa top-10K websites, and find that it is highly\naccurate, able to replicate the labels of human-generated filter lists with\n95.33% accuracy, and can even identify many mistakes in filter lists. We\nimplement AdGraph as a modification to Chromium. AdGraph adds only minor\noverhead to page loading and execution, and is actually faster than stock\nChromium on 42% of websites and AdBlock Plus on 78% of websites. Overall, we\nconclude that AdGraph is both accurate enough and performant enough for online\nuse, breaking comparable or fewer websites than popular filter list based\napproaches.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  We investigate the production and decays of doubly-charged Higgs bosons for\nthe Type-II seesaw mechanism at an $e^{+} e^{-}$ collider with two center of\nmass energies, $\\sqrt{s}=380$ GeV and 3 TeV, and analyze the fully hadronic\nfinal states in detail. Lower mass ranges can be probed during the 380 GeV run\nof the collider, while high mass ranges, which are beyond the 13 TeV Large\nHadron Collider discovery reach, can be probed with $\\sqrt{s}=3$ TeV. For such\na heavy Higgs boson, the final decay products are collimated, resulting in\nfat-jets. We perform a substructure analysis to reduce the background and find\nthat a doubly-charged Higgs boson in the mass range 800-1120 GeV can be\ndiscovered during the 3 TeV run, with integrated luminosity $\\mathcal{L} \\sim\n95\\, \\rm{fb}^{-1}$ of data. For 380 GeV center of mass energy, we find that for\nthe doubly-charged Higgs boson in the range 160-172 GeV, a $5\\sigma$\nsignificance can be achieved with only integrated luminosity $\\mathcal{L} \\sim\n24 \\, \\rm{fb}^{-1}$. Therefore, a light Higgs boson can be discovered\nimmediately during the run of a future $e^{+} e^{-}$ collider.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We study optimal distributed first-order optimization algorithms when the\nnetwork (i.e., communication constraints between the agents) changes with time.\nThis problem is motivated by scenarios where agents experience network\nmalfunctions. We provide a sufficient condition that guarantees a convergence\nrate with optimal (up lo logarithmic terms) dependencies on the network and\nfunction parameters if the network changes are constrained to a small\npercentage $\\alpha$ of the total number of iterations. We call such networks\nslowly time-varying networks. Moreover, we show that Nesterov's method has an\niteration complexity of $\\Omega \\big( \\big(\\sqrt{\\kappa_\\Phi \\cdot \\bar{\\chi}}\n+ \\alpha \\log(\\kappa_\\Phi \\cdot \\bar{\\chi})\\big) \\log(1 / \\varepsilon)\\big)$\nfor decentralized algorithms, where $\\kappa_\\Phi$ is condition number of the\nobjective function, and $\\bar\\chi$ is a worst case bound on the condition\nnumber of the sequence of communication graphs. Additionally, we provide an\nexplicit upper bound on $\\alpha$ in terms of the condition number of the\nobjective function and network topologies.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We have investigated the thorium (Th) abundance in a sample of 53 thin disc\nsolar twins covering a wide range of ages. These data provide constrains on the\nmantle energy budget of terrestrial planets that can be formed over the\nevolution of the Galaxy's thin disc. We have estimated Th abundances with an\naverage precision of 0.025\\,dex (in both [Th/H] and [Th/Fe]) through\ncomprehensive spectral synthesis of a Th\\,II line present at 4019.1290\\,{\\AA},\nusing very high resolution (R\\,=\\,115,000) high quality HARPS spectra obtained\nat the ESO La Silla Observatory. We have confirmed that there is a large energy\nbudget from Th decay for maintaining mantle convection inside potential rocky\nplanets around solar twins, from the Galactic thin disc formation until now,\nbecause the pristine [Th/H]$_{\\rm ZAMS}$ is super-solar on average under a\nuniform dispersion of 0.056\\,dex (varying from +0.037 up to +0.138\\,dex based\non linear fits against isochrone stellar age). Comparing to neodymium (Nd) and\neuropium (Eu), two others neutron-capture elements, the stellar pristine\nabundance of Th follows Eu along the Galactic thin disc evolution, but it does\nnot follow Nd, probably because neodymium has a significant contribution from\nthe $s$-process (about 60\\,per\\,cent).\n\n\n###\n\n", "completion": " 04"}
{"prompt": "  Modification of the photon dispersion relation in chiral matter enables $1\\to\n2$ scattering. As a result, the single fermion and photon states are unstable\nto photon radiation and pair production respectively. In particular, a fast\nfermion moving through chiral matter can spontaneously radiate a photon, while\na photon can spontaneously radiate a fast fermion and anti-fermion pair. The\ncorresponding spectra are derived in the ultra-relativistic approximation. It\nis shown that the polarization of the produced and decayed photons is\ndetermined by the sign of the chiral conductivity. Impact of a flat thin domain\nwall on the spectra is computed.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  We investigate quantum authentication schemes constructed from quantum\nerror-correcting codes. We show that if the code has a property called purity\ntesting, then the resulting authentication scheme guarantees the integrity of\nciphertexts, not just plaintexts. On top of that, if the code is strong purity\ntesting, the authentication scheme also allows the encryption key to be\nrecycled, partially even if the authentication rejects. Such a strong notion of\nauthentication is useful in a setting where multiple ciphertexts can be present\nsimultaneously, such as in interactive or delegated quantum computation. With\nthese settings in mind, we give an explicit code (based on the trap code) that\nis strong purity testing but, contrary to other known strong-purity-testing\ncodes, allows for natural computation on ciphertexts.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Graphite has been one of the promising materials in diverse application\ndomains owing to its high conductivity, tunability into different structures\nand mechanical strength its. The effectiveness of graphite and its derivatives\nhas been studied for electromagnetic domains as well. Pencil strokes on paper\ncreate a film of graphite composites which is reported to be useful for\nfabrication of electronic components. In our study, we extend use of pencil\ntraces on paper for studying its electromagnetic properties. The pencil traces\non paper is facile method of coating graphite composite films with relatively\nlower cost and ease of processing. The interaction of electromagnetic wave with\ngraphite composites produces in modulation of the incident RF power. The RF\npower was observed to get attenuated with pencil coating on paper as compared\nto plain paper. The attenuation increased with increasing the signal frequency.\nFurther, stacking more pencil coated papers onto each other results in\nincreasing attenuation factor. Additionally, these pencil coated paper roll was\nable to attenuate the incoming noise signals in the radio signal reception.\nThis demonstrates potential ability of pencil coated papers to be used for\nsmall RF power attenuation applications.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  The hierarchy of channel networks in landscapes displays features that are\ncharacteristic of non-equilibrium complex systems. Here we show that a sequence\nof increasingly complex ridge and valley networks is produced by a system of\npartial differential equations coupling landscape evolution dynamics with a\nspecific catchment area equation. By means of a linear stability analysis we\nidentify the critical conditions triggering channel formation and the emergence\nof characteristic valley spacing. The ensuing channelization cascade, described\nby a dimensionless number accounting for diffusive soil creep, runoff erosion,\nand tectonic uplift, is reminiscent of the subsequent instabilities in fluid\nturbulence, while the structure of the simulated patterns is indicative of a\ntendency to evolve toward optimal configurations, with anomalies similar to\ndislocation defects observed in pattern-forming systems. The choice of specific\ngeomorphic transport laws and boundary conditions strongly influences the\nchannelization cascade, underlying the nonlocal and nonlinear character of its\ndynamics.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Dual structures on causal sets called timelets are introduced, being discrete\nanalogs of global time coordinates. Algebraic and geometrical features of the\nset of timelets on a causal set are studied. A characterization of timelets in\nterms of incidence matrix of causal set is given. The connection between\ntimelets and preclusive coevents is established, it is shown that any timelet\nhas a unique decomposition over preclusive coevents. The equivalence classes of\ntimelets with respect to reascaling are shown to form a simplicial complex.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Quantum open systems evolve according to completely positive, trace\npreserving maps acting on the density operator, which can equivalently be\nunraveled in term of so-called quantum trajectories. These stochastic sequences\nof pure states correspond to the actual dynamics of the quantum system during\nsingle realizations of an experiment in which the system's environment is\nmonitored. In this chapter, we present an extension of stochastic\nthermodynamics to the case of open quantum systems, which builds on the analogy\nbetween the quantum trajectories and the trajectories in phase space of\nclassical stochastic thermodynamics. We analyze entropy production, work and\nheat exchanges at the trajectory level, identifying genuinely quantum\ncontributions due to decoherence induced by the environment. We present three\nexamples: the thermalization of a quantum system, the fluorescence of a driven\nqubit and the continuous monitoring of a qubit's observable.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Clinical Named Entity Recognition (CNER) aims to identify and classify\nclinical terms such as diseases, symptoms, treatments, exams, and body parts in\nelectronic health records, which is a fundamental and crucial task for clinical\nand translational research. In recent years, deep neural networks have achieved\nsignificant success in named entity recognition and many other Natural Language\nProcessing (NLP) tasks. Most of these algorithms are trained end to end, and\ncan automatically learn features from large scale labeled datasets. However,\nthese data-driven methods typically lack the capability of processing rare or\nunseen entities. Previous statistical methods and feature engineering practice\nhave demonstrated that human knowledge can provide valuable information for\nhandling rare and unseen cases. In this paper, we address the problem by\nincorporating dictionaries into deep neural networks for the Chinese CNER task.\nTwo different architectures that extend the Bi-directional Long Short-Term\nMemory (Bi-LSTM) neural network and five different feature representation\nschemes are proposed to handle the task. Computational results on the CCKS-2017\nTask 2 benchmark dataset show that the proposed method achieves the highly\ncompetitive performance compared with the state-of-the-art deep learning\nmethods.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Retinal images have the highest resolution and clarity among medical images.\nThus, vessel analysis in retinal images may facilitate early diagnosis and\ntreatment of many chronic diseases. In this paper, we propose a novel\nmulti-scale residual convolutional neural network structure based on a\n\\emph{scale-space approximation (SSA)} block of layers, comprising subsampling\nand subsequent upsampling, for multi-scale representation. Through analysis in\nthe frequency domain, we show that this block structure is a close\napproximation of Gaussian filtering, the operation to achieve scale variations\nin scale-space theory. Experimental evaluations demonstrate that the proposed\nnetwork outperforms current state-of-the-art methods. Ablative analysis shows\nthat the SSA is indeed an important factor in performance improvement.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We examine catalogs of white dwarfs (WDs) and find that there are sufficient\nnumber of massive WDs, M_WD > 1.35Mo, that might potentially explode as type Ia\nsupernovae (SNe Ia) in the frame of the core degenerate scenario. In the core\ndegenerate scenario a WD merges with the carbon-oxygen core of a giant star,\nand they form a massive WD that might explode with a time delay of years to\nbillions of years. If the core degenerate scenario accounts for all SNe Ia,\nthen we calculate that about 0.2 per cent of the present WDs in the Galaxy are\nmassive. Furthermore, we find from the catalogs that the fraction of massive\nWDs relative to all WDs is about 1-3 per cent, with large uncertainties.\nNamely, five to ten times the required number. If there are many SNe Ia that\nresult from lower mass WDs, M_WD < 1.3Mo, for which another scenario is\nresponsible for, and the core degenerate scenario accounts only for the SNe Ia\nthat explode as massive WDs, then the ratio of observed massive WDs to required\nis larger even. Our finding leaves the core degenerate scenario as a viable and\npromising SN Ia scenario.\n\n\n###\n\n", "completion": " 02"}
{"prompt": "  Gaussian processes (GPs) with derivatives are useful in many applications,\nincluding Bayesian optimization, implicit surface reconstruction, and terrain\nreconstruction. Fitting a GP to function values and derivatives at $n$ points\nin $d$ dimensions requires linear solves and log determinants with an ${n(d+1)\n\\times n(d+1)}$ positive definite matrix -- leading to prohibitive\n$\\mathcal{O}(n^3d^3)$ computations for standard direct methods. We propose\niterative solvers using fast $\\mathcal{O}(nd)$ matrix-vector multiplications\n(MVMs), together with pivoted Cholesky preconditioning that cuts the iterations\nto convergence by several orders of magnitude, allowing for fast kernel\nlearning and prediction. Our approaches, together with dimensionality\nreduction, enables Bayesian optimization with derivatives to scale to\nhigh-dimensional problems and large evaluation budgets.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Detecting the cosmological sky-averaged (global) 21 cm signal as a function\nof observed frequency will provide a powerful tool to study the ionization and\nthermal history of the intergalactic medium (IGM) in the early Universe ($\\sim$\n400 million years after the Big Bang). The greatest challenge in conventional\ntotal-power global 21 cm experiments is the removal of the foreground\nsynchrotron emission ($\\sim 10^3$-$10^4$ K) to uncover the weak cosmological\nsignal (tens to hundreds of mK), especially since the intrinsic smoothness of\nthe foreground spectrum is corrupted by instrumental effects. Although the\nEDGES team has recently reported an absorption profile at 78 MHz in the\nsky-averaged spectrum, it is necessary to confirm this detection with an\nindependent approach. The projection effect from observing anisotropic\nforeground source emission with a wide-view antenna pointing at the North\nCelestial Pole (NCP) can induce a net polarization, referred as the\nProjection-Induced Polarization Effect (PIPE). Due to Earth's rotation,\nobservation centered at the circumpolar region will impose a dynamic sky\nmodulation on the net polarization's waveforms which is unique to the\nforeground component. In this study, we review the implementation practicality\nand underlying instrumental effects of this new polarimetry-based technique\nwith detailed numerical simulation and a testbed instrument, the Cosmic\nTwilight Polarimeter (CTP). In addition, we explore an SVD-based analysis\napproach for separating the foreground and instrumental effects from the\nbackground global 21 cm signal using the sky-modulated PIPE.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Maxwell equations generally explain the propagation of light through an\narbitrary medium by using wave mechanics. However, scientific evidence since\nNewton suggest a discrete interpretation of light more generally explains its\nnature. This interpretation lends itself well to the discrete form of computer\nsimulation. While current simulations attempt to discretize Maxwell equations,\nwe present an inherently discrete physical model of light propagation that\nnaturally forms a causal space-time scattering network (STSN). STSN has the\ntopology of neural networks, inverse design and tomography based on STSN can be\nreadily implemented in a variety of software and hardware that are optimized\nfor deep learning. Also, STSN inherently includes the physics of light\npropagation, and hence the number of unknown weights in STSN is at a minimum.\nWe show this property leads to orders of magnitude smaller number of unknown\nweights, and a much faster convergence, compared with inverse design methods\nusing conventional neural networks. In addition, the intrinsic presence of\nspace-time fabric in STSN allows time-dependent inverse design and tomography.\nWe show examples of the fast convergence of STSN in predicting time-dependent\nindex profiles while avoiding approximations typically used.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We report the discovery of a new actinide-boost star, 2MASS\nJ09544277+5246414, originally identified as a very bright (V = 10.1), extremely\nmetal-poor ([Fe/H] = -2.99) K giant in the LAMOST survey, and found to be\nhighly r-process-enhanced (r-II; [Eu/Fe]= +1.28]), during the snapshot phase of\nthe R-Process Alliance (RPA). Based on a high S/N, high-resolution spectrum\nobtained with the Harlan J. Smith 2.7-m telescope, this star is the first\nconfirmed actinide-boost star found by RPA efforts. With an enhancement of\n[Th/Eu] = +0.37, 2MASS J09544277+5246414 is also the most actinide-enhanced\nr-II star yet discovered, and only the sixth metal-poor star with a measured\nuranium abundance ([U/Fe] = +1.40). Using the Th/U chronometer, we estimate an\nage of 13.0+/-4.7 Gyr for this star. The unambiguous actinide-boost signature\nof this extremely metal-poor star, combined with additional r-process-enhanced\nand actinide-boost stars identified by the RPA, will provide strong constraints\non the nature and origin of the r-process at early times.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  A new design of a detector plane of sub-millimetre thickness for an\nelectromagnetic sampling calorimeter is presented. It is intended to be used in\nthe luminometers LumiCal and BeamCal in future linear $e^+e^-$ collider\nexperiments. The detector planes were produced utilising novel connectivity\nscheme technologies. They were installed in a compact prototype of the\ncalorimeter and tested at DESY with an electron beam of energy 1-5 GeV. The\nperformance of a prototype of a compact LumiCal comprising eight detector\nplanes was studied. The effective Moli`ere radius at 5 GeV was determined to be\n(8.1 +/- 0.1 (stat) +/- 0.3 (syst)) mm, a value well reproduced by the Monte\nCarlo (MC) simulation (8.4 +/- 0.1) mm. The dependence of the effective\nMoli`ere radius on the electron energy in the range 1-5 GeV was also studied.\nGood agreement was obtained between data and MC simulation.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  We present CGO-AS, a generalized Ant System (AS) implemented in the framework\nof Cooperative Group Optimization (CGO), to show the leveraged optimization\nwith a mixed individual and social learning. Ant colony is a simple yet\nefficient natural system for understanding the effects of primary intelligence\non optimization. However, existing AS algorithms are mostly focusing on their\ncapability of using social heuristic cues while ignoring their individual\nlearning. CGO can integrate the advantages of a cooperative group and a\nlow-level algorithm portfolio design, and the agents of CGO can explore both\nindividual and social search. In CGO-AS, each ant (agent) is added with an\nindividual memory, and is implemented with a novel search strategy to use\nindividual and social cues in a controlled proportion. The presented CGO-AS is\ntherefore especially useful in exposing the power of the mixed individual and\nsocial learning for improving optimization. The optimization performance is\ntested with instances of the Traveling Salesman Problem (TSP). The results\nprove that a cooperative ant group using both individual and social learning\nobtains a better performance than the systems solely using either individual or\nsocial learning. The best performance is achieved under the condition when\nagents use individual memory as their primary information source, and\nsimultaneously use social memory as their searching guidance. In comparison\nwith existing AS systems, CGO-AS retains a faster learning speed toward those\nhigher-quality solutions, especially in the later learning cycles. The leverage\nin optimization by CGO-AS is highly possible due to its inherent feature of\nadaptively maintaining the population diversity in the individual memory of\nagents, and of accelerating the learning process with accumulated knowledge in\nthe social memory.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  One of the most fascinating topics in current quantum physics are hybridised\nsystems, in which different quantum resonators are strongly coupled. Prominent\nexamples are circular resonators with high quality factors that allow the\ncoupling of optical whispering gallery modes to microwave cavities or magnon\nresonances in optomagnonics. Whispering gallery modes play a special role in\nthis endeavour because of their high quality factor and strong localisation,\nwhich ultimately increases the overlap of the wavefunctions of quantum\nparticles in hybridised systems. The hybridisation with magnons, the collective\nquantum excitations of the electron spins in a magnetically ordered material,\nis of particular interest because magnons can take over two functionalities:\ndue to their collective nature they are robust and can serve as a quantum\nmemory and, moreover, they can act as a wavelength converter between microwave\nand THz photons. However, the observation of whispering gallery magnons has not\nyet been achieved due to the lack of efficient excitation schemes for magnons\nwith large wave vectors in a circular geometry. To tackle this problem, we\nstudied nonlinear 3-magnon scattering as a means to generate whispering gallery\nmagnons. This Letter discusses the basics of this nonlinear mechanism in a\nconfined, circular geometry from experimental and theoretical point of view.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  In this paper, we investigate the geodesic motion of massive and massless\ntest particles in the vicinity of a black hole space-time surrounded by perfect\nfluid (quintessence, dust, radiation, cosmological constant and phantom) in\nRastall theory. We obtain the full set of analytical solutions of the geodesic\nequation of motion in the space-time of this black hole. For all cases of\nperfect fluid, we consider some different values of Rastall coupling constant\n$k\\lambda$ so that the equations of motion have integer powers of $\\tilde{r}$\nand also can be solved analytically. These analytical solutions are presented\nin the form of elliptic and also hyperelliptic functions. In addition, using\nobtained analytical solution and also figures of effective potential and\n$L-E^2$ diagrams, we plot some examples of possibles orbits. moreover we use of\nthe angular momentum, conserved energy, electrical charge and also Rastall\nparameter, to classify the different types of the possible gained orbits.\nMoreover, we show that when Rastall field structure constant becomes zero\n($N=0$) our results are consistent with the analysis of a Reissner-Nordstr\\\"om\nblack hole, however when both Rastall geometric parameter and electric charge\nvanish $(N=Q=0)$, the metric and results are same as analysis of a\nSchwarzschild black hole.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  In this paper, we propose a joint dynamic power control and user pairing\nalgorithm for power-efficient and low-latency hybrid multiple access systems.\nIn a hybrid multiple access system, user pairing determines whether the\ntransmitter should serve a certain user by orthogonal multiple access (OMA) or\nnon-orthogonal multiple access (NOMA). The proposed optimization framework\nminimizes the long-term time-average transmit power expenditure while reducing\nthe queueing delay and satisfying time-average data rate requirements. The\nproposed technique observes channel and queue state information and adjusts\nqueue backlogs to avoid an excessive queueing delay by appropriate user pairing\nand power allocation. Further, user scheduling for determining the activation\nof a given user link as well as flexible use of resources are captured in the\nproposed algorithm. Data-intensive simulation results show that the proposed\nscheme guarantees an end-to-end delay smaller than 1 ms with high\npower-efficiency and high reliability, based on the short frame structure\ndesigned for ultra-reliable low-latency communications (URLLC).\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We generalize the swampland criterion forbidding stable non-supersymmetric\nAdS vacua and propose a new swampland conjecture forbidding stable\nnon-supersymmetric \"locally AdS\" warped throats. The conjecture is motivated by\nthe properties of systems of fractional D3-branes at singularities, and can be\nused to rule out large classes of warped throats with supersymmetry breaking\ningredients, and their possible application to de Sitter uplift. In particular,\nthis allows to reinterpret the runaway instabilities of the gravity dual of\nfractional branes in the dP$_1$ theory, and to rule out warped throats with\nDynamical Supersymmetry Breaking D-brane sectors at their bottom. We also\ndiscuss the instabilities of warped throats with supersymmetry broken by the\nintroduction of anti-orientifold planes. These examples lead to novel decay\nmechanisms in explicit non-supersymmetric examples of locally AdS warped\nthroats, and also of pure AdS backgrounds.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  A spreading process on a network is influenced by the network's underlying\nspatial structure, and it is insightful to study the extent to which a\nspreading process follows such structure. We consider a threshold contagion\nmodel on a network whose nodes are embedded in a manifold and which has both\n`geometric edges', which respect the geometry of the underlying manifold, and\n`nongeometric edges' that are not constrained by that geometry. Building on\nideas from Taylor et al. \\cite{Taylor2015}, we examine when a contagion\npropagates as a wave along a network whose nodes are embedded in a torus and\nwhen it jumps via long nongeometric edges to remote areas of the network. We\nbuild a `contagion map' for a contagion spreading on such a `noisy geometric\nnetwork' to produce a point cloud; and we study the dimensionality, geometry,\nand topology of this point cloud to examine qualitative properties of this\nspreading process. We identify a region in parameter space in which the\ncontagion propagates predominantly via wavefront propagation. We consider\ndifferent probability distributions for constructing nongeometric edges --\nreflecting different decay rates with respect to the distance between nodes in\nthe underlying manifold -- and examine the effect of such choices on the\nqualitative properties of the spreading dynamics. Our work generalizes the\nanalysis in Taylor et al. and consolidates contagion maps both as a tool for\ninvestigating spreading behavior on spatial networks and as a technique for\nmanifold learning.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We reconsider the theory of Hall effect in the systems with hopping\nconduction. The purpose of the present study is to compare the percolation\napproach based on the optimal triad model with numerical simulations and recent\nexperimental results. We show that, in the nearest neighbor hopping regime, the\nresults of the percolation theory agree to the simulation. However, in the\nvariable range hopping (VRH) regime, the optimal triad model fails to describe\nthe numerical results. It is related to the extremely small probability to find\nthe optimal triad of sites in the percolation cluster in the VRH regime. The\ncontribution of these triads to the Hall effect appears to be small. We\ndescribe the Hall mobility in the VRH regime with the empirical law obtained\nfrom the numerical results. The law is in agreement with our recent\nexperimental data in 2D quantum dot arrays with the hopping transport.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  Let $G$ be a locally compact totally disconnected topological group. Under a\nnecessary mild assumption, we show that the irreducible unitary representations\nof $G$ are uniformly admissible if and only if the irreducible smooth\nrepresentations of $G$ are uniformly admissible. We also show that the latter\nproperty is inherited by finite-index subgroups and overgroups of $G$.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Kolmogorov $n$-widths and Hankel singular values are two commonly used\nconcepts in model reduction. Here we show that for the special case of linear\ntime-invariant dynamical (LTI) systems, these two concepts are directly\nconnected. More specifically, the greedy search applied to the Hankel operator\nof an LTI system resembles the minimizing subspace for the Kolmogorov n-width\nand the Kolmogorov $n$-width of an LTI system equals its $(n+1)st$ Hankel\nsingular value once the subspaces are appropriately defined. We also establish\na lower bound for the Kolmorogov $n$-width for parametric LTI systems and\nillustrate that the method of active subspaces can be viewed as the dual\nconcept to the minimizing subspace for the Kolmogorov $n$-width.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Hydrogen atoms absorbed by metals in the hydrogen-containing environments can\nlead to the premature fracture of the metal components used in load-bearing\nconditions. Since metals used in practice are mostly polycrystalline, grain\nboundaries (GBs) can play an important role in hydrogen embrittlement of\nmetals. Here we show that the reaction of GB with lattice dislocations is a key\ncomponent in hydrogen embrittlement mechanism for polycrystalline metals. We\nuse atomistic modeling methods to investigate the mechanical response of GBs in\nalpha-iron with various hydrogen concentrations. Analysis indicates that\ndislocations impingement and emission on the GB cause the GB to locally\ntransform into an activated state with a more disordered atomistic structure,\nand introduce a local stress concentration. The activation of the GB segregated\nwith hydrogen atoms can greatly facilitate decohesion of the GB. We show that\nthe hydrogen embrittlement model proposed here can give better explanation of\nmany experimental observations.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  We study the dynamics of 2+1 dimensional theories with ${\\cal N}=1$\nsupersymmetry. In these theories the supersymmetric ground states behave\ndiscontinuously at co-dimension one walls in the space of couplings, with new\nvacua coming in from infinity in field space. We show that the dynamics near\nthese walls is calculable: the two-loop effective potential yields exact\nresults about the ground states near the walls. Far away from the walls the\nground states can be inferred by decoupling arguments. In this way, we are able\nto follow the ground states of ${\\cal N}=1$ theories in 2+1 dimensions and\nconstruct the infrared phases of these theories. We study two examples in\ndetail: Adjoint SQCD and SQCD with one fundamental quark. In Adjoint QCD we\nshow that for sufficiently small Chern-Simons level the theory has a\nnon-perturbative metastable supersymmetry-breaking ground state. We also\nbriefly discuss the critical points of this theory. For SQCD with one quark we\nestablish an infrared duality between a $U(N)$ gauge theory and an $SU(N)$\ngauge theory. The duality crucially involves the vacua that appear from\ninfinity near the walls.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  It is widely accepted that astrophysical magnetic fields are generated by\ndynamo action. In many cases these fields exhibit organisation on a scale\nlarger than that of the underlying turbulent flow (e.g., the eleven-year solar\ncycle). The mechanism for the generation of so-called large scale fields\nremains an open problem. In cases where the magnetic Reynolds number ($Rm$) is\nsmall, dynamo-generated fields are coherent but at (the astrophysically\nrelevant) high $Rm$, the fields are overwhelmed by small scale fluctuating\nfield. Recently Tobias and Cattaneo (2013) have shown that an imposed large\nscale shear flow can suppress the small scale fluctuations and allow the large\nscale temporal behaviour to emerge. Shear is also believed to modify the\nelectromotive force by introducing correlations between the flow and the field.\nHowever in previous models at high $Rm$ the shear is often artificially imposed\nor driven by an arbitrary body force. Here we consider a simple kinematic model\nof a convective dynamo in which shear is self consistently driven by the\npresence of a horizontal temperature gradient (resulting in a thermal wind) and\na rotation vector that is oblique to gravity. By considering a\n$2.5$-dimensional system, we are able to reach high $Rm$ so that the dynamo\napproaches the asymptotic regime where the growth rate becomes approximately\nindependent of $Rm$. We find the flows studied here to be excellent small-scale\ndynamos, but with very little systematic behaviour evident at large $Rm$. We\nattribute this to being unable to self-consistently generate flows with both\nlarge (net) helicity and strong shear in this setup.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We describe an algorithm to compute the Wiener index of a sequence of finite\ngraphs approximating the Sierpinski carpet.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  The conical Radon transform, which assigns to a given function $f$ on\n$\\mathbb R^3$ its integrals over conical surfaces, arises in several imaging\ntechniques, e.g. in astronomy and homeland security, especially when the\nso-called Compton cameras are involved. In many practical situations we know\nthis transform only on a subset of its domain. In these situations, it is a\nnatural question what we can say about $f$ from partial information. In this\npaper, we investigate some uniqueness theorems regarding a conical Radon\ntransform.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  While there has been some discussion on how Symbolic Computation could be\nused for AI there is little literature on applications in the other direction.\nHowever, recent results for quantifier elimination suggest that, given enough\nexample problems, there is scope for machine learning tools like Support Vector\nMachines to improve the performance of Computer Algebra Systems. We survey the\nauthors own work and similar applications for other mathematical software.\n  It may seem that the inherently probabilistic nature of machine learning\ntools would invalidate the exact results prized by mathematical software.\nHowever, algorithms and implementations often come with a range of choices\nwhich have no effect on the mathematical correctness of the end result but a\ngreat effect on the resources required to find it, and thus here, machine\nlearning can have a significant impact.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  The Kondo and Periodic Anderson Model (PAM) are known to provide a\nmicroscopic picture of many of the fundamental properties of heavy fermion\nmaterials and, more generally, a variety of strong correlation phenomena in\n$4f$ and $5f$ systems. In this paper, we apply the Determinant Quantum Monte\nCarlo (DQMC) method to include disorder in the PAM, specifically the removal of\na fraction $x$ of the localized orbitals. We determine the evolution of the\ncoherence temperature $T^*$, where the local moments and conduction electrons\nbecome entwined in a heavy fermion fluid, with $x$ and with the hybridization\n$V$ between localized and conduction orbitals. We recover several of the\nprincipal observed trends in $T^*$ of doped heavy fermions, and also show that,\nwithin this theoretical framework, the calculated Nuclear Magnetic Resonance\n(NMR) relaxation rate tracks the experimentally measured behavior in pure and\ndoped CeCoIn$_5$. Our results contribute to important issues in the\ninterpretation of local probes of disordered, strongly correlated systems.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Current and emerging trends such as cloud computing, fog computing, and more\nrecently, multi-access edge computing (MEC) increase the interest in finding\nsolutions to the verifiable computation problem. Furthermore, the number of\ncomputationally weak devices have increased drastically in recent years due to\nthe ongoing realization of the Internet of Things. This work proposes a\nsolution which enjoys the following two desirable properties: (1) cost of input\npreparation and verification is very low (low enough to allow verifiable\noutsourcing of computations by resource-constrained devices on constrained\nnetworks); (2) the running time of the verifiable computation is RAM-like.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We consider a multi-cell Massive MIMO system in a line-of-sight (LoS)\npropagation environment, for which each user is served by one base station,\nwith no cooperation among the base stations. Each base station knows the\nchannel between its service antennas and its users, and uses these channels for\nprecoding and decoding. Under these assumptions we derive explicit downlink and\nuplink effective SINR formulas for maximum-ratio (MR) processing and\nzero-forcing (ZF) processing. We also derive formulas for power control to meet\npre-determined SINR targets. A numerical example demonstrating the usage of the\nderived formulas is provided.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  The present work shows the application of transfer learning for a pre-trained\ndeep neural network (DNN), using a small image dataset ($\\approx$ 12,000) on a\nsingle workstation with enabled NVIDIA GPU card that takes up to 1 hour to\ncomplete the training task and archive an overall average accuracy of $94.7\\%$.\nThe DNN presents a $20\\%$ score of misclassification for an external test\ndataset. The accuracy of the proposed methodology is equivalent to ones using\nHSI methodology $(81\\%-91\\%)$ used for the same task, but with the advantage of\nbeing independent on special equipment to classify wheat kernel for FHB\nsymptoms.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  We tackle the problem of learning concept classifiers from videos on the web\nwithout using manually labeled data. Although metadata attached to videos\n(e.g., video titles, descriptions) can be of help collecting training data for\nthe target concept, the collected data is often very noisy. The main challenge\nis therefore how to select good examples from noisy training data. Previous\napproaches firstly learn easy examples that are unlikely to be noise and then\ngradually learn more complex examples. However, hard examples that are much\ndifferent from easy ones are never learned. In this paper, we propose an\napproach called multimodal co-training (MMCo) for selecting good examples from\nnoisy training data. MMCo jointly learns classifiers for multiple modalities\nthat complement each other to select good examples. Since MMCo selects examples\nby consensus of multimodal classifiers, a hard example for one modality can\nstill be used as a training example by exploiting the power of the other\nmodalities. The algorithm is very simple and easily implemented but yields\nconsistent and significant boosts in example selection and classification\nperformance on the FCVID and YouTube8M benchmarks.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  One promising route toward encoding information is to utilize the two stable\nelectronic states of a spin crossover molecule. However, while this property is\nclearly manifested in transport across single molecule junctions, evidence\nlinking charge transport across a solid-state device to the molecular film's\nspin state has thus far remained indirect. To establish this link, we deploy\nmaterials-centric and device-centric operando experiments involving X-ray\nabsorption spectroscopy. We find a correlation between the temperature\ndependencies of the junction resistance and the Fe spin state within the\ndevice's Fe(bpz)2(phen) molecular film. We also factually observe that the Fe\nmolecular site mediates charge transport. Our dual operando studies reveal that\ntransport involves a subset of molecules within an electronically heterogeneous\nspin crossover film. Our work confers an insight that substantially improves\nthe state-of-the-art regarding spin crossover-based devices, thanks to a\nmethodology that can benefit device studies of other next-generation molecular\ncompounds.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  The gas-driven dust activity of comets is still an unresolved question in\ncometary science. In the past, it was believed that comets are dirty snowballs\nand that the dust is ejected when the ice retreats. However, thanks to the\nvarious space missions to comets, it has become evident that comets have a much\nhigher dust-to-ice ratio than previously thought and that most of the dust mass\nis ejected in large particles. Here we report on new comet-simulation\nexperiments dedicated to the study of the ejection of dust aggregates caused by\nthe sublimation of solid water ice. We find that dust ejection exactly occurs\nwhen the pressure of the water vapor above the ice surface exceeds the tensile\nstrength plus the gravitational load of the covering dust layer. Furthermore,\nwe observed the ejection of clusters of dust aggregates, whose sizes increase\nwith increasing thickness of the ice-covering dust-aggregate layer. In\naddition, the trajectories of the ejected aggregates suggest that most of the\naggregates obtained a non-vanishing initial velocity from the ejection event.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We discuss a recently proposed interpretation of some model descriptions of\nthe proton-proton elastic scattering data as a manifestation of alleged\nrelative transparency of the central part of the interaction region in the\nimpact parameter space. We argue that the presence of nonzero real part of the\nelastic scattering amplitude in the unitarity condition enables to conserve the\ntraditional interpretation.\n\n\n###\n\n", "completion": " 99"}
{"prompt": "  In this paper we consider the nonlinear Schr\\\"odinger system (NLS) with\nquadratic interaction in five dimensions. We determine the global behavior of\nthe solutions to the system with data below the ground state. Our proof of the\nscattering result is based on an argument by Kenig Merle [16]. In particular,\nthe new part of this paper is to deal with asymmetric interaction. A blowing up\nor growing up result is proved by combining the argument by Du Wu Zhang in [6]\nand a variational characterization of minimizers. Moreover, we show a\nblowing-up result if the data has finite variance or is radial.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Dense and narrow rings have been discovered recently around the small Centaur\nobject Chariklo and the dwarf planet Haumea, while being suspected around the\nCentaur Chiron. They are the first rings observed in the Solar System elsewhere\nthan around giant planets. Contrarily to the latters, gravitational fields of\nsmall bodies may exhibit large non-axisymmetric terms that create strong\nresonances between the spin of the object and the mean motion of rings\nparticles. Here we show that modest topographic features or elongations of\nChariklo and Haumea explain why their rings are relatively far away from the\ncentral body, when scaled to those of the giant planets. Lindblad-type\nresonances actually clear on decadal time-scales an initial collisional disk\nthat straddles the corotation resonance (where the particles mean motion\nmatches the spin rate of the body). The disk material inside the corotation\nradius migrates onto the body, while the material outside the corotation radius\nis pushed outside the 1/2 resonance, where the particles complete one\nrevolution while the body completes two rotations. Consequently, the existence\nof rings around non-axisymmetric bodies requires that the 1/2 resonance resides\ninside the Roche limit of the body, favoring fast rotators for being surrounded\nby rings.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We report on the first femtoscopic measurement of baryon pairs, such as p-p,\np-$\\Lambda$ and $\\Lambda$-$\\Lambda$, measured by ALICE at the Large Hadron\nCollider (LHC) in proton-proton collisions at $\\sqrt{s}$ = 7 TeV. This study\ndemonstrates the feasibility of such measurements in pp collisions at\nultrarelativistic energies. The femtoscopy method is employed to constrain the\nhyperon-nucleon and hyperon-hyperon interactions, which are still rather poorly\nunderstood. A new method to evaluate the influence of residual correlations\ninduced by the decays of resonances and experimental impurities is hereby\npresented. The p-p, p-$\\Lambda$ and $\\Lambda$-$\\Lambda$ correlation functions\nwere fitted simultaneously with the help of a new tool developed specifically\nfor the femtoscopy analysis in small colliding systems 'Correlation Analysis\nTool using the Schr\\\"odinger Equation' (CATS). Within the assumption that in pp\ncollisions the three particle pairs originate from a common source, its radius\nis found to be equal to $r_{0} = 1.125\\pm0.018$ (stat) $^{+0.058}_{-0.035}$\n(syst) fm. The sensitivity of the measured p-$\\Lambda$ correlation is tested\nagainst different scattering parameters which are defined by the interaction\namong the two particles, but the statistics is not sufficient yet to\ndiscriminate among different models. The measurement of the $\\Lambda$-$\\Lambda$\ncorrelation function constrains the phase space spanned by the effective range\nand scattering length of the strong interaction. Discrepancies between the\nmeasured scattering parameters and the resulting correlation functions at LHC\nand RHIC energies are discussed in the context of various models.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  The normal form and zero dynamics are powerful tools useful in analysis and\ncontrol of both linear and nonlinear systems. There are no simple closed form\nsolutions to the general zero dynamics problem for nonlinear systems. A few\nalgorithms exist for determining the zero dynamics, but none is straightforward\nand all are difficult to apply to large dimensional problems. A Closed form\nsolution to the zero dynamics problem would motivate more usage of this\npowerful technique. The author presents here a simple algebraic methodology for\nthe normal form and zero dynamics calculation of a class of nonlinear systems,\nmostly found in dynamical mechanical systems. The solution is in closed form so\nthat application of the theorem presented is straight forward. As an\nillustration, the zero dynamics calculations for the complex dynamics of a\nflexible spacecraft is presented to demonstrate the simplicity and usefulness\nof the proposed closed form solution.\n  Keywords: Control, Differential Geometry, Normal Form, Zero Dynamics,\nNonlinear Systems, Feedback Linearization, Attitude Dynamics, Flexible\nSpacecraft.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We prove that reflected Brownian motion with normal reflections in a convex\ndomain satisfies a dimension free Talagrand type transportation\ncost-information inequality. The result is generalized to other reflected\ndiffusions with suitable drifts and diffusions. We apply this to get such an\ninequality for interacting Brownian particles with rank-based drift and\ndiffusion coefficients such as the infinite Atlas model. This is an improvement\nover earlier dimension-dependent results.\n\n\n###\n\n", "completion": " 14"}
