{"prompt": "  We have studied the cathodo- and radioluminescence of Nd:YAG and of Tm:YAG\nsingle crystals in an extended wavelength range up to $\\approx 5\\,\\mu$m in view\nof developing a new kind of detector for low-energy, low-rate energy deposition\nevents. Whereas the light yield in the visible range is as large as $\\approx\n10^{4}\\,$photons/MeV, in good agreement with literature results, in the\ninfrared range we have found a light yield $\\approx 5\\times\n10^{4}\\,$photons/MeV, thereby proving that ionizing radiation is particularly\nefficient in populating the low lying levels of rare earth doped crystals.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Wavelength determines the length scale of the cross section when\nelectromagnetic waves are scattered by an electrically small object. The cross\nsection diverges for resonant scattering, and diminishes for non-resonant\nscattering, when wavelength approaches infinity. This scattering law explains\nthe color of the sky as well as the strength of a mobile phone signal. We show\nthat such wavelength scaling comes from free space's conical dispersion at zero\nfrequency. Emerging Weyl systems, offering similar dispersion at non-zero\nfrequencies, lead to new laws of electromagnetic scattering that allow cross\nsections to be decoupled from the wavelength limit. Diverging and diminishing\ncross sections can be realized at any target wavelength in a Weyl system,\nproviding unprecedented ability to tailor the strength of wave-matter\ninteractions for radio-frequency and optical applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Lindblad dynamics of the XX quantum chain with large random fields $h_j$\n(the couplings $J_j$ can be either uniform or random) is considered for\nboundary-magnetization-drivings acting on the two end-spins. Since each\nboundary-reservoir tends to impose its own magnetization, we first study the\nrelaxation spectrum in the presence of a single reservoir as a function of the\nsystem size via some boundary-strong-disorder renormalization approach. The\nnon-equilibrium-steady-state in the presence of two reservoirs can be then\nanalyzed from the effective renormalized Linbladians associated to the two\nreservoirs. The magnetization is found to follow a step profile, as found\npreviously in other localized chains. The strong disorder approach allows to\ncompute explicitly the location of the step of the magnetization profile and\nthe corresponding magnetization-current for each disordered sample in terms of\nthe random fields and couplings.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In their work on differential operators in positive characteristic, Smith and\nVan den Bergh define and study the derived functors of differential operators;\nthey arise naturally as obstructions to differential operators reducing to\npositive characteristic. In this note, we provide formulas for the ring of\ndifferential operators as well as these derived functors of differential\noperators. We apply these descriptions to show that differential operators\nbehave well under reduction to positive characteristic under certain\nhypotheses. We show that these functors also detect a number of interesting\nproperties of singularities.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider several previously studied online variants of bin packing and\nprove new and improved lower bounds on the asymptotic competitive ratios for\nthem. For that, we use a method of fully adaptive constructions. In particular,\nwe improve the lower bound for the asymptotic competitive ratio of online\nsquare packing significantly, raising it from roughly 1.68 to above 1.75.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report the first measurement of the fraction of $J/\\psi$ mesons coming\nfrom $B$-meson decay ($F_{B{\\rightarrow}J/\\psi}$) in $p$+$p$ collisions at\n$\\sqrt{s}=$ 510 GeV. The measurement is performed using the forward silicon\nvertex detector and central vertex detector at PHENIX, which provide precise\ntracking and distance-of-closest-approach determinations, enabling the\nstatistical separation of $J/\\psi$ due to $B$-meson decays from prompt\n$J/\\psi$. The measured value of $F_{B{\\rightarrow}J/\\psi}$ is 8.1\\%$\\pm$2.3\\%\n(stat)$\\pm$1.9\\% (syst) for $J/\\psi$ with transverse momenta $0<p_T<5$ GeV/$c$\nand rapidity $1.2<|y|<2.2$. The measured fraction $F_{B{\\rightarrow}J/\\psi}$ at\nPHENIX is compared to values measured by other experiments at higher center of\nmass energies and to fixed-order-next-to-leading-logarithm and\ncolor-evaporation-model predictions. The $b\\bar{b}$ cross section per unit\nrapidity ($d\\sigma/dy(pp{\\rightarrow}b\\bar{b})$) extracted from the obtained\n$F_{B{\\rightarrow}J/\\psi}$ and the PHENIX inclusive $J/\\psi$ cross section\nmeasured at 200 GeV scaled with color-evaporation-model calculations, at the\nmean $B$ hadron rapidity $y={\\pm}1.7$ in 510 GeV $p$$+$$p$ collisions, is\n$3.63^{+1.92}_{-1.70}\\mu$b, and it is consistent with the\nfixed-order-next-to-leading-logarithm calculations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given an $n$-point metric space, consider the problem of finding a point with\nthe minimum sum of distances to all points. We show that this problem has a\nrandomized algorithm that {\\em always} outputs a $(2+\\epsilon)$-approximate\nsolution in an expected $O(n/\\epsilon^2)$ time for each constant $\\epsilon>0$.\nInheriting Indyk's algorithm, our algorithm outputs a\n$(1+\\epsilon)$-approximate $1$-median in $O(n/\\epsilon^2)$ time with\nprobability $\\Omega(1)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Network administration is an inherently complex task, in particular with\nregard to security. Using the Isabelle interactive proof assistant, we develop\ntwo automated, formally verified tools which help uncovering and preventing\nbugs in network-level access control configurations. Our first tool guides the\nprocess of designing networks from scratch. Our second tool facilitates the\nanalysis of existing iptables configurations. Combined, the two form a powerful\ntoolset.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We survey problems and results from combinatorial geometry in normed spaces,\nconcentrating on problems that involve distances. These include various\nproperties of unit-distance graphs, minimum-distance graphs, diameter graphs,\nas well as minimum spanning trees and Steiner minimum trees. In particular, we\ndiscuss translative kissing (or Hadwiger) numbers, equilateral sets, and the\nBorsuk problem in normed spaces. We show how to use the angular measure of\nPeter Brass to prove various statements about Hadwiger and blocking numbers of\nconvex bodies in the plane, including some new results. We also include some\nnew results on thin cones and their application to distinct distances and other\ncombinatorial problems for normed spaces.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using arguments built on ergodicity, we derive an analytical expression for\nthe Renyi entanglement entropies corresponding to the finite-energy density\neigenstates of chaotic many-body Hamiltonians. The expression is a universal\nfunction of the density of states and is valid even when the subsystem is a\nfinite fraction of the total system - a regime in which the reduced density\nmatrix is not thermal. We find that in the thermodynamic limit, only the von\nNeumann entropy density is independent of the subsystem to the total system\nratio $V_A/V$, while the Renyi entropy densities depend non-linearly on\n$V_A/V$. Surprisingly, Renyi entropies $S_n$ for $n > 1$ are convex functions\nof the subsystem size, with a volume law coefficient that depends on $V_A/V$,\nand exceeds that of a thermal mixed state at the same energy density. We\nprovide two different arguments to support our results: the first one relies on\na many-body version of Berry's formula for chaotic quantum mechanical systems,\nand is closely related to eigenstate thermalization hypothesis. The second\nargument relies on the assumption that for a fixed energy in a subsystem, all\nstates in its complement allowed by the energy conservation are equally likely.\nWe perform Exact Diagonalization study on quantum spin-chain Hamiltonians to\ntest our analytical predictions, and find good agreement.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In neural machine translation, a source sequence of words is encoded into a\nvector from which a target sequence is generated in the decoding phase.\nDifferently from statistical machine translation, the associations between\nsource words and their possible target counterparts are not explicitly stored.\nSource and target words are at the two ends of a long information processing\nprocedure, mediated by hidden states at both the source encoding and the target\ndecoding phases. This makes it possible that a source word is incorrectly\ntranslated into a target word that is not any of its admissible equivalent\ncounterparts in the target language.\n  In this paper, we seek to somewhat shorten the distance between source and\ntarget words in that procedure, and thus strengthen their association, by means\nof a method we term bridging source and target word embeddings. We experiment\nwith three strategies: (1) a source-side bridging model, where source word\nembeddings are moved one step closer to the output target sequence; (2) a\ntarget-side bridging model, which explores the more relevant source word\nembeddings for the prediction of the target sequence; and (3) a direct bridging\nmodel, which directly connects source and target word embeddings seeking to\nminimize errors in the translation of ones by the others.\n  Experiments and analysis presented in this paper demonstrate that the\nproposed bridging models are able to significantly improve quality of both\nsentence translation, in general, and alignment and translation of individual\nsource words with target words, in particular.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We recently used Virasoro symmetry considerations to propose an exact formula\nfor a bulk proto-field $\\phi$ in AdS$_3$. In this paper we study the propagator\n$\\langle \\phi \\phi \\rangle$. We show that many techniques from the study of\nconformal blocks can be generalized to compute it, including the semiclassical\nmonodromy method and both forms of the Zamolodchikov recursion relations. When\nthe results from recursion are expanded at large central charge, they match\ngravitational perturbation theory for a free scalar field coupled to gravity in\nour chosen gauge.\n  We find that although the propagator is finite and well-defined at long\ndistances, its perturbative expansion in $G_N = \\frac{3}{2c}$ exhibits UV/IR\nmixing effects. If we nevertheless interpret $\\langle \\phi \\phi \\rangle$ as a\nprobe of bulk locality, then when $G_N m_\\phi \\ll 1$ locality breaks down at\nthe new short-distance scale $\\sigma_* \\sim \\sqrt[4]{G_N R_{AdS}^3}$. For\n$\\phi$ with very large bulk mass, or at small central charge, bulk locality\nfails at the AdS length scale. In all cases, locality `breakdown' manifests as\nsingularities or branch cuts at spacelike separation arising from\nnon-perturbative quantum gravitational effects.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In a group sequential clinical trial, accumulated data are analysed at\nnumerous time-points in order to allow early decisions about a hypothesis of\ninterest. These designs have historically been recommended for their ethical,\nadministrative and economic benefits. In this work, we discuss a collection of\nnew Stata commands for computing the stopping boundaries and required group\nsize of various classical group sequential designs, assuming a normally\ndistributed outcome variable. Following this, we demonstrate how the\nperformance of several designs can be compared graphically.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In quantum error correction, it is an important assumption that errors on\ndifferent qubits are independent. In our previous work [Phys. Rev. A {\\bf 92},\n052320 (2015)], the generality of the concatenated five-qubit code has been\ninvestgated when noises of the principal system and the auxiliary environment\nare assumed to be the same. In the error correction with concatenated code,\ntiny differences (in fidelity or independent errors) between initial quantum\nchannels may introduce different effective channels in the next level, and\ntherefore, it is necessary to study a meaningful question: Does five-qubit code\nstill work efficiently when errors on different qubits are different? In the\npresent work, it is discovered that even errors for different qubits are\narbitrary, the five-qubit code still works efficiently. Since it is much easier\nand more accurate to measure the fidelity, one can construct quantum error\ncorrection with five-qubit code according to the initial channel fidelity, and\nit is not necessary to know the complete information of the initial channel.\nMoreover, when the initial channel fidelity is below $0.992$, the fidelity\nthreshold for five-qubit code is the fidelity of the effective channel after\nerror correction in bit-flip channels.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Nowadays, the ubiquity of various sensors enables the collection of\nvoluminous datasets of car trajectories. Such datasets enable analysts to make\nsense of driving patterns and behaviors: in order to understand the behavior of\ndrivers, one approach is to break a trajectory into its underlying patterns and\nthen analyze that trajectory in terms of derived patterns. The process of\ntrajectory segmentation is a function of various resources including a set of\nground truth trajectories with their driving patterns. To the best of our\nknowledge, no such ground-truth dataset exists in the literature. In this\npaper, we describe a trajectory annotation framework and report our results to\nannotate a dataset of personal car trajectories. Our annotation methodology\nconsists of a crowd-sourcing task followed by a precise process of aggregation.\nOur annotation process consists of two granularity levels, one to specify the\nannotation (segment border) and the other one to describe the type of the\nsegment (e.g. speed-up, turn, merge, etc.). The output of our project, Dataset\nof Annotated Car Trajectories (DACT), is available online at\nhttps://figshare.com/articles/dact_dataset_of_annotated_car_trajectories/5005289 .\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recently, three-component new fermions in topological semimetal MoP are\nexperimentally observed, which may have potential applications like topological\nqubits, low-power electronics and spintronics. These are closely related to\nthermal transport properties of MoP. In this work, the phonon transport of MoP\nis investigated by solving the linearized phonon Boltzmann equation within the\nsingle-mode relaxation time approximation (RTA). The calculated\nroom-temperature lattice thermal conductivity is 18.41 $\\mathrm{W m^{-1}\nK^{-1}}$ and 34.71 $\\mathrm{W m^{-1} K^{-1}}$ along the in- and cross-plane\ndirections, exhibiting very strong anisotropy. The isotope and size effects on\nthe lattice thermal conductivity are also considered. It is found that isotope\nscattering produces little effect, and phonon has little contribution to the\nlattice thermal conductivity, when phonon mean free path(MFP) is larger than\n0.15 $\\mathrm{\\mu m}$ at 300 K. It is noted that average room-temperature\nlattice thermal conductivity of MoP is lower than that of representative Weyl\nsemimetal TaAs, which is due to smaller group velocities and larger\nGr$\\mathrm{\\ddot{u}}$neisen parameters. Our works provide valuable informations\nfor the thermal management of MoP-based nano-electronics devices, and motivate\nfurther experimental works to study thermal transport of MoP.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In recent years the use of digital communication has increased. This also\nincreased the chance to find privileged data in the digital evidence.\nPrivileged data is protected by law from viewing by anyone other than the\nclient. It is up to the digital investigator to handle this privileged data\nproperly without being able to view the contents. Procedures on handling this\ninformation are available, but do not provide any practical information nor is\nit known how effective filtering is. The objective of this paper is to describe\nthe handling of privileged data in the current digital forensic tools and the\ncreation of a script within the digital forensic tool Nuix. The script\nautomates the handling of privileged data to minimize the exposure of the\ncontents to the digital investigator. The script also utilizes technology\nwithin Nuix that extends the automated search of identical privileged document\nto relate files based on their contents. A comparison of the 'traditional' ways\nof filtering within the digital forensic tools and the script written in Nuix\nshowed that digital forensic tools are still limited when used on privileged\ndata. The script manages to increase the effectiveness as direct result of the\nuse of relations based on file content.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Quantum Null Energy Condition (QNEC) is a new local energy condition that\na general Quantum Field Theory (QFT) is believed to satisfy, relating the\nclassical null energy condition (NEC) to the second functional derivative of\nthe entanglement entropy in the corresponding null direction. We present the\nfirst series of explicit computations of QNEC in a strongly coupled QFT, using\nholography. We consider the vacuum, thermal equilibrium, a homogeneous\nfar-from-equilibrium quench as well as a colliding system that violates NEC.\nFor vacuum and the thermal phase QNEC is always weaker than NEC. While for the\nhomogeneous quench QNEC is satisfied with a finite gap, we find the interesting\nresult that the colliding system can saturate QNEC, depending on the null\ndirection.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The X-ray emission spectrum of liquid ethanol was calculated using density\nfunctional theory and a semi-classical approximation to the Kramers-Heisenberg\nformula including core-hole-induced dynamics. Our spectrum agrees well with the\nexperimental spectrum. We found that the intensity ratio between the two peaks\nat 526 and 527 eV assigned as 10a' and 3a\" depends not only on the hydrogen\nbonding network around the target molecule, but also on the intramolecular\nconformation. This effect is absent in liquid methanol and demonstrates the\nhigh sensitivity of X-ray emission to molecular structure. The dependence of\nspectral features on hydrogen-bonding as well as on dynamical effects following\ncore-excitation are also discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Energetic ions have been observed since the very first laser-plasma\nexperiments.Their origin was found to be the charge separation of electrons\nheated by thelaser, which transfers energy to the ions accelerated in the\nfield. The adventof ultra-intense lasers with pulse lengths in the femtosecond\nregime resulted inthe discovery of very energetic ions with characteristics\nquite different fromthose driven by long-pulse lasers. Discovered in the late\n1990s, these ion beamshave become the focus of intense research worldwide,\nbecause of their uniqueproperties and high particle numbers. Based on their\nnon-isotropic, beam-likebehaviour, which is always perpendicular to the\nemitting surface, theacceleration mechanism is called target normal sheath\nacceleration (TNSA). Weaddress the physics of the mechanism and its dependence\non laser and targetparameters. Techniques to explore and diagnose the beams, to\nmake them usefulfor applications, are also addressed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  These notes are intended to provide a brief primer in plasma physics,\nintroducing common definitions, basic properties, and typical processes found\nin plasmas. These concepts are inherent in contemporary plasma-based\naccelerator schemes, and thus provide a foundation for the more advanced\nexpositions that follow in this volume. No prior knowledge of plasma physics is\nrequired, but the reader is assumed to be familiar with basic electrodynamics\nand fluid mechanics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work we study the implications of light-quark pionic matter at finite\ntemperatures on the properties of open and hidden charm mesons. The meson-meson\ninteractions are described by means of a chiral unitary approach accounting for\ncoupled channels effects. The in-medium Lippmann-Schwinger Equations, which\nconsider the change in self-energy that the mesons acquire from interacting\nwith the surrounding pionic matter, are solved self-consistently, and the\nspectral functions of the mesons in the hot pion bath are obtained. It is\nobserved that the charmed mesons develop a quite substantial pion-induced\nwidth, being of several tens at a temperature of 150 MeV. The $J/\\Psi$ meson\nstays narrow, but its pionic width at 150 MeV, found to be around 0.1 MeV, is\nalready larger that its vacuum width.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let D be a division ring with centre F. Let T(D) be the vector space over F\ngenerated by all multiplicative commutators in D. In [1], authors have\nconjectured that every division ring is generated as a vector space over its\ncentre by all of its multiplicative commutators. In this note it is shown that\nif D is centrally finite, then the conjecture holds.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Learning on Grassmann manifold has become popular in many computer vision\ntasks, with the strong capability to extract discriminative information for\nimagesets and videos. However, such learning algorithms particularly on\nhigh-dimensional Grassmann manifold always involve with significantly high\ncomputational cost, which seriously limits the applicability of learning on\nGrassmann manifold in more wide areas. In this research, we propose an\nunsupervised dimensionality reduction algorithm on Grassmann manifold based on\nthe Locality Preserving Projections (LPP) criterion. LPP is a commonly used\ndimensionality reduction algorithm for vector-valued data, aiming to preserve\nlocal structure of data in the dimension-reduced space. The strategy is to\nconstruct a mapping from higher dimensional Grassmann manifold into the one in\na relative low-dimensional with more discriminative capability. The proposed\nmethod can be optimized as a basic eigenvalue problem. The performance of our\nproposed method is assessed on several classification and clustering tasks and\nthe experimental results show its clear advantages over other Grassmann based\nalgorithms.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A search for baryon-number-violating $\\Xi_b^0$ oscillations is performed with\na sample of $pp$ collision data recorded by the LHCb experiment, corresponding\nto an integrated luminosity of 3 fb$^{-1}$. The baryon number at the moment of\nproduction is identified by requiring that the $\\Xi_b^0$ come from the decay of\na resonance $\\Xi_b^{*-} \\to \\Xi_b^0 \\pi^-$ or $\\Xi_b^{\\prime-} \\to \\Xi_b^0\n\\pi^-$, and the baryon number at the moment of decay is identified from the\nfinal state using the decays $\\Xi_b^0 \\to \\Xi_c^+ \\pi^-, ~ \\Xi_c^+ \\to p K^-\n\\pi^+$. No evidence of baryon number violation is found, and an upper limit at\nthe 95% confidence level is set on the oscillation rate of $\\omega < 0.08$\nps$^{-1}$, where $\\omega$ is the associated angular frequency.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The delta-shell representation of the nuclear force allows a simplified\ntreatment of nuclear correlations. We show how this applies to the\nBethe-Goldstone equation as an integral equation in coordinate space with a few\nmesh points, which is solved by inversion of a 5-dimensional square matrix in\nthe single channel cases and a $10\\times10$ matrix for the tensor-coupled\nchannels. This allows us to readily obtain the high momentum distribution, for\nall partial waves, of a back-to-back correlated nucleon pair in nuclear matter.\nWe find that the probability of finding a high-momentum correlated\nneutron-proton pair is about 18 times that of a proton-proton one, as a result\nof the strong tensor force, thus confirming in an independent way previous\nresults and measurements.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Vector AutoRegressive Moving Average (VARMA) model is fundamental to the\ntheory of multivariate time series; however, identifiability issues have led\npractitioners to abandon it in favor of the simpler but more restrictive Vector\nAutoRegressive (VAR) model. We narrow this gap with a new optimization-based\napproach to VARMA identification built upon the principle of parsimony. Among\nall equivalent data-generating models, we use convex optimization to seek the\nparameterization that is \"simplest\" in a certain sense. A user-specified\nstrongly convex penalty is used to measure model simplicity, and that same\npenalty is then used to define an estimator that can be efficiently computed.\nWe establish consistency of our estimators in a double-asymptotic regime. Our\nnon-asymptotic error bound analysis accommodates both model specification and\nparameter estimation steps, a feature that is crucial for studying large-scale\nVARMA algorithms. Our analysis also provides new results on penalized\nestimation of infinite-order VAR, and elastic net regression under a singular\ncovariance structure of regressors, which may be of independent interest. We\nillustrate the advantage of our method over VAR alternatives on three real data\nexamples.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the relationship between the MgII $\\lambda2798$ emission-line\nand the 3000 {\\AA} continuum variations using a sample of 68\nintermediate-redshift ($z\\sim$ 0.65$-$1.50) broad-line quasars spanning a\nbolometric luminosity range of 44.49 erg s$^{-1} \\leq \\rm{log}$$L_{\\rm{bol}}\n\\leq 46.31$ erg s$^{-1}$ (Eddington ratio from $\\sim$ 0.026 to 0.862). This\nsample is constructed from SDSS-DR7Q and BOSS-DR12Q, each with at least 2\nspectroscopic epochs in SDSS-I/II/III surveys. Additionally, we adopt the\nfollowing signal-to-noise ratio (S/N) selection criteria: a) for MgII and the\n3000 {\\AA} continuum, S/N $\\geq$ 10; b) for narrow lines, S/N $\\geq$ 5. All our\nquasar spectra are recalibrated based on the assumption of constant narrow\nemission-line fluxes. In an analysis of spectrum-to-spectrum variations, we\nfind a fairly close correlation (Spearman $\\rho = 0.593$) between the\nvariations in broad MgII and in the continuum. This is consistent with the idea\nthat MgII is varying in response to the continuum emission variations. Adopting\nthe modified weighted least squares regression method, we statistically\nconstrain the slopes (i.e., the responsivity $\\alpha$ of the broad MgII)\nbetween the variations in both components for the sources in different\nluminosity bins after eliminating intrinsic biases introduced by the rescaling\nprocess itself. It is shown that the responsivity is quite small (average\n$\\bar{\\alpha} \\approx$ 0.464) and anti-correlates with the quasar luminosity.\nOur results indicate that high signal-to-noise flux measurements are required\nto robustly detect the intrinsic variability and the time lag of MgII line.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We construct an extremizer for the kinetic energy inequality (except the\nendpoint cases) developing the concentration-compactness technique for operator\nvalued inequality in the formulation of the profile decomposition. Moreover, we\ninvestigate the properties of the extremizer, such as the system of\nEuler-Lagrange equations, regularity and summability. As an application, we\nstudy a dynamical consequence of a system of nonlinear Schr\\\"odinger equations\nwith focusing cubic nonlinearities in three dimension when each wave function\nis restricted to be orthogonal. Using the critical element of the kinetic\nenergy inequality, we establish a global existence versus finite time blowup\ndichotomy. This result extends the single particle result of Holmer and\nRoudenko to infinitely many particles system.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We experimentally simulate the spin networks -- a fundamental description of\nquantum spacetime at the Planck level. We achieve this by simulating quantum\ntetrahedra and their interactions. The tensor product of these quantum\ntetrahedra comprises spin networks. In this initial attempt to study quantum\nspacetime by quantum information processing, on a four-qubit nuclear magnetic\nresonance quantum simulator, we simulate the basic module -- comprising five\nquantum tetrahedra -- of the interactions of quantum spacetime. By measuring\nthe geometric properties on the corresponding quantum tetrahedra and simulate\ntheir interactions, our experiment serves as the basic module that represents\nthe Feynman diagram vertex in the spin-network formulation of quantum\nspacetime.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose an integrable discrete model of one-dimensional soil water\ninfiltration. This model is based on the continuum model by Broadbridge and\nWhite, which takes the form of nonlinear convection-diffusion equation with a\nnonlinear flux boundary condition at the surface. It is transformed to the\nBurgers equation with a time-dependent flux term by the hodograph\ntransformation. We construct a discrete model preserving the underlying\nintegrability, which is formulated as the self-adaptive moving mesh scheme. The\ndiscretization is based on linearizability of the Burgers equation to the\nlinear diffusion equation, but the na\\\"ive discretization based on the Euler\nscheme which is often used in the theory of discrete integrable systems does\nnot necessarily give a good numerical scheme. Taking desirable properties of a\nnumerical scheme into account, we propose an alternative discrete model that\nproduces solutions with similar accuracy to direct computation on the original\nnonlinear equation, but with clear benefits regarding computational cost.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Cartan-Hartogs domains are defined as a class of Hartogs type domains\nover irreducible bounded symmetric domains. For a Cartan-Hartogs domain\n$\\Omega^{B}(\\mu)$ endowed with the natural K\\\"{a}hler metric $g(\\mu),$ Zedda\nconjectured that the coefficient $a_2$ of the Rawnsley's $\\varepsilon$-function\nexpansion for the Cartan-Hartogs domain $(\\Omega^{B}(\\mu), g(\\mu))$ is constant\non $\\Omega^{B}(\\mu)$ if and only if $(\\Omega^{B}(\\mu), g(\\mu))$ is\nbiholomorphically isometric to the complex hyperbolic space. In this paper,\nfollowing Zedda's argument, we give a geometric proof of the Zedda's conjecture\nby computing the curvature tensors of the Cartan-Hartogs domain\n$(\\Omega^{B}(\\mu), g(\\mu))$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The O8f?p star HD 108 is implied to have experienced the most extreme\nrotational braking of any magnetic, massive star, with a rotational period\n$P_{\\rm rot}$ of at least 55 years, but the upper limit on its spindown\ntimescale is over twice the age estimated from the Hertzsprung-Russell diagram.\nHD 108's observed X-ray luminosity is also much higher than predicted by the\nXADM model, a unique discrepancy amongst magnetic O-type stars. Previously\nreported magnetic data cover only a small fraction ($\\sim$3.5\\%) of $P_{\\rm\nrot}$, and were furthermore acquired when the star was in a photometric and\nspectroscopic `low state' at which the longitudinal magnetic field $\\langle\nB_z\\rangle$~was likely at a minimum. We have obtained a new ESPaDOnS magnetic\nmeasurement of HD 108, 6 years after the last reported measurement. The star is\nreturning to a spectroscopic high state, although its emission lines are still\nbelow their maximum observed strength, consistent with the proposed 55-year\nperiod. We measured $\\langle B_z\\rangle=-325 \\pm 45$ G, twice the strength of\nthe 2007-2009 observations, raising the lower limit of the dipole surface\nmagnetic field strength to $B_{\\rm d} \\ge 1$ kG. The simultaneous increase in\n$\\langle B_z\\rangle$~and emission strength is consistent with the oblique\nrotator model. Extrapolation of the $\\langle B_z\\rangle$~maximum via comparison\nof HD 108's spectroscopic and magnetic data with the similar Of?p star HD\n191612 suggests that $B_{\\rm d} > 2$~kG, yielding $t_{\\rm S, max}<3$~Myr,\ncompatible with the stellar age. These results also yield a better agreement\nbetween the observed X-ray luminosity and that predicted by the XADM model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a unified mathematical framework that elegantly describes\nminimally SUSY gauge theories in even dimension, ranging from $6d$ to $0d$, and\ntheir dualities. This approach combines recent developments on graded quiver\nwith potentials, higher Ginzburg algebras and higher cluster categories (also\nknown as $m$-cluster categories). Quiver mutations studied in the context of\nmathematics precisely correspond to the order $(m+1)$ dualities of the gauge\ntheories. Our work suggests that these equivalences of quiver gauge theories\nsit inside an infinite family of such generalized dualities, whose physical\ninterpretation is yet to be understood.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We pioneer a new future in robotic dust collection by introducing passive\ndust-collecting robots that, unlike their predecessors, do not require\nlocomotion to collect dust. While previous research has exclusively focused on\nactive dust-collecting robots, we show that these robots fail with respect to\npractical and theoretical aspects, as well as human factors. By contrast,\npassive robots, through their unconstrained versatility, shine brilliantly in\nall three metrics. We present a mathematical formalism of both paradigms\nfollowed by a user study and field study.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The quantum efficiency and reflectivity of thick, back-illuminated CCD's\nbeing fabricated at LBNL for astronomical applications are modeled and compared\nwith experiment. The treatment differs from standard thin-film optics in that\n(a) absorption is permitted in any film, (b) the 200--500~$\\mu$m thick silicon\nsubstrate is considered as a thin film in order to observe the fringing\nbehavior at long wavelengths, and (c) by using approximate boundary conditions,\nabsorption in the surface films is separated from absorption in the substrate.\nFor the quantum efficiency measurements the CCD's are normally operated as\nCCD's, usually at $T = -140^\\circ$C, and at higher temperatures as photodiodes.\nThey are mounted on mechanical substrates. Reflectivity is measured on\nair-backed wafer samples at room temperature. The agreement between model\nexpectation and quantum efficiency measurement is in general satisfactory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss how visions for the futures of humanity in space and SETI are\nintertwined, and are shaped by prior work in the fields and by science fiction.\nThis appears in the language used in the fields, and in the sometimes implicit\nassumptions made in discussions of them. We give examples from articulations of\nthe so-called Fermi Paradox, discussions of the settlement of the Solar System\n(in the near future) and the Galaxy (in the far future), and METI. We argue\nthat science fiction, especially the campy variety, is a significant\ncontributor to the \"giggle factor\" that hinders serious discussion and funding\nfor SETI and Solar System settlement projects. We argue that humanity's\nlong-term future in space will be shaped by our short-term visions for who goes\nthere and how. Because of the way they entered the fields, we recommend\navoiding the term \"colony\" and its cognates when discussing the settlement of\nspace, as well as other terms with similar pedigrees. We offer examples of\nscience fiction and other writing that broaden and challenge our visions of\nhuman futures in space and SETI. In an appendix, we use an analogy with the\nwell-funded and relatively uncontroversial searches for the dark matter\nparticle to argue that SETI's lack of funding in the national science portfolio\nis primarily a problem of perception, not inherent merit.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report the serendipitous discovery of the first gravitationally lensed\nquasar candidate from Pan-STARRS. The grizy images reveal four point-like\nimages with magnitudes between 14.9 mag and 18.1 mag. The colors of the point\nsources are similar, and they are more consistent with quasars than with stars\nor galaxies. The lensing galaxy is detected in the izy bands, with an inferred\nphotometric redshift of ~0.6, lower than that of the point sources. We\nsuccessfully model the system with a singular isothermal ellipsoid with shear,\nusing the relative positions of the five objects as constraints. While the\nbrightness ranking of the point sources is consistent with that of the model,\nwe find discrepancies between the model-predicted and observed fluxes, likely\ndue to microlensing by stars and millilensing due to the dark matter\nsubstructure. In order to fully confirm the gravitational lens nature of this\nsystem and add it to the small but growing number of the powerful probes of\ncosmology and astrophysics represented by quadruply lensed quasars, we require\nfurther spectroscopy and high-resolution imaging.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We provide a unified approach, via deformations of incidence algebras, to\nseveral important types of representations with finiteness conditions, as well\nas the combinatorial algebras which produce them. We show that over finite\ndimensional algebras, representations with finitely many orbits, or finitely\nmany invariant subspaces, or distributive coincide, and further coincide with\nthin modules in the acyclic case. Incidence algebras produce examples of such\nmodules, and we show that algebras which are locally hereditary, and whose\nprojective are distributive, or equivalently, which have finitely many ideals,\nare precisely the deformations of incidence algebras, and they are the finite\ndimensional algebra analogue of Pr${\\rm \\ddot{u}}$fer rings. New\ncharacterizations of incidence algebras are obtained, such as they are exactly\nalgebras which have a faithful thin module. A main consequence is that \"every\nthin module comes from an incidence algebra\": if $V$ is either a thin module\nover a finite dimensional algebra $A$, or $V$ is distributive and $A$ is\nacyclic, then $A/{\\rm ann}(V)$ is an incidence algebra and $V$ can be presented\nas its defining representation. We classify thin/distributive modules, and\nrespectively deformations, of incidence algebras in terms of first and second\ncohomology of the simplicial realization of the poset. As a main application we\nobtain a complete classification of thin modules over any finite dimensional\nalgebra. Their moduli spaces are multilinear varieties, and we show that any\nmultilinear variety can be obtained in this way. A few other applications, to\nGrothendieck rings of combinatorial algebras, to graphs and their incidence\nmatrices, to linear algebra (tori actions on matrices), and to a positive\nanswer to the \"no-gap conjecture\" of Ringel and Bongartz, in the distributive\ncase, are given. Other results in the literature are re-derived.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This article provides next step towards solving speed bottleneck of any\nsystem that intensively uses convolutions operations (e.g. CNN). Method\ndescribed in the article is applied on deformable part models (DPM) algorithm.\nMethod described here is based on multidimensional tensors and provides\nefficient tradeoff between DPM performance and accuracy. Experiments on various\ndatabases, including Pascal VOC, show that the proposed method allows\ndecreasing a number of convolutions up to 4.5 times compared with DPM v.5,\nwhile maintaining similar accuracy. If insignificant accuracy degradation is\nallowable, higher computational gain can be achieved. The method consists of\nfilters tensor decomposition and convolutions shortening using the decomposed\nfilter. Mathematical overview of the proposed method as well as simulation\nresults are provided.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Modelling of thermonuclear X-ray bursts on accreting neutron stars has to\ndate focused on stable accretion rates. However, bursts are also observed\nduring episodes of transient accretion. During such events, the accretion rate\ncan evolve significantly between bursts, and this regime provides a unique test\nfor burst models. The accretion-powered millisecond pulsar SAX J1808.4-3658\nexhibits accretion outbursts every 2-3 years. During the well-sampled\nmonth-long outburst of 2002 October, four helium-rich X-ray bursts were\nobserved. Using this event as a test case, we present the first multi-zone\nsimulations of X-ray bursts under a time-dependent accretion rate. We\ninvestigate the effect of using a time-dependent accretion rate in comparison\nto constant, averaged rates. Initial results suggest that using a constant,\naverage accretion rate between bursts may underestimate the recurrence time\nwhen the accretion rate is decreasing, and overestimate it when the accretion\nrate is increasing. Our model, with an accreted hydrogen fraction of $X=0.44$\nand a CNO metallicity of $Z_\\mathrm{CNO}=0.02$, reproduces the observed burst\narrival times and fluences with root mean square (RMS) errors of\n$2.8\\,\\mathrm{h}$, and $0.11\\times 10^{-6}\\,\\mathrm{erg\\, cm^{-2}}$,\nrespectively. Our results support previous modelling that predicted two\nunobserved bursts, and indicate that additional bursts were also missed by\nobservations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hippocampal cognitive map---a neuronal representation of the spatial\nenvironment---is broadly discussed in the computational neuroscience literature\nfor decades. More recent studies point out that hippocampus plays a major role\nin producing yet another cognitive framework that incorporates not only\nspatial, but also nonspatial memories---the memory space. However, unlike\ncognitive maps, memory spaces have been barely studied from a theoretical\nperspective. Here we propose an approach for modeling hippocampal memory spaces\nas an epiphenomenon of neuronal spiking activity. First, we suggest that the\nmemory space may be viewed as a finite topological space---a hypothesis that\nallows treating both spatial and nonspatial aspects of hippocampal function on\nequal footing. We then model the topological properties of the memory space to\ndemonstrate that this concept naturally incorporates the notion of a cognitive\nmap. Lastly, we suggest a formal description of the memory consolidation\nprocess and point out a connection between the proposed model of the memory\nspaces to the so-called Morris' schemas, which emerge as the most compact\nrepresentation of the memory structure.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper presents an empirical study of two machine translation-based\napproaches for Vietnamese diacritic restoration problem, including phrase-based\nand neural-based machine translation models. This is the first work that\napplies neural-based machine translation method to this problem and gives a\nthorough comparison to the phrase-based machine translation method which is the\ncurrent state-of-the-art method for this problem. On a large dataset, the\nphrase-based approach has an accuracy of 97.32% while that of the neural-based\napproach is 96.15%. While the neural-based method has a slightly lower\naccuracy, it is about twice faster than the phrase-based method in terms of\ninference speed. Moreover, neural-based machine translation method has much\nroom for future improvement such as incorporating pre-trained word embeddings\nand collecting more training data.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A rational function on a real algebraic curve $C$ is called separating if it\ntakes real values only at real points. Such a function defines a covering $\\Bbb\nR C\\to\\Bbb{RP}^1$. Let $A_1,\\dots,A_n$ be connected components of $C$. In a\nrecent paper M. Kummer and K. Shaw defined the separating semigroup of $C$ as\nthe set of all sequences $(d_1(f),\\dots,d_n(f))$ where $f$ is a separating\nfunction and $d_i(f)$ is the degree of the restriction of $f$ to $A_i$.\n  We describe the separating semigroup for hyperelliptic curves and for genus 3\ncurves.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Answering a question posed by Conway and Norton in their seminal 1979 paper\non moonshine, we prove the existence of a graded infinite-dimensional module\nfor the sporadic simple group of O'Nan, for which the McKay--Thompson series\nare weight $3/2$ modular forms. The coefficients of these series may be\nexpressed in terms of class numbers, traces of singular moduli, and central\ncritical values of quadratic twists of weight 2 modular $L$-functions. As a\nconsequence, for primes $p$ dividing the order of the O'Nan group we obtain\ncongruences between O'Nan group character values and class numbers, $p$-parts\nof Selmer groups, and Tate--Shafarevich groups of certain elliptic curves. This\nwork represents the first example of moonshine involving arithmetic invariants\nof this type.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  LCLs or locally checkable labelling problems (e.g. maximal independent set,\nmaximal matching, and vertex colouring) in the LOCAL model of computation are\nvery well-understood in cycles (toroidal 1-dimensional grids): every problem\nhas a complexity of $O(1)$, $\\Theta(\\log^* n)$, or $\\Theta(n)$, and the design\nof optimal algorithms can be fully automated.\n  This work develops the complexity theory of LCL problems for toroidal\n2-dimensional grids. The complexity classes are the same as in the\n1-dimensional case: $O(1)$, $\\Theta(\\log^* n)$, and $\\Theta(n)$. However, given\nan LCL problem it is undecidable whether its complexity is $\\Theta(\\log^* n)$\nor $\\Theta(n)$ in 2-dimensional grids.\n  Nevertheless, if we correctly guess that the complexity of a problem is\n$\\Theta(\\log^* n)$, we can completely automate the design of optimal\nalgorithms. For any problem we can find an algorithm that is of a normal form\n$A' \\circ S_k$, where $A'$ is a finite function, $S_k$ is an algorithm for\nfinding a maximal independent set in $k$th power of the grid, and $k$ is a\nconstant.\n  Finally, partially with the help of automated design tools, we classify the\ncomplexity of several concrete LCL problems related to colourings and\norientations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove that every surjective isometry between the unit spheres of two\natomic JBW$^*$-triples $E$ and $B$ admits a unit extension to a surjective real\nlinear isometry from $E$ into $B$. This result constitutes a new positive\nanswer to Tignley's problem in the Jordan setting.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We construct (infinitely many) examples in all dimensions of\ncontactomorphisms of closed overtwisted contact manifolds that are smoothly\nisotopic but not contact-isotopic to the identity.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Kapustin-Witten equations on R^4 are equations for a pair of connection\non the product principle SU(2) bundle and 1-form with values in the product Lie\nalgebra bundle. The 1-form is the Higgs field. A dichotomy is proved to the\neffect that either the averaged norm of the Higgs field on large radius spheres\ngrows faster than a power of the radius, or its 1-form components everywhere\npairwise commute.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this article we give an order-dividing bijective function between cyclic\nand non cyclic groups of finite order. In particular, we prove that there\nexists a bijective function from D_{2n} to Z_{2n} for any natural integer n;\nand from Z_p x Z_k to Z_{pk} when p is an odd prime and k is not a multiple of\np.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present the QCD predictions for the azimuthal $\\cos 2\\varphi$ asymmetry in\ncharm leptoproduction for the kinematics of the COMPASS experiment at CERN. The\nasymmetry is predicted to be large, about 15%. The radiative corrections to the\nQCD predictions for the $\\cos 2\\varphi$ distribution are estimated to be small,\nless than 10%. Our calculations show that the azimuthal asymmetry in charm\nproduction is well defined in pQCD: it is stable both perturbatively and\nparametrically, and practically insensitive to theoretical uncertainties in the\ninput parameters. We analyze the nonperturbative contributions to the $\\cos\n2\\varphi$ distribution due to the gluon transverse motion in the target and the\n$c$-quark fragmentation. Because of the $c$-quark low mass, the nonperturbative\ncontributions are expected to be sizable, about (30--40)%. We conclude that\nextraction of the azimuthal asymmetries from available COMPASS data will\nprovide valuable information about the transverse momentum dependent\ndistribution of the gluon in the proton and the $c$-quark hadronization\nmechanism. Finally, we discuss the $\\cos 2\\varphi$ asymmetry as a probe of the\ngluonic analogue of the Boer-Mulders function, $h_{1}^{\\perp g}$, describing\nthe linear polarization of gluons inside unpolarized proton.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper investigates lozenge tilings of non-convex hexagonal regions and\nmore specifically the asymptotic fluctuations of the tilings within and near\nthe strip formed by opposite cuts in the regions, when the size of the regions\ntend to infinity, together with the cuts. It leads to a new kernel, which is\nexpected to have universality properties.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We comprehensively evaluate renormalized Higgs boson couplings at one-loop\nlevel in non-minimal Higgs models such as the Higgs Singlet Model (HSM) and the\nfour types of Two Higgs Doublet Models (THDMs) with a softly-broken $Z_2$\nsymmetry. The renormalization calculation is performed in the on-shell scheme\nimproved by using the pinch technique to eliminate the gauge dependence in the\nrenormalized couplings. We first review the pinch technique for scalar boson\ntwo-point functions in the Standard Model (SM), the HSM and the THDMs. We then\ndiscuss the difference in the results of the renormalized Higgs boson couplings\nbetween the improved on-shell scheme and the ordinal one with a gauge\ndependence appearing in mixing parameters of scalar bosons. Finally, we widely\ninvestigate how we can identify the HSM and the THDMs focusing on the pattern\nof deviations in the renormalized Higgs boson couplings from predictions in the\nSM.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We provide a classification of Einstein submanifolds in space forms with flat\nnormal bundle and parallel mean curvature. This extends a previous result due\nto Dajczer and Tojeiro for isometric immersions of Riemannian manifolds with\nconstant sectional curvature.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The nearly perfect fluid-like nature of the Quark Gluon Plasma may be\nunderstood through two key experimental signatures: collective flow and jet\nsuppression. Event-by-event relativistic viscous hydrodynamics (with an\nextremely small shear viscosity to entropy density ratio) has been very\nsuccessful at describing collective flow observables for the last 7 years. More\nrecently, the effects of event-by-event fluctuations have been studied in the\ncontext of high $p_T$ particles that lose energy as they pass through the dense\nQuark Gluon Plasma liquid. In this summary of the corresponding plenary talk at\nQuark Matter 2017, the recent developments on the effects of event-by-event\nfluctuations on jet suppression are summarized.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the hierarchical paradigm of structure formation, galaxy clusters are the\nlargest objects ever to virialize. They are thought to grow by accreting mass\nthrough large scale, strong virial shocks. Such a collisionless shock is\nexpected to accelerate relativistic electrons, thus generating a spectrally\nflat leptonic virial ring. However attempts to detect virial rings have all\nfailed, leaving the shock paradigm unconfirmed. Here we identify a virial\n$\\gamma$-ray signal by stacking Fermi-LAT data for 112 clusters, enhancing the\nring sensitivity by rescaling clusters to their virial radii and utilizing the\nanticipated spectrum. In addition to a central unresolved, hard signal\n(detected at the nominal $5.8\\sigma$ confidence level), probably dominated by\nactive galactic nuclei, we identify ($5.9\\sigma$) a bright, spectrally flat\n$\\gamma$-ray ring at the expected shock position. It corresponds to $\\sim\n0.6\\%$ (with an uncertainty factor $\\sim2$) thermal energy deposition in\nrelativistic electrons over a Hubble time. This result validates the shock\nparadigm, calibrates its parameters, and indicates that the cumulative emission\nfrom such shocks significantly contributes to the diffuse extragalactic\n$\\gamma$-ray and radio backgrounds.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We compute the topological susceptibility $\\chi_t$ of 2+1-flavor lattice QCD\nwith dynamical M\\\"obius domain-wall fermions, whose residual mass is kept at 1\nMeV or smaller. In our analysis, we focus on the fluctuation of the topological\ncharge density in a \"slab\" sub-volume of the simulated lattice, as proposed by\nBietenholz et al. The quark mass dependence of our results agrees well with the\nprediction of the chiral perturbation theory, from which the chiral condensate\nis extracted. Combining the results for the pion mass $M_\\pi$ and decay\nconstant $F_\\pi$, we obtain $\\chi_t$ = 0.227(02)(11)$M_\\pi^2 F_\\pi^2$ at the\nphysical point, where the first error is statistical and the second is\nsystematic.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We develop a simple one-zone model of the steady-state Crab nebula spectrum\nencompassing both the radio/soft $X$-ray and the GeV/multi-TeV observations. By\nsolving the transport equation for GeV-TeV electrons injected at the wind\ntermination shock as a log-parabola momentum distribution and evolved via\nenergy losses, we determine analytically the resulting differential energy\nspectrum of photons. We find an impressive agreement with the observed spectrum\nof synchrotron emission, and the synchrotron self-Compton component reproduces\nthe previously unexplained broad $200$-GeV peak that matches the Fermi/LAT data\nbeyond $1$ GeV with the MAGIC data. We determine the parameters of the single\nlog-parabola electron injection distribution, in contrast with multiple broken\npower-law electron spectra proposed in the literature. The resulting photon\ndifferential spectrum provides a natural interpretation of the deviation from\npower-law customarily fit with empirical multiple broken power-laws. Our model\ncan be applied to the radio-to-multi-TeV spectrum of a variety of astrophysical\noutflows, including pulsar wind nebulae and supernova remnants, as well as to\ninterplanetary shocks.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  How does the neocortex learn and develop the foundations of all our\nhigh-level cognitive abilities? We present a comprehensive framework spanning\nbiological, computational, and cognitive levels, with a clear theoretical\ncontinuity between levels, providing a coherent answer directly supported by\nextensive data at each level. Learning is based on making predictions about\nwhat the senses will report at 100 msec (alpha frequency) intervals, and\nadapting synaptic weights to improve prediction accuracy. The pulvinar nucleus\nof the thalamus serves as a projection screen upon which predictions are\ngenerated, through deep-layer 6 corticothalamic inputs from multiple brain\nareas and levels of abstraction. The sparse driving inputs from layer 5\nintrinsic bursting neurons provide the target signal, and the temporal\ndifference between it and the prediction reverberates throughout the cortex,\ndriving synaptic changes that approximate error backpropagation, using only\nlocal activation signals in equations derived directly from a detailed\nbiophysical model. In vision, predictive learning requires a\ncarefully-organized developmental progression and anatomical organization of\nthree pathways (What, Where, and What * Where), according to two central\nprinciples: top-down input from compact, high-level, abstract representations\nis essential for accurate prediction of low-level sensory inputs; and the\ncollective, low-level prediction error must be progressively and\nopportunistically partitioned to enable extraction of separable factors that\ndrive the learning of further high-level abstractions. Our model self-organized\nsystematic invariant object representations of 100 different objects from\nsimple movies, accounts for a wide range of data, and makes many testable\npredictions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Traditional approaches to stereo visual SLAM rely on point features to\nestimate the camera trajectory and build a map of the environment. In\nlow-textured environments, though, it is often difficult to find a sufficient\nnumber of reliable point features and, as a consequence, the performance of\nsuch algorithms degrades. This paper proposes PL-SLAM, a stereo visual SLAM\nsystem that combines both points and line segments to work robustly in a wider\nvariety of scenarios, particularly in those where point features are scarce or\nnot well-distributed in the image. PL-SLAM leverages both points and segments\nat all the instances of the process: visual odometry, keyframe selection,\nbundle adjustment, etc. We contribute also with a loop closure procedure\nthrough a novel bag-of-words approach that exploits the combined descriptive\npower of the two kinds of features. Additionally, the resulting map is richer\nand more diverse in 3D elements, which can be exploited to infer valuable,\nhigh-level scene structures like planes, empty spaces, ground plane, etc. (not\naddressed in this work). Our proposal has been tested with several popular\ndatasets (such as KITTI and EuRoC), and is compared to state of the art methods\nlike ORB-SLAM, revealing a more robust performance in most of the experiments,\nwhile still running in real-time. An open source version of the PL-SLAM C++\ncode will be released for the benefit of the community.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $R$ be a ring, let $\\mathfrak{a}\\subseteq R$ be an ideal, and let $M$ be\nan $R$-module. Let $\\Gamma_{\\mathfrak{a}}$ denote the $\\mathfrak{a}$-torsion\nfunctor. Conditions are given for the (weakly) associated primes of\n$\\Gamma_{\\mathfrak{a}}(M)$ to be the (weakly) associated primes of $M$\ncontaining $\\mathfrak{a}$, and for the (weakly) associated primes of\n$M/\\Gamma_{\\mathfrak{a}}(M)$ to be the (weakly) associated primes of $M$ not\ncontaining $\\mathfrak{a}$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report a study of structural and electronic properties of a germanium\nlayer on Al(111) using scanning tunneling microscopy (STM), low energy electron\ndiffraction and core-level photoelectron spectroscopy. Experimental results\nshow that a germanium layer can be formed at a relatively high substrate\ntemperature showing either (3$\\times$3) or\n($\\sqrt{7}$$\\times$$\\sqrt{7}$)R$\\pm$19.1{\\deg} reconstructions.\nFirst-principles calculations based on density functional theory suggest an\natomic model consisting of a strongly buckled (2$\\times$2) germanene layer,\nwhich is stable in two different orientations on Al(111). Simulated STM of both\norientations fit nicely with experimental STM images and the Ge 3d core-level\ndata decomposed into four components is consistent with the suggested model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This study aims to investigate the effects of violations of the sphericity\nassumption on Type I error rates for different methodical approaches of\nrepeated measures analysis using a simulation approach. In contrast to previous\nsimulation studies on this topic, up to nine measurement occasions were\nconsidered. Therefore, two populations representing the conditions of a\nviolation vs. a non-violation of the sphericity assumption without any\nbetween-group effect or within-subject effect were created and 5,000 random\nsamples of each population were drawn. Finally, the mean Type I error rates for\nMultilevel linear models (MLM) with an unstructured covariance matrix (MLM-UN),\nMLM with compound-symmetry (MLM-CS) and for repeated measures analysis of\nvariance (rANOVA) models (without correction, with\nGreenhouse-Geisser-correction, and Huynh-Feldt-correction) were computed. To\nexamine the effect of both the sample size and the number of measurement\noccasions, sample sizes of n = 20, 40, 60, 80, and 100 were considered as well\nas measurement occasions of m = 3, 6 and 9. For MLM-UN, the results illustrate\na massive progressive bias for small sample sizes (n =20) and m = 6 or more\nmeasurement occasions. This effect could not be found in previous simulation\nstudies with a smaller number of measurement occasions. The mean Type I error\nrates for rANOVA with Greenhouse-Geisser-correction demonstrate a small\nconservative bias if sphericity was not violated, sample sizes were small (n =\n20), and m = 6 or more measurement occasions were conducted. The results plead\nfor a use of rANOVA with Huynh-Feldt-correction, especially when the sphericity\nassumption is violated, the sample size is rather small and the number of\nmeasurement occasions is large. MLM-UN may be used when the sphericity\nassumption is violated and when sample sizes are large.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the following two-parameter variant of the Erd\\H os-Falconer\ndistance problem. Given $E,F \\subset {\\Bbb F}_q^{k+l}$, $l \\geq k \\ge 2$, the\n$k+l$-dimensional vector space over the finite field with $q$ elements, let\n$B_{k,l}(E,F)$ be given by $$\\{(\\Vert x'-y'\\Vert, \\Vert x\"-y\" \\Vert): x=(x',x\")\n\\in E, y=(y',y\") \\in F; x',y' \\in {\\Bbb F}_q^k, x\",y\" \\in {\\Bbb F}_q^l \\}.$$\n  We prove that if $|E||F| \\geq C q^{k+2l+1}$, then $B_{k,l}(E,F)={\\Bbb F}_q\n\\times {\\Bbb F}_q$. Furthermore this result is sharp if $k$ is odd. For the\ncase of $l=k=2$ and $q$ a prime with $q \\equiv 3 \\mod 4$ we get that for every\npositive $C$ there is $c$ such that $$ \\text{if } |E||F|>C\nq^{6+\\frac{2}{3}}\\text{, then } |B_{2,2}(E,F)|> c q^{2}.$$\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Quantum mechanics makes the otherwise stable vacua of a theory metastable\nthrough the nucleation of bubbles of the new vacuum. This in turn causes a\nfirst order phase transition. These cosmological phase transitions may have\nplayed an important role in settling our universe into its current vacuum, and\nthey may also happen in future. The most important frameworks where vacuum\ndecay happens contain a large number of fields. Unfortunately, calculating the\ntunneling rates in these models is very time-consuming. In this paper we\npresent a simple approximation for the tunneling rate by reducing it to a\none-field problem which is easy to calculate. We demonstrate the validity of\nthis approximation using our recent code \"Anybubble\" for several classes of\npotentials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We calculate power corrections to TMD factorization for particle production\nby gluon-gluon fusion in hadron-hadron collisions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Large area Gas Electron Multiplier (GEM) detectors have been the preferred\nchoice for tracking devices in major nuclear and particle physics experiments.\nUniformity over surface of the detector in terms of gain, energy resolution and\nefficiency is crucial for the optimum performance of these detectors. In the\npresent work, detailed performance study of a 10x10 cm^2 triple GEM detector\noperated using Ar and CO_2 gas mixtures in proportions of 70:30 and 90:10, has\nbeen made by making a voltage scan of the efficiency with 106^Ru-Rh beta-source\nand cosmic rays. The gain and energy resolution of the detector were studied\nusing the X-ray spectrum of 55^Fe source. The uniformity of the detector has\nbeen investigated by dividing the detector in 7x7 zones and measuring the gain\nand energy resolution at the center of each zone. The variations of the gain\nand energy resolution have been found to be 8.8% and 6.7%, respectively. These\nstudies are essential to characterise GEM detectors before their final use in\nthe experiments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Plasmonic nanoparticles hold great promise as photon handling elements and as\nchannels for coherent transfer of energy and information in future all-optical\ncomputing devices. Coherent energy oscillations between two spatially separated\nplasmonic entities via a virtual middle state exemplify electron-based\npopulation transfer, but their realization requires precise nanoscale\npositioning of heterogeneous particles. Here, we show the assembly and optical\nanalysis of a triple particle system consisting of two gold nanoparticles with\nan inter-spaced silver island. We observe strong plasmonic coupling between the\nspatially separated gold particles mediated by the connecting silver particle\nwith almost no dissipation of energy. As the excitation energy of the silver\nisland exceeds that of the gold particles, only quasi-occupation of the silver\ntransfer channel is possible. We describe this effect both with exact classical\nelectrodynamic modeling and qualitative quantum-mechanical calculations. We\nidentify the formation of strong hot spots between all particles as the main\nmechanism for the loss-less coupling and thus coherent ultra-fast energy\ntransfer between the remote partners. Our findings could prove useful for\nquantum gate operations, but also for classical charge and information transfer\nprocesses.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We detect the quantum phase transition of a quantum many-body system by\nmapping the observed results of the quantum state onto a neural network. In the\npresent study, we utilized the simplest case of a quantum many-body system,\nnamely a one-dimensional chain of Ising spins with the transverse Ising model.\nWe prepared several spin configurations, which were obtained using repeated\nobservations of the model for a particular strength of the transverse field, as\ninput data for the neural network. Although the proposed method can be employed\nusing experimental observations of quantum many-body systems, we tested our\ntechnique with spin configurations generated by a quantum Monte Carlo\nsimulation without initial relaxation. The neural network successfully\nclassified the strength of transverse field only from the spin configurations,\nleading to consistent estimations of the critical point of our model $\\Gamma_c\n=J$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper provides an overview of the triple scoring task at the WSDM Cup\n2017, including a description of the task and the dataset, an overview of the\nparticipating teams and their results, and a brief account of the methods\nemployed. In a nutshell, the task was to compute relevance scores for\nknowledge-base triples from relations, where such scores make sense. Due to the\nway the ground truth was constructed, scores were required to be integers from\nthe range 0..7. For example, reasonable scores for the triples \"Tim Burton\nprofession Director\" and \"Tim Burton profession Actor\" would be 7 and 2,\nrespectively, because Tim Burton is well-known as a director, but he acted only\nin a few lesser known movies.\n  The triple scoring task attracted considerable interest, with 52 initial\nregistrations and 21 teams who submitted a valid run before the deadline. The\nwinning team achieved an accuracy of 87%, that is, for that fraction of the\ntriples from the test set (which was revealed only after the deadline) the\ndifference to the score from the ground truth was at most 2. The best result\nfor the average difference from the test set scores was 1.50.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Regardless of the gold-standard being considered as outdated, it provides\nvaluable signs concerning the development of novel monetary standards, better\nadjusted to the current macroeconomic environment. By using a point of view of\nclassical physics, the intent of this work is doing a review of the concept of\nmonetary standard and show that the energy matrix of an economy together with a\nnew monetary standard, based on the energy supply capacity, can play an\nessential role in the sustainable growth.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, the analysis of the performance of the concatenation of a\nshort polar code with an outer binary linear block code is addressed from a\ndistance spectrum viewpoint. The analysis targets the case where an outer\ncyclic code is employed together with an inner systematic polar code. A\nconcatenated code ensemble is introduced placing an interleaver at the input of\nthe polar encoder. The introduced ensemble allows deriving bounds on the\nachievable error rates under maximum likelihood decoding, by applying the union\nbound to the (expurgated) average weight enumerators. The analysis suggests the\nneed of careful optimization of the outer code, to attain low error floors.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A geometric reformulation of the martingale problem associated with a set of\ndiffusion processes is proposed. This formulation, based on second order\ngeometry and Ito integration on manifolds, allows us to give a natural and\neffective definition of Lie symmetries for diffusion processes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Compared to LiDAR-based localization methods, which provide high accuracy but\nrely on expensive sensors, visual localization approaches only require a camera\nand thus are more cost-effective while their accuracy and reliability typically\nis inferior to LiDAR-based methods. In this work, we propose a vision-based\nlocalization approach that learns from LiDAR-based localization methods by\nusing their output as training data, thus combining a cheap, passive sensor\nwith an accuracy that is on-par with LiDAR-based localization. The approach\nconsists of two deep networks trained on visual odometry and topological\nlocalization, respectively, and a successive optimization to combine the\npredictions of these two networks. We evaluate the approach on a new\nchallenging pedestrian-based dataset captured over the course of six months in\nvarying weather conditions with a high degree of noise. The experiments\ndemonstrate that the localization errors are up to 10 times smaller than with\ntraditional vision-based localization methods.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A cosmic lepton asymmetry\n$\\eta_{\\text{l}}=(n_{\\text{l}}-n_{\\bar{\\text{l}}})/n_{\\gamma}$ affects the\nprimordial helium abundance and the expansion rate of the early Universe. Both\nof these effects have an impact on the anisotropies of the cosmic microwave\nbackground (CMB). We derive constraints on the neutrino chemical potentials\nfrom the Planck 2015 data, assuming equal lepton flavour asymmetries and\nnegligible neutrino masses. We find $\\xi=-0.002 ^{+0.114}_{-0.111}$ (95\\% CL)\nfor the chemical potentials, which corresponds to $ -0.085 \\leq \\eta_{\\text{l}}\n\\leq 0.084$. Our constraints on the lepton asymmetry are significantly stronger\nthan previous constraints from CMB data analysis and we argue that they are\nmore robust than those from primordial light element abundances. The resulting\nconstraints on the primordial helium and deuterium abundances are consistent\nwith those from direct measurements.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Assuming the classical Farrell-Jones conjecture we produce an explicit\n(commutative) group ring $R$ and a thick subcategory $\\mathsf{C}$ of perfect\n$R$-complexes such that the Waldhausen $K$-theory space\n$\\mathrm{K}(\\mathsf{C})$ is equivalent to a rational Eilenberg-Maclane space.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We numerically investigate and experimentally demonstrate an in-situ\ntopological band transition in a highly tunable mechanical system made of\ncylindrical granular particles. This system allows us to tune its\ninter-particle stiffness in a controllable way, simply by changing the contact\nangles between the cylinders. The spatial variation of particles' stiffness\nresults in an in-situ transition of the system's topology. This manifests as\nthe emergence of a boundary mode in the finite system, which we observe\nexperimentally via laser Doppler vibrometry. When two topologically different\nsystems are placed adjacently, we analytically predict and computationally and\nexperimentally demonstrate the existence of a finite-frequency topologically\nprotected mode at their interface.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a new theoretical framework for deriving lower bounds on data\nmovement in bilinear algorithms. Bilinear algorithms are a general\nrepresentation of fast algorithms for bilinear functions, which include\ncomputation of matrix multiplication, convolution, and symmetric tensor\ncontractions. A bilinear algorithm is described by three matrices. Our\ncommunication lower bounds are based on quantifying the minimal matrix ranks of\nmatching subsets of columns of these matrices. This infrastructure yields new\ncommunication lower bounds for symmetric tensor contraction algorithms, which\nprovide qualitative new insights. Tensor symmetry (invariance under permutation\nof modes) is common to many applications of tensor computations (e.g., tensor\nrepresentation of hypergraphs, analysis of high order moments in data, as well\nas tensors modelling interactions of electrons in computational chemistry).\nTensor symmetry enables reduction in representation size as well as arithmetic\ncost of contractions by factors that scale with the number of equivalent\npermutations. However, we derive lower bounds showing that these arithmetic\ncost and memory reductions can necessitate increases in data movement by\nfactors that scale with the size of the tensors.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a new blind source separation algorithm based on mixtures of\nalpha-stable distributions. Complex symmetric alpha-stable distributions have\nbeen recently showed to better model audio signals in the time-frequency domain\nthan classical Gaussian distributions thanks to their larger dynamic range.\nHowever, inference of these models is notoriously hard to perform because their\nprobability density functions do not have a closed-form expression in general.\nHere, we introduce a novel method for estimating mixture of alpha-stable\ndistributions based on characteristic function matching. We apply this to the\nblind estimation of binary masks in individual frequency bands from\nmultichannel convolutive audio mixes. We show that the proposed method yields\nbetter separation performance than Gaussian-based binary-masking methods.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Observations strongly suggest that filaments in galactic molecular clouds are\nin a non-thermal state. As a simple model of a filament we study a\ntwo-dimensional system of self-gravitating point particles by means of\nnumerical simulations of the dynamics, with various methods: direct $N$-body\nintegration of the equations of motion, particle-in-cell simulations and a\nrecently developed numerical scheme that includes multiparticle collisions in a\nparticle-in-cell approach. Studying the collapse of Gaussian overdensities we\nfind that after the damping of virial oscillations the system settles in a\nnon-thermal steady state whose radial density profile is similar to the\nobserved ones, thus suggesting a dynamical origin of the non-thermal states\nobserved in real filaments. Moreover, for sufficiently cold collapses the\ndensity profiles are anticorrelated with the kinetic temperature, i.e., exhibit\ntemperature inversion, again a feature that has been found in some observations\nof filaments. The same happens in the state reached after a strong perturbation\nof an initially isothermal cylinder. Finally, we discuss our results in the\nlight of recent findings in other contexts (including non-astrophysical ones)\nand argue that the same kind of non-thermal states may be observed in any\nphysical system with long-range interactions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recent studies showed that the in-plane and inter-plane thermal\nconductivities of two-dimensional (2D) MoS2 are low, posing a significant\nchallenge in heat management in MoS2-based electronic devices. To address this\nchallenge, we design the interfaces between MoS2 and graphene by fully\nutilizing graphene, a 2D material with an ultra-high thermal conduction. We\nfirst perform ab initio atomistic simulations to understand the bonding nature\nand structure stability of the interfaces. Our results show that the designed\ninterfaces, which are found to be connected together by strong covalent bonds\nbetween Mo and C atoms, are energetically stable. We then perform molecular\ndynamics simulations to investigate the interfacial thermal conductance. It is\nfound surprisingly that the interface thermal conductance is high, comparable\nto that of graphene-metal covalent-bonded interfaces. Importantly, each\ninterfacial Mo-C bond serves as an independent thermal channel, enabling the\nmodulation of interfacial thermal conductance by controlling Mo vacancy\nconcentration at the interface. The present work provides a viable route for\nheat management in MoS2 based electronic devices.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Bosonic cascade lasers are terahertz (THz) lasers based on stimulated\nradiative transitions between bosonic condensates of excitons or\nexciton-polaritons confined in a trap. We study the interaction of an incoming\nTHz pulse resonant in frequency with the transitions between neighboring energy\nlevels of the cascade. We show that at certain optical pump conditions the\ncascade becomes transparent to the incident pulse: it neither absorbs nor\namplifies it, in the mean field approximation. The populations of intermediate\nlevels of the bosonic cascade change as the THz pulse passes, nevertheless. In\ncomparison, a fermionic cascade laser does not reveal any of these properties.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  It is well known that a sequence of two non-collinear pure Lorentz\ntransformations (boosts) is not a boost again, but involves a spatial rotation,\nthe Wigner or Thomas-Wigner rotation. The formation of this rotation is\nvisually illustrated by moving a Born-rigid object on a closed trajectory in\nseveral sections. Within each section the boost's proper time duration is\nassumed to be the same and the object's centre accelerates uniformly.\nBorn-rigidity implies that the stern of this object accelerates faster than its\nbow. It is shown that at least five boosts are required to return the object's\ncentre to its start position. With these assumptions, the Thomas-Wigner\nrotation angle depends on a single parameter only, the maximum speed reached\nwithin each boost section. The visualization highlights the close relationship\nbetween the Thomas-Wigner rotation and the relativity of simultaneity.\nFurthermore, it is illustrated that accelerated motion implies the formation of\nan event horizon. The event horizons associated with the five boosts constitute\na boundary to the rotated Born-rigid object and ensure its finite size.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Band structure, Fermi surface, and phonon dispersions of noncentrosymmetric\nB20-type RhGe are calculated ab initio for the first time and their evolution\nwith increasing pressure is investigated. We consider in detail\nsymmetry-conditioned features of the band structure, as well as\npressure-induced changes in the Fermi surface topology, which are expected to\naffect the thermopower of RhGe. We also report on special calculations of\nelectric field gradients on the Rh and Ge nuclei and compare these results with\na very recent 111 Cd-TDPAC study of B20-RhGe.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we investigate the $\\mathrm{L}^\\infty$-stability of fully\ndiscrete approximations of abstract linear parabolic partial differential\nequations. The method under consideration is based on an $hp$-type\ndiscontinuous Galerkin time stepping scheme in combination with general\nconforming Galerkin discretizations in space. Our main result shows that the\nglobal-in-time maximum norm of the discrete solution is bounded by the data of\nthe PDE, with a constant that is robust with respect to the discretization\nparameters (in particular, it is uniformly bounded with respect to the local\ntime steps and approximation orders).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Human actions often involve complex interactions across several inter-related\nobjects in the scene. However, existing approaches to fine-grained video\nunderstanding or visual relationship detection often rely on single object\nrepresentation or pairwise object relationships. Furthermore, learning\ninteractions across multiple objects in hundreds of frames for video is\ncomputationally infeasible and performance may suffer since a large\ncombinatorial space has to be modeled. In this paper, we propose to efficiently\nlearn higher-order interactions between arbitrary subgroups of objects for\nfine-grained video understanding. We demonstrate that modeling object\ninteractions significantly improves accuracy for both action recognition and\nvideo captioning, while saving more than 3-times the computation over\ntraditional pairwise relationships. The proposed method is validated on two\nlarge-scale datasets: Kinetics and ActivityNet Captions. Our SINet and\nSINet-Caption achieve state-of-the-art performances on both datasets even\nthough the videos are sampled at a maximum of 1 FPS. To the best of our\nknowledge, this is the first work modeling object interactions on open domain\nlarge-scale video datasets, and we additionally model higher-order object\ninteractions which improves the performance with low computational costs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper presents a novel method for assessing multiple fault\ndiagnosability and detectability of nonlinear parametrized dynamical models.\nThis method is based on computer algebra algorithms which return precomputed\nvalues of algebraic expressions characterizing the presence of some constant\nmultiple fault(s). Estimations of these expressions, obtained from inputs and\noutputs measurements, permit then the detection and the isolation of multiple\nfaults acting on the system. This method applied on a coupled water-tank model\nattests the relevance of the suggested approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we prove the existence of an exponentially localized stationary\nsolution for a two-dimensional cubic Dirac equation. It appears as an effective\nequation in the description of nonlinear waves for some Condensed Matter\n(Bose-Einstein condensates) and Nonlinear Optics (optical fibers) systems. The\nnonlinearity is of Kerr-type, that is of the form |$\\psi$| 2 $\\psi$ and thus\nnot Lorenz-invariant. We solve compactness issues related to the critical\nSobolev embedding H 1 2 (R 2 , C 2) $\\rightarrow$ L 4 (R 2 , C 4) thanks to a\nparticular radial ansatz. Our proof is then based on elementary dynamical\nsystems arguments. Contents\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Gene regulation is a series of processes that control gene expression and its\nextent. The connections among genes and their regulatory molecules, usually\ntranscription factors, and a descriptive model of such connections, are known\nas gene regulatory networks (GRNs). Elucidating GRNs is crucial to understand\nthe inner workings of the cell and the complexity of gene interactions. To\ndate, numerous algorithms have been developed to infer gene regulatory\nnetworks. However, as the number of identified genes increases and the\ncomplexity of their interactions is uncovered, networks and their regulatory\nmechanisms become cumbersome to test. Furthermore, prodding through\nexperimental results requires an enormous amount of computation, resulting in\nslow data processing. Therefore, new approaches are needed to expeditiously\nanalyze copious amounts of experimental data resulting from cellular GRNs. To\nmeet this need, cloud computing is promising as reported in the literature.\nHere we propose new MapReduce algorithms for inferring gene regulatory networks\non a Hadoop cluster in a cloud environment. These algorithms employ an\ninformation-theoretic approach to infer GRNs using time-series microarray data.\nExperimental results show that our MapReduce program is much faster than an\nexisting tool while achieving slightly better prediction accuracy than the\nexisting tool.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a general framework for nonasymptotic covariance matrix estimation\nmaking use of concentration inequality-based confidence sets. We specify this\nframework for the estimation of large sparse covariance matrices through\nincorporation of past thresholding estimators with key emphasis on support\nrecovery. This technique goes beyond past results for thresholding estimators\nby allowing for a wide range of distributional assumptions beyond merely\nsub-Gaussian tails. This methodology can furthermore be adapted to a wide range\nof other estimators and settings. The usage of nonasymptotic dimension-free\nconfidence sets yields good theoretical performance. Through extensive\nsimulations, it is demonstrated to have superior performance when compared with\nother such methods. In the context of support recovery, we are able to specify\na false positive rate and optimize to maximize the true recoveries.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We determine theoretically the effect of spin-orbit coupling on the magnetic\nexcitation spectrum of itinerant multi-orbital systems, with specific\napplication to iron-based superconductors. Our microscopic model includes a\nrealistic ten-band kinetic Hamiltonian, atomic spin-orbit coupling, and\nmulti-orbital Hubbard interactions. Our results highlight the remarkable\nvariability of the resulting magnetic anisotropy despite constant spin-orbit\ncoupling. At the same time, the magnetic anisotropy exhibits robust universal\nbehavior upon changes in the bandstructure corresponding to different materials\nof iron-based superconductors. A natural explanation of the observed\nuniversality emerges when considering optimal nesting as a resonance\nphenomenon. Our theory is also of relevance to other itinerant system with\nspin-orbit coupling and nesting tendencies in the bandstructure.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We determine local topological types of binary differential equations of\nasymptotic curves at parabolic and flat umbilical points for generic\n$2$-parameter families of surfaces in $\\mathbb P^3$ by comparing our projective\nclassification of Monge forms and classification of general BDE obtained by\nTari and Oliver. In particular, generic bifurcations of the parabolic curve are\nclassified. The flecnodal curve is also examined by direct computations, and we\npresent new bifurcation diagrams in typical examples.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report $^{23}$Na nuclear magnetic resonance (NMR) measurements of the Mott\ninsulator with strong spin-orbit interaction Ba$_{2}$NaOsO$_{6}$ as a function\nof temperature in different magnetic fields ranging from 7 T to 29 T. The\nmeasurements, intended to concurrently probe spin and orbital/lattice degrees\nof freedom, are an extension of our work at lower fields reported in Nat.\nCommun., v 8, 14407 (2017). We have identified clear quantitative NMR\nsignatures that display the appearance of a canted ferromagnetic phase, which\nis preceded by local point symmetry breaking. We have compiled the field\ntemperature phase diagram extending up to 29 T. We find that the broken local\npoint symmetry phase extends over a wider temperature range as magnetic field\nincreases.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the literature, channel estimation and synchronization (CE/SY) algorithms\nare classified as blind, and hence spectrally efficient, if they do not require\npilot symbols. However, we show in this letter that such classification is not\naccurate and can be misleading. Consequently, this letter presents a more\nreliable and accurate approach to evaluate the spectral efficiency of\ncommunications systems with various CE/SY algorithms. The proposed approach\nallows fair spectral efficiency comparison between various systems with blind\nor non-blind CE/SY algorithms. In particular, we evaluate the spectral\nefficiency of communications systems that incorporates blind CE/SY algorithms\nand compare it to other blind and pilot-based algorithms. The obtained results\nreveal that, on the contrary to what is widely accepted, blind CE/SY algorithms\nwith modulation-type constrain do not necessarily improve the spectral\nefficiency as compared to pilot-based techniques. Consequently, such techniques\nare classified as conditionally blind, to distinguish them from fully blind\ntechniques.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For rings $\\mathcal{O}_K$ of totally real algebraic integers, J. Robinson\ndefined a set which is always $\\{+\\infty\\}$ or of the form $[\\lambda,+\\infty)$\nor $(\\lambda,+\\infty)$ for some real number $\\lambda\\ge4$. All known examples\ngive either $\\{+\\infty\\}$ or $[4,+\\infty)$. In this paper, we construct\ninfinitely many fields such that the set is an interval, but not equal to\n$[4,+\\infty)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This chapter explores the physics shared by planetary rings and the various\ndisks that populate the Universe. It begins with an observational overview,\nranging from protoplanetary disks to spiral galaxies, and then compares and\ncontrasts these astrophysical disks with the rings of the Solar System.\nEmphasis is placed on fundamental physics and dynamics, and how research into\nthe two classes of object connects. Topics covered include disk formation,\naccretion, collisional processes, waves, instabilities, and satellite-disk\ninteractions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Planning the motion for humanoid robots is a computationally-complex task due\nto the high dimensionality of the system. Thus, a common approach is to first\nplan in the low-dimensional space induced by the robot's feet---a task referred\nto as footstep planning. This low-dimensional plan is then used to guide the\nfull motion of the robot. One approach that has proven successful in footstep\nplanning is using search-based planners such as A* and its many variants. To do\nso, these search-based planners have to be endowed with effective heuristics to\nefficiently guide them through the search space. However, designing effective\nheuristics is a time-consuming task that requires the user to have good domain\nknowledge. Thus, our goal is to be able to effectively plan the footstep\nmotions taken by a humanoid robot while obviating the burden on the user to\ncarefully design local-minima free heuristics. To this end, we propose to use\nuser-defined homotopy classes in the workspace that are intuitive to define.\nThese homotopy classes are used to automatically generate heuristic functions\nthat efficiently guide the footstep planner. Additionally, we present an\nextension to homotopy classes such that they are applicable to complex\nmulti-level environments. We compare our approach for footstep planning with a\nstandard approach that uses a heuristic common to footstep planning. In simple\nscenarios, the performance of both algorithms is comparable. However, in more\ncomplex scenarios our approach allows for a speedup in planning of several\norders of magnitude when compared to the standard approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Deep neural networks have been investigated in learning latent\nrepresentations of medical images, yet most of the studies limit their approach\nin a single supervised convolutional neural network (CNN), which usually rely\nheavily on a large scale annotated dataset for training. To learn image\nrepresentations with less supervision involved, we propose a deep Siamese CNN\n(SCNN) architecture that can be trained with only binary image pair\ninformation. We evaluated the learned image representations on a task of\ncontent-based medical image retrieval using a publicly available multiclass\ndiabetic retinopathy fundus image dataset. The experimental results show that\nour proposed deep SCNN is comparable to the state-of-the-art single supervised\nCNN, and requires much less supervision for training.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The \\emph{distance matrix} of a simple connected graph $G$ is\n$D(G)=(d_{ij})$, where $d_{ij}$ is the distance between the vertices $i$ and\n$j$ in $G$. We consider a weighted tree $T$ on $n$ vertices with edge weights\nare square matrix of same size. The distance $d_{ij}$ between the vertices $i$\nand $j$ is the sum of the weight matrices of the edges in the unique path from\n$i$ to $j$. In this article we establish a characterization for the trees in\nterms of rank of (matrix) weighted Laplacian matrix associated with it. Then we\nestablish a necessary and sufficient condition for the distance matrix $D$,\nwith matrix weights, to be invertible and the formula for the inverse of $D$,\nif it exists. Also we study some of the properties of the distance matrices of\nmatrix weighted trees in connection with the Laplacian matrices, g-inverses and\neigenvalues.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The late medieval Voynich Manuscript (VM) has resisted decryption and was\nconsidered a meaningless hoax or an unsolvable cipher. Here, we provide\nevidence that the VM is written in natural language by establishing a relation\nof the Voynich alphabet and the Iranian Pahlavi script. Many of the Voynich\ncharacters are upside-down versions of their Pahlavi counterparts, which may be\nan effect of different writing directions. Other Voynich letters can be\nexplained as ligatures or departures from Pahlavi with the intent to cope with\nknown problems due to the stupendous ambiguity of Pahlavi text. While a\ntranslation of the VM text is not attempted here, we can confirm the\nVoynich-Pahlavi relation at the character level by the transcription of many\nwords from the VM illustrations and from parts of the main text. Many of the\ntranscribed words can be identified as terms from Zoroastrian cosmology which\nis in line with the use of Pahlavi script in Zoroastrian communities from\nmedieval times.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We calculate the higher-twist corrections to the QCD light-cone sum rule for\nthe $B \\to \\pi$ transition form factor. The light-cone expansion of the massive\nquark propagator in the external gluonic field is extended to include new terms\ncontaining the derivatives of gluon-field strength. The resulting analytical\nexpressions for the twist-5 and twist-6 contributions to the correlation\nfunction are obtained in a factorized approximation, expressed via the product\nof the lower-twist pion distribution amplitudes and the quark-condensate\ndensity. The numerical analysis reveals that new higher-twist effects for the\n$B \\to \\pi$ form factor are strongly suppressed. This result justifies the\nconventional truncation of the operator product expansion in the light-cone sum\nrules up to twist-4 terms.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the magnetoresistance of an ultrahigh mobility GaAs/AlGaAs\ntwo-dimensional electron sample in a weak magnetic field under low-frequency (f\n< 20 GHz) microwave (MW) irradiation. We observe that with decreasing MW\nfrequency, microwave induced resistance oscillations (MIRO) damp and\nmulti-photon processes become dominant. At very low MW frequency (f < 4 GHz),\nMIRO disappears gradually and a new SdH-like oscillation develops. The analysis\nindicates that the new oscillation may originate from alternating Hall-field\ninduced resistance oscillations (ac-HIRO), or can be viewed as a multi-photon\nprocess of MIRO in low MW frequency limit. Our findings bridge the\nnon-equilibrium states of MIRO and HIRO, which can be brought into a frame of\nquantum tunneling junction model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We compute the holographic stress tensor and the logarithmic energy-momentum\ntensor of Einstein-Weyl gravity at the critical point. This computation is\ncarried out performing a holographic expansion in a bulk action supplemented by\nthe Gauss-Bonnet term with a fixed coupling. The renormalization scheme defined\nby the addition of this topological term has the remarkable feature that all\nEinstein modes are identically cancelled both from the action and its\nvariation. Thus, what remains comes from a nonvanishing Bach tensor, which\naccounts for non-Einstein modes associated to logarithmic terms which appear in\nthe expansion of the metric. In particular, we compute the holographic\n$1$-point functions for a generic boundary geometric source.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The effect of micron-sized particles on a low-pressure capacitively-coupled\nrf discharge is studied both experimentally and using numerical simulations. In\nthe laboratory experiments, microparticle clouds occupying a considerable\nfraction of the discharge volume are supported against gravity with the help of\nthe thermophoretic force. The spatiotemporally resolved optical emission\nmeasurements are performed with different arrangements of microparticles. The\nnumerical simulations are carried out on the basis of a one-dimensional hybrid\n(fluid-kinetic) discharge model describing the interaction between plasma and\nmicroparticles in a self-consistent way. The study is focused on the role of\nmicroparticle arrangement in interpreting the spatiotemporal emission\nmeasurements. We show that it is not possible to reproduce simultaneously the\nobserved microparticle arrangement and emission pattern in the framework of the\nconsidered one-dimensional model. This disagreement is discussed and attributed\nto two-dimensional effects, e.g., radial diffusion of the plasma components.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A highly dynamic urban space in a metropolis such as New York City, the\nspatio-temporal variation in demand for transportation, particularly taxis, is\nimpacted by various factors such as commuting, weather, road work and closures,\ndisruption in transit services, etc. To understand the user demand for taxis\nthrough space and time, a generalized spatio-temporal autoregressive (STAR)\nmodel is proposed in this study. In order to deal with the high dimensionality\nof the model, LASSO-type penalized methods are proposed to tackle the parameter\nestimation. The forecasting performance of the proposed models is measured\nusing the out-of-sample mean squared prediction error (MSPE), and it is found\nthat the proposed models outperform other alternative models such as vector\nautoregressive (VAR) models. The proposed modeling framework has an easily\ninterpretable parameter structure and practical to be applied by taxi\noperators. Efficiency of the proposed model also helps in model estimation in\nreal-time applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We express two CR invariant surface area elements in terms of quantities in\npseudohermitian geometry. We deduce the Euler-Lagrange equations of the\nassociated energy functionals. Many solutions are given and discussed. In\nrelation to the singular CR Yamabe problem, we show that one of the energy\nfunctionals appears as the coefficient (up to a constant multiple) of the log\nterm in the associated volume renormalization.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Enhanced Quality of Service (QoS) and satisfaction of mobile phone user are\nmajor concerns of a service provider. In order to manage network efficiently\nand to provide enhanced end to end Quality of Experience (QoE), operator is\nexpected to measure and analyze QoS from various perspectives and at different\nrelevant points of network. The scope of this paper is measurement and\nstatistically analysis of QoS of mobile networks from end user perspective in\nAfghanistan. The study is based on primary data collected on random basis from\n1,515 mobile phone users of five cellular operators. The paper furthermore\nproposes adequate technical solutions to mobile operators in order to address\nexisting challenges in the area of QoS and to remain competitive in the market.\nBased on the result of processed data, considering geographical locations,\npopulation and telecom regulations of the government, authors recommend\ndeployment of small cells (SCs), increasing number of regular performance\ntests, optimal placement of base stations, increasing number of carriers, and\nhigh order sectorization as proposed technical solutions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this note, we compute the higher spin spectrum of $U(M)_k$ Chern-Simons\ntheory coupled to $N$ flavours of fundamental fermions, in the limit $N\\gg M$\nwith the 't Hooft coupling $\\lambda_M =\\frac{N}{k_m}$ held fixed, to order\n$M/N$. This theory possesses a slightly broken higher spin symmetry, and may be\nof interest from the perspective of higher-spin and non-supersymmetric\nholography. We find that anomalous dimensions of the higher spin currents\nachieve a finite value at strong coupling $\\lambda_M \\rightarrow \\infty$, which\ngrows with spin as $\\log s$ for large $s$, as expected for gauge theories.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The scintillation properties of a $\\mathrm{CdMoO_4}$ crystal have been\ninvestigated experimentally. The fluorescence yields and decay times measured\nfrom 22 K to 300 K demonstrate that $\\mathrm{CdMoO_4}$ crystal is a good\ncandidate for an absorber for a bolometer readout, for both heat and\nscintillation signals. The results from Monte Carlo studies taking the\nbackgrounds from $\\mathrm{2\\nu2\\beta}$ of $\\mathrm{{}_{42}^{100}Mo}$\n($\\mathrm{{}_{48}^{116}Cd}$) and internal trace nuclides $\\mathrm{{}^{214}Bi}$\nand $\\mathrm{{}^{208}Tl}$ into account show that the expected sensitivity of\n$\\mathrm{CdMoO_4}$ bolometer for neutrinoless double beta decay experiment with\nan exposure of 100 $\\mathrm{{kg}\\cdot{years}}$ is one order of magnitude higher\nthan those of the current sets of the $\\mathrm{\\lim{T^{0\\nu\\beta\\beta}_{1/2}}}$\nof $\\mathrm{{}_{42}^{100}Mo}$ and $\\mathrm{{}_{48}^{116}Cd}$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Scene text recognition has been a hot research topic in computer vision due\nto its various applications. The state of the art is the attention-based\nencoder-decoder framework that learns the mapping between input images and\noutput sequences in a purely data-driven way. However, we observe that existing\nattention-based methods perform poorly on complicated and/or low-quality\nimages. One major reason is that existing methods cannot get accurate\nalignments between feature areas and targets for such images. We call this\nphenomenon \"attention drift\". To tackle this problem, in this paper we propose\nthe FAN (the abbreviation of Focusing Attention Network) method that employs a\nfocusing attention mechanism to automatically draw back the drifted attention.\nFAN consists of two major components: an attention network (AN) that is\nresponsible for recognizing character targets as in the existing methods, and a\nfocusing network (FN) that is responsible for adjusting attention by evaluating\nwhether AN pays attention properly on the target areas in the images.\nFurthermore, different from the existing methods, we adopt a ResNet-based\nnetwork to enrich deep representations of scene text images. Extensive\nexperiments on various benchmarks, including the IIIT5k, SVT and ICDAR\ndatasets, show that the FAN method substantially outperforms the existing\nmethods.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We demonstrate the application of the multiplex networks-approach for the\nanalysis of various networks which connected individuals and communities in the\npolitically highly fragmented late medieval Balkans (1204-1453 AD) within and\nacross border zones. We present how we obtain relational data from our sources\nand the integration of these data into three different networks (of roads,\nstate administration and ecclesiastical administration) of various topologies;\nthen we calculate several indicators for influences and overlaps between these\ndifferent networks which connect the same set of nodes (settlements). We\nanalyse changes and continuities in the topologies of the various networks for\nthree time-steps (1210, 1324 and 1380 CE) and demonstrate the role of these\nnetworks as frameworks for social interactions. Finally, we combine all three\nnetworks into one network which shows properties observed for the small world\nmodel. Thus, we demonstrate possibilities for capturing historical complexity\nwith the help of the multiplex networks approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider the 3D Euler equations with Coriolis force (EC) in the whole\nspace. We show long-time solvability in Besov spaces for high speed of rotation\n$\\Omega $ and arbitrary initial data. For that, we obtain $\\Omega$-uniform\nestimates and a blow-up criterion of BKM type in our framework. Our initial\ndata class is larger than previous ones considered for (EC) and covers\nborderline cases of the regularity. The uniqueness of solutions is also\ndiscussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The collision of ultra-relativistic electron beams with intense short laser\npulses makes possible to study QED in the high-intensity regime. Present day\nhigh-intensity lasers mostly operate with short pulse durations of several tens\nof femtoseconds, i.e. only a few optical cycles. A profound theoretical\nunderstanding of short pulse effects is important not only for studying\nfundamental aspects of high-intensity laser matter interaction, but also for\napplications as novel X- and gamma-ray radiation sources. In this article we\ngive a brief overview of the theory of high-intensity QED with focus on effects\ndue to the short pulse duration. The non-linear spectral broadening in\nnon-linear Compton scattering due to the short pulse duration and its\ncompensation is discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The presence of dark matter is nowadays widely supported by a large body of\nastronomical and cosmological observations. A large amount of dark matter is\nexpected to be present in the central region of the Milky Way. Very-high-energy\n(>100 GeV) {\\gamma}-rays can be produced in the annihilation of dark matter\nparticles. The H.E.S.S. array of Imaging Atmospheric Cherenkov Telescopes is a\npowerful tools to observe the Galactic Centre trying to detect {\\gamma}-rays\nfrom dark matter annihilation. A new search for a dark matter signal has been\ncarried out on the full H.E.S.S.-I data set of 2004-2014 observations. A\n2D-binned likelihood method has been applied to exploit the spectral and\nspatial properties of signal and background. Updated constraints are derived on\nthe velocity-weighted annihilation cross section for signals from prompt\nannihilation of dark matter particles into two photons. The larger statistics\nfrom the 10-year Galactic Center dataset of H.E.S.S.-I together with the\n2D-analysis technique allows to significantly improve the previous limits.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The optical properties of dielectric plates coated with gapped graphene are\ninvestigated on the basis of first principles of quantum electrodynamics. The\nreflection coefficients and reflectivities of graphene-coated plates are\nexpressed in terms of the polarization tensor of gapped graphene and the\ndielectric permittivity of plate material. Simple approximate expressions for\nthe required combinations of components of the polarization tensor applicable\nin the wide frequency region, where the presence of a gap influences the\noptical properties, are found. Numerical computations of the reflectivities of\ngraphene-coated SiO${}_2$ plates are performed for different values of the\nmass-gap parameter at different temperatures. It is shown that with an\nincreasing gap width the reflectivity of a graphene-coated plate at the normal\nincidence decreases by up to a factor of 8 depending on the values of frequency\nand mass-gap parameter. The angle dependences of reflectivities for both\npolarizations of the incident electromagnetic waves have been computed for Si\nand SiO${}_2$ plates coated with gapped graphene. We demonstrate that the TM\nreflectivity has a minimum value at some angle of incidence depending on the\nmass-gap parameter, frequency and temperature, whereas the TE reflectivity\ndepends on the angle of incidence monotonously. However, for the graphene\ncoatings with a nonzero mass-gap parameter the reflected light cannot be fully\npolarized. Possible applications of the obtained results are discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $\\mathbb{B}$ be the unit ball of a complex Banach space $X$. In this\npaper, we will generalize the Bloch-type spaces and the little Bloch-type\nspaces to the open unit ball $\\mathbb{B}$ by using the radial derivative. Next,\nwe define an extended Ces\\`{a}ro operator $T_{\\varphi}$ with holomorphic symbol\n$\\varphi$ and characterize those $\\varphi$ for which $T_{\\varphi}$ is bounded\nbetween the Bloch-type spaces and the little Bloch-type spaces. We also\ncharacterize those $\\varphi$ for which $T_{\\varphi}$ is compact between the\nBloch-type spaces and the little Bloch-type spaces under some additional\nassumption on the symbol $\\varphi$. When $\\mathbb{B}$ is the open unit ball of\na finite dimensional complex Banach space $X$, this additional assumption is\nautomatically satisfied.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study effects of a potential barrier on collective modes of superfluid\nBose gases in optical lattices. We assume that the barrier is created by local\nsuppression of the hopping amplitude. When the system is in a close vicinity of\nthe Mott transition at commensurate fillings, where an approximate\nparticle-hole symmetry emerges, there exist bound states of Higgs amplitude\nmode that are localized around the barrier. By applying the Gutzwiller\nmean-field approximation to the Bose-Hubbard model, we analyze properties of\nnormal modes of the system with a special focus on the Higgs bound states. We\nshow that when the system becomes away from the Mott transition point, the\nHiggs bound states turn into quasi-bound states due to inevitable breaking of\nthe particle-hole symmetry. We use a stabilization method to compute the\nresonance energy and line width of the quasi-bound states. We compare the\nresults obtained by the Gutzwiller approach with those by the Ginzburg-Landau\ntheory. We find that the Higgs bound states survive even in a parameter region\nfar from the Mott transition, where the Ginzburg-Landau theory fails.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we introduce the problem of denoting and deriving the\ncomplexity of workflows (plans, schedules) in collaborative, planner-assisted\nsettings where humans and agents are trying to jointly solve a task. The\ninteractions -- and hence the workflows that connect the human and the agents\n-- may differ according to the domain and the kind of agents. We adapt insights\nfrom prior work in human-agent teaming and workflow analysis to suggest metrics\nfor workflow complexity. The main motivation behind this work is to highlight\nmetrics for human comprehensibility of plans and schedules. The planning\ncommunity has seen its fair share of work on the synthesis of plans that take\ndiversity into account -- what value do such plans hold if their generation is\nnot guided at least in part by metrics that reflect the ease of engaging with\nand using those plans?\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Approximating the time to extinction of infection is an important problem in\ninfection modelling. A variety of different approaches have been proposed in\nthe literature. We study the performance of a number of such methods, and\ncharacterize their performance in terms of simplicity, accuracy, and\ngenerality. To this end, we consider first the classic stochastic\nsusceptible-infected-susceptible (SIS) model, and then a multi-dimensional\ngeneralization of this which allows for Erlang distributed infectious periods.\nWe find that (i) for a below-threshold infection initiated by a small number of\ninfected individuals, approximation via a linear branching process works well;\n(ii) for an above-threshold infection initiated at endemic equilibrium, methods\nfrom Hamiltonian statistical mechanics yield correct asymptotic behaviour as\npopulation size becomes large; (iii) the widely-used Ornstein-Uhlenbeck\ndiffusion approximation gives a very poor approximation, but may retain some\nvalue for qualitative comparisons in certain cases; (iv) a more detailed\ndiffusion approximation can give good numerical approximation in certain\ncircumstances, but does not provide correct large population asymptotic\nbehaviour, and cannot be relied upon without some form of external validation\n(eg simulation studies).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we study moduli spaces of low dimensional complex Lie\nsuperalgebras. We discover a similar pattern for the structure of these moduli\nspaces as we observed for ordinary Lie algebras, namely, that there is a\nstratification of the moduli space by projective orbifolds. The moduli spaces\nconsist of some families as well as some singleton elements. The different\nstrata are linked by jump deformations, which gives a uniques manner of\ndecomposing the moduli space which is consistent with deformation theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper contributes to the understanding of strongly coupled\nspatio-temporal processes by describing a generic method based on Granger\ncausality. The method is validated by the robust identification of causality\nregimes and of their phase diagram for an urban morphogenesis model that\ncouples network growth with density. The application to the real case study of\nGreater Paris transportation projects shows a link between territorial\ndynamics, more particularly of real estate and socio-economic, and the\nanticipated network growth. We finally discuss potential extensions to other\ntemporal and spatial scales.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Two unavoidable processes punctuate our century: The unprecedented\nurbanisation of our planet (United Nations, 2014) and the spread of ubiquitous\ncomputing (Weiser, 1991) and urban data streams. This process of urbanisation\ncorresponds with the process of digitalisation of urban life: while\nurbanisation acts on a physical infrastructural level, the digital develops as\na kind of metastructure above the infrastructure. This metastructural level\noffers a flexible framework through which information is continuously and\noperatively being symbolized. Today, Information technology and the\navailability of abundant urban data streams could be considered as forerunners\nof our time, having unprecedented impacts comparable to the ones brought by the\nsteam engine at the dawn of industrialisation and the electrification of\ncities. It is therefore no longer conceivable to think of the physical\nstructure of the city without including its digital counterpart. Against this\nbackground, we will explore the role of computational power and information\ntechnologies as dominant factors in the formation of computational urban models\nand normative city theories. We will show how these models and theories,\nemerging mainly during the 19th and 20th centuries, present leaping\ncorrespondences with more ancient conceptions of the city, when observed from a\nmeta-level or episteme (Foucault, 2002) approach. First, and for the sake of\nclarity, we will deal with some methodological elucidations around the concepts\nof theory, model and episteme, and how we will refer conceptually to these\nterms throughout this paper. Secondly, we will review these evolving\ntechnological and computational levels of abstraction and their influence on\nthe different conceptions of the city. Thirdly, we will develop the hypothesis\nof a conceptual gap, between our current technological capacity -- grounded on\nthe abundance and availability of urban data streams -- and the state of the\nart in urban modelling and city theory. Lastly, building upon Foucault's\nconcept of episteme (Foucault, 1970) and genealogy (Foucault, 1977b), we will\nexplore this gap by speculating around the possibility of an inversion in\ncomputational urban modelling and city theory. And above all, we will question\nthe terms in which we can think of the city, in an age where the world can be\nvirtually conceived as fully urban, and the continuity and abundance of urban\ndata streams giving account of it can be taken for granted. How are we\narticulating the phenomena we call city on top of this generic common ground?\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using the category of finite sets and injections, we construct a new model\nfor the multilinearization of multifunctors between spaces that appears in the\nderivatives of Goodwillie calculus. We show that this model yields a lax\nmonoidal functor from the category of symmetric functor sequences to the\ncategory of symmetric sequences of spaces after evaluating at the unit.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A valley plasmonic crystal for graphene surface plasmons (GSPs) is proposed.\nWe demonstrate that a designer metagate, placed within a few nanometers from\ngraphene, can be used to impose a triangular periodic Fermi energy landscape on\nthe latter. For specific metagate geometries and bias voltages, the combined\nmetagate-graphene structure is shown to produce sufficiently strong Bragg\nscattering of GSPs to produce complete propagation bandgaps, and to impart the\nGSPs with nontrivial valley-linked topological properties. Valley-selective\nkink states supported by a domain wall between differently patterned metagates\nare shown to propagate without reflections along sharply curved interfaces\nowing to suppressed inter-valley scattering. Our approach paves the way for\nnon-magnetic dynamically reconfigurable topological nanophotonic devices.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider the current-phase relation (CPR) in the Josephson junctions with\ncomplex insulator-superconductor-ferromagnetic interlayers in the vicinity of\n0-$\\pi$ transition. We find a strong impact of the second harmonic on CPR of\nthe junctions. It is shown that the critical current can be kept constant in\nthe region of 0-pi transition, while the CPR transforms through multi-valued\nhysteretic states depending on the relative values of tunnel transparency and\nmagnetic thickness. Moreover, CPR in the transition region has multiple\nbranches with distinct ground states.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the topological properties of magnon excitations in a wide class of\nthree dimensional (3D) honeycomb lattices with ferromagnetic ground states. It\nis found that they host nodal ring magnon excitations. These rings locate on\nthe same plane in the momentum space. The rings can be gapped by\nDzyaloshinskii-Moriya (DM) interactions to form two Weyl points with opposite\ncharges. We explicitly discuss these physics in the simplest 3D honeycomb\nlattice, the hyperhoneycomb lattice and show drumhead and arc surface states in\nthe nodal ring and Weyl phases, respectively, due to the bulk-boundary\ncorrespondence.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The H.E.S.S. collaboration has discovered a new very high energy (VHE, E $>$\n0.1 TeV) $\\gamma$-ray source, HESS J1741-302, located in the Galactic plane.\nDespite several attempts to constrain its nature, no plausible counterpart has\nbeen found so far at X-ray and MeV/GeV $\\gamma$-ray energies, and the source\nremains unidentified. An analysis of 145-hour of observations of HESS J1741-302\nat VHEs has revealed a steady and relatively weak TeV source ($\\sim$1$\\%$ of\nthe Crab Nebula flux), with a spectral index of $\\Gamma$ = 2.3 $\\pm$\n0.2$_{\\text{stat}}$ $\\pm$ 0.2$_{\\text{sys}}$, extending to energies up to 10\nTeV without any clear signature of a cut-off. In a hadronic scenario, such a\nspectrum implies an object with particle acceleration up to energies of several\nhundred TeV. Contrary to most H.E.S.S. unidentified sources, the angular size\nof HESS J1741-302 is compatible with the H.E.S.S. point spread function at\nVHEs, with an extension constrained to be below 0.068$^{\\circ}$ at a 99$\\%$\nconfidence level. The $\\gamma$-ray emission detected by H.E.S.S. can be\nexplained both within a hadronic scenario, due to collisions of protons with\nenergies of hundreds of TeV with dense molecular clouds, and in a leptonic\nscenario, as a relic pulsar wind nebula, possibly powered by the middle-aged\n(20 kyr) pulsar PSR B1737-30. A binary scenario, related to the compact radio\nsource 1LC 358.266+0.038 found to be spatially coincident with the best fit\nposition of HESS J1741-302, is also envisaged.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Inference about a scalar parameter of interest is a core statistical task\nthat has attracted immense research in statistics. The Wald statistic is a\nprime candidate for the task, on the grounds of the asymptotic validity of the\nstandard normal approximation to its finite-sample distribution, simplicity and\nlow computational cost. It is well known, though, that this normal\napproximation can be inadequate, especially when the sample size is small or\nmoderate relative to the number of parameters. A novel, algebraic adjustment to\nthe Wald statistic is proposed, delivering significant improvements in\ninferential performance with only small implementation and computational\noverhead, predominantly due to additional matrix multiplications. The Wald\nstatistic is viewed as an estimate of a transformation of the model parameters\nand is appropriately adjusted, using either maximum likelihood or reduced-bias\nestimators, bringing its expectation asymptotically closer to zero. The\nlocation adjustment depends on the expected information, an approximation to\nthe bias of the estimator, and the derivatives of the transformation, which are\nall either readily available or easily obtainable in standard software for a\nwealth of models. An algorithm for the implementation of the location-adjusted\nWald statistics in general models is provided, as well as a bootstrap scheme\nfor the further scale correction of the location-adjusted statistic. Ample\nanalytical and numerical evidence is presented for the adoption of the\nlocation-adjusted statistic in prominent modelling settings, including\ninference about log-odds and binomial proportions, logistic regression in the\npresence of nuisance parameters, beta regression, and gamma regression. The\nlocation-adjusted Wald statistics are used for the construction of significance\nmaps for the analysis of multiple sclerosis lesions from MRI data.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate certain properties of $\\mathfrak{su}(N)$-valued\ntwo-dimensional soliton surfaces associated with the integrable\n$\\mathbb{C}P^{N-1}$ sigma models constructed by the orthogonal rank-one\nHermitian projectors, which are defined on the two-dimensional Riemann sphere\nwith finite action functional. Several new properties of the projectors mapping\nonto one-dimensional subspaces as well as their relations with three mutually\ndifferent immersion formulas, namely, the generalized Weierstrass, Sym-Tafel\nand Fokas-Gel'fand have been discussed in detail. Explicit connections among\nthese three surfaces are also established by purely analytical descriptions\nand, it is demonstrated that the three immersion formulas actually correspond\nto the single surface parametrized by some specific conditions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $E/F$ be an unramified extension of non-archimedean local fields of\nresidual characteristic different than $2$. We provide a simple geometric proof\nof a variation of a result of Y. Hironaka. Namely we prove that the module\n$\\mathcal{S}(X)^{K_0}$ is free over the Hecke algebra\n$\\mathcal{H}(SL_{n}(E),SL_{n}(O_E))$, where $X$ is the space of unimodular\nHermitian forms on $E^n$ and $O_E$ is the ring of integers in $E$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The lecture \"Atomistic Materials Modeling\" is a core qualification of the\nmaster program \"materials science\" at the Hamburg University of Technology\n(TUHH). Within the lecture, various modern methods for atomistic materials\nmodeling are presented. Originally, the course was conceived as a traditional\nlecture. That didactic-methodical conception, however, does not seem to be\nideal to support the students in reaching the educational objectives and to\nfoster the students' interest in the covered topics. A new didactic concept\nbased on interactive engagement is designed to allow for a more individual and\nresearch-oriented learning experience of the students. To this end, team-work\nunits involving worksheets and computer exercises are established replacing\ntraditional lectures. Additionally, the students get the possibility to sketch\nresearch proposals in small teams during their individual study time. The\nstudents are supposed to apply, discuss, and immerse themselves in selected\ntopics of the lecture via those new elements. The effects of these innovations\non the students' ability to reach the educational objectives and on their level\nof interest in related research activities are investigated in this work using\nseveral questionnaires, observations by the lectures, and the results of the\nfinal exams as data sources. The analysis shows that the students are highly in\nfavor of the new, interactive elements. Those elements support the students in\nreaching important educational objectives of the lecture. Moreover, the\ninterest in research is increased. The questionnaires and exams, however,\nindicate some room for improvement. For example, the assessment of the\nlimitations of different methods is difficult for the students. Consequently,\nan updated version of the presented concept including the findings of this work\nis supposed to be implemented in the future.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The position and motion of localized states of light in propagative\ngeometries can be controlled via an adequate parameter modulation. Here, we\nshow theoretically and experimentally that this process can be accurately\ndescribed as the phase locking of oscillators to an external forcing and that\nnon-reciprocal interactions between light bits can drastically modify this\npicture. Interactions lead to the convective motion of defects and to unlocking\nas a collective emerging phenomenon.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a first principles investigation of the electronic properties of\nmonolayer WS$_2$ coated with an overlayer of Fe. Our ab initio calculations\nreveal that the system is a half-metallic ferromagnet with a gap of $\\sim 1$ eV\nfor the majority spin channel. Furthermore, the combined effect of\ntime-reversal symmetry breaking due to the magnetic Fe overlayer and the large\nspin-orbit coupling induced by W gives rise to non-degenerate K and K$'$\nvalleys. This has a tremendous impact on the excited state properties induced\nby externally applied circularly polarized light. Our analysis demonstrates\nthat the latter induces a singular hot spot structure of the transition\nprobability around the K and K$'$ valleys for right and left circular\npolarization, respectively. We trace back the emergence of this remarkable\neffect to the strong momentum dependent spin-noncollinearity of the valence\nband involved. As a main consequence, a strong valley-selective magnetic\ncircular dichroism is obtained, making this system a prime candidate for\nspintronics and photonics applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Two-dimensional semiconducting materials are particularly appealing for many\napplications. Although theory predicts a large number of two-dimensional\nmaterials, experimentally only a few of these materials have been identified\nand characterized comprehensively in the ultrathin limit. Lead iodide, which\nbelongs to the transition metal halides family and has a direct bandgap in the\nvisible spectrum, has been known for a long time and has been well\ncharacterized in its bulk form. Nevertheless, studies of this material in the\nnanometer thickness regime are rather scarce. In this article we demonstrate an\neasy way to synthesize ultrathin, highly crystalline flakes of PbI2 by\nprecipitation from a solution in water. We thoroughly characterize the produced\nthin flakes with different techniques ranging from optical and Raman\nspectros-copy to temperature-dependent photoluminescence and electron\nmicroscopy. We compare the results to ab initio calculations of the band\nstructure of the material. Finally, we fabricate photodetectors based on PbI2\nand study their optoelectronic properties.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For quite some time non-monotonic flow curve was thought to be a requirement\nfor shear banded flows in complex fluids. Thus, in simple yield stress fluids\nshear banding was considered to be absent. Recent spatially resolved\nrheological experiments have found simple yield stress fluids to exhibit shear\nbanded flow profiles. One proposed mechanism for the initiation of such\ntransient shear banding process has been a small stress heterogeneity rising\nfrom the experimental device geometry. Here, using Computational Fluid Dynamics\nmethods, we show that transient shear banding can be initialized even under\nhomogeneous stress conditions by the fluid start-up inertia, and that such\nmechanism indeed is present in realistic experimental conditions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we present a new type of fractional operator, which is a\ngeneralization of the Caputo and Caputo--Hadamard fractional derivative\noperators. We study some properties of the operator, namely we prove that it is\nthe inverse operation of a generalized fractional integral. A relation between\nthis operator and a Riemann--Liouville type is established. We end with a\nfractional Gronwall inequality type, which is useful to compare solutions of\nfractional differential equations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Quantum key distribution (QKD) provides theoretic information security in\ncommunications based on the laws of quantum physics. In this work, we report an\nimplementation of quantum-secured data transmission in the infrastructure of\nSberbank of Russia in standard communication lines in Moscow. The experiment is\nrealized on the basis of already deployed urban fiber-optics communication\nchannels with significant losses. We realize the decoy-state BB84 QKD protocol\nusing the one-way scheme with polarization encoding for generating keys.\nQuantum-generated keys are then used for continuous key renewal in the hardware\ndevices for establishing a quantum-secured VPN Tunnel between two offices of\nSberbank. The hybrid approach used offers possibilities for long-term\nprotection of the transmitted data; it is promising for integrating into the\nalready existing information security infrastructure.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The problem of finding the maximum-weight, planar subgraph of a finite,\nsimple graph with nonnegative real edge weights is well known in industrial and\nelectrical engineering, systems biology, sociology and finance. As the problem\nis known to be NP-hard, much research effort has been devoted over the years to\nattempt to improve a given approximate solution to the problem by using local\nmoves applied to a planar embedding of the solution. It has long been\nestablished that any feasible solution to the problem, a maximal planar graph,\ncan be transformed into any other (having the same vertex set) in a finite\nsequence of local moves of based on: (i) edge substitution and (ii) vertex\nrelocation and it has been conjectured that moves of only type (i) are\nsufficient. In this note we settle this conjecture in the affirmative.\nFurthermore, contrary to recent supposition, we demonstrate that any maximal\nspanning tree of the original graph is not necessarily a part of any optimal\nsolution to the problem. We hope these results will be useful in the design of\nfuture approximate methods for the problem.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this article, we extended our approach, that is mentioned in part 1, to\nmodel the indentation of an adhesive beam by a rigid cylindrical punch. We\nconsidered clamped and simply supported beams for this study. We first modeled\nthese beams as infinite length elastic layers which obey the kinetic and\nkinematic constraints imposed by the end supports. The adhesion effects are\nconsidered via the Dugdale-Barenblatt model based adhesive zone model. Solving\nthe governing equations of this infinite layer along with its boundary\nconditions, we obtain a set of coupled Fredholm integral equations of first\nkind. These integral equations are then solved employing the collocation\ntechnique. The results obtained are then compared with finite element (FE)\nsimulations and the previously published results for the non-adhesive case. We\nalso obtained the results for the well-known Johnson-Kendall-Roberts (JKR)\napproximation of the contact. Finally we investigated the effect of various\nadhesive strengths on the contact parameters and showed the transition of the\nresults from 'Hertzian' to 'JKR' approximation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Contrary to most natural language processing research, which makes use of\nstatic datasets, humans learn language interactively, grounded in an\nenvironment. In this work we propose an interactive learning procedure called\nMechanical Turker Descent (MTD) and use it to train agents to execute natural\nlanguage commands grounded in a fantasy text adventure game. In MTD, Turkers\ncompete to train better agents in the short term, and collaborate by sharing\ntheir agents' skills in the long term. This results in a gamified, engaging\nexperience for the Turkers and a better quality teaching signal for the agents\ncompared to static datasets, as the Turkers naturally adapt the training data\nto the agent's abilities.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove that any finite-degree polynomial functor is topologically\nNoetherian. This theorem is motivated by the recent resolution of Stillman's\nconjecture and a recent Noetherianity proof for the space of cubics. Via work\nby Erman-Sam-Snowden, our theorem implies Stillman's conjecture and indeed\nboundedness of a wider class of invariants of ideals in polynomial rings with a\nfixed number of generators of prescribed degrees.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We have surveyed the core regions of the z = 1.46 cluster XCS J2215.9-1738\nwith the Atacama Large Millimeter Array (ALMA) and the MUSE-GALACSI\nspectrograph on the VLT. We obtained high spatial resolution observations with\nALMA of the 1.2 mm dust continuum and molecular gas emission in the central\nregions of the cluster. These observations detect 14 significant millimetre\nsources in a region with a projected diameter of just ~500kpc (~1'). For six of\nthese galaxies we also obtain 12 CO(2-1) and 12 CO(5-4) line detections,\nconfirming them as cluster members, and a further five of our millimetre\ngalaxies have archival 12CO(2-1) detections which also place them in the\ncluster. An additional two millimetre galaxies have photometric redshifts\nconsistent with cluster membership, although neither show strong line emission\nin the MUSE spectra. This suggests that the bulk (> 11/14, ~80%) of the\nsubmillimetre sources in the field are in fact luminous infrared galaxies lying\nwithin this young cluster. We then use our sensitive new observations to\nconstrain the dust-obscured star formation activity and cold molecular gas\nwithin this cluster. We find hints that the cooler dust and gas components\nwithin these galaxies may have been influenced by their environment reducing\nthe gas reservoir available for their subsequent star formation. We also find\nthat these actively star- forming galaxies have the dynamical masses and\nstellar population ages expected for the progenitors of massive, early-type\ngalaxies in local clusters potentially linking these populations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a new neural text to speech (TTS) method that is able to transform\ntext to speech in voices that are sampled in the wild. Unlike other systems,\nour solution is able to deal with unconstrained voice samples and without\nrequiring aligned phonemes or linguistic features. The network architecture is\nsimpler than those in the existing literature and is based on a novel shifting\nbuffer working memory. The same buffer is used for estimating the attention,\ncomputing the output audio, and for updating the buffer itself. The input\nsentence is encoded using a context-free lookup table that contains one entry\nper character or phoneme. The speakers are similarly represented by a short\nvector that can also be fitted to new identities, even with only a few samples.\nVariability in the generated speech is achieved by priming the buffer prior to\ngenerating the audio. Experimental results on several datasets demonstrate\nconvincing capabilities, making TTS accessible to a wider range of\napplications. In order to promote reproducibility, we release our source code\nand models.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  While the P vs NP problem is mainly approached form the point of view of\ndiscrete mathematics, this paper proposes reformulations into the field of\nabstract algebra, geometry, fourier analysis and of continuous global\noptimization - which advanced tools might bring new perspectives and approaches\nfor this question. The first one is equivalence of satisfaction of 3-SAT\nproblem with the question of reaching zero of a nonnegative degree 4\nmultivariate polynomial (sum of squares), what could be tested from the\nperspective of algebra by using discriminant. It could be also approached as a\ncontinuous global optimization problem inside $[0,1]^n$, for example in\nphysical realizations like adiabatic quantum computers. However, the number of\nlocal minima usually grows exponentially. Reducing to degree 2 polynomial plus\nconstraints of being in $\\{0,1\\}^n$, we get geometric formulations as the\nquestion if plane or sphere intersects with $\\{0,1\\}^n$. There will be also\npresented some non-standard perspectives for the Subset-Sum, like through\nconvergence of a series, or zeroing of $\\int_0^{2\\pi} \\prod_i \\cos(\\varphi k_i)\nd\\varphi $ fourier-type integral for some natural $k_i$. The last discussed\napproach is using anti-commuting Grassmann numbers $\\theta_i$, making $(A \\cdot\n\\textrm{diag}(\\theta_i))^n$ nonzero only if $A$ has a Hamilton cycle. Hence,\nthe P$\\ne$NP assumption implies exponential growth of matrix representation of\nGrassmann numbers. There will be also discussed a looking promising\nalgebraic/geometric approach to the graph isomorphism problem -- tested to\nsuccessfully distinguish strongly regular graphs with up to 29 vertices.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Magnetic activity strongly impacts stellar RVs and the search for small\nplanets. We showed previously that in the solar case it induces RV variations\nwith an amplitude over the cycle on the order of 8 m/s, with signals on short\nand long timescales. The major component is the inhibition of the convective\nblueshift due to plages. We explore a new approach to correct for this major\ncomponent of stellar radial velocities in the case of solar-type stars. The\nconvective blueshift depends on line depths; we use this property to develop a\nmethod that will characterize the amplitude of this effect and to correct for\nthis RV component. We build realistic RV time series corresponding to RVs\ncomputed using different sets of lines, including lines in different depth\nranges. We characterize the performance of the method used to reconstruct the\nsignal without the convective component and the detection limits derived from\nthe residuals. We identified a set of lines which, combined with a global set\nof lines, allows us to reconstruct the convective component with a good\nprecision and to correct for it. For the full temporal sampling, the power in\nthe range 100-500~d significantly decreased, by a factor of 100 for a RV noise\nbelow 30 cm/s. We also studied the impact of noise contributions other than the\nphoton noise, which lead to uncertainties on the RV computation, as well as the\nimpact of the temporal sampling. We found that these other sources of noise do\nnot greatly alter the quality of the correction, although they need a better\nnoise level to reach a similar performance level. A very good correction of the\nconvective component can be achieved providing very good RV noise levels\ncombined with a very good instrumental stability and realistic granulation\nnoise. Under the conditions considered in this paper, detection limits at 480~d\nlower than 1 MEarth could be achieved for RV noise below 15 cm/s.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using a quantum fluid model, a set of three paraxial coupled equations to\ndescribe the FEL instability is derived. These equations are solved numerically\nconsidering Laguerre-Gaussian modes as the initial conditions to study the\ntransfer of orbital angular momentum (OAM) between them, which satisfies the\ntotal angular momentum conservation as matching condition. The amplification\nand compression of the output radiation is observed and using the separation of\nvariables method, the set of coupled equations, which describes a $\\pi$-pulse\nsolution, is obtained in such a way that a transverse overlapping factor, R,\ngoverns the energy exchange efficiency of the process.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Satisfiability of word equations is an important problem in the intersection\nof formal languages and algebra: Given two sequences consisting of letters and\nvariables we are to decide whether there is a substitution for the variables\nthat turns this equation into true equality of strings. The exact computational\ncomplexity of this problem remains unknown, with the best lower and upper\nbounds being, respectively, NP and PSPACE. Recently, the novel technique of\nrecompression was applied to this problem, simplifying the known proofs and\nlowering the space complexity to (nondeterministic) O(n log n). In this paper\nwe show that satisfiability of word equations is in nondeterministic linear\nspace, thus the language of satisfiable word equations is context-sensitive,\nand by the famous Immerman-Szelepcsenyi theorem: the language of unsatisfiable\nword equations is also context-sensitive. We use the known recompression-based\nalgorithm and additionally employ Huffman coding for letters. The proof,\nhowever, uses analysis of how the fragments of the equation depend on each\nother as well as a new strategy for nondeterministic choices of the algorithm,\nwhich uses several new ideas to limit the space occupied by the letters.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recently, Eklund et al. (2016) analyzed clustering methods in standard FMRI\npackages: AFNI (which we maintain), FSL, and SPM [1]. They claimed: 1) false\npositive rates (FPRs) in traditional approaches are greatly inflated,\nquestioning the validity of \"countless published fMRI studies\"; 2)\nnonparametric methods produce valid, but slightly conservative, FPRs; 3) a\ncommon flawed assumption is that the spatial autocorrelation function (ACF) of\nFMRI noise is Gaussian-shaped; and 4) a 15-year-old bug in AFNI's 3dClustSim\nsignificantly contributed to producing \"particularly high\" FPRs compared to\nother software. We repeated simulations from [1] (Beijing-Zang data [2], see\n[3]), and comment on each point briefly.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A Riemannian symmetric space is a Riemannian manifold in which it is possible\nto reflect all geodesics through a point by an isometry of the space. On such\nspaces, we introduce the notion of a distributional lattice, generalizing the\nnotion of lattice. Distributional lattices exist in any Riemannian symmetric\nspace: the Voronoi tessellation of a stationary Poisson point process is an\nexample. We show that for an appropriate notion of amenability, the amenability\nof a distributional lattice is equivalent to the amenability of the ambient\nspace. Using this equivalence, we show that the simple random walk on any\ndistributional lattice in a nonamenable space has positive embedded speed. For\nnonpositively curved, simply connected spaces, we show that the simple random\nwalk on a Poisson--Voronoi tessellation has positive graph speed by developing\nsome additional structure for Poisson--Voronoi tessellations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Macquarie University's contribution to the BioASQ challenge (Task 5b Phase B)\nfocused on the use of query-based extractive summarisation techniques for the\ngeneration of the ideal answers. Four runs were submitted, with approaches\nranging from a trivial system that selected the first $n$ snippets, to the use\nof deep learning approaches under a regression framework. Our experiments and\nthe ROUGE results of the five test batches of BioASQ indicate surprisingly good\nresults for the trivial approach. Overall, most of our runs on the first three\ntest batches achieved the best ROUGE-SU4 results in the challenge.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Mathisson-Papapetrou-Dixon (MPD) equations, providing the \"pole-dipole\"\ndescription of spinning test particles in general relativity, have to be\nsupplemented by a condition specifying the worldline that will represent the\nhistory of the studied body. It has long been thought that the Mathisson-Pirani\n(MP) spin condition -- unlike other major choices made in the literature --\ndoes not yield an explicit momentum-velocity relation. We derive here the\ndesired (and very simple) relation and show that it is in fact equivalent to\nthe MP condition. We clarify the apparent paradox between the existence of such\na definite relation and the known fact that the MP condition is degenerate\n(does not specify a unique worldline), thus shedding light on some conflicting\nstatements made in the literature. We then show how, for a given body, this\nspin condition yields infinitely many possible representative worldlines, and\nderive a detailed method how to switch between them in a curved spacetime. The\nMP condition is a convenient choice in situations when it is easy to recognize\nits \"non-helical\" solution, as exemplified here by bodies in circular orbits\nand in radial fall in the Schwarzschild spacetime.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  According to the DeGroot-Friedkin model of a social network, an individual's\nsocial power evolves as the network discusses individual opinions over a\nsequence of issues. Under mild assumptions on the connectivity of the network,\nthe social power of every individual converges to a constant strictly positive\nvalue as the number of issues discussed increases. If the network has a special\ntopology, termed \"star topology\", then all social power accumulates with the\nindividual at the centre of the star. This paper studies the strategic\nintroduction of new individuals and/or interpersonal relationships into a\nsocial network with star topology to reduce the social power of the centre\nindividual. In fact, several strategies are proposed. For each strategy, we\nderive necessary and sufficient conditions on the strength of the new\ninterpersonal relationships, based on local information, which ensures that the\ncentre individual no longer has the greatest social power within the social\nnetwork. Interpretations of these conditions show that the strategies are\nremarkably intuitive and that certain strategies are favourable compared to\nothers, all of which is sociologically expected.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Penalized spline regression is a popular method for scatterplot smoothing,\nbut there has long been a debate on how to construct confidence intervals for\npenalized spline fits. Due to the penalty, the fitted smooth curve is a biased\nestimate of the target function. Many methods, including Bayesian intervals and\nthe simple-shift bias-reduction, have been proposed to upgrade the coverage of\nthe confidence intervals, but these methods usually fail to adequately improve\nthe situation at predictor values where the function is sharply curved. In this\npaper, we develop a novel approach to improving the confidence intervals by\nusing a smaller smoothing strength than that of the spline fits. With a\ncarefully selected amount of reduction in smoothing strength, the confidence\nintervals achieve nearly nominal coverage without being excessively wide or\nwiggly. The coverage performance of the proposed method is investigated via\nsimulation experiments in comparison with the bias-correction techniques\nproposed by Hodges (2013) and Kuusela and Panaretos (2015).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider an anisotropic hyperbolic equation with memory term: $$\n\\partial_t^2 u(x,t) = \\sum_{i,j=1}^n \\partial_i(a_{ij}(x)\\partial_ju) +\n\\int^t_0 \\sum_{| \\alpha| \\le 2}\nb_{\\alpha}(x,t,\\eta)\\partial_x^{\\alpha}u(x,\\eta) d\\eta + F(x,t) $$ for $x \\in\n\\Omega$ and $t\\in (0,T)$ or $\\in (-T,T)$, which is a model equation for\nviscoelasticity. First we establish a Carleman estimate for this equation with\noverdetermining boundary data on a suitable lateral subboundary $\\Gamma \\times\n(-T,T)$. Second we apply the Carleman estimate to establish a both-sided\nestimate of $| u(\\cdot,0)|_{H^3(\\Omega)}$ by $\\partial_{\\nu}u|_{\\Gamma\\times\n(0,T)}$ under the assumption that $\\partial_tu(\\cdot,0) = 0$ and $T>0$ is\nsufficiently large, $\\Gamma \\subset \\partial\\Omega$ satisfies some geometric\ncondition. Such an estimate is a kind of observability inequality and related\nto the exact controllability. Finally we apply the Carleman estimate to an\ninverse source problem of determining a spatial varying factor in $F(x,t)$ and\nwe establish a both-sided Lipschitz stability estimate.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate atom-based electric-field calibration and polarization\nmeasurement of a 100-MHz linearly polarized radio-frequency (RF) field using\ncesium Rydberg-atom electromagnetically induced transparency (EIT) in a\nroom-temperature vapor cell. The calibration method is based on matching\nexperimental data with the results of a theoretical Floquet model. The utilized\n60$D_J$ fine structure Floquet levels exhibit $J$- and $m_j$-dependent AC Stark\nshifts and splittings, and develop even-order RF-modulation sidebands. The\nFloquet map of cesium 60$D_J$ fine structure states exhibits a series of exact\ncrossings between states of different $m_j$, which are not RF-coupled. These\nexact level crossings are employed to perform a rapid and precise ($\\pm 0.5\\%$)\ncalibration of the RF electric field. We also map out three series of narrow\navoided crossings between fine structure Floquet levels of equal $m_j$ and\ndifferent $J$, which are weakly coupled by the RF field via a Raman process.\nThe coupling leads to narrow avoided crossings that can also be applied as\nspectroscopic markers for RF field calibration. We further find that the\nline-strength ratio of intersecting Floquet levels with different $m_j$\nprovides a fast and robust measurement of the RF field's polarization.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Many aspects of the Atacama Large Millimeter Array (ALMA) instrument are\nstill unknown due to its young age. One such aspect is the true nature of the\nprimary beam of each baseline, and how changes to the individual primary beams\naffect astronomical observations when said changes are ignored during imaging.\nThis paper aims to create a more thorough understanding of the strengths and\nweaknesses of ALMA through realistic modeling of the primary beams and\nsimulated observations, which in turn can inform the user of the necessity of\nimplementing more computationally costly algorithms, such as A-Projection, and\nwhen simpler, quicker algorithms will suffice. We quantify our results by\nexamining the dynamic range of each observation, along with the ability to\nreconstruct the Stokes I amplitude of the test sources. These tests conclude\nthat for dynamic ranges of less than 1000, for point sources and sources much\nsmaller than the main lobe of the primary beam, the accuracy of the primary\nbeam model beyond the physical size of the aperture simply doesn't matter. In\nobservations of large extended sources, deconvolution errors dominate the\nreconstructed images and the individual primary beam errors were\nindistinguishable from each other.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We give a new bound on colinear triples in subgroups of prime finite fields\nand use it to give some new bounds on exponential sums with trinomials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Cosmological models assuming the scale invariance of the macroscopic empty\nspace show an accelerated expansion, without calling for some unknown\nparticles. Several comparisons between models and observations (tests on\ndistances, m-z diagram, Omega_Lambda vs. Omega_m plot, age vs. H_0, H(z) vs. z,\ntransition braking-acceleration) have indicated an impressive agreement {Maeder\n2017}. We pursue the tests with the CMB temperatures T(CMB) as a function of\nredshifts z. CO molecules in DLA systems provide the most accurate excitation\ntemperatures T(exc) up to z ~ 2.7. Such data need corrections for local\neffects, like particle collisions, optical depths, UV radiation, etc. We\nestimate these corrections as a function of the (CO/H_2) ratios from far UV\nobservations of CO molecules in the Galaxy. The results show that it is not\nsufficient to apply theoretical collisional corrections to get the proper\nvalues of T(CMB) vs.z. Thus, the agreement often found with the standard model\nmay be questioned. The T(CMB)vs. z relation needs further careful attention and\nthe same for the scale invariant cosmology in view of its positive tests.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A zonal function (ZF) network on the $q$ dimensional sphere $\\mathbb{S}^q$ is\na network of the form $\\mathbf{x}\\mapsto \\sum_{k=1}^n\na_k\\phi(\\mathbf{x}\\cdot\\mathbf{x}_k)$ where $\\phi :[-1,1]\\to\\mathbf{R}$ is the\nactivation function, $\\mathbf{x}_k\\in\\mathbb{S}^q$ are the centers, and\n$a_k\\in\\mathbb{R}$. While the approximation properties of such networks are\nwell studied in the context of positive definite activation functions, recent\ninterest in deep and shallow networks motivate the study of activation\nfunctions of the form $\\phi(t)=|t|$, which are not positive definite. In this\npaper, we define an appropriate smoothess class and establish approximation\nproperties of such networks for functions in this class. The centers can be\nchosen independently of the target function, and the coefficients are linear\ncombinations of the training data. The constructions preserve rotational\nsymmetries.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Observations of cosmic rays are a sensitive probe of dark matter annihilation\nin our Galaxy. In this article we present an analysis of the AMS-02 antiproton\ndata, reducing cosmic-ray propagation uncertainties by fitting at the same time\ndark matter and propagation parameters. The result exhibits a possible hint for\ndark matter pointing to an annihilation cross section close to the thermal\nvalue. We investigate the compatibility of this signal with a dark matter\ninterpretation of the Galactic center excess seen in the Fermi-LAT gamma-ray\ndata and discuss implications for dark matter models.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A search for the associated production of the Higgs boson with a top quark\npair ($t\\bar t H$) is reported. The search is performed in multilepton final\nstates using a dataset corresponding to an integrated luminosity of 36.1\nfb$^{-1}$ of proton--proton collision data recorded by the ATLAS experiment at\na center-of-mass energy $\\sqrt{s} = 13$ TeV at the Large Hadron Collider. Higgs\nboson decays to $WW^*$, $\\tau\\tau$, and $ZZ^*$ are targeted. Seven final\nstates, categorized by the number and flavor of charged-lepton candidates, are\nexamined for the presence of the Standard Model Higgs boson with a mass of 125\nGeV and a pair of top quarks. An excess of events over the expected background\nfrom Standard Model processes is found with an observed significance of 4.1\nstandard deviations, compared to an expectation of 2.8 standard deviations. The\nbest fit for the $t\\bar t H$ production cross section is $\\sigma(t\\bar t H) =\n790^{+230}_{-210}$ fb, in agreement with the Standard Model prediction of\n$507^{+35}_{-50}$ fb. The combination of this result with other $t\\bar t H$\nsearches from the ATLAS experiment using the Higgs boson decay modes to $b\\bar\nb$, $\\gamma\\gamma$ and $ZZ^* \\to 4\\ell$, has an observed significance of 4.2\nstandard deviations, compared to an expectation of 3.8 standard deviations.\nThis provides evidence for the $t\\bar t H$ production mode.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The seek for a new universal formulation for describing various\nnon-equilibrium processes is a central task of modern non-equilibrium\nthermodynamics. In this paper, a novel steady-state thermodynamic formalism was\nestablished for general Markov processes described by the Chapman-Kolmogorov\nequation. Furthermore, corresponding formalisms of steady-state thermodynamics\nfor master equation and Fokker-Planck equation could be rigorously derived in\nmathematics. To be concrete, we proved that: 1) in the limit of continuous\ntime, the steady-state thermodynamic formalism for the Chapman-Kolmogorov\nequation fully agrees with that for the master equation; 2) a similar\none-to-one correspondence could be established rigorously between the master\nequation and Fokker-Planck equation in the limit of large system size; 3) when\na Markov process is restrained to one-step jump, the steady-state thermodynamic\nformalism for the Fokker-Planck equation with discrete state variables also\ngoes to that for master equations, as the discretization step gets smaller and\nsmaller. Our analysis indicated that, with respect to the steady state, general\nMarkov processes admit a unified and self-consistent non-equilibrium\nthermodynamic formulation, regardless of underlying detailed models.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Feshbach resonance provides precise control over the scattering length\nand effective range of interactions between ultracold atoms. We propose the\nultratransferable pseudopotential to model effective interaction ranges $-1.5\n\\leq k_\\mathrm{F}^2 R_\\mathrm{eff}^2 \\leq 0$, here $R_\\mathrm{eff}$ is the\neffective range and $k_\\mathrm{F}$ is the Fermi wave vector, describing narrow\nto broad Feshbach resonances. We develop a mean-field treatment and exploit the\npseudopotential to perform a variational and diffusion Monte Carlo study of the\nground state of the two-dimensional Fermi gas, reporting on the ground-state\nenergy, contact, condensate fraction, momentum distribution, and\npair-correlation functions as a function of the effective interaction range\nacross the BEC-BCS crossover. The limit $k_\\mathrm{F}^2 R_\\mathrm{eff}^2 \\to\n-\\infty$ is a gas of bosons with zero binding energy, whereas $\\ln(k_\\mathrm{F}\na) \\to -\\infty$ corresponds to noninteracting bosons with infinite binding\nenergy.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  GRB 120323A is a very intense short Gamma Ray Burst (GRB) detected\nsimultaneously during its prompt gamma-ray emission phase with the Gamma-ray\nBurst Monitor (GBM) on board the Fermi Gamma-ray Space Telescope and the Konus\nexperiment on board the Wind satellite. GBM and Konus operate in the keV--MeV\nregime, however, the GBM range is broader both toward the low and the high\nparts of the gamma-ray spectrum. Analysis of such bright events provide a\nunique opportunity to check the consistency of the data analysis as well as\ncross-calibrate the two instruments. We performed time-integrated and coarse\ntime-resolved spectral analysis of GRB 120323A prompt emission. We conclude\nthat the analyses of GBM and Konus data are only consistent when using a\ndouble-hump spectral shape for both data sets; in contrast, the single-hump of\nthe empirical Band function, traditionally used to fit GRB prompt emission\nspectra, leads to significant discrepancies between GBM and Konus analysis\nresults. Our two-hump model is a combination of a thermal-like and a\nnon-thermal component. We interpret the first component as a natural\nmanifestation of the jet photospheric emission.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a class of Two Higgs Doublet Models where there are Flavour\nChanging Neutral Currents (FCNC) at tree level, but under control due to the\nintroduction of a discrete symmetry in the full Lagrangian. It is shown that in\nthis class of models, one can have simultaneously FCNC in the up and down\nsectors, in contrast to the situation encountered in BGL models. The intensity\nof FCNC is analysed and it is shown that in this class of models one can\nrespect all the strong constraints from experiment without unnatural\nfine-tuning. It is pointed out that the additional sources of flavour and CP\nviolation are such that they can enhance significantly the generation of the\nBaryon Asymmetry of the Universe, with respect to the Standard Model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss a general procedure to construct an integrable real-time\ntrotterization of interacting lattice models. As an illustrative example we\nconsider a spin-$1/2$ chain, with continuous time dynamics described by the\nisotropic ($XXX$) Heisenberg Hamiltonian. For periodic boundary conditions\nlocal conservation laws are derived from an inhomogeneous transfer matrix and a\nboost operator is constructed. In the continuous time limit these local charges\nreduce to the known integrals of motion of the Heisenberg chain. In a simple\nKraus representation we also examine the nonequilibrium setting, where our\nintegrable cellular automaton is driven by stochastic processes at the\nboundaries. We show explicitly, how an exact nonequilibrium steady state\ndensity matrix can be written in terms of a staggered matrix product ansatz.\nThis simple trotterization scheme, in particular in the open system framework,\ncould prove to be a useful tool for experimental simulations of the lattice\nmodels in terms of trapped ion and atom optics setups.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Solid interfaces have intrinsic elasticity. However, in most experiments,\nthis is obscured by bulk stresses. Through microscopic observations of the\ncontact-line geometry of a partially wetting droplet on an anisotropically\nstretched substrate, we measure two surface-elastic constants that quantify the\nlinear dependence of the surface stress of a soft polymer gel on its strain.\nWith these two parameters, one can predict surface stresses for general\ndeformations of the material in the linear-elastic limit.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Providing consistently high wireless capacity is becoming increasingly\nimportant to support the applications required by future digital enterprises.\nIn this paper, we propose Eigen-direction-aware ZF (EDA-ZF) with partial\ncoordination among base stations (BSs) and distributed interference suppression\nas a practical approach to achieve this objective. We compare our solution with\nZero Forcing (ZF), entailing neither BS coordination or inter-cell interference\nmitigation, and Network MIMO (NeMIMO), where full BS coordination enables\ncentralized inter-cell interference management. We also evaluate the\nperformance of said schemes for three sub-6 GHz deployments with varying BS\ndensities -- sparse, intermediate, and dense -- all with fixed total number of\nantennas and radiated power. Extensive simulations show that: (i) indoor\nmassive MIMO implementing the proposed EDA-ZF provides uniformly good rates for\nall users; (ii) indoor network densification is detrimental unless full\ncoordination is implemented; (iii) deploying NeMIMO pays off under strong\noutdoor interference, especially for cell-edge users.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A Schroedinger equation proposed for the GMP gapped spin-2 mode of fractional\nQuantum Hall states is found from a novel non-relativistic limit, applicable\nonly in 2+1 dimensions, of the massive spin-2 Fierz-Pauli field equations. It\nis also found from a novel null reduction of the linearized Einstein field\nequations in 3+1 dimensions, and in this context a uniform distribution of\nspin-2 particles implies, via a Brinkmann-wave solution of the non-linear\nEinstein equations, a confining harmonic oscillator potential for the\nindividual particles.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This letter introduces the LOOP binary descriptor (local optimal oriented\npattern) that encodes rotation invariance into the main formulation itself.\nThis makes any post processing stage for rotation invariance redundant and\nimproves on both accuracy and time complexity. We consider fine-grained\nlepidoptera (moth/butterfly) species recognition as the representative problem\nsince it involves repetition of localized patterns and textures that may be\nexploited for discrimination. We evaluate the performance of LOOP against its\npredecessors as well as few other popular descriptors. Besides experiments on\nstandard benchmarks, we also introduce a new small image dataset on NZ\nLepidoptera. Loop performs as well or better on all datasets evaluated compared\nto previous binary descriptors. The new dataset and demo code of the proposed\nmethod are to be made available through the lead author's academic webpage and\nGitHub.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Spatio-temporal covariances are important for describing the spatio-temporal\nvariability of underlying random processes in geostatistical data. For\nsecond-order stationary processes, there exist subclasses of covariance\nfunctions that assume a simpler spatio-temporal dependence structure with\nseparability and full symmetry. However, it is challenging to visualize and\nassess separability and full symmetry from spatio-temporal observations. In\nthis work, we propose a functional data analysis approach that constructs test\nfunctions using the cross-covariances from time series observed at each pair of\nspatial locations. These test functions of temporal lags summarize the\nproperties of separability or symmetry for the given spatial pairs. We use\nfunctional boxplots to visualize the functional median and the variability of\nthe test functions, where the extent of departure from zero at all temporal\nlags indicates the degree of non-separability or asymmetry. We also develop a\nrank-based nonparametric testing procedure for assessing the significance of\nthe non-separability or asymmetry. The performances of the proposed methods are\nexamined by simulations with various commonly used spatio-temporal covariance\nmodels. To illustrate our methods in practical applications, we apply it to\nreal datasets, including weather station data and climate model outputs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The theoretical description of the thermodynamics of water is challenged by\nthe structural transition towards tetrahedral symmetry at ambient conditions.\nAs perturbation theories typically assume a spherically symmetric reference\nfluid, they are incapable of accurately describing the liquid properties of\nwater at ambient conditions. In this paper we solve this problem, by\nintroducing the concept of an associated reference perturbation theory (APT).\nIn APT we treat the reference fluid as an associating hard sphere fluid which\ntransitions to tetrahedral symmetry in the fully hydrogen bonded limit. We\ncalculate this transition in a theoretically self-consistent manner without\nappealing to molecular simulations. This associated reference provides the\nreference fluid for a second order Barker-Hendersen perturbative treatment of\nthe long-range attractions. We demonstrate that this new approach gives a\nsignificantly improved description of water as compared to standard\nperturbation theories.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We synthesize performance-aware safe cruise control policies for longitudinal\nmotion of platoons of autonomous vehicles. Using set-invariance theories, we\nguarantee infinite-time collision avoidance in the presence of bounded additive\ndisturbances, while ensuring that the length and the cruise speed of the\nplatoon are bounded within specified ranges. We propose (i) a centralized\ncontrol policy, and (ii) a distributed control policy, where each vehicle's\ncontrol decision depends solely on its relative kinematics with respect to the\nplatoon leader. Numerical examples are included.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Nystrom method is a popular technique that uses a small number of\nlandmark points to compute a fixed-rank approximation of large kernel matrices\nthat arise in machine learning problems. In practice, to ensure high quality\napproximations, the number of landmark points is chosen to be greater than the\ntarget rank. However, for simplicity the standard Nystrom method uses a\nsub-optimal procedure for rank reduction. In this paper, we examine the\ndrawbacks of the standard Nystrom method in terms of poor performance and lack\nof theoretical guarantees. To address these issues, we present an efficient\nmodification for generating improved fixed-rank Nystrom approximations.\nTheoretical analysis and numerical experiments are provided to demonstrate the\nadvantages of the modified method over the standard Nystrom method. Overall,\nthe aim of this paper is to convince researchers to use the modified method, as\nit has nearly identical computational complexity, is easy to code, has greatly\nimproved accuracy in many cases, and is optimal in a sense that we make\nprecise.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hydrogen-rich compounds are important for understanding the dissociation of\ndense molecular hydrogen, as well as searching for room temperature\nBardeen-Cooper-Schrieffer (BCS) superconductors. A recent high pressure\nexperiment reported the successful synthesis of novel insulating lithium\npolyhydrides when above 130 GPa. However, the results are in sharp contrast to\nprevious theoretical prediction by PBE functional that around this pressure\nrange all lithium polyhydrides (LiHn (n = 2-8)) should be metallic. In order to\naddress this discrepancy, we perform unbiased structure search with first\nprinciples calculation by including the van der Waals interaction that was\nignored in previous prediction to predict the high pressure stable structures\nof LiHn (n = 2-11, 13) up to 200 GPa. We reproduce the previously predicted\nstructures, and further find novel compositions that adopt more stable\nstructures. The van der Waals functional (vdW-DF) significantly alters the\nrelative stability of lithium polyhydrides, and predicts that the stable\nstoichiometries for the ground-state should be LiH2 and LiH9 at 130-170 GPa,\nand LiH2, LiH8 and LiH10 at 180-200 GPa. Accurate electronic structure\ncalculation with GW approximation indicates that LiH, LiH2, LiH7, and LiH9 are\ninsulative up to at least 208 GPa, and all other lithium polyhydrides are\nmetallic. The calculated vibron frequencies of these insulating phases are also\nin accordance with the experimental infrared (IR) data. This reconciliation\nwith the experimental observation suggests that LiH2, LiH7, and LiH9 are the\npossible candidates for lithium polyhydrides synthesized in that experiment.\nOur results reinstate the credibility of density functional theory in\ndescription H-rich compounds, and demonstrate the importance of considering van\nder Waals interaction in this class of materials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The antidynamical Casimir effect (ADCE) is a term coined to designate the\ncoherent annihilation of excitations due to resonant external perturbation of\nsystem parameters, allowing for extraction of quantum work from nonvacuum\nstates of some field. Originally proposed for a two-level atom (qubit) coupled\nto a single cavity mode in the context of nonstationary quantum Rabi model, it\nsuffered from very low transition rate and correspondingly narrow resonance\nlinewidth. In this paper we show analytically and numerically that the ADCE\nrate can be increased by at least one order of magnitude by replacing the qubit\nby an artificial three-level atom (qutrit) in a properly chosen configuration.\nFor the cavity thermal state we demonstrate that the dynamics of the average\nphoton number and atomic excitation is completely different from the qubit's\ncase, while the behavior of the total number of excitations is qualitatively\nsimilar yet significantly faster.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  High-dimensional encoding of quantum information provides a promising method\nof transcending current limitations in quantum communication. One of the\ncentral challenges in the pursuit of such an approach is the certification of\nhigh-dimensional entanglement. In particular, it is desirable to do so without\nresorting to inefficient full state tomography. Here, we show how carefully\nconstructed measurements in two bases (one of which is not orthonormal) can be\nused to faithfully and efficiently certify bipartite high-dimensional states\nand their entanglement for any physical platform. To showcase the practicality\nof this approach under realistic conditions, we put it to the test for photons\nentangled in their orbital angular momentum. In our experimental setup, we are\nable to verify 9-dimensional entanglement for a pair of photons on a\n11-dimensional subspace each, at present the highest amount certified without\nany assumptions on the state.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper is concerned with the differential sensitivity analysis of\nvariational inequalities in Banach spaces whose solution operators satisfy a\ngeneralized Lipschitz condition. We prove a sufficient criterion for the\ndirectional differentiability of the solution map that turns out to be also\nnecessary for elliptic variational inequalities in Hilbert spaces (even in the\npresence of asymmetric bilinear forms, nonlinear operators and nonconvex\nfunctionals). In contrast to classical results, our method of proof does not\nrely on Attouch's theorem on the characterization of Mosco convergence but is\nfully elementary. Moreover, our technique allows us to also study those cases\nwhere the variational inequality at hand is not uniquely solvable and where\ndirectional differentiability can only be obtained w.r.t. the weak or the\nweak-$\\star$ topology of the underlying space. As tangible examples, we\nconsider a variational inequality arising in elastoplasticity, the projection\nonto prox-regular sets, and a bang-bang optimal control problem.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we study a class of graph drawings that arise from bobbin lace\npatterns. The drawings are periodic and require a combinatorial embedding with\nspecific properties which we outline and demonstrate can be verified in linear\ntime. In addition, a lace graph drawing has a topological requirement: it\ncontains a set of non-contractible directed cycles which must be homotopic to\n$(1,0)$, that is, when drawn on a torus, each cycle wraps once around the minor\nmeridian axis and zero times around the major longitude axis. We provide an\nalgorithm for finding the two fundamental cycles of a canonical rectangular\nschema in a supergraph that enforces this topological constraint. The polygonal\nschema is then used to produce a straight-line drawing of the lace graph inside\na rectangular frame. We argue that such a polygonal schema always exists for\ncombinatorial embeddings satisfying the conditions of bobbin lace patterns, and\nthat we can therefore create a pattern, given a graph with a fixed\ncombinatorial embedding of genus one.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Eigenvalue analysis is a well-established tool for stability analysis of\ndynamical systems. However, there are situations where eigenvalues miss some\nimportant features of physical models. For example, in models of incompressible\nfluid dynamics, there are examples where linear stability analysis predicts\nstability but transient simulations exhibit significant growth of infinitesimal\nperturbations. This behavior can be predicted by pseudo-spectral analysis. In\nthis study, we show that an approach similar to pseudo-spectral analysis can be\nperformed inexpensively using stochastic collocation methods and the results\ncan be used to provide quantitative information about instability. In addition,\nwe demonstrate that the results of the perturbation analysis provide insight\ninto the behavior of unsteady flow simulations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss the most general necessary and sufficient condition for three\nmassless light neutrinos in variants of the type I seesaw mechanism in which we\nintroduce an arbitrary number of fermionic gauge singlets. We find that having\nmassless light neutrinos is equivalent to enforcing the conservation of lepton\nnumber. As a consequence, any symmetry that leads to massless light neutrinos\nwill contain as an unbroken subgroup a conserved lepton number. This will be\nimportant for searches for heavy sterile neutrinos since in general the light\nneutrino masses will be proportional to small lepton number violating\nparameters that will also suppress lepton number violating signatures.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The average density of states in a disordered three-dimensional Weyl system\nis discussed in the case of a continuous distribution of random scattering. Our\nresult clearly indicate that the average density of states does not vanish,\nreflecting the absence of a critical point for a metal-insulator transition.\nThis calculation supports recent suggestions of an avoided quantum critical\npoint in the disordered three-dimensional Weyl semimetal. However, the\neffective density of states can be very small such that the\nsaddle-approximation with a vanishing density of states might be valid for\npractical cases.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider bond percolation on $\\Z^d\\times \\Z^s$ where edges of $\\Z^d$ are\nopen with probability $p<p_c(\\Z^d)$ and edges of $\\Z^s$ are open with\nprobability $q$, independently of all others. We obtain bounds for the critical\ncurve in $(p, q)$, with $p$ close to the critical threshold $p_c(\\Z^d)$. The\nresults are related to the so-called dimensional crossover from $\\Z^d$ to\n$\\Z^{d+s}$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  With the intention of bringing uniformity to Bengali text entry research,\nhere we present a new approach for calculating the most popular English text\nentry evaluation metrics for Bengali. To demonstrate our approach, we conducted\na user study where we evaluated four popular Bengali text entry techniques.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we find the optimal error bound (smallest possible estimate,\nindependent of the starting point) for the linear convergence rate of the\nsimultaneous projection method applied to closed linear subspaces in a real\nHilbert space. We achieve this by computing the norm of an error operator which\nwe also express in terms of the Friedrichs number. We compare our estimate with\nthe optimal one provided for the alternating projection method by Kayalar and\nWeinert (1988). Moreover, we relate our result to the alternating projection\nformalization of Pierra (1984) in a product space. Finally, we adjust our\nresults to closed affine subspaces and put them in context with recent\ndichotomy theorems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We model continuous-time information flows generated by a number of\ninformation sources that switch on and off at random times. By modulating a\nmulti-dimensional L\\'evy random bridge over a random point field, our framework\nrelates the discovery of relevant new information sources to jumps in\nconditional expectation martingales. In the canonical Brownian random bridge\ncase, we show that the underlying measure-valued process follows jump-diffusion\ndynamics, where the jumps are governed by information switches. The dynamic\nrepresentation gives rise to a set of stochastically-linked Brownian motions on\nrandom time intervals that capture evolving information states, as well as to a\nstate-dependent stochastic volatility evolution with jumps. The nature of\ninformation flows usually exhibits complex behaviour, however, we maintain\nanalytic tractability by introducing what we term the effective and\ncomplementary information processes, which dynamically incorporate active and\ninactive information, respectively. As an application, we price a financial\nvanilla option, which we prove is expressed by a weighted sum of option values\nbased on the possible state configurations at expiry. This result may be viewed\nas an information-based analogue of Merton's option price, but where\njump-diffusion arises endogenously. The proposed information flows also lend\nthemselves to the quantification of asymmetric informational advantage among\ncompetitive agents, a feature we analyse by notions of information geometry.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A computational method is presented which is capable to obtain low lying\nenergy structures of topological amorphous systems. The method merges a\ndifferential mutation genetic algorithm with simulated annealing. This is done\nby incorporating a thermal selection criterion, which makes it possible to\nreliably obtain low lying minima with just a small population size and is\nsuitable for multimodal structural optimization. The method is tested on the\nstructural optimization of amorphous graphene from unbiased atomic starting\nconfigurations. With just a population size of six systems, energetically very\nlow structures are obtained. While each of the structures represents a\ndistinctly different arrangement of the atoms, their properties, such as\nenergy, distribution of rings, radial distribution function, coordination\nnumber and distribution of bond angles, are very similar.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report compressive mechanical response of graphene foams (GFs) and the\nthermal resistance ($R_{TIM}$) between copper (Cu) and GFs, where GFs were\nprepared by the chemical vapor deposition (CVD) method. We observe that Young's\nmodulus ($E_{GF}$) and compressive strength ($\\sigma_{GF}$) of GFs have a power\nlaw dependence on increasing density ($\\rho_{GF}$) of GFs. The maximum\nefficiency of absorbed energy ($\\eta_{max}$) for all GFs during the compression\nis larger than ~0.39. We also find that a GF with a higher $\\rho_{GF}$ shows a\nlarger $\\eta_{max}$. In addition, we observe that the measured $R_{TIM}$ of\nCu/GFs at room temperature with a contact pressure of 0.25 MP applied increases\nfrom ~50 to ~90 $mm^2K/W$ when $\\rho_{GF}$ increases from 4.7 to 31.9\n$mg/cm^3$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  It is well known that rate-independent systems involving nonconvex energy\nfunctionals in general do not allow for time-continuous solutions even if the\ngiven data are smooth. In the last years, several solution concepts were\nproposed that include discontinuities in the notion of solution, among them the\nclass of global energetic solutions and the class of BV-solutions. In general,\nthese solution concepts are not equivalent and numerical schemes are needed\nthat reliably approximate that type of solutions one is interested in. In this\npaper we analyse the convergence of solutions of three time-discretisation\nschemes, namely an approach based on local minimization, a penalized version of\nit and an alternate minimization scheme. For all three cases we show that under\nsuitable conditions on the discretisation parameters discrete solutions\nconverge to limit functions that belong to the class of BV-solutions. The\nproofs rely on a reparametrization argument. We illustrate the different\nschemes with a toy example.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Red giant stars are solar-like pulsators presenting mixed-modes. Such modes\nconsist in a coupling between pressure waves propagating in the external\nconvective envelope and gravity waves propagating in the radiative interior.\nTherefore, the red giant asteroseismology provides us with a direct view on\ntheir core and opens the possibility to monitor the evolution of their core\nrotation. Previous measurements of the mean core rotation revealed that angular\nmomentum is efficiently transferred from the core to the envelope inside red\ngiants, but the physical mechanisms at work are not yet fully understood. We\nthus need stronger observational constraints on the evolution of the red giant\ncore rotation. In this context, we developed an automated method to determine\nthe mean core rotation of red giant branch stars observed with Kepler. This\nautomated method is paving the way for the future PLATO data, representing\nhundreds of thousands of potential red giant oscillation spectra. Results\nobtained for almost 1200 red giant branch stars indicate that the rate of the\ncore rotation braking is lower than previously estimated and does not seem to\ndepend on the stellar mass.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given two finite ordered sets $A = \\{a_1, \\ldots, a_m\\}$ and $B = \\{b_1,\n\\ldots, b_n\\}$, introduce the set of $m n$ outcomes of the game $O = \\{(a, b)\n\\mid a \\in A, b \\in B\\} = \\{(a_i, b_j) \\mid i \\in I = \\{1, \\ldots, m\\}, j \\in J\n= \\{1, \\ldots, n\\}$. Two players, Alice and Bob, have the sets of strategies\n$X$ and $Y$ that consist of all monotone non-decreasing mappings $x: A\n\\rightarrow B$ and $y: B \\rightarrow A$, respectively. It is easily seen that\neach pair $(x,y) \\in X \\times Y$ produces at least one {\\em deal}, that is, an\noutcome $(a,b) \\in O$ such that $x(a) = b$ and $y(b) = a$. Denote by $G(x,y)\n\\subseteq O$ the set of all such deals related to $(x,y)$. The obtained mapping\n$G = G_{m,n}: X \\times Y \\rightarrow 2^O$ is a game correspondence. Choose an\narbitrary deal $g(x,y) \\in G(x,y)$ to obtained a mapping $g : X \\times Y\n\\rightarrow O$, which is a game form. We will show that each such game form is\ntight and, hence, Nash-solvable, that is, for any pair $u = (u_A, u_B)$ of\nutility functions $u_A : O \\rightarrow \\mathbb R$ of Alice and $u_B: O\n\\rightarrow \\mathbb R$ of Bob, the obtained monotone bargaining game $(g, u)$\nhas at least one Nash equilibrium in pure strategies. Moreover, the same\nequilibrium can be chosen for all selections $g(x,y) \\in G(x,y)$. We also\nobtain an efficient algorithm that determines such an equilibrium in time\nlinear in $m n$, although the numbers of strategies $|X| = \\binom{m+n-1}{m}$\nand $|Y| = \\binom{m+n-1}{n}$ are exponential in $m n$. Our results show that,\nsomewhat surprising, the players have no need to hide or randomize their\nbargaining strategies, even in the zero-sum case.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hyperpolarized 13C-MRI allows real time observation of metabolism in vivo.\nImaging sequences have been developed to follow the metabolism of [1-13C]\npyruvate and extract reaction kinetics, which can show tumour treatment\nresponse. We applied the fitting model and algorithm for the imaging data of\nmice tumour models and determined error estimates for the parameters of\ninterest. Data was least-squares fitted onto a two-site exchange model in\nMATLAB, followed by statistic computation to assess model performance.\nInference through the application of MCMC was also performed. The modelling and\ninference process extracted quantitative information satisfactorily and\nreproducibly, demonstrating metabolic activity and intratumour heterogeneity.\nFinally, novel fitting methods were evaluated and further recommendations were\nmade.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hesselholt and Madsen in [7] define and study the (absolute, p-typical) de\nRham-Witt complex in mixed characteristic, where p is an odd prime. They give\nas an example an elementary algebraic description of the de Rham-Witt complex\nover Z_(p). The main goal of this paper is to construct, for k a perfect ring\nof characteristic p > 2, a Witt complex over A = W(k) with an algebraic\ndescription which is completely analogous to Hesselholt and Madsen's\ndescription for Z_(p). Our Witt complex is not isomorphic to the de Rham-Witt\ncomplex; instead we prove that, in each level, the de Rham-Witt complex over\nW(k) surjects onto our Witt complex, and that the kernel consists of all\nelements which are divisible by arbitrarily high powers of p. We deduce an\nexplicit description of the de Rham-Witt complex over W(k). We also deduce\nresults concerning the de Rham-Witt complex over certain perfectoid rings.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Assume that $G$ is a finite group. For every $a, b \\in\\mathbb N,$ we define a\ngraph $\\Gamma_{a,b}(G)$ whose vertices correspond to the elements of $G^a\\cup\nG^b$ and in which two tuples $(x_1,\\dots,x_a)$ and $(y_1,\\dots,y_b)$ are\nadjacent if and only if $\\langle x_1,\\dots,x_a,y_1,\\dots,y_b \\rangle =G.$ We\nstudy several properties of these graphs (isolated vertices, loops,\nconnectivity, diameter of the connected components) and we investigate the\nrelations between their properties and the group structure, with the aim of\nunderstanding which information about $G$ are encoded by these graphs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We extend the local theory of available potential energy (APE) to a general\nmulticomponent compressible stratified fluid, accounting for the effects of\ndiabatic sinks and sources. As for simple compressible fluids, the total\npotential energy density of a fluid parcel is the sum of its available elastic\nenergy (AEE) and APE density. These respectively represent the adiabatic\ncompression/expansion work needed to bring it from its reference pressure to\nits actual pressure and the work against buoyancy forces required to move it\nfrom its reference state position to its actual position. Our expression for\nthe APE density is new and derived using only elementary manipulations of the\nequations of motion; it is significantly simpler than existing published\nexpressions, while also being more transparently linked to the relevant form of\nAPE density for the Boussinesq and hydrostatic primitive equations. Our new\nframework is used to clarify the links between some aspects of the energetics\nof Boussinesq and real fluids, as well as to shed light on the physical basis\nunderlying the choice of reference state(s) in local APE theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper demonstrates the use of genetic algorithms for evolving a\ngrandmaster-level evaluation function for a chess program. This is achieved by\ncombining supervised and unsupervised learning. In the supervised learning\nphase the organisms are evolved to mimic the behavior of human grandmasters,\nand in the unsupervised learning phase these evolved organisms are further\nimproved upon by means of coevolution.\n  While past attempts succeeded in creating a grandmaster-level program by\nmimicking the behavior of existing computer chess programs, this paper presents\nthe first successful attempt at evolving a state-of-the-art evaluation function\nby learning only from databases of games played by humans. Our results\ndemonstrate that the evolved program outperforms a two-time World Computer\nChess Champion.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let k be a base field of positive characteristic. Making use of topological\nperiodic cyclic homology, we start by proving that the category of\nnoncommutative numerical motives over k is abelian semi-simple, as conjectured\nby Kontsevich. Then, we establish a far-reaching noncommutative generalization\nof the Weil conjectures, originally proved by Dwork and Grothendieck. In the\nsame vein, we establish a far-reaching noncommutative generalization of the\ncohomological interpretations of the Hasse-Weil zeta function, originally\nproven by Hesselholt. As a third main result, we prove that the numerical\nGrothendieck group of every smooth proper dg category is a finitely generated\nfree abelian group, as claimed (without proof) by Kuznetsov. Then, we introduce\nthe noncommutative motivic Galois (super-)groups and, following an insight of\nKontsevich, relate them to their classical commutative counterparts. Finally,\nwe explain how the motivic measure induced by Berthelot's rigid cohomology can\nbe recovered from the theory of noncommutative motives.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In Ho\\v{r}ava-Lifshitz gravity a scaling isotropic in space but anisotropic\nin spacetime, often called anisotropic scaling with the dynamical critical\nexponent z=3, lies at the base of its renormalizability. This scaling also\nleads to a novel mechanism of generating scale-invariant cosmological\nperturbations, solving the horizon problem without inflation. In this paper we\npropose a possible solution to the flatness problem, in which we assume that\nthe initial condition of the Universe is set by a small instanton respecting\nthe same scaling. We argue that the mechanism may be more general than the\nconcrete model presented here, and rely simply on the deformed dispersion\nrelations of the theory, and on equipartition of the various forms of energy at\nthe starting point.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Binary neutron star mergers are considered to be the most favorable sources\nthat produce electromagnetic (EM) signals associated with gravitational waves\n(GWs). These mergers are the likely progenitors of short duration gamma-ray\nbursts (GRBs). The brief gamma-ray emission (the \"prompt GRB\" emission) is\nproduced by ultra-relativistic jets, as a result, this emission is strongly\nbeamed over a small solid angle along the jet. It is estimated to be a decade\nor more before a short GRB jet within the LIGO volume points along our line of\nsight. For this reason, the study of the prompt signal as an EM counterpart to\nGW events has been sparse. We argue that for a realistic jet model, one whose\nluminosity and Lorentz factor vary smoothly with angle, the prompt signal can\nbe detected for a significantly broader range of viewing angles. This can lead\nto a new type of EM counterpart, an \"off-axis\" short GRB. Our estimates and\nsimulations show that it is feasible to detect these signals with the aid of\nthe temporal coincidence from a LIGO trigger, even if the observer is\nsubstantially misaligned with respect to the jet.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We combine the theoretical method of calculating spin wave excitation with\nthe finite-temperature modeling and calculate the magnon-phonon relaxation time\nin the technologically important material Yttrium iron garnet (YIG) from first\nprinciples. The finite lifetime of magnon excitation is found to arise from the\nfluctuation of the exchange interaction of magnetic atoms in YIG. At room\ntemperature, the magnon spectra have significant broadening that is used to\nextract the magnon-phonon relaxation time quantitatively. The latter is a\nphenomenological parameter of great importance in YIG-based spintronics\nresearch. We find that the magnon-phonon relaxation time for the optical magnon\nis a constant while that for the acoustic magnon is proportional to $1/k^2$ in\nthe long-wavelength regime.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Nonuniform strain distributions in a graphene lattice can give rise to\nuniform pseudomagnetic fields and associated pseudo-Landau levels without\nbreaking time-reversal symmetry. We demonstrate that by inducing\nsuperconductivity in a nonuniformly strained graphene sheet, the lowest\npseudo-Landau levels split by a pairing gap can be inverted by changing the\nsign of the pairing potential. As a consequence of this inversion, we predict\nthat a Josephson $\\pi$ junction deposited on top of a strained graphene sheet\nexhibits one-dimensional gapless modes propagating along the junction. These\ngapless modes mediate single electron tunneling across the junction, giving\nrise to the $4\\pi$-periodic fractional Josephson effect.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The compression property of regolith reflects the strength and porosity of\nthe regolith layer on small bodies and their variations in the layer that\nlargely influence the collisional and thermal evolution of the bodies. We\nconducted compression experiments and investigated the relationship between the\nporosity and the compression using fluffy granular samples. We focused on a\nlow-pressure and high-porosity regime. We used tens of {\\mu}m-sized irregular\nand spherical powders as analogs of porous regolith. The initial porosity of\nthe samples ranged from 0.80 to 0.53. The uniaxial pressure applied to the\nsamples lays in the range from 30 to 4x10^5 Pa. The porosity of the samples\nremained at their initial values below a threshold pressure and then decreased\nwhen the pressure exceeded the threshold. We defined this uniaxial pressure at\nthe threshold as \"yield strength\". The yield strength increased as the initial\nporosity of a sample decreased. The yield strengths of samples consisting of\nirregular particles did not significantly depend on their size distributions\nwhen the samples had the same initial porosity. We compared the results of our\nexperiments with a previously proposed theoretical model. We calculated the\naverage interparticle force acting on contact points of constituent particles\nunder the uniaxial pressure of yield strength using the theoretical model and\ncompared it with theoretically estimated forces required to roll or slide the\nparticles. The calculated interparticle force was larger than the rolling\nfriction force and smaller than the sliding friction force. The yield strength\nof regolith may be constrained by these forces. Our results may be useful for\nplanetary scientists to estimate the depth above which the porosity of a\nregolith layer is almost equal to that of the regolith surface and to interpret\nthe compression property of an asteroid surface obtained by a lander.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  MOTIVATION: Left ventricular (LV) hypertrophy is a strong predictor of\ncardiovascular outcomes, but its genetic regulation remains largely\nunexplained. Conventional phenotyping relies on manual calculation of LV mass\nand wall thickness, but advanced cardiac image analysis presents an opportunity\nfor high-throughput mapping of genotype-phenotype associations in three\ndimensions (3D). RESULTS: High-resolution cardiac magnetic resonance images\nwere automatically segmented in 1,124 healthy volunteers to create a 3D shape\nmodel of the heart. Mass univariate regression was used to plot a 3D\neffect-size map for the association between wall thickness and a set of\npredictors at each vertex in the mesh. The vertices where a significant effect\nexists were determined by applying threshold-free cluster enhancement to boost\nareas of signal with spatial contiguity. Experiments on simulated phenotypic\nsignals and SNP replication show that this approach offers a substantial gain\nin statistical power for cardiac genotype-phenotype associations while\nproviding good control of the false discovery rate. This framework models the\neffects of genetic variation throughout the heart and can be automatically\napplied to large population cohorts. AVAILABILITY: The proposed approach has\nbeen coded in an R package freely available at\nhttps://doi.org/10.5281/zenodo.834610 together with the clinical data used in\nthis work.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The motivation of our current research is to devise motion planners for\nlegged locomotion that are able to exploit the robot's actuation capabilities.\nThis means, when possible, to minimize joint torques or to propel as much as\nadmissible when required. For this reason we define two new 6 dimensional\nbounded polytopes that we name Actuation-consistent Wrench Polytope (AWP) and\nFeasible Wrench Polytope (FWP). These objects turn out to be very useful in\nmotion planning for the definition of constraints on the accelerations of the\nCenter of Mass of the robot that respect the friction cones and the actuation\nlimits. The AWP and the FWP could be used also in the robot design phase to\nsize the actuators of the system based on some predefined reference motion.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $I$ and $J$ be nonzero ideals in two Noetherian algebras $A$ and $B$ over\na field $k$. Let $I+J$ denote the ideal generated by $I$ and $J$ in $A\\otimes_k\nB$. We prove the following expansion for the symbolic powers: $$(I+J)^{(n)} =\n\\sum_{i+j = n} I^{(i)} J^{(j)}.$$ If $A$ and $B$ are polynomial rings and if\nchara$(k) = 0$ or if $I$ and $J$ are monomial ideals, we give exact formulas\nfor the depth and the Castelnuovo-Mumford regularity of $(I+J)^{(n)}$, which\ndepend on the interplay between the symbolic powers of $I$ and $J$. The proof\ninvolves a result of independent interest which states that under the above\nassumption, the induced map Tor$_i^A(k,I^{(n)}) \\to$ Tor$_i^A(k,I^{(n-1)})$ is\nzero for all $i \\ge 0$, $n \\ge 0$. We also investigate other properties and\ninvariants of $(I+J)^{(n)}$ such as the equality between ordinary and symbolic\npowers, the Waldschmidt constant and the Cohen-Macaulayness.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Relativistic heavy-ion collisions provide a unique opportunity to search for\nparity violation in non-central collisions. This could lead to charge\nseparation perpendicular to the reaction plane. An event-by-event measurement\nof charge separation effect in Pb-Pb collisions at $\\sqrt{s_{\\rm NN}}$ = 2.76\nTeV using Sliding Dumbbell Method (SDM) is discussed in this article.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce TrustVI, a fast second-order algorithm for black-box variational\ninference based on trust-region optimization and the reparameterization trick.\nAt each iteration, TrustVI proposes and assesses a step based on minibatches of\ndraws from the variational distribution. The algorithm provably converges to a\nstationary point. We implemented TrustVI in the Stan framework and compared it\nto two alternatives: Automatic Differentiation Variational Inference (ADVI) and\nHessian-free Stochastic Gradient Variational Inference (HFSGVI). The former is\nbased on stochastic first-order optimization. The latter uses second-order\ninformation, but lacks convergence guarantees. TrustVI typically converged at\nleast one order of magnitude faster than ADVI, demonstrating the value of\nstochastic second-order information. TrustVI often found substantially better\nvariational distributions than HFSGVI, demonstrating that our convergence\ntheory can matter in practice.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper applies techniques from algebraic and differential geometry to\ndetermine how to best pack points in real projective spaces. We present a\ncomputer-assisted proof of the optimality of a particular 6-packing in\n$\\mathbb{R}\\mathbf{P}^3$, we introduce a linear-time constant-factor\napproximation algorithm for packing in the so-called Gerzon range, and we\nprovide local optimality certificates for two infinite families of packings.\nFinally, we present perfected versions of various putatively optimal packings\nfrom Sloane's online database, along with a handful of infinite families they\nsuggest, and we prove that these packings enjoy a certain weak notion of\noptimality.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we present a time scale version of the Hermite-Hadamard\ninequality for functions convex on the coordinates via the diamond-$\\alpha$\ncalculus. Our results are new and they generalize and extend a result due to\nDragomir.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We generalize work of Bourgain-Kontorovich and Zhang, proving an almost\nlocal-to-global property for the curvatures of certain circle packings, to a\nlarge class of Kleinian groups. Specifically, we associate in a natural way an\ninfinite family of integral packings of circles to any Kleinian group $\\mathcal\nA\\leq\\textrm{PSL}_2(K)$ satisfying certain conditions, where $K$ is an\nimaginary quadratic field, and show that the curvatures of the circles in any\nsuch packing satisfy an almost local-to-global principle. A key ingredient in\nthe proof of this is that $\\mathcal A$ possesses a spectral gap property, which\nwe prove for any infinite-covolume, geometrically finite, Zariski dense\nKleinian group in $\\textrm{PSL}_2(\\mathcal{O}_K)$ containing a Zariski dense\nsubgroup of $\\textrm{PSL}_2(\\mathbb{Z})$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study a notion of order in Jordan algebras based on the version for Jordan\nalgebras of the ideas of Fountain and Gould as adapted to the Jordan context by\nFern\\'{a}ndez-L\\'{o}pez and Garc\\'{\\i}a-Rus, making use of results on general\nalgebras of quotients of Jordan algebras. In particular, we characterize the\nset of Lesieur-Croisot elements of a nondegenerate Jordan algebra as those\nelements of the Jordan algebra lying in the socle of its maximal algebra of\nquotients, and apply this relationship to extend to quadratic Jordan algebras\nthe results of Fern\\'{a}ndez-L\\'{o}pez and Garc\\'{\\i}a-Rus on local orders in\nnondegenerate Jordan algebras satisfying the descending chain condition on\nprincipal inner ideals and not containing ideals which are nonartinian\nquadratic factors.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given $k\\in\\mathbb N$, we study the vanishing of the Dirichlet series\n$$D_k(s,f):=\\sum_{n\\geq1} d_k(n)f(n)n^{-s}$$ at the point $s=1$, where $f$ is a\nperiodic function modulo a prime $p$. We show that if $(k,p-1)=1$ or\n$(k,p-1)=2$ and $p\\equiv 3\\mod 4$, then there are no odd rational-valued\nfunctions $f\\not\\equiv 0$ such that $D_k(1,f)=0$, whereas in all other cases\nthere are examples of odd functions $f$ such that $D_k(1,f)=0$.\n  As a consequence, we obtain, for example, that the set of values\n$L(1,\\chi)^2$, where $\\chi$ ranges over odd characters mod $p$, are linearly\nindependent over $\\mathbb Q$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A space of entire functions of several complex variables rapidly decreasing\non ${\\mathbb R}^n$ and such that their growth along $i{\\mathbb R}^n$ is\nmajorized with the help of a family of weight functions is considered in this\npaper. For such space an equivalent description in terms of estimates on all of\nits partial derivatives as functions on ${\\mathbb R}^n$ and a Paley-Wiener type\ntheorem are obtained.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recent progress in variational inference has paid much attention to the\nflexibility of variational posteriors. One promising direction is to use\nimplicit distributions, i.e., distributions without tractable densities as the\nvariational posterior. However, existing methods on implicit posteriors still\nface challenges of noisy estimation and computational infeasibility when\napplied to models with high-dimensional latent variables. In this paper, we\npresent a new approach named Kernel Implicit Variational Inference that\naddresses these challenges. As far as we know, for the first time implicit\nvariational inference is successfully applied to Bayesian neural networks,\nwhich shows promising results on both regression and classification tasks.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider a stochastic queueing system modelling the behaviour of a\nwireless network with nodes employing a discrete-time version of the standard\ndecentralised medium access algorithm. The system is {\\em unsaturated} -- each\nnode receives an exogenous flow of packets at the rate $\\lambda$ packets per\ntime slot. Each packet takes one slot to transmit, but neighboring nodes cannot\ntransmit simultaneously. The algorithm we study is {\\em standard} in that: a\nnode with empty queue does {\\em not} compete for medium access; the access\nprocedure by a node does {\\em not} depend on its queue length, as long as it is\nnon-zero. Two system topologies are considered, with nodes arranged in a circle\nand in a line. We prove that, for either topology, the system is stochastically\nstable under condition $\\lambda < 2/5$. This result is intuitive for the circle\ntopology as the throughput each node receives in a saturated system (with\ninfinite queues) is equal to the so called {\\em parking constant}, which is\nlarger than $2/5$. (The latter fact, however, does not help to prove our\nresult.) The result is not intuitive at all for the line topology as in a\nsaturated system some nodes receive a throughput lower than $2/5$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This review is based on the lectures given by the author at the Les Houches\nSummer School 2016. It describes the recently developed Quantum Spectral Curve\n(QSC) for a non-perturbative planar spectrum of N=4 Super Yang-Mills theory in\na pedagogical way starting from the harmonic oscillator and avoiding a long\nhistorical path. We give many examples and provide exercises. At the end we\ngive a list of the recent and possible future applications of the QSC.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Short review of experimental and theoretical researches influence of inner\nboundaries at properties of composite materials. Reviewing articles that are\nmade at the last, approximately, thirty years, and which demonstrate role of\ninner boundaries in determining the properties of composite materials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $p$ be an odd prime. We construct a $p$-group $P$ of nilpotency class\ntwo, rank seven and exponent $p$, such that $\\mathrm{Aut}(P)$ induces\n$N_{\\mathrm{GL}(7,p)}(G_2(p)) = Z(\\mathrm{GL}(7,p)) G_2(p)$ on the Frattini\nquotient $P/\\Phi(P)$. The constructed group $P$ is the smallest $p$-group with\nthese properties, having order $p^{14}$, and when $p = 3$, our construction\ngives two nonisomorphic $p$-groups. To show that $P$ satisfies the specified\nproperties, we study the action of $G_2(q)$ on the octonion algebra over\n$\\mathbb{F}_q$, for each power $q$ of $p$, and explore the reducibility of the\nexterior square of each irreducible seven-dimensional\n$\\mathbb{F}_q[G_2(q)]$-module.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the universal thermodynamics of the two-component\none-dimensional Bose gas with contact interactions in the vicinity of the\nquantum critical point separating the vacuum and the ferromagnetic liquid\nregime. We find that the quantum critical region belongs to the universality\nclass of the spin-degenerate impenetrable particle gas which, surprisingly, is\nvery different from the single-component case and identify its boundaries with\nthe peaks of the specific heat. In addition, we show that the compressibility\nWilson ratio, which quantifies the relative strength of thermal and quantum\nfluctuations, serves as a good discriminator of the quantum regimes near the\nquantum critical point. Remarkably, in the Tonks-Girardeau regime the universal\ncontact develops a pronounced minimum, reflected in a counterintuitive\nnarrowing of the momentum distribution as we increase the temperature. This\nmomentum reconstruction, also present at low and intermediate momenta, signals\nthe transition from the ferromagnetic to the spin-incoherent Luttinger liquid\nphase and can be detected in current experiments with ultracold atomic gases in\noptical lattices.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recent years have witnessed the rapid development and wide adoption of\nimmersive head-mounted devices, such as HTC VIVE, Oculus Rift, and Microsoft\nHoloLens. These immersive devices have the potential to significantly extend\nthe methodology of urban visual analytics by providing critical 3D context\ninformation and creating a sense of presence. In this paper, we propose an\ntheoretical model to characterize the visualizations in immersive urban\nanalytics. Further more, based on our comprehensive and concise model, we\ncontribute a typology of combination methods of 2D and 3D visualizations that\ndistinguish between linked views, embedded views, and mixed views. We also\npropose a supporting guideline to assist users in selecting a proper view under\ncertain circumstances by considering visual geometry and spatial distribution\nof the 2D and 3D visualizations. Finally, based on existing works, possible\nfuture research opportunities are explored and discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present the first simultaneous analysis of the galaxy overdensity and\npeculiar velocity fields by modelling their cross-covariance. We apply our new\nmaximum-likelihood approach to data from the 6-degree Field Galaxy Survey\n(6dFGS), which has the largest single collection of peculiar velocities to\ndate. We present a full derivation of the analytic expression for the\ncross-covariance between the galaxy overdensity and peculiar velocity fields\nand find direct evidence for a non-zero correlation between the fields on\nscales up to $\\sim50 h^{-1}$ Mpc. When utilising the cross-covariance, our\nmeasurement of the normalised growth rate of structure is $f\\sigma_8(z=0) =\n0.424^{+0.067}_{-0.064}$ (15% precision), and our measurement of the\nredshift-space distortion parameter is $\\beta=0.341^{+0.062}_{-0.058}$ (18%\nprecision). Both measurements improve by $\\sim$20% compared to only using the\nauto-covariance information. This is consistent with the literature on\nmultiple-tracer approaches, as well as Fisher matrix forecasts and previous\nanalyses of 6dFGS. Our measurement of $f\\sigma_8$ is consistent with the\nstandard cosmological model, and we discuss how our approach can be extended to\ntest alternative models of gravity.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Lusternik-Schnirelmann category and topological complexity are important\ninvariants of manifolds (and more generally, topological spaces). We study the\nbehavior of these invariants under the operation of taking the connected sum of\nmanifolds. We give a complete answer for the LS-categoryof orientable\nmanifolds, $\\cat(M\\# N)=\\max\\{\\cat M,\\cat N\\}$. For topological complexity we\nprove the inequality $\\TC (M\\# N)\\ge\\max\\{\\TC M,\\TC N\\}$ for simply connected\nmanifolds.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a magnetic analogue of the seven-dimensional nonassociative\noctonionic R-flux algebra that describes the phase space of M2-branes in\nfour-dimensional locally non-geometric M-theory backgrounds. We show that these\ntwo algebras are related by a Spin(7) automorphism of the 3-algebra that\nprovides a covariant description of the eight-dimensional M-theory phase space.\nWe argue that this algebra also underlies the phase space of electrons probing\na smeared magnetic monopole in quantum gravity by showing that upon appropriate\ncontractions, the algebra reduces to the noncommutative algebra of a spin foam\nmodel of three-dimensional quantum gravity, or to the nonassociative algebra of\nelectrons in a background of uniform magnetic charge. We realise this set-up in\nM-theory as M-waves probing a delocalised Kaluza-Klein monopole, and show that\nthis system also has a seven-dimensional phase space. We suggest that the\nsmeared Kaluza-Klein monopole is non-geometric because it cannot be described\nby a local metric. This is the magnetic analogue of the local non-geometry of\nthe R-flux background and arises because the smeared Kaluza-Klein monopole is\ndescribed by a U(1)-gerbe rather than a U(1)-fibration.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We derive two versions of an effective model to describe dynamical effects of\nthe Yukawa interaction among Dirac electrons in the plane. Such short-range\ninteraction is obtained by introducing a mass term for the intermediate\nparticle, which may be either scalar or an abelian gauge field, both of them in\n(3+1) dimensions. Thereafter, we consider that the matter field propagates only\nin (2+1) dimensions, whereas the bosonic field is free to propagate out of the\nplane. Within these assumptions, we apply a mechanism for dimensional\nreduction, which yields an effective model in (2+1) dimensions. In particular,\nfor the gauge-field case, we use the Stueckelberg mechanism in order to\npreserve gauge invariance. We refer to this version as nonlocal-Proca quantum\nelectrodynamics (NPQED). For both scalar and gauge cases, the effective models\nreproduce the usual $e^{-m r}/r$ Yukawa interaction in the static limit. By\nmeans of perturbation theory at one loop, we calculate the mass renormalization\nof the Dirac field. Our model is a generalization of Pseudoquantum\nelectrodynamics (PQED), which is a gauge-field model that provides a Coulomb\ninteraction for two-dimensional electrons. Possibilities of application to\nFermi-Bose mixtures in mixed dimensions, using cold atoms, are briefly\ndiscussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Compared with numerous X-ray dominant active galactic nuclei (AGNs) without\nemission-line signatures in their optical spectra, the X-ray selected AGNs with\noptical emission lines are probably still in the high-accretion phase of black\nhole growth. This paper presents an investigation on the fraction of these\nX-ray detected AGNs with optical emission-line spectra in 198 galaxy groups at\n$z<1$ in a rest frame 0.1-2.4 keV luminosity range 41.3 <log(L_X/erg s-1) <\n44.1 within the COSMOS field, as well as its variations with redshift and group\nrichness. For various selection criteria of member galaxies, the numbers of\ngalaxies and the AGNs with optical emission lines in each galaxy group are\nobtained. It is found that, in total 198 X-ray groups, there are 27 AGNs\ndetected in 26 groups. AGN fraction is on everage less than $4.6 (\\pm 1.2)\\%$\nfor individual groups hosting at least one AGN. The corrected overall AGN\nfraction for whole group sample is less than $0.98 (\\pm 0.11) \\%$. The\nnormalized locations of group AGNs show that 15 AGNs are found to be located in\ngroup centers, including all 6 low-luminosity group AGNs. A week rising\ntendency with $z$ are found: overall AGN fraction is 0.30-0.43% for the groups\nat $z<0.5$, and 0.55-0.64% at 0.5 < z < 1.0. For the X-ray groups at $z>0.5$,\nmost member AGNs are X-ray bright, optically dull, which results in a lower AGN\nfractions at higher redshifts. The AGN fraction in isolated fields also\nexhibits a rising trend with redshift, and the slope is consistent with that in\ngroups. The environment of galaxy groups seems to make no difference in\ndetection probability of the AGNs with emission lines. Additionally, a larger\nAGN fractions are found in poorer groups, which implies that the AGNs in poorer\ngroups might still be in the high-accretion phase, whereas the AGN population\nin rich clusters is mostly in the low-accretion, X-ray dominant phase.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  With the rapid advances in the development of nanotechnology, nowadays, the\nsizes of elementary unit, i.e. transistor, of micro- and nanoelectronic devices\nare well deep into nanoscale. For the pursuit of cheaper and faster nanoscale\nelectronic devices, the size of transistors keeps scaling down. As the\nminiaturization of the nanoelectronic devices, the electrical resistivity\nincreases dramatically, resulting rapid growth in the heat generation. The heat\ngeneration and limited thermal dissipation in nanoscale materials have become a\ncritical problem in the development of the next generation nanoelectronic\ndevices. Copper (Cu) is widely used conducting material in nanoelectronic\ndevices, and the electron-phonon scattering is the dominant contributor to the\nresistivity in Cu nanowires at room temperature. Meanwhile, phonons are the\nmain carriers of heat in insulators, intrinsic and lightly doped\nsemiconductors. The thermal transport is an ensemble of phonon transport, which\nstrongly depends on the phonon frequency. In addition, the phonon transport in\nnanoscale materials can behave fundamentally different than in bulk materials,\nbecause of the spatial confinement. However, the size effect on electron-phonon\nscattering and frequency dependent phonon transport in nanoscale materials\nremain largely unexplored, due to the lack of suitable experimental techniques.\nThis thesis is mainly focusing on the study of carrier dynamics and acoustic\nphonon transport in nanoscale materials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A superconducting loop stores persistent current without any ohmic loss,\nmaking it an ideal platform for energy efficient memories. Conventional\nsuperconducting memories use an architecture based on Josephson junctions (JJs)\nand have demonstrated access times less than 10 ps and power dissipation as low\nas $10^{-19}$ J. However, their scalability has been slow to develop due to the\nchallenges in reducing the dimensions of JJs and minimizing the area of the\nsuperconducting loops. In addition to the memory itself, complex readout\ncircuits require additional JJs and inductors for coupling signals, increasing\nthe overall area. Here, we have demonstrated a superconducting memory based\nsolely on lithographic nanowires. The small dimensions of the nanowire ensure\nthat the device can be fabricated in a dense area in multiple layers, while the\nhigh kinetic inductance makes the loop essentially independent of geometric\ninductance, allowing it to be scaled down without sacrificing performance. The\nmemory is operated by a group of nanowire cryotrons patterned alongside the\nstorage loop, enabling us to reduce the entire memory cell to 3 {\\mu}m $\\times\n$ 7 {\\mu}m in our proof-of-concept device. In this work we present the\noperation principles of a superconducting nanowire memory (nMem) and\ncharacterize its bit error rate, speed, and power dissipation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the genomic era, the identification of gene signatures associated with\ndisease is of significant interest. Such signatures are often used to predict\nclinical outcomes in new patients and aid clinical decision-making. However,\nrecent studies have shown that gene signatures are often not replicable. This\noccurrence has practical implications regarding the generalizability and\nclinical applicability of such signatures. To improve replicability, we\nintroduce a novel approach to select gene signatures from multiple datasets\nwhose effects are consistently non-zero and account for between-study\nheterogeneity. We build our model upon some rank-based quantities, facilitating\nintegration over different genomic datasets. A high dimensional penalized\nGeneralized Linear Mixed Model (pGLMM) is used to select gene signatures and\naddress data heterogeneity. We compare our method to some commonly used\nstrategies that select gene signatures ignoring between-study heterogeneity. We\nprovide asymptotic results justifying the performance of our method and\ndemonstrate its advantage in the presence of heterogeneity through thorough\nsimulation studies. Lastly, we motivate our method through a case study\nsubtyping pancreatic cancer patients from four gene expression studies.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Multilevel converters have found many applications within renewable energy\nsystems thanks to their unique capability of generating multiple voltage\nlevels. However, these converters need multiple DC sources and the voltage\nbalancing over capacitors for these systems is cumbersome. In this work, a new\ngrid-tie multicell inverter with high level of safety has been designed,\nengineered and optimized for integrating energy storage devices to the electric\ngrid. The multilevel converter proposed in this work is capable of maintaining\nthe flying capacitors voltage in the desired value. The solar cells are the\nprimary energy sources for proposed inverter where the maximum power density is\nobtained. Finally, the performance of the inverter and its control method\nsimulated using PSCAD/EMTDC software package and good agreement achieved with\nexperimental data.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a priori and a posteriori error analysis of a Virtual Element\nMethod (VEM) to approximate the vibration frequencies and modes of an elastic\nsolid. We analyze a variational formulation relying only on the solid\ndisplacement and propose an $H^1({\\Omega})$-conforming discretization by means\nof VEM. Under standard assumptions on the computational domain, we show that\nthe resulting scheme provides a correct approximation of the spectrum and prove\nan optimal order error estimate for the eigenfunctions and a double order for\nthe eigenvalues. Since, the VEM has the advantage of using general polygonal\nmeshes, which allows implementing efficiently mesh refinement strategies, we\nalso introduce a residual-type a posteriori error estimator and prove its\nreliability and efficiency. We use the corresponding error estimator to drive\nan adaptive scheme. Finally, we report the results of a couple of numerical\ntests that allow us to assess the performance of this approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  From its surface properties it can be difficult to determine whether a\nred-giant star is in its helium-core-burning phase or only burning hydrogen in\na shell around an inert helium core. Stars in either of these stages can have\nsimilar effective temperatures, radii and hence luminosities, i.e. they can be\nlocated at the same position in the Hertzsprung-Russell diagram.\nAsteroseismology -- the study of the internal structure of stars through their\nglobal oscillations -- can provide the necessary additional constraints to\ndetermine the evolutionary states of red-giant stars. Here, we present a method\nthat uses grid-based modelling based on global asteroseismic properties\n($\\nu_{\\rm max}$, frequency of maximum oscillation power; and $\\Delta\\nu$,\nfrequency spacing between modes of the same degree and consecutive radial\norders) as well as effective temperature and metallicity to determine the\nevolutionary phases. This method is applicable even to timeseries data of\nlimited length, although with a small fraction of miss-classifications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A Skeleton-stabilized IsoGeometric Analysis (SIGA) technique is proposed for\nincompressible viscous flow problems with moderate Reynolds number. The\nproposed method allows utilizing identical finite dimensional spaces (with\narbitrary B-splines/NURBS order and regularity) for the approximation of the\npressure and velocity components. The key idea is to stabilize the jumps of\nhigh-order derivatives of variables over the skeleton of the mesh. For\nB-splines/NURBS basis functions of degree $k$ with $C^{\\alpha}$-regularity ($0\n\\leq \\alpha < k$), only the derivative of order $\\alpha +1$ has to be\ncontrolled. This stabilization technique thus can be viewed as a\nhigh-regularity generalization of the (Continuous) Interior-Penalty Finite\nElement Method. Numerical experiments are performed for the Stokes and\nNavier-Stokes equations in two and three dimensions. Oscillation-free solutions\nand optimal convergence rates are obtained. In terms of the sparsity pattern of\nthe algebraic system, we demonstrate that the block matrix associated with the\nstabilization term has a considerably smaller bandwidth when using B-splines\nthan when using Lagrange basis functions, even in the case of $C^0$-continuity.\nThis important property makes the proposed isogeometric framework practical\nfrom a computational effort point of view.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The present paper, along with its sequel, establishes the correspondence\nbetween the properties of the solutions of a class of PDEs and the geometry of\nsets in Euclidean space. We settle the question of whether (quantitative)\nabsolute continuity of the elliptic measure with respect to the surface measure\nand uniform rectifiability of the boundary are equivalent, in an optimal class\nof divergence form elliptic operators satisfying a suitable Carleson measure\ncondition. The result can be viewed as a quantitative analogue of the Wiener\ncriterion adapted to the singular $L^p$ data case.\n  This paper addresses the free boundary problem under the assumption of\nsmallness of the Carleson measure of the coefficients. Part II of this work\ndevelops an extrapolation argument to bootstrap this result to the general\ncase. The ideas in Part I constitute a novel application of techniques\ndeveloped in geometric measure theory. They highlight the synergy between\nseveral areas. The ideas developed in this paper are well suited to study\nsingularities arising in variational problems in a geometric setting.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $X$ be an observable random variable with unknown distribution function\n$F(x) = \\mathbb{P}(X \\leq x), - \\infty < x < \\infty$, and let \\[\\ \\theta =\n\\sup\\left \\{ r \\geq 0:~ \\mathbb{E}|X|^{r} < \\infty \\right \\}. \\] We call\n$\\theta$ the power of moments of the random variable $X$. Let $X_{1}, X_{2},\n..., X_{n}$ be a random sample of size $n$ drawn from $F(\\cdot)$. In this paper\nwe propose the following simple point estimator of $\\theta$ and investigate its\nasymptotic properties: \\[ \\hat{\\theta}_{n} = \\frac{\\log n}{\\log \\max_{1 \\leq k\n\\leq n} |X_{k}|}, \\] where $\\log x = \\ln(e \\vee x), ~- \\infty < x < \\infty$. In\nparticular, we show that \\[ \\hat{\\theta}_{n} \\rightarrow_{\\mathbb{P}}\n\\theta~~\\mbox{if and only if}~~ \\lim_{x \\rightarrow \\infty} x^{r}\n\\mathbb{P}(|X| > x) = \\infty ~~\\forall~r > \\theta. \\] This means that, under\nvery reasonable conditions on $F(\\cdot)$, $\\hat{\\theta}_{n}$ is actually a\nconsistent estimator of $\\theta$. Hypothesis testing for the power of moments\nis conducted and, as an application of our main results, the formula for\nfinding the p-value of the test is given. In addition, a theoretical\napplication of our main results is provided together with three illustrative\nexamples.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A forensics investigation after a breach often uncovers network and host\nindicators of compromise (IOCs) that can be deployed to sensors to allow early\ndetection of the adversary in the future. Over time, the adversary will change\ntactics, techniques, and procedures (TTPs), which will also change the data\ngenerated. If the IOCs are not kept up-to-date with the adversary's new TTPs,\nthe adversary will no longer be detected once all of the IOCs become invalid.\nTracking the Known (TTK) is the problem of keeping IOCs, in this case regular\nexpressions (regexes), up-to-date with a dynamic adversary. Our framework\nsolves the TTK problem in an automated, cyclic fashion to bracket a previously\ndiscovered adversary. This tracking is accomplished through a data-driven\napproach of self-adapting a given model based on its own detection\ncapabilities.\n  In our initial experiments, we found that the true positive rate (TPR) of the\nadaptive solution degrades much less significantly over time than the naive\nsolution, suggesting that self-updating the model allows the continued\ndetection of positives (i.e., adversaries). The cost for this performance is in\nthe false positive rate (FPR), which increases over time for the adaptive\nsolution, but remains constant for the naive solution. However, the difference\nin overall detection performance, as measured by the area under the curve\n(AUC), between the two methods is negligible. This result suggests that\nself-updating the model over time should be done in practice to continue to\ndetect known, evolving adversaries.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The symplectic isotopy conjecture states that every smooth symplectic surface\nin $CP^2$ is symplectically isotopic to a complex algebraic curve. Progress\nbegan with Gromov's pseudoholomorphic curves [Gro85], and progressed further\nculminating in Siebert and Tian's proof of the conjecture up to degree 17\n[ST05], but further progress has stalled. In this article we provide a new\ndirection of attack on this problem. Using a solution to a nodal symplectic\nisotopy problem we guide model symplectic isotopies of smooth surfaces. This\nresults in an equivalence between the smooth symplectic isotopy problem and an\nexistence problem of certain embedded Lagrangian disks. This redirects study of\nthis problem from the realm of pseudoholomorphic curves of high genus to the\nrealm of Lagrangians and Floer theory. Because the main theorem is an\nequivalence going both directions, it could theoretically be used to either\nprove or disprove the symplectic isotopy conjecture.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Large volumes of spatio-temporal data are increasingly collected and studied\nin diverse domains including, climate science, social sciences, neuroscience,\nepidemiology, transportation, mobile health, and Earth sciences.\nSpatio-temporal data differs from relational data for which computational\napproaches are developed in the data mining community for multiple decades, in\nthat both spatial and temporal attributes are available in addition to the\nactual measurements/attributes. The presence of these attributes introduces\nadditional challenges that needs to be dealt with. Approaches for mining\nspatio-temporal data have been studied for over a decade in the data mining\ncommunity. In this article we present a broad survey of this relatively young\nfield of spatio-temporal data mining. We discuss different types of\nspatio-temporal data and the relevant data mining questions that arise in the\ncontext of analyzing each of these datasets. Based on the nature of the data\nmining problem studied, we classify literature on spatio-temporal data mining\ninto six major categories: clustering, predictive learning, change detection,\nfrequent pattern mining, anomaly detection, and relationship mining. We discuss\nthe various forms of spatio-temporal data mining problems in each of these\ncategories.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the following we construct spaces of dimension $(n\\pm \\varepsilon)$ lying\nin the neighborhood of $\\mathbb{Z}^n, \\mathbb{Z}^n$ in the context of the\n$(n-\\varepsilon)$-expansion. We provide means and criteria to deform the spaces\nof integer dimension into this neighborhood. We argue that the field theoretic\nmodels living on these deformed spaces are the continuation of the models\ndefined on the corresponding integer valued spaces. Furthermore we perform the\ncontinuum limit of subgraphs of $\\mathbb{Z}^n$ having non-integer dimension to\nthe corresponding (fractal) subspaces of $\\mathbb{Z}^n$. We make sense of a\nfractal volume measure like $d^{(n-\\varepsilon)}x$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The largest global symmetry that can be made local in the Standard Model +\n3$\\nu_R$ while being compatible with Pati-Salam unification is $SU(3)_H\\times\nU(1)_{B-L}$. The gauge bosons of this theory would induce flavour effects\ninvolving both quarks and leptons, and are a potential candidate to explain the\nrecent reports of lepton universality violation in rare B meson decays. In this\nletter we characterise this type of models and show how they can accommodate\nthe data and naturally be within reach of direct searches.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present Loopix, a low-latency anonymous communication system that provides\nbi-directional 'third-party' sender and receiver anonymity and unobservability.\nLoopix leverages cover traffic and brief message delays to provide anonymity\nand achieve traffic analysis resistance, including against a global network\nadversary. Mixes and clients self-monitor the network via loops of traffic to\nprovide protection against active attacks, and inject cover traffic to provide\nstronger anonymity and a measure of sender and receiver unobservability.\nService providers mediate access in and out of a stratified network of Poisson\nmix nodes to facilitate accounting and off-line message reception, as well as\nto keep the number of links in the system low, and to concentrate cover\ntraffic. We provide a theoretical analysis of the Poisson mixing strategy as\nwell as an empirical evaluation of the anonymity provided by the protocol and a\nfunctional implementation that we analyze in terms of scalability by running it\non AWS EC2. We show that a Loopix relay can handle upwards of 300 messages per\nsecond, at a small delay overhead of less than 1.5 ms on top of the delays\nintroduced into messages to provide security. Overall message latency is in the\norder of seconds - which is low for a mix-system. Furthermore, many mix nodes\ncan be securely added to a stratified topology to scale throughput without\nsacrificing anonymity.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this document, we provide supplementary material to a paper that will be\npublished in ERTS2. It includes a more detailed description of the described\nrequirement transformations, outlined in the paper. For this purpose, we also\nprovide a formal description of the temporal semantics model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Various solar features can be seen on maps of the Sun in the mm and sub-mm\nwavelength range. The recently installed Atacama Large Millimeter/submillimeter\nArray (ALMA) is capable of observing the Sun in that wavelength range with an\nunprecedented spatial, temporal and spectral resolution. To interpret solar\nobservations with ALMA the first important step is to compare ALMA maps with\nsimultaneous images of the Sun recorded in other spectral ranges. First we\nidentify different structures in the solar atmosphere seen in the optical, IR\nand EUV parts of the spectrum (quiet Sun (QS), active regions (AR), prominences\non the disc, magnetic inversion lines (IL), coronal holes (CH) and coronal\nbright points (CBPs)) in a full disc solar ALMA image. The second aim is to\nmeasure the intensities (brightness temperatures) of those structures and\ncompare them with the corresponding QS level. A full disc solar image at 1.21\nmm obtained on December 18, 2015 during a CSV-EOC campaign with ALMA is\ncalibrated and compared with full disc solar images from the same day in\nH\\alpha, in He I 1083 nm core, and with SDO images (AIA at 170 nm, 30.4 nm,\n21.1 nm, 19.3 nm, and 17.1 nm and HMI magnetogram). The brightness temperatures\nof various structures are determined by averaging over corresponding regions of\ninterest in the ALMA image. Positions of the QS, ARs, prominences on the disc,\nILs, CHs and CBPs are identified in the ALMA image. At 1.21 mm ARs appear as\nbright areas (but sunspots are dark), while prominences on the disc and CHs are\nnot discernible from the QS background, although having slightly less intensity\nthan surrounding QS regions. ILs appear as large, elongated dark structures and\nCBPs correspond to ALMA bright points. These results are in general agreement\nwith sparse earlier measurements at similar wavelengths. The identification of\nCBPs represents the most important new result.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The phenomenon of spin transfer torque (STT) has attracted a great deal of\ninterests due to its promising prospects in practical spintronic devices. In\nthis paper, we report a theoretical investigation of STT in a noncollinear\nmagnetic tunnel junction under ac modulation based on the nonequilibrium\nGreen's function formalism, and derive a closed-formulation for predicting the\ntime-averaged STT. Using this formulation, the ac STT of a\ncarbon-nanotube-based magnetic tunnel junction is analyzed. Under ac\nmodulation, the low-bias linear (quadratic) dependence of the in-plane\n(out-of-plane) torque on bias still holds, and the $\\sin\\theta$ dependence on\nthe noncollinear angle is maintained. By photon-assisted tunneling, the\nbias-induced components of the in-plane and out-of-plane torques can be\nenhanced significantly, about 12 and 75 times, respectively. Our analysis\nreveals the condition for achieving optimized STT enhancement and suggests that\nac modulation is a very effective way for electrical manipulation of STT.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Multiple adverse health conditions co-occurring in a patient are typically\nassociated with poor prognosis and increased office or hospital visits.\nDeveloping methods to identify patterns of co-occurring conditions can assist\nin diagnosis. Thus identifying patterns of associations among co-occurring\nconditions is of growing interest. In this paper, we report preliminary results\nfrom a data-driven study, in which we apply a machine learning method, namely,\ntopic modeling, to electronic medical records, aiming to identify patterns of\nassociated conditions. Specifically, we use the well established latent\ndirichlet allocation, a method based on the idea that documents can be modeled\nas a mixture of latent topics, where each topic is a distribution over words.\nIn our study, we adapt the LDA model to identify latent topics in patients'\nEMRs. We evaluate the performance of our method both qualitatively, and show\nthat the obtained topics indeed align well with distinct medical phenomena\ncharacterized by co-occurring conditions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this document, the technical details of the JSNS$^2$ (J-PARC Sterile\nNeutrino Search at J-PARC Spallation Neutron Source) experiment are described.\n  The search for sterile neutrinos is currently one of the hottest topics in\nneutrino physics. The JSNS$^2$ experiment aims to search for the existence of\nneutrino oscillations with $\\Delta m^2$ near 1 eV$^2$ at the J-PARC Materials\nand Life Science Experimental Facility (MLF). A 1 MW beam of 3 GeV protons\nincident on a spallation neutron target produces an intense neutrino beam from\nmuon decay at rest. Neutrinos come predominantly from $\\mu^+$ decay: $\\mu^{+}\n\\to e^{+} + \\bar{\\nu}_{\\mu} + \\nu_{e}$. The experiment will search for\n$\\bar{\\nu}_{\\mu}$ to $\\bar{\\nu}_{e}$ oscillations which are detected by the\ninverse beta decay interaction $\\bar{\\nu}_{e} + p \\to e^{+} + n$, followed by\ngammas from neutron capture on Gd. The detector has a fiducial volume of 17\ntons and is located 24 meters away from the mercury target. JSNS$^2$ offers the\nultimate direct test of the LSND anomaly.\n  In addition to the sterile neutrino search, the physics program includes\ncross section measurements with neutrinos with a few 10's of MeV from muon\ndecay at rest and with monochromatic 236 MeV neutrinos from kaon decay at rest.\nThese cross sections are relevant for our understanding of supernova explosions\nand nuclear physics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the duality between local (complex analytic) projective\nstructures on surfaces and two dimensional (complex analytic) neighborhoods of\nrational curves having self-intersection +1. We study the analytic\nclassification, existence of normal forms, pencil/fibration decomposition,\ninfinitesimal symmetries. We deduce some transcendental result about Painlev'e\nequations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study quintessential inflation using a generalized exponential potential\n$V(\\phi)\\propto exp(-\\lambda \\phi^n/Mpl^n), n>1$, the model admits slow-roll\ninflation at early times and leads to close-to-scaling behaviour in the post\ninflationary era with an exit to dark energy at late times. We present detailed\ninvestigations of the inflationary stage in the light of the Planck 2015\nresults, study post-inflationary dynamics and analytically confirm the\nexistence of an approximately scaling solution. Additionally, assuming that\nstandard massive neutrinos are non-minimally coupled, makes the field $\\phi$\ndominant once again at late times giving rise to present accelerated expansion\nof the Universe. We derive observational constraints on the field and\ntime-dependent neutrino masses. In particular, for $n=6 (8)$, the parameter\n$\\lambda$ is constrained to be,$\\log \\lambda > -7.29 (-11.7)$; the model\nproduces the spectral index of the power spectrum of primordial scalar (matter\ndensity) perturbations as $ n_s = 0.959 \\pm 0.001 (0.961 \\pm 0.001)$ and tiny\ntensor-to-scalar ratio, $r<1.72 \\times 10^{-2} (2.32 \\times 10^{-2})$\nrespectively. Consequently, the upper bound on possible values of the sum of\nneutrino masses $\\Sigma m_{\\nu} \\lesssim 2.5$ eV significantly enhances\ncompared to that in the standard $\\Lambda$CDM model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We generalize the result of Wirsing on Gauss transformation to the\ngeneralized tranformation $T_p(x)=\\{\\cfrac{p}{x}\\}$ for any positive integer\n$p$. We give an estimate for the generalized Gauss-Kuzmin-Wirsing constant.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Transient negative capacitance effects in epitaxial ferroelectric\nPb(Zr$_{0.2}$Ti$_{0.8}$)O$_3$ capacitors are investigated with a focus on the\ndynamical switching behavior governed by domain nucleation and growth. Voltage\npulses are applied to a series connection of the ferroelectric capacitor and a\nresistor to directly measure the ferroelectric negative capacitance during\nswitching. A time-dependent Ginzburg-Landau approach is used to investigate the\nunderlying domain dynamics. The transient negative capacitance is shown to\noriginate from reverse domain nucleation and unrestricted domain growth.\nHowever, with the onset of domain coalescence, the capacitance becomes positive\nagain. The persistence of the negative capacitance state is therefore limited\nby the speed of domain wall motion. By changing the applied electric field,\ncapacitor area or external resistance, this domain wall velocity can be varied\npredictably over several orders of magnitude. Additionally, detailed insights\ninto the intrinsic material properties of the ferroelectric are obtainable\nthrough these measurements. A new method for reliable extraction of the average\nnegative capacitance of the ferroelectric is presented. Furthermore, a simple\nanalytical model is developed, which accurately describes the negative\ncapacitance transient time as a function of the material properties and the\nexperimental boundary conditions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Perception-driven approach and end-to-end system are two major vision-based\nframeworks for self-driving cars. However, it is difficult to introduce\nattention and historical information of autonomous driving process, which are\nthe essential factors for achieving human-like driving into these two methods.\nIn this paper, we propose a novel model for self-driving cars named\nbrain-inspired cognitive model with attention (CMA). This model consists of\nthree parts: a convolutional neural network for simulating human visual cortex,\na cognitive map built to describe relationships between objects in complex\ntraffic scene and a recurrent neural network that combines with the real-time\nupdated cognitive map to implement attention mechanism and long-short term\nmemory. The benefit of our model is that can accurately solve three tasks\nsimultaneously:1) detection of the free space and boundaries of the current and\nadjacent lanes. 2)estimation of obstacle distance and vehicle attitude, and 3)\nlearning of driving behavior and decision making from human driver. More\nsignificantly, the proposed model could accept external navigating instructions\nduring an end-to-end driving process. For evaluation, we build a large-scale\nroad-vehicle dataset which contains more than forty thousand labeled road\nimages captured by three cameras on our self-driving car. Moreover, human\ndriving activities and vehicle states are recorded in the meanwhile.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Following the works of Lyons and Oberlin, Seeger, Tao, Thiele and Wright, we\nrelate the variation of certain discrete curves on the Lie group\n$\\text{SU}(1,1)$ to the corresponding variation of their linearized versions on\nthe Lie algebra. Combining this with a discrete variational\nMenshov-Paley-Zygmund theorem, we establish a variational Hausdorff-Young\ninequality for a discrete version of the nonlinear Fourier transform on\n$\\text{SU}(1,1)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT\nare computationally expensive. To address this problem, we recently proposed a\ndeep convolutional neural network (CNN) for low-dose X-ray CT and won the\nsecond place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the\ntexture were not fully recovered. To address this problem, here we propose a\nnovel framelet-based denoising algorithm using wavelet residual network which\nsynergistically combines the expressive power of deep learning and the\nperformance guarantee from the framelet-based denoising algorithms. The new\nalgorithms were inspired by the recent interpretation of the deep convolutional\nneural network (CNN) as a cascaded convolution framelet signal representation.\nExtensive experimental results confirm that the proposed networks have\nsignificantly improved performance and preserves the detail texture of the\noriginal images.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Predicting long-term outcomes of interventions is necessary for educational\nand social policy-making processes that might widely influence our society for\nthe long-term. However, performing such predictions based on data from\nlarge-scale experiments might be challenging due to the lack of time and\nresources. In order to address this issue, computer simulations based on\nEvolutionary Causal Matrices and Markov Chain can be used to predict long-term\noutcomes with relatively small-scale lab data. In this paper, we introduce\nPython classes implementing a computer simulation model and presented some\npilots implementations demonstrating how the model can be utilized for\npredicting outcomes of diverse interventions. We also introduce the\nclass-structured simulation module both with real experimental data and with\nhypothetical data formulated based on social psychological theories. Classes\ndeveloped and tested in the present study provide researchers and practitioners\nwith a feasible and practical method to simulate intervention outcomes\nprospectively.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the statistics of the kinetic (or equivalently potential) energy for\n$N$ non-interacting fermions in a $1d$ harmonic trap of frequency $\\omega$, at\nfinite temperature $T$. Remarkably, we find an exact solution for the full\ndistribution of the kinetic energy, at any temperature $T$ and for any $N$,\nusing a non-trivial mapping to an integrable Calogero-Moser-Sutherland model.\nAs a function of temperature $T$, and for large $N$, we identify: (i) a quantum\nregime, for $T \\sim \\hbar \\omega$, where quantum fluctuations dominate and (ii)\na thermal regime, for $T \\sim N \\hbar \\omega$, governed by thermal\nfluctuations. We show how the mean, the variance as well as the large deviation\nfunction associated with the distribution of the kinetic energy cross over from\nthe quantum to the thermal regime as temperature increases.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report the strong coupling of a single electron spin and a single\nmicrowave photon. The electron spin is trapped in a silicon double quantum dot\nand the microwave photon is stored in an on-chip high-impedance superconducting\nresonator. The electric field component of the cavity photon couples directly\nto the charge dipole of the electron in the double dot, and indirectly to the\nelectron spin, through a strong local magnetic field gradient from a nearby\nmicromagnet. This result opens the way to the realization of large networks of\nquantum dot based spin qubit registers, removing a major roadblock to scalable\nquantum computing with spin qubits.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A brief overview of the development of neutrino detectors for long-baseline\noscillation experiments at accelerators and reactors is presented. Basic\nprinciples and main features of detectors of running accelerator experiments\nT2K and NOvA sensitive to a first level of CP violation and neutrino mass\nhierarchy, and reactor experiments Daya Bay, RENO and Double Chooz which\nmeasured the mixing angle \\theta_13 are discussed. A variety of different\nexperimental techniques is proposed and developed for the next generation\noscillation experiments: a 20 kt scintillator detector for the reactor\nexperiment JUNO, a 0.52 kt water-Cherenkov detector Hyper-Kamiokande, and a\nmassive liquid argon time-projection chamber neutrino detector envisaged for\nthe DUNE experiment. Present status of these detectors, recent progress in R&D\nand future prospects are summarized in this paper.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Based on the multi-level model, we have calculated light shifts for Zeeman\nstates of hyperfine levels of cesium (Cs) 6S1/2 ground state and 6P3/2 excited\nstate.The magic-wavelength linearly-polarized optical dipole trap (ODT) for Cs\n6S1/2 F=4, mF=+4 - 6P3/2 F'=5, mF=+5 transition is experimentally constructed\nand characterized by using the laser-induced fluorescence spectra of trapped\nsingle Cs atoms. The magic wavelength is 937.7 nm which produces almost the\nsame light shift for 6S1/2 F=4, mF=+4 ground state and 6P3/2 F'=5, mF=+5\nexcited state with linearly-polarized ODT laser beam. Compared to undisturbed\nCs 6S1/2 F=4, mF=+4 - 6P3/2 F'=5, mF=+5 transition frequency in free space, the\ndifferential light shift is less than 0.7 MHz in a linearly-polarized 937.7 nm\nODT, which is less than 1.2% of the trap depth. We also discussed influence of\nthe trap depth and the bias magnetic field on the measurement results.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We often seek to estimate the impact of an exposure naturally occurring or\nrandomly assigned at the cluster-level. For example, the literature on\nneighborhood determinants of health continues to grow. Likewise, community\nrandomized trials are applied to learn about real-world implementation,\nsustainability, and population effects of interventions with proven\nindividual-level efficacy. In these settings, individual-level outcomes are\ncorrelated due to shared cluster-level factors, including the exposure, as well\nas social or biological interactions between individuals. To flexibly and\nefficiently estimate the effect of a cluster-level exposure, we present two\ntargeted maximum likelihood estimators (TMLEs). The first TMLE is developed\nunder a non-parametric causal model, which allows for arbitrary interactions\nbetween individuals within a cluster. These interactions include direct\ntransmission of the outcome (i.e. contagion) and influence of one individual's\ncovariates on another's outcome (i.e. covariate interference). The second TMLE\nis developed under a causal sub-model assuming the cluster-level and\nindividual-specific covariates are sufficient to control for confounding.\nSimulations compare the alternative estimators and illustrate the potential\ngains from pairing individual-level risk factors and outcomes during\nestimation, while avoiding unwarranted assumptions. Our results suggest that\nestimation under the sub-model can result in bias and misleading inference in\nan observational setting. Incorporating working assumptions during estimation\nis more robust than assuming they hold in the underlying causal model. We\nillustrate our approach with an application to HIV prevention and treatment.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Among the probes used to investigate the properties of the Quark-Gluon\nPlasma, the measurement of the energy loss of high-energy partons can be used\nto put constraints on energy-loss models and to ultimately access medium\ncharacteristics, such as the energy density or the temperature. The study of\ntwo-particle correlations allows us to obtain very different constraints\ncompared to the nuclear modification factor. In particular, the correlation of\ncharged hadrons with high energy $\\pi^{0}$ or direct photons is believed to\ngive a measurement of the parton energy loss and insights into the\nmedium-induced modification of the fragmentation process. High energy neutral\npions are reconstructed using the ALICE electromagnetic calorimeters EMCal and\nPHOS, and the charged particles are detected by the main tracking detectors ITS\nand TPC. In these proceedings, the measurement of neutral mesons at $\\sqrt{s} =\n$2.76 TeV in pp collisions are presented, as well as the measurements of\nazimuthal $\\pi^{0}$-hadron correlations in pp and Pb-Pb collisions at\n$\\sqrt{s_{\\rm{NN}}} = 2.76$~TeV, and the extracted per-trigger yield\nmodification factor ($I_{AA}$). Comparisons with theoretical model calculations\nare also added.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Neutron stars are among the most fascinating astrophysical sources, being\ncharacterized by strong gravity, densities about the nuclear one or even above,\nand huge magnetic fields. Their observational signatures can be extremely\ndiverse across the electromagnetic spectrum, ranging from the periodic and\nlow-frequency signals of radio pulsars, up to the abrupt high-energy gamma-ray\nflares of magnetars, where energies of ~10^46 erg are released in a few\nseconds. Fast-rotating and highly magnetized neutron stars are expected to\nlaunch powerful relativistic winds, whose interaction with the supernova\nremnants gives rise to the non-thermal emission of pulsar wind nebulae, which\nare known cosmic accelerators of electrons and positrons up to PeV energies. In\nthe extreme cases of proto-magnetars (magnetic fields of ~10^15 G and\nmillisecond periods), a similar mechanism is likely to provide a viable engine\nfor the still mysterious gamma-ray bursts. The key ingredient in all these\nspectacular manifestations of neutron stars is the presence of strong magnetic\nfields in their constituent plasma. Here we will present recent updates of a\ncouple of state-of-the-art numerical investigations by the high-energy\nastrophysics group in Arcetri: a comprehensive modeling of the steady-state\naxisymmetric structure of rotating magnetized neutron stars in general\nrelativity, and dynamical 3-D MHD simulations of relativistic pulsar winds and\ntheir associated nebulae.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a novel method to automatically adjust camera exposure for image\nprocessing and computer vision applications on mobile robot platforms. Because\nmost image processing algorithms rely heavily on low-level image features that\nare based mainly on local gradient information, we consider that gradient\nquantity can determine the proper exposure level, allowing a camera to capture\nthe important image features in a manner robust to illumination conditions. We\nthen extend this concept to a multi-camera system and present a new control\nalgorithm to achieve both brightness consistency between adjacent cameras and a\nproper exposure level for each camera. We implement our prototype system with\noff-the-shelf machine-vision cameras and demonstrate the effectiveness of the\nproposed algorithms on practical applications, including pedestrian detection,\nvisual odometry, surround-view imaging, panoramic imaging and stereo matching.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For a safe, natural and effective human-robot social interaction, it is\nessential to develop a system that allows a robot to demonstrate the\nperceivable responsive behaviors to complex human behaviors. We introduce the\nMultimodal Deep Attention Recurrent Q-Network using which the robot exhibits\nhuman-like social interaction skills after 14 days of interacting with people\nin an uncontrolled real world. Each and every day during the 14 days, the\nsystem gathered robot interaction experiences with people through a\nhit-and-trial method and then trained the MDARQN on these experiences using\nend-to-end reinforcement learning approach. The results of interaction based\nlearning indicate that the robot has learned to respond to complex human\nbehaviors in a perceivable and socially acceptable manner.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In a general decay chain $A\\to B_1B_2\\to C_1C_2\\ldots$, we prove that the\nangular correlation function $I(\\theta_1,\\theta_2,\\phi_+)$ in the decay of\n$B_{1,2}$ is irrelevant to the polarization of the mother particle $A$ at\nproduction. This guarantees that we can use these angular distributions to\ndetermine the spin-parity nature of $A$ without knowing its production details.\nAs an example, we investigate the decay of a potential doubly-charged boson\n$H^{\\pm\\pm}$ going to same-sign $\\tau$ lepton pair.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Wallenius distribution is a generalisation of the Hypergeometric\ndistribution where weights are assigned to balls of different colours. This\nnaturally defines a model for ranking categories which can be used for\nclassification purposes. Since, in general, the resulting likelihood is not\nanalytically available, we adopt an approximate Bayesian computational (ABC)\napproach for estimating the importance of the categories. We illustrate the\nperformance of the estimation procedure on simulated datasets. Finally, we use\nthe new model for analysing two datasets about movies ratings and Italian\nacademic statisticians' journal preferences. The latter is a novel dataset\ncollected by the authors.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The R*-operation by Chetyrkin, Tkachov, and Smirnov is a generalisation of\nthe BPHZ R-operation, which subtracts both ultraviolet and infrared divergences\nof euclidean Feynman graphs with non-exceptional external momenta. It can be\nused to compute the divergent parts of such Feynman graphs from products of\nsimpler Feynman graphs of lower loops. In this paper we extend the R*-operation\nto Feynman graphs with arbitrary numerators, including tensors. We also provide\na novel way of defining infrared counterterms which closely resembles the\ndefinition of its ultraviolet counterpart. We further express both infrared and\nultraviolet counterterms in terms of scaleless vacuum graphs with a logarithmic\ndegree of divergence. By exploiting symmetries, integrand and integral\nrelations, which the counterterms of scaleless vacuum graphs satisfy, we can\nvastly reduce their number and complexity. A FORM implementation of this method\nwas used to compute the five loop beta function in QCD for a general gauge\ngroup. To illustrate the procedure, we compute the poles in the dimensional\nregulator of all top-level propagator graphs at five loops in four dimensional\nphi^3 theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider semi-group BMO-spaces associated with arbitrary von Neumann\nalgebras and prove interpolation theorems. This extends results by Junge-Mei\nfor the tracial case. We give examples of multipliers on free Araki-Woods\nalgebras and in particular we find $L_\\infty \\rightarrow {\\rm BMO}$\nmultipliers. We also provide $L_p$-bounds for a natural generalization of the\nHilbert transform.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  It is shown that every 2-planar graph is quasiplanar, that is, if a simple\ngraph admits a drawing in the plane such that every edge is crossed at most\ntwice, then it also admits a drawing in which no three edges pairwise cross. We\nfurther show that quasiplanarity is witnessed by a simple topological drawing,\nthat is, any two edges cross at most once and adjacent edges do not cross.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The purpose of this paper is to prove the equality between the algebraic\nIwasawa $\\lambda$-invariant and the analytic Iwasawa $\\lambda$-invariant for a\nHilbert cusp form of parallel weight $2$ at an ordinary prime $p$ when the\nassociated residual Galois representation is reducible. This is a\ngeneralization of a result of R. Greenberg and V. Vatsal.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study static and spherically symmetric black hole (BH) solutions in\nsecond-order generalized Proca theories with nonminimal vector field derivative\ncouplings to the Ricci scalar, the Einstein tensor, and the double dual Riemann\ntensor. We find concrete Lagrangians which give rise to exact BH solutions by\nimposing two conditions of the two identical metric components and the constant\nnorm of the vector field. These exact solutions are described by either\nReissner-Nordstr\\\"{o}m (RN), stealth Schwarzschild, or extremal RN solutions\nwith a non-trivial longitudinal mode of the vector field. We then numerically\nconstruct BH solutions without imposing these conditions. For cubic and quartic\nLagrangians with power-law couplings which encompass vector Galileons as the\nspecific cases, we show the existence of BH solutions with the difference\nbetween two non-trivial metric components. The quintic-order power-law\ncouplings do not give rise to non-trivial BH solutions regular throughout the\nhorizon exterior. The sixth-order and intrinsic vector-mode couplings can lead\nto BH solutions with a secondary hair. For all the solutions, the vector field\nis regular at least at the future or past horizon. The deviation from General\nRelativity induced by the Proca hair can be potentially tested by future\nmeasurements of gravitational waves in the nonlinear regime of gravity.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We analyze the spectral efficiency performance and limits of orthogonal\nfrequency-division multiple access (OFDMA) cognitive radios (CRs) with an\nimperfect availability of cross-link knowledge. In particular, in contrast to\nthe conventional `average' and `worst' cases of channel estimation error in the\nliterature, we propose a stochastic approach to mitigate the total imposed\ninterference on primary users. Channel-adaptive resource allocation algorithms\nare incorporated to optimize the cognitive system functionality under transmit\nand interference power constraints. An expression for the cumulative density\nfunction (cdf) of the received signal-to-interference-plus-noise ratio (SINR)\nis developed to evaluate the average spectral efficiency. Analytical\nderivations and results are confirmed through computer simulations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A preconditioning strategy for the Powell-Hestenes-Rockafellar Augmented\nLagrangian method (ALM) is presented. The scheme exploits the structure of the\nAugmented Lagrangian Hessian. It is a modular preconditioner consisting of two\nblocks. The first one is associated with the Lagrangian of the objective while\nthe second administers the Jacobian of the constraints and possible low-rank\ncorrections to the Hessian. The proposed updating strategies take advantage of\nALM convergence results and avoid frequent refreshing. Constraint\nadministration takes into account complementarity over the Lagrange multipliers\nand admits relaxation. The preconditioner is designed for problems where\nconstraint quantity is small compared to the search space. A virtue of the\nscheme is that it is agnostic to the preconditioning technique used for the\nHessian of the Lagrangian function. The strategy described can be used for\nlinear and nonlinear preconditioning. Numerical experiments report on spectral\nproperties of preconditioned matrices from Matrix Market while some\noptimization problems where taken from the CUTEst collection. Preliminary\nresults indicate that the proposed scheme could be attractive and further\nexperimentation is encouraged.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Synthetic aperture imaging systems achieve constant azimuth resolution by\ncoherently summating the observations acquired along the aperture path. At this\naim, their locations have to be known with subwavelength accuracy. In\nunderwater Synthetic Aperture Sonar (SAS), the nature of propagation and\nnavigation in water makes the retrieval of this information challenging.\nInertial sensors have to be employed in combination with signal processing\ntechniques, which are usually referred to as micronavigation. In this paper we\npropose a novel micronavigation approach based on the minimization of an error\nfunction between two contiguous pings having some mutual information. This\nerror is obtained by comparing the vector space intersections between the pings\northogonal projectors. The effectiveness and generality of the proposed\napproach is demonstrated by means of simulations and by means of an experiment\nperformed in a controlled environment.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Grand Unified Theories (GUT) offer an elegant and unified description of\nelectromagnetic, weak and strong interactions at high energy scales. A\nphenomenological and exciting possibility to grasp GUT is to search for TeV\nscale observables arising from Abelian groups embedded in GUT constructions.\nThat said, we use dilepton data (ee and $\\mu\\mu$) that has been proven to be a\ngolden channel for a wide variety of new phenomena expected in theories beyond\nthe Standard Model to probe GUT-inspired models. Since heavy dilepton\nresonances feature high signal selection efficiencies and relatively\nwell-understood backgrounds, stringent and reliable bounds can be placed on the\nmass of the $Z^{\\prime}$ gauge boson arising in such theories. In this work, we\nobtain 95\\% C.L. limits on the $Z^{\\prime}$ mass for several GUT-models using\ncurrent and future proton-proton colliders with $\\sqrt{s}= 13~{\\rm TeV},\\,\n33~{\\rm TeV},\\,{\\rm and}\\, 100$~TeV, and put them into perspective with dark\nmatter searches in light of the next generation of direct detection\nexperiments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Position-sensitive-detectors (PSDs) based on lateral photoeffect has been\nwidely used in diverse applications, including optical engineering, aerospace\nand military fields. With increasing demand in long distance, low energy\nconsumption, and weak signal sensing systems, the poor responsivity of\nconventional PSDs has become a bottleneck limiting its applications. Herein, we\npresent a high performance graphene based PSDs with revolutionary interfacial\namplification mechanism. Signal amplification in the order of ~10^4 has been\ndemonstrated by utilizing the ultrahigh mobility of graphene and long lifetime\nof photo-induced carriers at the interface of SiO2/Si. This would improve the\ndetection limit of Si-based PSDs from uW to nW level, without sacrificing the\nspatial resolution and response speed. Such interfacial amplification mechanism\nis compatible with current Si technology and can be easily extended to other\nsensing systems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The recently derived distributions for the scattering-matrix elements in\nquantum chaotic systems are not accessible in the majority of experiments,\nwhereas the cross sections are. We analytically compute distributions for the\noff-diagonal cross sections in the Heidelberg approach, which is ap- plicable\nto a wide range of quantum chaotic systems. We thus eventually fully solve a\nproblem which already arose more than half a century ago in compound-nucleus\nscattering. We compare our results with data from microwave and\ncompound-nucleus experiments, particularly addressing the transition from\nisolated resonances towards the Ericson regime of strongly overlapping ones.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We develop a formalism suitable for studying Maxwell's equations in the\npresence of a medium that is axially symmetric, in particular with respect to\nCasimir-Polder interaction energies. As an application, we derive the\nCasimir-Polder interaction energy between an electric $\\delta$-function plate\nand an anisotropically polarizable molecule for arbitrary orientations of the\nprincipal axes of polarizabilities of the molecule. We show that in the perfect\nconductor limit for the plate the interaction is insensitive to the orientation\nof the polarizabilities of the molecule. We obtain the Casimir-Polder energy\nbetween an electric $\\delta$-function sphere and an anisotropically polarizable\nmolecule, again for arbitrary orientations of the principal axes of\npolarizabilities of the molecule. We derive results when the polarizable\nmolecule is either outside the sphere, or inside the sphere. We present the\nperfectly conducting limit for the $\\delta$-function sphere, and also the\ninteraction energy for the special case when the molecule is at the center of\nthe sphere. Our general proposition is that the Casimir-Polder energy between a\ndielectric body with axial symmetry and an unidirectionally polarizable\nmolecule placed on the axis with its polarizability parallel to the axis gets\nnon-zero contribution only from the $m=0$ azimuth mode. This feature in\nconjunction with the property that the $m=0$ mode separates into transverse\nelectric and transverse magnetic modes allows the evaluation of Casimir-Polder\nenergies for axially symmetric systems in a relatively easy manner.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study quasi-semisimple elements of disconnected reductive algebraic groups\nover an algebraically closed field. We describe their centralizers, define\nisolated and quasi-isolated quasi-semisimple elements and classify their\nconjugacy classes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We analysed Washington $CMT_1$ photometry of star clusters located along the\nminor axis of the LMC, from the LMC optical centre up to $\\sim$ 39 degrees\noutwards to the North-West. The data base was exploited in order to search for\nnew star cluster candidates, to produce cluster CMDs cleaned from field star\ncontamination and to derive age estimates for a statistically complete cluster\nsample. We confirmed that 146 star cluster candidates are genuine physical\nsystems, and concluded that an overall $\\sim$ 30 per cent of catalogued\nclusters in the surveyed regions are unlikely to be true physical systems. We\ndid not find any new cluster candidates in the outskirts of the LMC\n(deprojected distance $\\ge$ 8 degrees). The derived ages of the studied\nclusters are in the range 7.2 < log($t$ yr$^{-1}$) $\\le$ 9.4, with the sole\nexception of the globular cluster NGC\\,1786 (log($t$ yr$^{-1}$) = 10.10). We\nalso calculated the cluster frequency for each region, from which we confirmed\npreviously proposed outside-in formation scenarios. In addition, we found that\nthe outer LMC fields show a sudden episode of cluster formation (log($t$\nyr$^{-1}$) $\\sim$ 7.8-7.9) that continued until log($t$ yr$^{-1}$) $\\sim$ 7.3\nonly in the outermost LMC region. We link these features to the first\npericentre passage of the LMC to the MW, which could have triggered cluster\nformation due to ram pressure interaction between the LMC and MW halo.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove a one-dimensional symmetry result for a weighted\nDirichlet-to-Neumann problem arising in a model for water waves in dimension 3.\nMore precisely we prove that minimizers and bounded monotone solutions depend\non only one Euclidean variable. The analogue of this result for the\n2-dimensional case (and without weights) was established in an article by De La\nLlave and the third author. In this paper, a crucial ingredient in the proof is\ngiven by an energy estimate for minimizers obtained via a comparison argument.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we have proposed a generalized parametrization for the\ndeceleration parameter $q$ in order to study the evolutionary history of the\nuniverse. We have shown that the proposed model can reproduce three well known\n$q$-parametrized models for some specific values of the model parameter\n$\\alpha$. We have used the latest compilation of the Hubble parameter\nmeasurements obtained from the cosmic chronometer (CC) method (in combination\nwith the local value of the Hubble constant $H_{0}$) and the Type Ia supernova\n(SNIa) data to place constraints on the parameters of the model for different\nvalues of $\\alpha$. We have found that the resulting constraints on the\ndeceleration parameter and the dark energy equation of state support the\n$\\Lambda$CDM model within $1\\sigma$ confidence level at the present epoch.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we analysed the physical parameters of the spotless actives\nregions observed during solar minimum 23 - 24 (2007 - 2010). The study was\nbased on radio maps at 17~GHz obtained by the Nobeyama Radioheliograph (NoRH)\nand magnetograms provided by the Michelson Doppler Imager (MDI) on board the\nSolar and Heliospheric Observatory (SOHO). The results shows that the spotless\nactive regions presents the same radio characteristics of a ordinary one, they\ncan live in the solar surface for long periods (>10 days), and also can present\nsmall flares.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Superstatistics is a widely employed tool of non-equilibrium statistical\nphysics which plays an important role in analysis of hierarchical complex\ndynamical systems. Yet, its \"canonical\" formulation in terms of a single\nnuisance parameter is often too restrictive when applied to complex empirical\ndata. Here we show that a multi-scale generalization of the superstatistics\nparadigm is more versatile, allowing to address such pertinent issues as\ntransmutation of statistics or inter-scale stochastic behavior. To put some\nflesh on the bare bones, we provide a numerical evidence for a transition\nbetween two superstatistics regimes, by analyzing high-frequency (minute-tick)\ndata for share-price returns of seven selected companies. Salient issues, such\nas breakdown of superstatistics in fractional diffusion processes or connection\nwith Brownian subordination are also briefly discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  When used as a surrogate objective for maximum likelihood estimation in\nlatent variable models, the evidence lower bound (ELBO) produces\nstate-of-the-art results. Inspired by this, we consider the extension of the\nELBO to a family of lower bounds defined by a particle filter's estimator of\nthe marginal likelihood, the filtering variational objectives (FIVOs). FIVOs\ntake the same arguments as the ELBO, but can exploit a model's sequential\nstructure to form tighter bounds. We present results that relate the tightness\nof FIVO's bound to the variance of the particle filter's estimator by\nconsidering the generic case of bounds defined as log-transformed likelihood\nestimators. Experimentally, we show that training with FIVO results in\nsubstantial improvements over training the same model architecture with the\nELBO on sequential data.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Fuzzing consists of repeatedly testing an application with modified, or\nfuzzed, inputs with the goal of finding security vulnerabilities in\ninput-parsing code. In this paper, we show how to automate the generation of an\ninput grammar suitable for input fuzzing using sample inputs and\nneural-network-based statistical machine-learning techniques. We present a\ndetailed case study with a complex input format, namely PDF, and a large\ncomplex security-critical parser for this format, namely, the PDF parser\nembedded in Microsoft's new Edge browser. We discuss (and measure) the tension\nbetween conflicting learning and fuzzing goals: learning wants to capture the\nstructure of well-formed inputs, while fuzzing wants to break that structure in\norder to cover unexpected code paths and find bugs. We also present a new\nalgorithm for this learn&fuzz challenge which uses a learnt input probability\ndistribution to intelligently guide where to fuzz inputs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We explore a local form of second-order Vasiliev equations proposed in\n[arXiv:1706.03718] and obtain an explicit expression for quadratic corrections\nto bosonic Fronsdal equations, generated by gauge-invariant higher-spin\ncurrents. Our analysis is performed for general phase factor, and for the case\nof parity-invariant theory we find the agreement with expressions for cubic\nvertices available in the literature. This provides an additional indication\nthat field redefinition proposed in [arXiv:1706.03718] is the proper one.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The angular distributions of lepton pairs in the Drell-Yan process can\nprovide rich information on the underlying QCD production mechanisms. These\ndynamics can be parameterised in terms of a set of frame dependent angular\ncoefficients, $A_{i=0,\\ldots,7}$, which depend on the invariant mass,\ntransverse momentum, and rapidity of the lepton pair. Motivated by recent\nmeasurements of these coefficients by ATLAS and CMS, and in particular by the\napparent violation of the Lam-Tung relation $A_0-A_2=0$, we perform a precision\nstudy of the angular coefficients at $\\mathcal{O}(\\alpha_s^3)$ in perturbative\nQCD. We make predictions relevant for $pp$ collisions at $\\sqrt{s} = 8$ TeV,\nand perform comparisons with the available ATLAS and CMS data as well as\nproviding predictions for a prospective measurement at LHCb. To expose the\nviolation of the Lam-Tung relationship we propose a new observable\n$\\Delta^\\mathrm{LT} = 1-A_2/A_0$ that is more sensitive to the dynamics in the\nregion where $A_0$ and $A_2$ are both small. We find that the\n$\\mathcal{O}(\\alpha_s^3)$ corrections have an important impact on the $p_{T,Z}$\ndistributions for several of the angular coefficients, and are essential to\nprovide an adequate description of the data. The compatibility of the available\nATLAS and CMS data is reassessed by performing a partial $\\chi^2$ test with\nrespect to the central theoretical prediction which shows that\n$\\chi^2/N_\\mathrm{data}$ is significantly reduced by going from\n$\\mathcal{O}(\\alpha_s^2)$ to $\\mathcal{O}(\\alpha_s^3)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Mobile crowdsensing allows a large number of mobile devices to measure\nphenomena of common interests and form a body of knowledge about natural and\nsocial environments. In order to get location annotations for indoor mobile\ncrowdsensing, reference tags are usually deployed which are susceptible to\ntampering and compromises by attackers. In this work, we consider three types\nof location-related attacks including tag forgery, tag misplacement, and tag\nremoval. Different detection algorithms are proposed to deal with these\nattacks. First, we introduce location-dependent fingerprints as supplementary\ninformation for better location identification. A truth discovery algorithm is\nthen proposed to detect falsified data. Moreover, visiting patterns are\nutilized for the detection of tag misplacement and removal. Experiments on both\ncrowdsensed and emulated dataset show that the proposed algorithms can detect\nall three types of attacks with high accuracy.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  SDN promises to overcome vendor lock-in by enabling a multi-vendor hardware\nand software ecosystem in operator networks. However, we observe that this is\ncurrently not happening. A framework allowing to compose SDN applications\ncombining different frameworks can help revert the trend. In this paper, we\nanalyze the challenges in the current SDN landscape and then present the\nmulti-controller SDN framework developed by the NetIDE project. Our\narchitecture supports different SDN southbound protocols and we have\nimplemented a proof of concept using the OpenFlow protocol, which has given us\na greater insight on its shortcomings.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A simplified speech recognition system that uses the maximum mutual\ninformation (MMI) criterion is considered. End-to-end training using gradient\ndescent is suggested, similarly to the training of connectionist temporal\nclassification (CTC). We use an MMI criterion with a simple language model in\nthe training stage, and a standard HMM decoder. Our method compares favorably\nto CTC in terms of performance, robustness, decoding time, disk footprint and\nquality of alignments. The good alignments enable the use of a straightforward\nensemble method, obtained by simply averaging the predictions of several neural\nnetwork models, that were trained separately end-to-end. The ensemble method\nyields a considerable reduction in the word error rate.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this article we consider static Bayesian parameter estimation for\npartially observed diffusions that are discretely observed. We work under the\nassumption that one must resort to discretizing the underlying diffusion\nprocess, for instance using the Euler-Maruyama method. Given this assumption,\nwe show how one can use Markov chain Monte Carlo (MCMC) and particularly\nparticle MCMC [Andrieu, C., Doucet, A. and Holenstein, R. (2010). Particle\nMarkov chain Monte Carlo methods (with discussion). J. R. Statist. Soc. Ser. B,\n72, 269--342] to implement a new approximation of the multilevel (ML) Monte\nCarlo (MC) collapsing sum identity. Our approach comprises constructing an\napproximate coupling of the posterior density of the joint distribution over\nparameter and hidden variables at two different discretization levels and then\ncorrecting by an importance sampling method. The variance of the weights are\nindependent of the length of the observed data set. The utility of such a\nmethod is that, for a prescribed level of mean square error, the cost of this\nMLMC method is provably less than i.i.d. sampling from the posterior associated\nto the most precise discretization. However the method here comprises using\nonly known and efficient simulation methodologies. The theoretical results are\nillustrated by inference of the parameters of two prototypical processes given\nnoisy partial observations of the process: the first is an Ornstein Uhlenbeck\nprocess and the second is a more general Langevin equation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The ground state of two-dimensional (2D) electron systems with equal low\ndensities of electrons and holes in nearby layers is an exciton fluid. We show\nthat a reservoir for excitons can be established by contacting the two layers\nseparately and maintaining the chemical potential difference at a value less\nthan the spatially indirect band gap. Equilibration between the exciton fluid\nand the contacts proceeds via a process involving virtual intermediate states\nin which an unpaired electron or hole occupies a free carrier state in one of\nthe 2D layers. We derive an approximate relationship between the\nexciton-contact equilibration rate and the electrical conductances between the\ncontacts and individual 2D layers when the contact chemical potentials align\nwith the free-carrier bands, and explain how electrical measurements can be\nused to measure thermodynamic properties of the exciton fluid.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we explore three combinatorial descriptions of semistable\ntypes of hyperelliptic curves over local fields: dual graphs, their quotient\ntrees by the hyperelliptic involution, and configurations of the roots of the\ndefining equation (`cluster pictures'). We construct explicit combinatorial\none-to-one correspondences between the three, which furthermore respect\nautomorphisms and allow to keep track of the monodromy pairing and the Tamagawa\ngroup of the Jacobian. We introduce a classification scheme and a naming\nconvention for semistable types of hyperelliptic curves and types with a\nFrobenius action. This is the higher genus analogue of the distinction between\ngood, split and non-split multiplicative reduction for elliptic curves. Our\nmotivation is to understand $L$-factors, Galois representations, conductors,\nTamagawa numbers and other local invariants of hyperelliptic curves and their\nJacobians.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In order to understand the origin of observed molecular cloud properties, it\nis critical to understand how clouds interact with their environments during\ntheir formation, growth, and collapse. It has been suggested that\naccretion-driven turbulence can maintain clouds in a highly turbulent state,\npreventing runaway collapse, and explaining the observed non-thermal velocity\ndispersions. We present 3D, AMR, MHD simulations of a kiloparsec-scale,\nstratified, supernova-driven, self-gravitating, interstellar medium, including\ndiffuse heating and radiative cooling. These simulations model the formation\nand evolution of a molecular cloud population in the turbulent interstellar\nmedium. We use zoom-in techniques to focus on the dynamics of the mass\naccretion and its history for individual molecular clouds. We find that mass\naccretion onto molecular clouds proceeds as a combination of turbulent and near\nfree-fall accretion of a gravitationally bound envelope. Nearby supernova\nexplosions have a dual role, compressing the envelope, boosting accreted mass,\nbut also disrupting parts of the envelope and eroding mass from the cloud's\nsurface. It appears that the inflow rate of kinetic energy onto clouds from\nsupernova explosions is insufficient to explain the net rate of charge of the\ncloud kinetic energy. In the absence of self-consistent star formation,\nconversion of gravitational potential into kinetic energy during contraction\nseems to be the main driver of non-thermal motions within clouds. We conclude\nthat although clouds interact strongly with their environments, bound clouds\nare always in a state of gravitational contraction, close to runaway, and their\nproperties are a natural result of this collapse.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we compute the E-polynomials of the\n$PGL(2,\\mathbb{C})$-character varieties associated to surfaces of genus $g$\nwith one puncture, for any holonomy around it, and compare it with its\nLanglands dual case, $SL(2,\\mathbb{C})$. The study is based on the\nstratification of the space of representations and on the analysis of the\nbehaviour of the E-polynomial under fibrations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we establish the higher order convergence rates in periodic\nhomogenization of viscous Hamilton-Jacobi equations, which is convex and grows\nquadratically in the gradient variable. We observe that although the nonlinear\nstructure governs the first order approximation, the nonlinear effect is\nabsorbed as an external source term of a linear equation in the second and\nhigher order approximation. Moreover, we find that the geometric shape of the\ninitial data has to be chosen carefully according to the effective Hamiltonian,\nin order to achieve the higher order convergence rates.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Seiberg-Witten equation with multiple spinors generalises the classical\nSeiberg-Witten equation in dimension three. In contrast to the classical case,\nthe moduli space of solutions $\\mathcal{M}$ can be non-compact due to the\nappearance of so-called Fueter sections. In the absence of Fueter sections we\ndefine a signed count of points in $\\mathcal{M}$ and show its invariance under\nsmall perturbations. We then study the equation on the product of a Riemann\nsurface and a circle, describing $\\mathcal{M}$ in terms of holomorphic data\nover the surface. We define analytic and algebro-geometric compactifications of\n$\\mathcal{M}$, and construct a homeomorphism between them. For a generic choice\nof circle-invariant parameters of the equation, Fueter sections do not appear\nand $\\mathcal{M}$ is a compact K\\\"ahler manifold. After a perturbation it\nsplits into isolated points which can be counted with signs, yielding a number\nindependent of the initial choice of the parameters. We compute this number for\nsurfaces of low genus.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Demand for lightweight, highly reflective and mechanically compliant mirrors\nfor optics experiments has seen a significant surge. In this aspect, photonic\ncrystal (PhC) membranes are ideal alternatives to conventional mirrors, as they\nprovide high reflectivity with only a single suspended layer of patterned\ndielectric material. However, due to limitations in nanofabrication, these\ndevices are usually not wider than 300 $\\mu$m. Here we experimentally\ndemonstrate suspended PhC mirrors spanning areas up to 10$\\times$10 mm. We\novercome limitations imposed by the size of the PhC and measure reflectivities\ngreater than 90% on 56 nm thick mirrors at a wavelength of 1550 nm -- an\nunrivaled performance compared to PhC mirrors with micro scale diameters. These\nstructures bridge the gap between nano scale technologies and macroscopic\noptical elements.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report the detection of the 1.3 mm continuum and the molecular emission of\nthe disks of the young triple system SR24 by analyzing ALMA (The Atacama Large\nMillimeter/Submillimter Array) subarcsecond archival observations. We estimate\nthe mass of the disks (0.025 solar masses and 4E-5 earth masses for SR24S and\nSR24N, respectively) and the dynamical mass of the protostars (1.5 and 1.1\nsolar masses). A kinematic model of the SR24S disk to fit its C18O (2-1)\nemission allows us to develop an observational method to learn what is the tilt\nof a rotating and accreting disk. We derive the size, the inclination, the\nposition angle and the sense of rotation of each disk, finding that they are\nstrongly misaligned (108 degrees) and possibly rotate in opposite directions as\nseen from Earth, in projection. We compare the ALMA observations with 12CO SMA\narchival observations, which are more sensitive to extended structures. We find\nthree extended structures and estimate their masses: a molecular bridge joining\nthe disks of the system, a molecular gas reservoir associated with SR24N and a\ngas streamer associated with SR24S. Finally we discuss on the possible origin\nof the misaligned SR24 system, pointing out that a closer inspection of the\nnorthern gas reservoir is needed to better understand it.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A central challenge for the scaling of quantum computing systems is the need\nto control all qubits in the system without a large overhead. A solution for\nthis problem in classical computing comes in the form of so called crossbar\narchitectures. Recently we made a proposal for a large scale quantum\nprocessor~[Li et al. arXiv:1711.03807 (2017)] to be implemented in silicon\nquantum dots. This system features a crossbar control architecture which limits\nparallel single qubit control, but allows the scheme to overcome control\nscaling issues that form a major hurdle to large scale quantum computing\nsystems. In this work, we develop a language that makes it possible to easily\nmap quantum circuits to crossbar systems, taking into account their\narchitecture and control limitations. Using this language we show how to map\nwell known quantum error correction codes such as the planar surface and color\ncodes in this limited control setting with only a small overhead in time. We\nanalyze the logical error behavior of this surface code mapping for estimated\nexperimental parameters of the crossbar system and conclude that logical error\nsuppression to a level useful for real quantum computation is feasible.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show that the yielding transition in granular media displays second-order\ncritical-point scaling behavior. We carry out discrete element simulations in\nthe low inertial number limit for frictionless, purely repulsive spherical\ngrains undergoing simple shear at fixed nondimensional shear stress $\\Sigma$ in\ntwo and three spatial dimensions. To find a mechanically stable (MS) packing\nthat can support the applied $\\Sigma$, isotropically prepared states with size\n$L$ must undergo a total strain $\\gamma_{\\rm ms}(\\Sigma,L)$. The number density\nof MS packings ($\\propto \\gamma_{\\rm ms}^{-1}$) vanishes for $\\Sigma > \\Sigma_c\n\\approx 0.11$ according to a critical scaling form with a length scale $\\xi\n\\propto |\\Sigma - \\Sigma_c|^{-\\nu}$, where $\\nu \\approx 1.7-1.8$. Above the\nyield stress ($\\Sigma>\\Sigma_c$), no MS packings that can support $\\Sigma$\nexist in the large system limit, $L/\\xi \\gg 1$. MS packings generated via shear\npossess anisotropic force and contact networks, suggesting that $\\Sigma_c$ is\nassociated with an upper limit in the degree to which these networks can be\ndeformed away from those for isotropic packings.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The local event detection is to use posting messages with geotags on social\nnetworks to reveal the related ongoing events and their locations. Recent\nstudies have demonstrated that the geo-tagged tweet stream serves as an\nunprecedentedly valuable source for local event detection. Nevertheless, how to\neffectively extract local events from large geo-tagged tweet streams in real\ntime remains challenging. A robust and efficient cloud-based real-time local\nevent detection software system would benefit various aspects in the real-life\nsociety, from shopping recommendation for customer service providers to\ndisaster alarming for emergency departments. We use the preliminary research\nGeoBurst as a starting point, which proposed a novel method to detect local\nevents. GeoBurst+ leverages a novel cross-modal authority measure to identify\nseveral pivots in the query window. Such pivots reveal different geo-topical\nactivities and naturally attract related tweets to form candidate events. It\nfurther summarises the continuous stream and compares the candidates against\nthe historical summaries to pinpoint truly interesting local events. We mainly\nimplement a website demonstration system Event-Radar with an improved algorithm\nto show the real-time local events online for public interests. Better still,\nas the query window shifts, our method can update the event list with little\ntime cost, thus achieving continuous monitoring of the stream.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Finite-precision arithmetic computations face an inherent tradeoff between\naccuracy and efficiency. The points in this tradeoff space are determined,\namong other factors, by different data types but also evaluation orders. To put\nit simply, the shorter a precision's bit-length, the larger the roundoff error\nwill be, but the faster the program will run. Similarly, the fewer arithmetic\noperations the program performs, the faster it will run; however, the effect on\nthe roundoff error is less clear-cut. Manually optimizing the efficiency of\nfinite-precision programs while ensuring that results remain accurate enough is\nchallenging. The unintuitive and discrete nature of finite-precision makes\nestimation of roundoff errors difficult; furthermore the space of possible data\ntypes and evaluation orders is prohibitively large. We present the first fully\nautomated and sound technique and tool for optimizing the performance of\nfloating-point and fixed-point arithmetic kernels. Our technique combines\nrewriting and mixed-precision tuning. Rewriting searches through different\nevaluation orders to find one which minimizes the roundoff error at no\nadditional runtime cost. Mixed-precision tuning assigns different finite\nprecisions to different variables and operations and thus provides\nfiner-grained control than uniform precision. We show that when these two\ntechniques are designed and applied together, they can provide higher\nperformance improvements than each alone.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This is a write-up of introductory remarks that I made at the UIC conference\nin honor of Lawrence Ein's 60th birthday. It presents an informal survey of\nsome of Ein's work, interspersed with stories and reminiscences.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  It is a common incident in nature, that two waves or pulses run into each\nother head-on. The outcome of such an event is of special interest, because it\nallows conclusions about the underlying physical nature of the pulses. The\npresent experimental study dealt with the head-on meeting of two action\npotentials (AP) in a single excitable plant cell (Chara braunii internode). The\nmembrane potential was monitored at the two extremal regions of an excitable\ncell. In control experiments, an AP was excited electrically at either end of\nthe cell cylinder. Subsequently, stimuli were applied simultaneously at both\nends of the cell in order to generate two APs that met each other head-on. When\ntwo action potentials propagated into each other, the pulses did not penetrate\nbut annihilated (N=26 experiments in n=10 cells). APs in excitable plant cells\ndid not penetrate upon meeting head-on. In the classical electrical model, this\nbehavior is specifically attributed to relaxation of ion channel proteins. From\nan acoustic point of view, annihilation can be viewed as a result of nonlinear\nmaterial properties the entire system. The present results suggest that APs in\nexcitable animal and plant cells belong to a similar class of nonlinear\nphenomena. Intriguingly, other excitation waves in biology (intracellular\nwaves, cortical spreading depression, etc.) also annihilate upon collision and\nare thus expected to follow the same underlying principles as the observed\naction potentials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this study, we introduce a new approach to curve pairs by using integral\ncurves. We consider the direction curve and donor curve to study curve couples\nsuch as involute-evolute curves, Mannheim partner curves and Bertrand partner\ncurves. We obtain new methods to construct partner curves of a unit speed curve\nand give some applications related to helices, slant helices and plane curves.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Within the effective QCD action for the Regge kinematics amplitudes for\nvirtual gluon emission are studied in collision of a projectile with two and\nthree targets. It is demonstrated that all un- Feynman singularities cancel\nbetween induced vertices and rescattering contributions. Formulas simplify\nconsiderably in a special gauge which is a straightforward generalization of\nthe light-cone gauge for emission of real gluons.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Multifractal characteristics of the Internet traffic have been discovered and\ndiscussed in several research papers so far. However, the origin of this\nphenomenon is still not fully understood. It has been proven that the\ncongestion control mechanism of the Internet transport protocol, i.e., the\nmechanism of TCP Reno can generate multifractal traffic properties.\nNonetheless, TCP Reno does not exist in today's network any longer,\nsurprisingly traffic multifractality has still been observed. In this paper we\ngive the theoretical proof that TCP CUBIC, which is the default TCP version in\nthe Linux world, can generate multifractal traffic. We give the multifractal\nspectrum of TCP CUBIC traffic and compare it with the multifractal spectrum of\nTCP Reno traffic. Moreover, we present the multifractal spectrum for a more\ngeneral model, where TCP CUBIC and TCP Reno are special cases. Our results also\nshow that TCP CUBIC produces less bursty traffic than TCP Reno.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Transmission through a quantum point contact (QPC) in the quantum Hall regime\nusually exhibits multiple resonances as a function of gate voltage and high\nnonlinearity in bias. Such behavior is unpredictable and changes sample by\nsample. Here, we report the observation of a sharp transition of the\ntransmission through an open QPC at finite bias, which was observed\nconsistently for all the tested QPCs. It is found that the bias dependence of\nthe transition can be fitted to the Fermi-Dirac distribution function through\nuniversal scaling. The fitted temperature matches quite nicely to the electron\ntemperature measured via shot-noise thermometry. While the origin of the\ntransition is unclear, we propose a phenomenological model based on our\nexperimental results that may help to understand such a sharp transition.\nSimilar transitions are observed in the fractional quantum Hall regime, and it\nis found that the temperature of the system can be measured by rescaling the\nquasiparticle energy with the effective charge ($e^*=e/3$). We believe that the\nobserved phenomena can be exploited as a tool for measuring the electron\ntemperature of the system and for studying the quasiparticle charges of the\nfractional quantum Hall states.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We construct two complex-conjugated rigid surfaces with $p_g=q=2$ and $K^2=8$\nwhose universal cover is not biholomorphic to the bidisk. We show that these\nare the unique surfaces with these invariants and Albanese map of degree $2$,\napart the family of product-quotient surfaces constructed by Penegini. This\ncompletes the classification of surfaces with $p_g=q=2, K^2=8$ and Albanese map\nof degree $2$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss the GIT moduli of semistable pairs consisting of a cubic curve and\na line on the projective plane. We study in some detail this moduli and compare\nit with another moduli suggested by Alexeev. It is the moduli of pairs (with no\nspecified semi-abelian action) consisting of a cubic curve with at worst nodal\nsingularities and a line which does not pass through singular points of the\ncubic curve. Meanwhile, we make a comparison between Nakamura's\ncompactification of the moduli of level three elliptic curves and these two\nmoduli spaces.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, Runge-Kutta-Gegenbauer (RKG) stability polynomials of\narbitrarily high order of accuracy are introduced in closed form. The stability\ndomain of RKG polynomials extends in the the real direction with the square of\npolynomial degree, and in the imaginary direction as an increasing function of\nGegenbauer parameter. Consequently, the polynomials are naturally suited to the\nconstruction of high order stabilized Runge-Kutta (SRK) explicit methods for\nsystems of PDEs of mixed hyperbolic-parabolic type.\n  We present SRK methods composed of $L$ ordered forward Euler stages, with\ncomplex-valued stepsizes derived from the roots of RKG stability polynomials of\ndegree $L$. Internal stability is maintained at large stage number through an\nordering algorithm which limits internal amplification factors to $10 L^2$.\nTest results for mildly stiff nonlinear advection-diffusion-reaction problems\nwith moderate ($\\lesssim 1$) mesh P\\'eclet numbers are provided at second,\nfourth, and sixth orders, with nonlinear reaction terms treated by complex\nsplitting techniques above second order.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce the notion of asymptotically finitely generated contact\nstructures, which states essentially that the Symplectic Homology in a certain\ndegree of any filling of such contact manifolds is uniformly generated by only\nfinitely many Reeb orbits. This property is used to generalize a famous result\nby Ustilovsky: We show that in a large class of manifolds (including all unit\ncotangent bundles and all Weinstein fillable contact manifolds with torsion\nfirst Chern class) each carries infinitely many exactly fillable contact\nstructures. These are all different from the ones constructed recently by\nLazarev. Along the way, the construction of Symplectic Homology is made more\ngeneral. Moreover, we give a detailed exposition of Cieliebak's Invariance\nTheorem for subcritical handle attaching, where we provide explicit\nHamiltonians for the squeezing on the handle.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study spherically symmetric timelike thin-shells in $3+1-$dimensional bulk\nspacetime with a variable equation of state for the fluid presented on the\nshell. In such a fluid the angular pressure $p$ is a function of both surface\nenergy density $\\sigma $ and the radius $R$ of the thin-shell. Explicit cases\nof the thin shells connecting two non-identical cloud of strings spacetimes and\na flat Minkowski spacetime to the Schwarzschild metric are investigated.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This article provides an overview of power-domain non-orthogonal multiple\naccess for 5G systems. The basic concepts and benefits are briefly presented,\nalong with current solutions and standardization activities. In addition,\nlimitations and research challenges are discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A frequency mixer is a nonlinear device that combines electromagnetic waves\nto create waves at new frequencies. Mixers are ubiquitous components in modern\nradio-frequency technology and are widely used in microwave signal processing.\nThe development of versatile frequency mixers for optical frequencies remains\nchallenging: such devices generally rely on weak nonlinear optical processes\nand, thus, must satisfy phase matching conditions. In this work, we utilize a\nGaAs-based dielectric metasurface to demonstrate an optical frequency mixer\nthat concurrently generates eleven new frequencies spanning the ultraviolet to\nnear-infrared (NIR) spectral range. Our approach combines strong intrinsic\nmaterial nonlinearities, enhanced electromagnetic fields, and relaxed\nphase-matching requirements, to allow seven different nonlinear optical\nprocesses to occur simultaneously. Specifically, when pumped by two femtosecond\nNIR pulses, we observe second-, third- and fourth-harmonic generation,\nsum-frequency generation, two-photon absorption induced photoluminescence,\nfour-wave mixing, and six-wave mixing. Such ultracompact optical mixers may\nenable a plethora of applications in biology, chemistry, sensing,\ncommunications and quantum optics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A pseudo-edge graph of a convex polyhedron K is a 3-connected embedded graph\nin K whose vertices coincide with those of K, whose edges are distance\nminimizing geodesics, and whose faces are convex. We construct a convex\npolyhedron K in Euclidean 3-space with a pseudo-edge graph with respect to\nwhich K is not unfoldable. The proof is based on a result of Pogorelov on\nconvex caps with prescribed curvature, and an unfoldability obstruction for\nalmost flat convex caps due to Tarasov. Our example, which has 340 vertices,\nsignificantly simplifies an earlier construction by Tarasov, and confirms that\nDurer's conjecture does not hold for pseudo-edge unfoldings.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we give a complete characterization of the scaling limit of the\ncritical Interacting Partially Directed Self-Avoiding Walk (IPDSAW) introduced\nin Zwanzig and Lauritzen (1968). As the system size $L$ diverges, we prove that\nthe set of occupied sites, rescaled horizontally by $L^{2/3}$ and vertically by\n$L^{1/3}$ converges in law for the Hausdorff distance towards a non trivial\nrandom set. This limiting set is built with a Brownian motion $B$ conditioned\nto come back at the origin at $a_1$ the time at which its geometric area\nreaches $1$. The modulus of $B$ up to $a_1$ gives the height of the limiting\nset, while its center of mass process is an independent Brownian motion.\n  Obtaining the shape theorem requires to derive a functional central limit\ntheorem for the excursion of a random walk with Laplace symmetric increments\nconditioned on sweeping a prescribed geometric area. This result is proven in a\ncompanion paper arXiv:1709.06448.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Collisions with background gas can perturb the transition frequency of\ntrapped ions in an optical atomic clock. We develop a non-perturbative\nframework based on a quantum channel description of the scattering process, and\nuse it to derive a master equation which leads to a simple analytic expression\nfor the collisional frequency shift. As a demonstration of our method, we\ncalculate the frequency shift of the Sr$^+$ optical atomic clock transition due\nto elastic collisions with helium.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the specialization of the type A nonsymmetric Macdonald polynomials\nat $t=0$ based on the combinatorial formula of Haglund, Haiman, and Loehr. We\nprove that this specialization expands nonnegatively into the fundamental slide\npolynomials, introduced by the author and Searles. Using this and weak dual\nequivalence, we prove combinatorially that this specialization is a positive\ngraded sum of Demazure characters. We use stability results for fundamental\nslide polynomials to show that this specialization stabilizes and to show that\nthe Demazure character coefficients give a refinement of the Kostka--Foulkes\npolynomials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the existence of homoclinic type solutions for second order\nLagrangian systems of the type $\\ddot{q}(t)-q(t)+a(t)\\nabla G(q(t))=f(t)$,\nwhere $t\\in\\mathbb{R}$, $q\\in\\mathbb{R}^n$, $a\\colon\\mathbb{R}\\to\\mathbb{R}$ is\na continuous positive bounded function, $G\\colon\\mathbb{R}^n\\to\\mathbb{R}$ is a\n$C^1$-smooth potential satisfying the Ambrosetti-Rabinowitz superquadratic\ngrowth condition and $f\\colon\\mathbb{R}\\to\\mathbb{R}^n$ is a continuous bounded\nsquare integrable forcing term. A homoclinic type solution is obtained as limit\nof $2k$-periodic solutions of an approximative sequence of second order\ndifferential equations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this article we study the existence and strong consistency of GEE\nestimators, when the generalized estimating functions are martingales with\nrandom coefficients. Furthermore, we characterize estimating functions which\nare asymptotically optimal.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We compute the gravitational wave spectrum from a tachyonic preheating\ntransition of a Standard Model-like SU(2)-Higgs system. Tachyonic preheating\ninvolves exponentially growing IR modes, at scales as large as the horizon.\nSuch a transition at the electroweak scale could be detectable by LISA, if\nthese non-perturbatively large modes translate into non-linear dynamics\nsourcing gravitational waves. Through large-scale numerical simulations, we\nfind that the spectrum of gravitational waves does not exhibit such IR\nfeatures. Instead, we find two peaks corresponding to the Higgs and gauge field\nmass, respectively. We find that the gravitational wave production is reduced\nwhen adding non-Abelian gauge fields to a scalar-only theory, but increases\nwhen adding Abelian gauge fields. In particular, gauge fields suppress the\ngravitational wave spectrum in the IR. A tachyonic transition in the early\nUniverse will therefore not be detectable by LISA, even if it involves\nnon-Abelian gauge fields.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Diophantine equation $A^4+hB^4=C^4+hD^4$, where $h$ is a fixed arbitrary\npositive integer, has been investigated by some authors. Currently, by computer\nsearch, the integer solutions of this equation are known for all positive\ninteger values of $h \\le 5000$ and $A, B, C, D \\le 100000$, except for some\nnumbers, while a solution of this Diophantine equation is not known for\narbitrary positive integer values of $h$. Gerardin and Piezas found solutions\nof this equation when $h$ is given by polynomials of degrees $5$ and $2$\nrespectively. Also Choudhry presented some new solutions of this equation when\n$h$ is given by polynomials of degrees $2$, $3$, and $4$.\n  In this paper, by using the elliptic curves theory, we study this Diophantine\nequation, where $h$ is a fixed arbitrary rational number. We work out some\nsolutions of the Diophantine equation for certain values of $h$, in particular\nfor the values which has not already been found a solution in the range where\n$A, B, C, D \\le 100000$ by computer search. Also we present some new parametric\nsolutions for the Diophantine equation when $h$ is given by polynomials of\ndegrees $3$, $4$. Finally We present two conjectures such that if one of them\nis correct, then we may solve the above Diophantine equation for arbitrary\nrational number $h$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A central issue of Mott physics, with symmetries being fully retained in the\nspin background, concerns the charge excitation. In a two-leg spin ladder with\nspin gap, an injected hole can exhibit either a Bloch wave or a density wave by\ntuning the ladder anisotropy through a `quantum critical point' (QCP). The\nnature of such a QCP has been a subject of recent studies by density matrix\nrenormalization group (DMRG). In this paper, we reexamine the ground state of\nthe one doped hole, and show that a two-component structure is present in the\ndensity wave regime in contrast to the single component in the Bloch wave\nregime. In the former, the density wave itself is still contributed by a\nstanding-wave-like component characterized by a quasiparticle spectral weight\n$Z$ in a finite-size system. But there is an additional charge incoherent\ncomponent emerging, which intrinsically breaks the translational symmetry\nassociated with the density wave. The partial momentum is carried away by\nneutral spin excitations. Such an incoherent part does not manifest in the\nsingle-particle spectral function, directly probed by the angle-resolved\nphotoemission spectroscopy (ARPES) measurement, however it is demonstrated in\nthe momentum distribution function. The Landau's one-to-one correspondence\nhypothesis for a Fermi liquid breaks down here. The microscopic origin of this\ndensity wave state as an intrinsic manifestation of the doped Mott physics will\nbe also discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recently there has been a dramatic increase in the performance of recognition\nsystems due to the introduction of deep architectures for representation\nlearning and classification. However, the mathematical reasons for this success\nremain elusive. This tutorial will review recent work that aims to provide a\nmathematical justification for several properties of deep networks, such as\nglobal optimality, geometric stability, and invariance of the learned\nrepresentations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Accurate delineation of the left ventricle (LV) is an important step in\nevaluation of cardiac function. In this paper, we present an automatic method\nfor segmentation of the LV in cardiac CT angiography (CCTA) scans. Segmentation\nis performed in two stages. First, a bounding box around the LV is detected\nusing a combination of three convolutional neural networks (CNNs).\nSubsequently, to obtain the segmentation of the LV, voxel classification is\nperformed within the defined bounding box using a CNN. The study included CCTA\nscans of sixty patients, fifty scans were used to train the CNNs for the LV\nlocalization, five scans were used to train LV segmentation and the remaining\nfive scans were used for testing the method. Automatic segmentation resulted in\nthe average Dice coefficient of 0.85 and mean absolute surface distance of 1.1\nmm. The results demonstrate that automatic segmentation of the LV in CCTA scans\nusing voxel classification with convolutional neural networks is feasible.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we study the general problem of optimizing a convex function\n$F(L)$ over the set of $p \\times p$ matrices, subject to rank constraints on\n$L$. However, existing first-order methods for solving such problems either are\ntoo slow to converge, or require multiple invocations of singular value\ndecompositions. On the other hand, factorization-based non-convex algorithms,\nwhile being much faster, require stringent assumptions on the \\emph{condition\nnumber} of the optimum. In this paper, we provide a novel algorithmic framework\nthat achieves the best of both worlds: asymptotically as fast as factorization\nmethods, while requiring no dependency on the condition number.\n  We instantiate our general framework for three important matrix estimation\nproblems that impact several practical applications; (i) a \\emph{nonlinear}\nvariant of affine rank minimization, (ii) logistic PCA, and (iii) precision\nmatrix estimation in probabilistic graphical model learning. We then derive\nexplicit bounds on the sample complexity as well as the running time of our\napproach, and show that it achieves the best possible bounds for both cases. We\nalso provide an extensive range of experimental results, and demonstrate that\nour algorithm provides a very attractive tradeoff between estimation accuracy\nand running time.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Multithreaded software is typically built with specialized concurrent objects\nlike atomic integers, queues, and maps. These objects' methods are designed to\nbehave according to certain consistency criteria like atomicity, despite being\noptimized to avoid blocking and exploit parallelism, e.g., by using atomic\nmachine instructions like compare and exchange (cmpxchg). Exposing atomicity\nviolations is important since they generally lead to elusive bugs that are\ndifficult to identify, reproduce, and ultimately repair.\n  In this work we expose atomicity violations in concurrent object\nimplementations from the most widely-used software development kit: The Java\nDevelopment Kit (JDK). We witness atomicity violations via simple test\nharnesses containing few concurrent method invocations. While stress testing is\neffective at exposing violations given catalytic test harnesses and lightweight\nmeans of falsifying atomicity, divining effectual catalysts can be difficult,\nand atomicity checks are generally cumbersome. We overcome these problems by\nautomating test-harness search, and establishing atomicity via membership in\nprecomputed sets of acceptable return-value outcomes. Our approach enables\ntesting millions of executions of each harness each second (per processor\ncore). This scale is important since atomicity violations are observed in very\nfew executions (tens to hundreds out of millions) of very few harnesses (one\nout of hundreds to thousands). Our implementation is open source and publicly\navailable.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Deep learning methods are used on spectroscopic data to predict drug content\nin tablets from near infrared (NIR) spectra. Using convolutional neural\nnetworks (CNNs), features are ex- tracted from the spectroscopic data. Extended\nmultiplicative scatter correction (EMSC) and a novel spectral data augmentation\nmethod are benchmarked as preprocessing steps. The learned models perform\nbetter or on par with hypothetical optimal partial least squares (PLS) models\nfor all combinations of preprocessing. Data augmentation with subsequent EMSC\nin combination gave the best results. The deep learning model CNNs also\noutperform the PLS models in an extrapolation chal- lenge created using data\nfrom a second instrument and from an analyte concentration not covered by the\ntraining data. Qualitative investigations of the CNNs kernel activations show\ntheir resemblance to wellknown data processing methods such as smoothing,\nslope/derivative, thresholds and spectral region selection.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  With the installation of a new 28-m diameter imaging atmospheric Cherenkov\ntelescope in the middle of the array, the H.E.S.S. instrument has entered since\n2012 into its Phase II. The fifth large-size telescope is particularly\nimportant to lower the threshold energy of the array, and is thus a unique\ninstrument to observe low-frequency-peaked blazars, such as flat-spectrum\nradio-quasars (FSRQs), which remain rare in the very-high- energy (VHE; E $>$\n100 GeV) $\\gamma$-ray domain. In this contribution, we report on the discovery\nwith the H.E.S.S. telescopes of VHE $\\gamma$-ray emission from the FSRQ PKS\n0736+017 (z=0.189). H.E.S.S. observations were triggered as a\ntarget-of-opportunity in February 2015 following the detection of $\\gamma$-ray\nflaring activity in the MeV-GeV energy-band with Fermi-LAT. Significant VHE\nemission is detected with H.E.S.S. only during one of the nights of the\nobserving campaign, showing at least night-by-night variability in the VHE\nregime. We discuss the location of the $\\gamma$-ray emitting region within the\nrelativistic jet, using opacity and variability constraints.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Multi-agent path finding (MAPF) is a well-studied problem in artificial\nintelligence, where one needs to find collision-free paths for agents with\ngiven start and goal locations. In video games, agents of different types often\nform teams. In this paper, we demonstrate the usefulness of MAPF algorithms\nfrom artificial intelligence for moving such non-homogeneous teams in congested\nvideo game environments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper deals with a complete bipartite matching problem with the\nobjective of finding an optimal matching that maximizes a certain generic\npredefined utility function on the set of all matchings. After proving the\nNP-hardness of the problem using reduction from the 3-SAT problem, we propose a\nrandomized algorithm based on Markov Chain Monte Carlo (MCMC) technique for\nsolving this. We sample from Gibb's distribution and construct a reversible\npositive recurrent discrete time Markov chain (DTMC) that has the steady state\ndistribution same as the Gibb's distribution. In one of our key contributions,\nwe show that the constructed chain is `rapid mixing', i.e., the convergence\ntime to reach within a specified distance to the desired distribution is\npolynomial in the problem size. The rapid mixing property is established by\nobtaining a lower bound on the conductance of the DTMC graph and this result is\nof independent interest.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Interval Markov decision processes (IMDPs) generalise classical MDPs by\nhaving interval-valued transition probabilities. They provide a powerful\nmodelling tool for probabilistic systems with an additional variation or\nuncertainty that prevents the knowledge of the exact transition probabilities.\nIn this paper, we consider the problem of multi-objective robust strategy\nsynthesis for interval MDPs, where the aim is to find a robust strategy that\nguarantees the satisfaction of multiple properties at the same time in face of\nthe transition probability uncertainty. We first show that this problem is\nPSPACE-hard. Then, we provide a value iteration-based decision algorithm to\napproximate the Pareto set of achievable points. We finally demonstrate the\npractical effectiveness of our proposed approaches by applying them on several\ncase studies using a prototypical tool.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  With the rapid growth of services that stream to groups of users comes an\nincreased importance of and demand for reliable multicast. In this paper, we\nturn to software-defined networking and develop a novel general-purpose\nmulti-failure protection algorithm to provide quick failure recovery, via Fast\nFailover (FF) groups, for dynamic multicast groups. This extends previous\nresearch, which either could not realize fast failover, worked only for single\nlink failures, or was only applicable to static multicast groups. However,\nwhile FF is know to be fast, it requires pre-installing back-up rules. These\nadditional memory requirements, which in a multicast setting are even more\npronounced than for unicast, are often mentioned as a big disadvantage of using\nFF.\n  We develop an OpenFlow application for resilient multicast, with which we\nstudy FF resource usage, in an attempt to better understand the trade-off\nbetween recovery time and resource usage. Our tests on a realistic network\nsuggest that using FF groups can reduce the recovery time of the network\nsignificantly compared to other methods, especially when the latency between\nthe controller and the switches is relatively large.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The light curves and spectral properties of more than 200 $\\gamma$-ray\npulsars have been measured in unsurpassed detail in the eight years since the\nlaunch of the hugely successful Fermi Large Area Telescope (LAT) $\\gamma$-ray\nmission. We performed geometric pulsar light curve modelling using static,\nretarded vacuum, and offset polar cap (PC) dipole $B$-fields (the latter is\ncharacterized by a parameter $\\epsilon$), in conjunction with standard two-pole\ncaustic (TPC) and outer gap (OG) emission geometries. In addition to\nconstant-emissivity geometric models, we also considered a slot gap (SG)\n$E$-field associated with the offset-PC dipole $B$-field and found that its\ninclusion leads to qualitatively different light curves. We therefore find that\nthe assumed $B$-field and especially the $E$-field structure, as well as the\nemission geometry (magnetic inclination and observer angles), have a great\nimpact on the pulsar's visibility and its high-energy pulse shape. We compared\nour model light curves to the superior-quality $\\gamma$-ray light curve of the\nVela pulsar (for energies $>100$ MeV). Our overall optimal light curve fit\n(with the lowest $\\chi^2$ value) is for the retarded vacuum dipole field and OG\nmodel. We found that smaller values of $\\epsilon$ are favoured for the\noffset-PC dipole field when assuming constant emissivity, and larger $\\epsilon$\nvalues are favoured for variable emissivity, but not significantly so. When we\nincreased the relatively low SG $E$-fields we found improved light curve fits,\nwith the inferred pulsar geometry being closer to best fits from independent\nstudies in this case. In particular, we found that such a larger SG $E$-field\n(leading to variable emissivity) gives a second overall best fit. This and\nother indications point to the fact that the actual $E$-field may be larger\nthan predicted by the SG model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Gaze tracking is an important technology as the system can give information\nabout a person from what and where the person is seeing. There have been many\nattempts to make robust and accurate gaze trackers using either monitor or\nwearable devices. However, those contraptions often require fine individual\ncalibration per session and/or require a person wearing a device, which may not\nbe suitable for certain situations. In this paper, we propose a robust and a\ncompletely noninvasive gaze tracking system that involves neither complex\ncalibrations nor the use of wearable devices. We achieve this via direct eye\nreflection analysis by building a real-time system that effectively enables it.\nWe also show several interesting applications for our system including\nexperiments with young children.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a construction of a 2-Hilbert space of sections of a bundle gerbe,\na suitable candidate for a prequantum 2-Hilbert space in higher geometric\nquantisation. We introduce a direct sum on the morphism categories in the\n2-category of bundle gerbes and show that these categories are cartesian\nmonoidal and abelian. Endomorphisms of the trivial bundle gerbe, or higher\nfunctions, carry the structure of a rig-category, which acts on generic\nmorphism categories of bundle gerbes. We continue by presenting a\ncategorification of the hermitean metric on a hermitean line bundle. This is\nachieved by introducing a functorial dual that extends the dual of vector\nbundles to morphisms of bundle gerbes, and constructing a two-variable\nadjunction for the aforementioned rig-module category structure on morphism\ncategories. Its right internal hom is the module action, composed by taking the\ndual of higher functions, while the left internal hom is interpreted as a\nbundle gerbe metric. Sections of bundle gerbes are defined as morphisms from\nthe trivial bundle gerbe to a given bundle gerbe. The resulting categories of\nsections carry a rig-module structure over the category of finite-dimensional\nHilbert spaces. A suitable definition of 2-Hilbert spaces is given, modifying\nprevious definitions by the use of two-variable adjunctions. We prove that the\ncategory of sections of a bundle gerbe fits into this framework, thus obtaining\na 2-Hilbert space of sections. In particular, this can be constructed for\nprequantum bundle gerbes in problems of higher geometric quantisation. We\ndefine a dimensional reduction functor and show that the categorical structures\nintroduced on bundle gerbes naturally reduce to their counterparts on hermitean\nline bundles with connections. In several places in this thesis, we provide\nexamples, making 2-Hilbert spaces of sections and dimensional reduction very\nexplicit.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, a symbol-level selective transmission for virtual full-duplex\n(FD) relaying networks is proposed, which aims to mitigate error propagation\neffects and improve system spectral efficiency. The idea is to allow two\nhalf-duplex relays, mimicked as FD relaying, to alternatively serve as\ntransmitter and receiver to forward the source's messages. In this case, each\nrelay predicts the correctly decoded symbols of its received frame, based on\nthe generalized square deviation method, and discard the erroneously decoded\nsymbols, resulting in fewer errors being forwarded to the destination. Then, a\nmodified maximum \\textit{a posteriori} receiver at the destination is provided\nto eliminate the inter-frame interference and identify the positions of\ndiscarded symbols from the relays. In addition, the diversity-multiplexing\ntrade-off (DMT) for our proposed scheme is also analysed. It is found that our\nproposed scheme outperforms the conventional selective decode-and-forward\n(S-DF) relaying schemes, such as cyclic redundancy check based S-DF and\nthreshold based S-DF, in terms of DMT. Moreover, the bit-error-rate performance\nare also simulated to confirm the DMT results.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove uniqueness for weak solutions to abstract parabolic equations with\nthe fractional Marchaud or Caputo time derivative. We consider weak solutions\nin time for divergence form equations when the fractional derivative is\ntransferred to the test function.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  With the discovery of rocky planets in the temperate habitable zone (HZ) of\nthe close-by cool star TRAPPIST-1 the question of whether such planets could\nharbour life arises. Habitable planets around red dwarf stars can orbit in\nradiation environments that can be life-sterilizing. UV flares from these stars\nare more frequent and intense than solar flares. Additionally, their temperate\nHZs are closer to the star. Here we present UV surface environment models for\nTRAPPIST-1's HZ planets and explore the implications for life. TRAPPIST-1 has\nhigh X-ray/EUV activity, placing planetary atmospheres at risk from erosion. If\na dense Earth-like atmosphere with a protective ozone layer exists on planets\nin the HZ of TRAPPIST-1, UV surface environments would be similar to\npresent-day Earth. However an eroded or an anoxic atmosphere, would allow more\nUV to reach the surface, making surface environments hostile even to highly\nUV-tolerant terrestrial extremophiles. If future observations detect ozone in\nthe atmospheres of any of the planets in the HZ of TRAPPIST-1, these would be\ninteresting targets for the search for surface life. We anticipate our assay to\nbe a starting point for in-depth exploration of stellar and atmospheric\nobservations of the TRAPPIST-1 planets to constrain their\nUV-surface-habitability.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  [Background:] It is well known that effective nuclear interactions are in\ngeneral nonlocal. Thus if nuclear densities obtained from {\\it ab initio}\nno-core-shell-model (NCSM) calculations are to be used in reaction\ncalculations, translationally invariant nonlocal densities must be available.\n[Purpose:] Though it is standard to extract translationally invariant one-body\nlocal densities from NCSM calculations to calculate local nuclear observables\nlike radii and transition amplitudes, the corresponding nonlocal one-body\ndensities have not been considered so far. A major reason for this is that the\nprocedure for removing the center-of-mass component from NCSM wavefunctions up\nto now has only been developed for local densities. [Results:] A formulation\nfor removing center-of-mass contributions from nonlocal one-body densities\nobtained from NCSM and symmetry-adapted NCSM (SA-NCSM) calculations is derived,\nand applied to the ground state densities of $^4$He, $^6$Li, $^{12}$C, and\n$^{16}$O. The nonlocality is studied as a function of angular momentum\ncomponents in momentum as well as coordinate space [Conclusions:] We find that\nthe nonlocality for the ground state densities of the nuclei under\nconsideration increases as a function of the angular momentum. The relative\nmagnitude of those contributions decreases with increasing angular momentum. In\ngeneral, the nonlocal structure of the one-body density matrices we studied is\ngiven by the shell structure of the nucleus, and can not be described with\nsimple functional forms.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate how next-generation laser pulses at 10 PW $-$ 200 PW interact\nwith a solid target in the presence of a relativistically underdense preplasma\nproduced by amplified spontaneous emission (ASE). Laser hole boring and\nrelativistic transparency are strongly restrained due to the generation of\nelectron-positron pairs and $\\gamma$-ray photons via quantum electrodynamics\n(QED) processes. A pair plasma with a density above the initial preplasma\ndensity is formed, counteracting the electron-free channel produced by the hole\nboring. This pair-dominated plasma can block the laser transport and trigger an\navalanche-like QED cascade, efficiently transfering the laser energy to\nphotons. This renders a 1-$\\rm\\mu m$-scalelength, underdense preplasma\ncompletely opaque to laser pulses at this power level. The QED-induced opacity\ntherefore sets much higher contrast requirements for such pulse in solid-target\nexperiments than expected by classical plasma physics. Our simulations show for\nexample, that proton acceleration from the rear of a solid with a preplasma\nwould be strongly impaired.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper studies the initial-boundary-value problem (IBVP) of a nonlinear\nSchr\\\"odinger equation posed on a strip domain $\\mathbb{R}\\times[0,1]$ with\nnon-homogeneous Dirichlet boundary conditions. For any $s\\ge0$, if the initial\ndata $\\varphi(x,y)$ is in Sobolev space $H^s(\\mathbb{R}\\times[0,1])$ and the\nboundary data $h(x,t)$ is in $$ {\\cal H}^s (\\mathbb{R} ) = \\left \\{ h (x, t)\n\\in L^2 ( \\mathbb{R}^2 ) \\ \\big | \\ ( 1 + |\\lambda | + |\\xi|)^{\\frac12} ( 1+\n|\\lambda | + |\\xi |^2 )^{\\frac{s}{2}}\\hat h ( \\lambda, \\xi ) \\in L^2\n(\\mathbb{R}^2 ) \\right \\} $$ where $\\hat h $ is the Fourier transform of $h$\nwith respect to $t$ and $ x$, the local well-posedness of the IBVP in $C([0,T];\nH^s(\\mathbb{R} \\times [0,1]))$ is proved. The global well-posedness is also\nobtained for $s = 1$. The basic idea used here relies on the derivation of an\nintegral operator for the non-homogeneous boundary data and the proof of the\nseries version of Strichartz's estimates for this operator. After the problem\nis transformed to finding a fixed point of an integral operator, the\ncontraction mapping argument then yields a fixed point using the Strichartz's\nestimates for initial and boundary operators. The global well-posedness is\nproved using {\\it a-priori} estimates of the solutions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show that the standard approach of minimal invariant sets, which applies\nZorn's Lemma and is used to prove fixed point theorems for non-expansive\nmappings in Banach spaces can be applied without any reference to the full\nAxiom of Choice when the given Banach space is separable. Our method applies\nresults from classical and effective descriptive set theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A search for temporal changes on Pluto and Charon was motivated by (1) the\ndiscovery of young surfaces in the Pluto system that imply ongoing or recent\ngeologic activity, (2) the detection of active plumes on Triton during the\nVoyager 2 flyby, and (3) the abundant and detailed information that observing\ngeologic processes in action provides about the processes. A thorough search\nfor temporal changes using New Horizons images was completed. Images that\ncovered the same region were blinked and manually inspected for any differences\nin appearance. The search included full-disk images such that all illuminated\nregions of both bodies were investigated and higher resolution images such that\nparts of the encounter hemispheres were investigated at finer spatial scales.\nChanges of appearance between different images were observed but in all cases\nwere attributed to variability of the imaging parameters (especially geometry)\nor artifacts. No differences of appearance that are strongly indicative of a\ntemporal change were found on the surface or in the atmosphere of either Pluto\nor Charon. Limits on temporal changes as a function of spatial scale and\ntemporal interval during the New Horizons encounter are determined. The longest\ntime interval constraint is one Pluto/Charon rotation period (~6.4 Earth days).\nContrast reversal and high-phase bright features that change in appearance with\nsolar phase angle are identified. The change of appearance of these features is\nmost likely due to the change in phase angle rather than a temporal change. Had\nactive plumes analogous to the plumes discovered on Triton been present on the\nencounter hemispheres of either Pluto or Charon, they would have been detected.\nThe absence of active plumes may be due to temporal variability (i.e., plumes\ndo occur but none were active on the encounter hemispheres during the epoch of\nthe New Horizons encounter ...\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The {\\it Herschel} Astrophysical Terahertz Large Area Survey (H-ATLAS) is a\nsurvey of 660 deg$^2$ with the PACS and SPIRE cameras in five photometric\nbands: 100, 160, 250, 350 and 500\\mic. This is the second of three papers\ndescribing the data release for the large fields at the south and north\nGalactic poles (NGP and SGP). In this paper we describe the catalogues of\nfar-infrared and submillimetre sources for the NGP and SGP, which cover 177\ndeg$^2$ and 303 deg$^2$, respectively. The catalogues contain 153,367 sources\nfor the NGP field and 193,527 sources for the SGP field detected at more than\n4$\\sigma$ significance in any of the 250, 350 or 500\\mic\\ bands. The source\ndetection is based on the 250\\mic\\ map, and we present photometry in all five\nbands for each source, including aperture photometry for sources known to be\nextended. The rms positional accuracy for the faintest sources is about 2.4 arc\nseconds in both right ascension and declination. We present a statistical\nanalysis of the catalogues and discuss the practical issues -- completeness,\nreliability, flux boosting, accuracy of positions, accuracy of flux\nmeasurements -- necessary to use the catalogues for astronomical projects.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The recent discovery of triply degenerate points (TDPs) in topological\nmaterials has opened a new perspective toward the realization of novel\nquasiparticles without counterparts in quantum field theory. The emergence of\nsuch protected nodes is often attributed to spin-vector-momentum couplings.\nHere we show that the interplay between spin-tensor- and spin-vector-momentum\ncouplings can induce three types of TDPs, classified by different monopole\ncharges ($\\mathcal{C}=\\pm 2,\\pm 1,0$). A Zeeman field can lift them into Weyl\npoints with distinct numbers and charges. Different TDPs of the same type are\nconnected by intriguing Fermi arcs at surfaces, and transitions between\ndifferent types are accompanied by level crossings along high-symmetry lines.\nWe further propose an experimental scheme to realize such TDPs in cold-atom\noptical lattices. Our results provide a framework for studying\nspin-tensor-momentum coupling-induced TDPs and other exotic quasiparticles.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Alloyed MCrAlY bond coats, where M is usually cobalt and/or nickel, are\nessential parts of modern turbine blades, imparting environmental resistance\nwhile mediating thermal expansivity differences. Nanoindentation allows the\ndetermination of their properties without the complexities of traditional\nmechanical tests, but was not previously possible near turbine operating\ntemperatures.\n  Here, we determine the hardness and modulus of CMSX-4 and an Amdry-386 bond\ncoat by nanoindentation up to 1000$^{\\circ}$C. Both materials exhibit a\nconstant hardness until 400$^{\\circ}$C followed by considerable softening,\nwhich in CMSX-4 is attributed to the multiple slip systems operating underneath\na Berkovich indenter.\n  The creep behaviour has been investigated via the nanoindentation hold\nsegments. Above 700$^{\\circ}$C, the observed creep exponents match the\ntemperature-dependence of literature values in CMSX-4. In Amdry-386,\nnanoindentation produces creep exponents very close to literature data,\nimplying high-temperature nanoindentation may be powerful in characterising\nthese coatings and providing inputs for material, model and process\noptimisations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Partial Least Squares (PLS) methods have been heavily exploited to analyse\nthe association between two blocs of data. These powerful approaches can be\napplied to data sets where the number of variables is greater than the number\nof observations and in presence of high collinearity between variables.\nDifferent sparse versions of PLS have been developed to integrate multiple data\nsets while simultaneously selecting the contributing variables. Sparse\nmodelling is a key factor in obtaining better estimators and identifying\nassociations between multiple data sets. The cornerstone of the sparsity\nversion of PLS methods is the link between the SVD of a matrix (constructed\nfrom deflated versions of the original matrices of data) and least squares\nminimisation in linear regression. We present here an accurate description of\nthe most popular PLS methods, alongside their mathematical proofs. A unified\nalgorithm is proposed to perform all four types of PLS including their\nregularised versions. Various approaches to decrease the computation time are\noffered, and we show how the whole procedure can be scalable to big data sets.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Message-passing methods provide a powerful approach for calculating the\nexpected size of cascades either on random networks (e.g., drawn from a\nconfiguration-model ensemble or its generalizations) asymptotically as the\nnumber $N$ of nodes becomes infinite or on specific finite-size networks. We\nreview the message-passing approach and show how to derive it for\nconfiguration-model networks using the methods of (Dhar et al., 1997) and\n(Gleeson, 2008). Using this approach, we explain for such networks how to\ndetermine an analytical expression for a \"cascade condition\", which determines\nwhether a global cascade will occur. We extend this approach to the\nmessage-passing methods for specific finite-size networks (Shrestha and Moore,\n2014; Lokhov et al., 2015), and we derive a generalized cascade condition.\nThroughout this chapter, we illustrate these ideas using the Watts threshold\nmodel.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Face-off is an interesting case of style transfer where the facial\nexpressions and attributes of one person could be fully transformed to another\nface. We are interested in the unsupervised training process which only\nrequires two sequences of unaligned video frames from each person and learns\nwhat shared attributes to extract automatically. In this project, we explored\nvarious improvements for adversarial training (i.e. CycleGAN[Zhu et al., 2017])\nto capture details in facial expressions and head poses and thus generate\ntransformation videos of higher consistency and stability.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Full-wave 3D electromagnetic simulations of complex planar devices,\nmultilayer interconnects, and chip packages are presented for wide-band\nfrequency-domain analysis using the finite difference integration technique\ndeveloped in the PETSc software package. Initial reordering of the index\nassignment to the unknowns makes the resulting system matrix diagonally\ndominant. The rearrangement also facilitates the decomposition of large domain\ninto slices for passing the mesh information to different machines. Matrix-free\nmethods are then exploited to minimize the number of element-wise\nmultiplications and memory requirements in the construction of the system of\nlinear equations. Besides, the recipes provide extreme ease of modifications in\nthe kernel of the code. The applicability of different Krylov subspace solvers\nis investigated. The accuracy is checked through comparisons with CST MICROWAVE\nSTUDIO transient solver results. The parallel execution of the compiled code on\nspecific number of processors in multi-core distributed-memory architectures\ndemonstrate high scalability of the computational algorithm.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  To accelerate the thermal equilibrium sampling of multi-level quantum\nsystems, the infinite swapping limit of a recently proposed multi-level ring\npolymer representation is investigated. In the infinite swapping limit, the\nring polymer evolves according to an averaged Hamiltonian with respect to all\npossible surface index configurations of the ring polymer, thus connects the\nsurface hopping approach to the mean-field path integral molecular dynamics. A\nmultiscale integrator for the infinite swapping limit is also proposed to\nenable efficient sampling based on the limiting dynamics. Numerical results\ndemonstrate the huge improvement of sampling efficiency of the infinite\nswapping compared with the direct simulation of path integral molecular\ndynamics with surface hopping.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We fabricate devices in which a magnetic nanopillar spin valve makes contact\nto a Co/Pt bilayer thin film with perpendicular magnetic anisotropy, in order\nto achieve local control of domains in the Co/Pt bilayer underneath the\nnanopillar. The goal is to develop the ability to nucleate, detect, and\nannihilate magnetic skyrmions in the Co/Pt using spin-polarized currents from\nthe nanopillar. We demonstrate the ability to distinguish the local behavior of\nthe Co/Pt film beneath the nanopillar from the extended film and show that the\ntwo can switch independently of each other. This allows us to isolate a\nlocalized domain under the pillar that can be controlled separately from the\nrest of the Co/Pt film using applied currents and magnetic fields.\nMicromagnetic simulations indicate that this localized domain has skyrmion\nsymmetry. Our results represent a first step toward controlling\nroom-temperature skyrmions using localized spin-transfer torque.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we study solutions of the critical Lane-Emden equation in\nhigher space dimensions. We show that after certain transformations the general\nsolution can be written in terms of elliptic functions. We restrict ourselves\nto real solutions which can be used in physical applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Gaussian processes (GPs) have been proven to be powerful tools in various\nareas of machine learning. However, there are very few applications of GPs in\nthe scenario of multi-view learning. In this paper, we present a new GP model\nfor multi-view learning. Unlike existing methods, it combines multiple views by\nregularizing marginal likelihood with the consistency among the posterior\ndistributions of latent functions from different views. Moreover, we give a\ngeneral point selection scheme for multi-view learning and improve the proposed\nmodel by this criterion. Experimental results on multiple real world data sets\nhave verified the effectiveness of the proposed model and witnessed the\nperformance improvement through employing this novel point selection scheme.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This document contains a description of several of my papers, including\nremarks on history and connection with subsequent work. It also contains some\nnew results and conjectures.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Accelerating the data acquisition of dynamic magnetic resonance imaging (MRI)\nleads to a challenging ill-posed inverse problem, which has received great\ninterest from both the signal processing and machine learning community over\nthe last decades. The key ingredient to the problem is how to exploit the\ntemporal correlation of the MR sequence to resolve the aliasing artefact.\nTraditionally, such observation led to a formulation of a non-convex\noptimisation problem, which were solved using iterative algorithms. Recently,\nhowever, deep learning based-approaches have gained significant popularity due\nto its ability to solve general inversion problems. In this work, we propose a\nunique, novel convolutional recurrent neural network (CRNN) architecture which\nreconstructs high quality cardiac MR images from highly undersampled k-space\ndata by jointly exploiting the dependencies of the temporal sequences as well\nas the iterative nature of the traditional optimisation algorithms. In\nparticular, the proposed architecture embeds the structure of the traditional\niterative algorithms, efficiently modelling the recurrence of the iterative\nreconstruction stages by using recurrent hidden connections over such\niterations. In addition, spatiotemporal dependencies are simultaneously learnt\nby exploiting bidirectional recurrent hidden connections across time sequences.\nThe proposed algorithm is able to learn both the temporal dependency and the\niterative reconstruction process effectively with only a very small number of\nparameters, while outperforming current MR reconstruction methods in terms of\ncomputational complexity, reconstruction accuracy and speed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show that the Hopf elements, the Kervaire classes, and the\n$\\bar{\\kappa}$-family in the stable homotopy groups of spheres are detected by\nthe Hurewicz map from the sphere spectrum to the $C_2$-fixed points of the Real\nBrown-Peterson spectrum. A subset of these families is detected by the\n$C_2$-fixed points of Real Johnson-Wilson theory $E\\mathbb{R}(n)$, depending on\n$n$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We calculate the electron excitation in cubic silicon carbide (3C-SiC) caused\nby the intense femtosecond laser double pulses using time-dependent density\nfunctional theory (TDDFT). We assume the electron distributions in the valence\nband (VB) and the conduction band (CB) based on three different approaches to\ndetermine the dependence of the plasma that is formed on the excitation by the\nfirst pulse. First, we consider the simple double pulse irradiation, which does\nnot include the electron-electron collisions and relaxation. Second, we\nconsider the partially thermalized electronic state, in which the electron\ntemperatures and numbers in the VB and the CB are defined independently. This\nassumption corresponds to the plasma before the electron-hole collisions\nbecomes dominant. The third approach uses the fully thermalized electron\ndistribution, which corresponds to a timescale of hundreds fs. Our results\nindicate that the simple double pulse approach is the worst of the three, and\nshow that the plasma formation changes the efficiency of the excitation by the\nsecond pulse. When the electron temperature decreases, the laser excitation\nefficiency increases as a result.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The chaotic diffusion for a family of Hamiltonian mappings whose angles\ndiverge in the limit of vanishingly action is investigated by using the\nsolution of the diffusion equation. The system is described by a\ntwo-dimensional mapping for the variables action, $I$, and angle, $\\theta$ and\ncontrolled by two control parameters: (i) $\\epsilon$, controlling the\nnonlinearity of the system, particularly a transition from integrable for\n$\\epsilon=0$ to non-integrable for $\\epsilon\\ne0$ and; (ii) $\\gamma$ denoting\nthe power of the action in the equation defining the angle. For $\\epsilon\\ne0$\nthe phase space is mixed and chaos is present in the system leading to a finite\ndiffusion in the action characterized by the solution of the diffusion\nequation. The analytical solution is then compared to the numerical simulations\nshowing a remarkable agreement between the two procedures.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The ability of predicting the future is important for intelligent systems,\ne.g. autonomous vehicles and robots to plan early and make decisions\naccordingly. Future scene parsing and optical flow estimation are two key tasks\nthat help agents better understand their environments as the former provides\ndense semantic information, i.e. what objects will be present and where they\nwill appear, while the latter provides dense motion information, i.e. how the\nobjects will move. In this paper, we propose a novel model to simultaneously\npredict scene parsing and optical flow in unobserved future video frames. To\nour best knowledge, this is the first attempt in jointly predicting scene\nparsing and motion dynamics. In particular, scene parsing enables structured\nmotion prediction by decomposing optical flow into different groups while\noptical flow estimation brings reliable pixel-wise correspondence to scene\nparsing. By exploiting this mutually beneficial relationship, our model shows\nsignificantly better parsing and motion prediction results when compared to\nwell-established baselines and individual prediction models on the large-scale\nCityscapes dataset. In addition, we also demonstrate that our model can be used\nto predict the steering angle of the vehicles, which further verifies the\nability of our model to learn latent representations of scene dynamics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove that if a solution of the time-dependent Schr{\\\"o}dinger equation on\nan homogeneous tree with bounded potential decays fast at two distinct times\nthen the solution is trivial. For the free Schr{\\\"o}dinger operator, we use the\nspectral theory of the Laplacian and complex analysis and obtain a\ncharacterization of the initial conditions that lead to a sharp decay at any\ntime. We then use the recent spectral decomposition of the Schr{\\\"o}dinger\noperator with compactly supported potential due to Colin de Verdi{\\`e}rre and\nTurc to extend our results in the presence of such potentials. Finally, we use\nreal variable methods first introduced by Escauriaza, Kenig, Ponce and Vega to\nestablish a general sharp result in the case of bounded potentials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Electric manipulation of magnetic properties is a key problem of materials\nresearch. To fulfil the requirements of modern electronics, these processes\nmust be shifted to high frequencies. In multiferroic materials this may be\nachieved by electric and magnetic control of their fundamental excitations.\nHere we identify magnetic vibrations in multiferroic iron-borates which are\nsimultaneously sensitive to external electric and magnetic fields. Nearly 100%\nmodulation of the terahertz radiation in an external field is demonstrated for\nSmFe3(BO3)4. High sensitivity can be explained by a modification of the spin\norientation which controls the excitation conditions in multiferroic borates.\nThese experiments demonstrate the possibility to alter terahertz magnetic\nproperties of materials independently by external electric and magnetic fields.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Anticipating future actions is a key component of intelligence, specifically\nwhen it applies to real-time systems, such as robots or autonomous cars. While\nrecent works have addressed prediction of raw RGB pixel values, we focus on\nanticipating the motion evolution in future video frames. To this end, we\nconstruct dynamic images (DIs) by summarising moving pixels through a sequence\nof future frames. We train a convolutional LSTMs to predict the next DIs based\non an unsupervised learning process, and then recognise the activity associated\nwith the predicted DI. We demonstrate the effectiveness of our approach on 3\nbenchmark action datasets showing that despite running on videos with complex\nactivities, our approach is able to anticipate the next human action with high\naccuracy and obtain better results than the state-of-the-art methods.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  3D hand pose estimation from single depth image is an important and\nchallenging problem for human-computer interaction. Recently deep convolutional\nnetworks (ConvNet) with sophisticated design have been employed to address it,\nbut the improvement over traditional random forest based methods is not so\napparent. To exploit the good practice and promote the performance for hand\npose estimation, we propose a tree-structured Region Ensemble Network (REN) for\ndirectly 3D coordinate regression. It first partitions the last convolution\noutputs of ConvNet into several grid regions. The results from separate\nfully-connected (FC) regressors on each regions are then integrated by another\nFC layer to perform the estimation. By exploitation of several training\nstrategies including data augmentation and smooth $L_1$ loss, proposed REN can\nsignificantly improve the performance of ConvNet to localize hand joints. The\nexperimental results demonstrate that our approach achieves the best\nperformance among state-of-the-art algorithms on three public hand pose\ndatasets. We also experiment our methods on fingertip detection and human pose\ndatasets and obtain state-of-the-art accuracy.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Many popular applications use traces of user data to offer various services\nto their users. However, even if user data is anonymized and obfuscated, a\nuser's privacy can be compromised through the use of statistical matching\ntechniques that match a user trace to prior user behavior. In this work, we\nderive the theoretical bounds on the privacy of users in such a scenario. We\nbuild on our recent study in the area of location privacy, in which we\nintroduced formal notions of location privacy for anonymization-based location\nprivacy-protection mechanisms. Here we derive the fundamental limits of user\nprivacy when both anonymization and obfuscation-based protection mechanisms are\napplied to users' time series of data. We investigate the impact of such\nmechanisms on the trade-off between privacy protection and user utility. We\nfirst study achievability results for the case where the time-series of users\nare governed by an i.i.d. process. The converse results are proved both for the\ni.i.d. case as well as the more general Markov chain model. We demonstrate that\nas the number of users in the network grows, the obfuscation-anonymization\nplane can be divided into two regions: in the first region, all users have\nperfect privacy; and, in the second region, no user has privacy.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  M. Hanzer and I. Matic have proved that the genuine unitary principal series\nrepresentations of the metaplectic groups are irreducible. A simple consequence\nof that paper is a criterion for the irreducibility of the non-unitary\nprincipal series representations of the metaplectic groups that we give in this\npaper.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we study the ideal variable bandwidth kernel density estimator\nintroduced by McKay (1993) and Jones, McKay and Hu (1994) and the plug-in\npractical version of the variable bandwidth kernel estimator with two sequences\nof bandwidths as in Gin\\'e and Sang (2013). Based on the bias and variance\nanalysis of the ideal and true variable bandwidth kernel density estimators, we\nstudy the central limit theorems for each of them.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Gamma-Ray Bursts (GRBs) have been traditionally divided into two categories:\n\"short\" and \"long\" with durations less than and greater than two seconds,\nrespectively. However, there is a lot of literature (with conflicting results)\nregarding the existence of a third intermediate class. To investigate this\nissue, we carry out a two-dimensional classification using the GRB hardness and\nduration, and also incorporating the uncertainties in both the variables, by\nusing an extension of Gaussian Mixture Model called Extreme Deconvolution\n(XDGMM). We carry out this analysis on datasets from two detectors, viz. BATSE\nand Fermi-GBM. We consider the duration and hardness features in log-scale for\neach of these datasets and determine the best-fit parameters using XDGMM. This\nis followed by information theoretic criterion-based tests (AIC and BIC) to\ndetermine the optimum number of classes. For BATSE, we find that both AIC and\nBIC show preference for two components with close to decisive and decisive\nsignificance, respectively. For Fermi-GBM, AIC shows preference for three\ncomponents with decisive significance, whereas BIC does not find any\nsignificant difference between two and three components. Our analysis codes\nhave been made publicly available.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Winds from the North-West quadrant and lack of precipitation are known to\nlead to an increase of PM10 concentrations over a residential neighborhood in\nthe city of Taranto (Italy). In 2012 the local government prescribed a\nreduction of industrial emissions by 10% every time such meteorological\nconditions are forecasted 72 hours in advance. Wind forecasting is addressed\nusing the Weather Research and Forecasting (WRF) atmospheric simulation system\nby the Regional Environmental Protection Agency. In the context of\ndistributions-oriented forecast verification, we propose a comprehensive\nmodel-based inferential approach to investigate the ability of the WRF system\nto forecast the local wind speed and direction allowing different performances\nfor unknown weather regimes. Ground-observed and WRF-forecasted wind speed and\ndirection at a relevant location are jointly modeled as a 4-dimensional time\nseries with an unknown finite number of states characterized by homogeneous\ndistributional behavior. The proposed model relies on a mixture of joint\nprojected and skew normal distributions with time-dependent states, where the\ntemporal evolution of the state membership follows a first order Markov\nprocess. Parameter estimates, including the number of states, are obtained by a\nBayesian MCMC-based method. Results provide useful insights on the performance\nof WRF forecasts in relation to different combinations of wind speed and\ndirection.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The young and magnetically active K dwarf Epsilon Eridani exhibits a\nchromospheric activity cycle of about 3 years. Previous reconstructions of its\nlarge-scale magnetic field show strong variations at yearly epochs. To\nunderstand how Epsilon Eridani's large-scale magnetic field geometry evolves\nover its activity cycle we focus on high cadence observations spanning 5 months\nat its activity minimum. Over this timespan we reconstruct 3 maps of Epsilon\nEridani's large-scale magnetic field using the tomographic technique of Zeeman\nDoppler Imaging. The results show that at the minimum of its cycle, Epsilon\nEridani's large-scale field is more complex than the simple dipolar structure\nof the Sun and 61 Cyg A at minimum. Additionally we observe a surprisingly\nrapid regeneration of a strong axisymmetric toroidal field as Epsilon Eridani\nemerges from its S-index activity minimum. Our results show that all stars do\nnot exhibit the same field geometry as the Sun and this will be an important\nconstraint for the dynamo models of active solar-type stars.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A diurnal varying haze layer at the bright spots of Occator on dwarf planet\nCeres has been reported from images of the Dawn Framing Camera. This finding is\nsupported by ground-based observations revealing diurnal albedo changes at\nOccator's longitude. In the present work, we further investigate the previously\nreported haze phenomenon in more detail using additional Framing Camera images.\nWe demonstrate that the light scattering behavior at the central floor of\nOccator is different compared to a typical cerean surface and is likely\ninconsistent with a pure solid surface scatterer. The identified deviation is\nbest explained by an additional component to the scattered light of the\nsurface, i.e., a haze layer. Our results support the water vapor detection by\nHerschel observations though the existence of a tenuous cerean exosphere is not\nyet confirmed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Threshold tests have recently been proposed as a useful method for detecting\nbias in lending, hiring, and policing decisions. For example, in the case of\ncredit extensions, these tests aim to estimate the bar for granting loans to\nwhite and minority applicants, with a higher inferred threshold for minorities\nindicative of discrimination. This technique, however, requires fitting a\ncomplex Bayesian latent variable model for which inference is often\ncomputationally challenging. Here we develop a method for fitting threshold\ntests that is two orders of magnitude faster than the existing approach,\nreducing computation from hours to minutes. To achieve these performance gains,\nwe introduce and analyze a flexible family of probability distributions on the\ninterval [0, 1] -- which we call discriminant distributions -- that is\ncomputationally efficient to work with. We demonstrate our technique by\nanalyzing 2.7 million police stops of pedestrians in New York City.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A measurement is presented of decay-time-dependent $CP$ violation in the\ndecays $B^0\\rightarrow J/\\psi K^0_\\mathrm{S}$ and $B^0\\rightarrow\\psi(2S)\nK^0_\\mathrm{S}$, where the $J/\\psi$ is reconstructed from two electrons and the\n$\\psi(2S)$ from two muons. The analysis uses a sample of $pp$ collision data\nrecorded with the LHCb experiment at centre-of-mass energies of 7 and 8 TeV,\ncorresponding to an integrated luminosity of 3 $\\mathrm{fb}^{-1}$. The\n$CP$-violation observables are measured to be \\begin{equation*} \\begin{aligned}\nC\\left(B^0\\rightarrow J/\\psi\nK^0_\\mathrm{S}\\right)&=\\phantom{+}\\,0.12\\,\\pm\\,0.07\\pm\\,0.02\\,,\nS\\left(B^0\\rightarrow J/\\psi\nK^0_\\mathrm{S}\\right)&=\\phantom{+}\\,0.83\\,\\pm\\,0.08\\pm\\,0.01\\,,\nC\\left(B^0\\rightarrow\\psi(2S)\nK^0_\\mathrm{S}\\right)&=-\\,0.05\\,\\pm\\,0.10\\pm\\,0.01\\,,\nS\\left(B^0\\rightarrow\\psi(2S)\nK^0_\\mathrm{S}\\right)&=\\phantom{+}\\,0.84\\,\\pm\\,0.10\\pm\\,0.01\\,, \\end{aligned}\n\\end{equation*} where $C$ describes $CP$ violation in the direct decay, and $S$\ndescribes $CP$ violation in the interference between the amplitudes for the\ndirect decay and for the decay after $B^0$-$\\overline{B}^0$ oscillation. The\nfirst uncertainties are statistical and the second are systematic. The two sets\nof results are compatible with the previous LHCb measurement using\n$B^0\\rightarrow J/\\psi K^0_\\mathrm{S}$ decays, where the $J/\\psi$ meson was\nreconstructed from two muons. The averages of all three sets of LHCb results\nare \\begin{equation*} \\begin{aligned}\nC\\left(B^0\\rightarrow[c\\bar{c}]K^0_\\mathrm{S}\\right)&=-0.017 \\pm 0.029\\,,\nS\\left(B^0\\rightarrow[c\\bar{c}]K^0_\\mathrm{S}\\right)&=\\phantom{+}0.760 \\pm\n0.034\\,, \\end{aligned} \\end{equation*} under the assumption that higher-order\ncontributions to the decay amplitudes are negligible. The uncertainties include\nstatistical and systematic contributions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In $(k,r)$-Center we are given a (possibly edge-weighted) graph and are asked\nto select at most $k$ vertices (centers), so that all other vertices are at\ndistance at most $r$ from a center. In this paper we provide a number of tight\nfine-grained bounds on the complexity of this problem with respect to various\nstandard graph parameters. Specifically:\n  - For any $r\\ge 1$, we show an algorithm that solves the problem in\n$O^*((3r+1)^{\\textrm{cw}})$ time, where $\\textrm{cw}$ is the clique-width of\nthe input graph, as well as a tight SETH lower bound matching this algorithm's\nperformance. As a corollary, for $r=1$, this closes the gap that previously\nexisted on the complexity of Dominating Set parameterized by $\\textrm{cw}$.\n  - We strengthen previously known FPT lower bounds, by showing that\n$(k,r)$-Center is W[1]-hard parameterized by the input graph's vertex cover (if\nedge weights are allowed), or feedback vertex set, even if $k$ is an additional\nparameter. Our reductions imply tight ETH-based lower bounds. Finally, we\ndevise an algorithm parameterized by vertex cover for unweighted graphs.\n  - We show that the complexity of the problem parameterized by tree-depth is\n$2^{\\Theta(\\textrm{td}^2)}$ by showing an algorithm of this complexity and a\ntight ETH-based lower bound.\n  We complement these mostly negative results by providing FPT approximation\nschemes parameterized by clique-width or treewidth which work efficiently\nindependently of the values of $k,r$. In particular, we give algorithms which,\nfor any $\\epsilon>0$, run in time\n$O^*((\\textrm{tw}/\\epsilon)^{O(\\textrm{tw})})$,\n$O^*((\\textrm{cw}/\\epsilon)^{O(\\textrm{cw})})$ and return a\n$(k,(1+\\epsilon)r)$-center, if a $(k,r)$-center exists, thus circumventing the\nproblem's W-hardness.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Continuous-wave mode-locked femtosecond 2 um solid-state laser with a c-cut\nTm:CaYAlO4 as gain medium was experimentally demonstrated. The mode locked\nlaser generated stable pulses with average output power as high as 531 mW,\npulse duration of 496 fs, and repetition rate of 97 MHz at 1975 nm. The\nresearch results show that Tm:CaYAlO4 is an excellent gain medium for\nfemtosecond pulse generation at 2um wavelength.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report on three-dimensional (3D) electron momentum distributions from\nsingle ionization of helium by a laser pulse consisting of two counterrotating\ncircularly polarized fields (390 nm and 780 nm). A pronounced 3D low energy\nstructure and sub-cycle interferences are observed experimentally and\nreproduced numerically using a trajectory based semi-classical simulation. The\norientation of the low energy structure in the polarization plane is verified\nby numerical simulations solving the time dependent Schr\\\"odinger equation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider the phenomenon of Bose-Einstein condensation of quasi-equilibrium\nmagnons which leads to a spin superfluidity, the coherent quantum transfer of\nmagnetization in magnetic materials. These phenomena are beyond the classical\nLandau-Lifshitz-Gilbert paradigm. The critical conditions for excited magnon\ndensity for ferro- and antiferromagnets, bulk and thin films are estimated and\ndiscussed. The BEC should occur in the antiferromagnetic hematite at much lower\nexcited magnon density compared to the ferromagnetic YIG.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Dirac--Higgs bundle is a hyperholomorphic bundle over the moduli space of\nstable Higgs bundles of coprime rank and degree. We provide an algebraic\ngeneralization to the case of trivial degree and the rank higher than $1$. This\nallow us to generalize to this case the Nahm transform defined by Frejlich and\nthe second named author, which, out of a stable Higgs bundle, produces a vector\nbundle with connection over the moduli space of rank 1 Higgs bundles. By\nperforming the higher rank Nahm transform we obtain a hyperholomorphic bundle\nwith connection over the moduli space of stable Higgs bundles of rank $n$ and\ndegree 0, twisted by the gerbe of liftings of the projective universal bundle.\n  Such hyperholomorphic vector bundles over the moduli space of stable Higgs\nbundles can be seen, in the physicist's language, as BBB-branes twisted by the\nabove mentioned gerbe. We refer to these objects as Nahm branes. Finally, we\nstudy the behaviour of Nahm branes under Fourier--Mukai transform over the\nsmooth locus of the Hitchin fibration, checking that the resulting objects are\nsupported on a Lagrangian multisection of the Hitchin fibration, so they\ndescribe partial data of BAA-branes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The location of radio pulsars in the period-period derivative (P-Pdot) plane\nhas been a key diagnostic tool since the early days of pulsar astronomy. Of\nparticular importance is how pulsars evolve through the P-Pdot diagram with\ntime. Here we show that the decay of the inclination angle (alpha-dot) between\nthe magnetic and rotation axes plays a critical role. In particular, alpha-dot\nstrongly impacts on the braking torque, an effect which has been largely\nignored in previous work. We carry out simulations which include a negative\nalpha-dot term, and show that it is possible to reproduce the observational\nP-Pdot diagram without the need for either pulsars with long birth periods or\nmagnetic field decay. Our best model indicates a birth rate of 1 radio pulsar\nper century and a total Galactic population of ~20000 pulsars beaming towards\nEarth.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A protein is traditionally visualised as a piecewise linear discrete curve,\nand its geometry is conventionally characterised by the extrinsically\ndetermined Ramachandran angles. However, a protein backbone has also two\nindependent intrinsic geometric structures, due to the peptide planes and the\nside chains. Here we adapt and develop modern 3D virtual reality techniques to\nscrutinize the atomic geometry along a protein backbone, in the vicinity of a\npeptide plane. For this we compare backbone geometry-based (extrinsic) and\nstructure-based (intrinsic) coordinate systems, and as an example we inspect\nthe trans and cis peptide planes. We reveal systematics in the way how a cis\npeptide plane deforms the neighbouring atomic geometry, and we develop a\nvirtual reality based visual methodology that can identify the presence of a\ncis peptide plane from the arrangement of atoms in its vicinity. Our approach\ncan easily detect exceptionally placed atoms in crystallographic structures.\nThus it can be employed as a powerful visual refinement tool which is\napplicable also in the case when resolution of the protein structure is limited\nand whenever refinement is needed. As concrete examples we identify a number of\ncrystallographic protein structures in Protein Data Bank (PDB) that display\nexceptional atomic positions around their cis peptide planes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We improve an existing result on exponential quadrilinear sums in the case of\nsums over multiplicative subgroups of a finite field and use it to give a new\nbound on exponential sums with quadrinomials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the behavior of experts who seek to make predictions with\nmaximum impact on an audience. At a known future time, a certain continuous\nrandom variable will be realized. A public prediction gradually converges to\nthe outcome, and an expert has access to a more accurate prediction. We study\nwhen the expert should reveal his information, when his reward is based on a\nproper scoring rule (e.g., is proportional to the change in log-likelihood of\nthe outcome).\n  In Azar et. al. (2016), we analyzed the case where the expert may make a\nsingle prediction. In this paper, we analyze the case where the expert is\nallowed to revise previous predictions. This leads to a rather different set of\ndilemmas for the strategic expert. We find that it is optimal for the expert to\nalways tell the truth, and to make a new prediction whenever he has a new\nsignal. We characterize the expert's expectation for his total reward, and show\nasymptotic limits\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Neutral evolution assumes that there are no selective forces distinguishing\ndifferent variants in a population. Despite this striking assumption, many\nrecent studies have sought to assess whether neutrality can provide a good\ndescription of different episodes of cultural change. One approach has been to\ntest whether neutral predictions are consistent with observed progeny\ndistributions, recording the number of variants that have produced a given\nnumber of new instances within a specified time interval: a classic example is\nthe distribution of baby names. Using an overlapping generations model we show\nthat these distributions consist of two phases: a power law phase with a\nconstant exponent of -3/2, followed by an exponential cut-off for variants with\nvery large numbers of progeny. Maximum likelihood estimations of the model\nparameters provide a direct way to establish whether observed empirical\npatterns are consistent with neutral evolution. We apply our approach to a\ncomplete data set of baby names from Australia. Crucially we show that analyses\nbased on only the most popular variants, as is often the case in studies of\ncultural evolution, can provide misleading evidence for underlying transmission\nhypotheses. While neutrality provides a plausible description of progeny\ndistributions of abundant variants, rare variants deviate from neutrality.\nFurther, we develop a simulation framework that allows for the detection of\nalternative cultural transmission processes. We show that anti-novelty bias is\nable to replicate the complete progeny distribution of the Australian data set.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Clickbait (headlines) make use of misleading titles that hide critical\ninformation from or exaggerate the content on the landing target pages to\nentice clicks. As clickbaits often use eye-catching wording to attract viewers,\ntarget contents are often of low quality. Clickbaits are especially widespread\non social media such as Twitter, adversely impacting user experience by causing\nimmense dissatisfaction. Hence, it has become increasingly important to put\nforward a widely applicable approach to identify and detect clickbaits. In this\npaper, we make use of a dataset from the clickbait challenge 2017\n(clickbait-challenge.com) comprising of over 21,000 headlines/titles, each of\nwhich is annotated by at least five judgments from crowdsourcing on how\nclickbait it is. We attempt to build an effective computational clickbait\ndetection model on this dataset. We first considered a total of 331 features,\nfiltered out many features to avoid overfitting and improve the running time of\nlearning, and eventually selected the 60 most important features for our final\nmodel. Using these features, Random Forest Regression achieved the following\nresults: MSE=0.035 MSE, Accuracy=0.82, and F1-sore=0.61 on the clickbait class.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show the existence of an inertial manifold (i.e. a globally invariant,\nexponentially attracting, finite-dimensional manifold) for the approximate\ndeconvolution model of the 2D mean Boussinesq equations. This model is obtained\nby means of the Van Cittern approximate deconvolution operators, which is\napplied to the 2D filtered Boussinesq equations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Generalized Langevin Equation (GLE) is a Stochastic Integro-Differential\nEquation that is commonly used to describe the velocity of microparticles that\nmove randomly in viscoelastic fluids. Such particles commonly exhibit what is\nknown as anomalous subdiffusion, which is to say that their position\nMean-Squared Displacement (MSD) scales sublinearly with time. While it is\ncommon in the literature to observe that there is a relationship between the\nMSD and the memory structure of the GLE, and there exist special cases where\nexplicit solutions exist, this connection has never been fully characterized.\nHere, we establish a class of memory kernels for which the GLE is well-defined;\nwe investigate the associated regularity properties of solutions; and we prove\nthat large-time asymptotic behavior of the particle MSD is entirely determined\nby the tail behavior of the GLE's memory kernel.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Context: Refactoring is recognized as an effective practice to maintain\nevolving software systems. For software libraries, we study how library\ndevelopers refactor their Application Programming Interfaces (APIs), especially\nwhen it impacts client users by breaking an API of the library. Objective: Our\nwork aims to understand how clients that use a library API are affected by\nrefactoring activities. We target popular libraries that potentially impact\nmore library client users. Method: We distinguish between library APIs based on\ntheir client-usage (refereed to as client-used APIs) in order to understand the\nextent to which API breakages relate to refactorings. Our tool-based approach\nallows for a large-scale study across eight libraries (i.e., totaling 183\nconsecutive versions) with around 900 clients projects. Results: We find that\nlibrary maintainers are less likely to break client-used API classes.\nQuantitatively, we find that refactoring activities break less than 37% of all\nclient-used APIs. In a more qualitative analysis, we show two documented cases\nof where non-refactoring API breaking changes are motivated other maintenance\nissues (i.e., bug fix and new features) and involve more complex refactoring\noperations. Conclusion: Using our automated approach, we find that library\ndevelopers are less likely to break APIs and tend to break client-used APIs\nwhen addressing these maintenance issues.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Complex oxide interfaces are a promising platform for studying a wide array\nof correlated electron phenomena in low-dimensions, including magnetism and\nsuperconductivity. The microscopic origin of these phenomena in complex oxide\ninterfaces remains an open question. Here we investigate for the first time the\nmagnetic properties of semi-insulating NdTiO$_3$/SrTiO$_3$ (NTO/STO) interfaces\nand present the first milli-Kelvin study of NTO/STO. The magnetoresistance (MR)\nreveals signatures of local ferromagnetic order and of spin-dependent\nthermally-activated transport, which are described quantitatively by a simple\nphenomenological model. We discuss possible origins of the interfacial\nferromagnetism. In addition, the MR also shows transient hysteretic features on\na timescale of ~10-100 seconds. We demonstrate that these are consistent with\nan extrinsic magneto-thermal origin, which may have been misinterpreted in\nprevious reports of magnetism in STO-based oxide interfaces. The existence of\nthese two MR regimes (steady-state and transient) highlights the importance of\ntime-dependent measurements for distinguishing signatures of ferromagnetism\nfrom other effects that can produce hysteresis at low temperatures.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the study of Markov chain mixing times, analysis has centered on the\nperformance from a worst-case starting state. Here, in the context of Glauber\ndynamics for the one-dimensional Ising model, we show how new ideas from\ninformation percolation can be used to establish mixing times from other\nstarting states. At high temperatures we show that the alternating initial\ncondition is asymptotically the fastest one, and, surprisingly, its mixing time\nis faster than at infinite temperature, accelerating as the inverse-temperature\n$\\beta$ ranges from 0 to $\\beta_0=\\frac12\\mathrm{arctanh}(\\frac13)$. Moreover,\nthe dominant test function depends on the temperature: at $\\beta<\\beta_0$ it is\nautocorrelation, whereas at $\\beta>\\beta_0$ it is the Hamiltonian.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For a fixed $r$, let $f_r(n)$ denote the minimum number of complete\n$r$-partite $r$-graphs needed to partition the complete $r$-graph on $n$\nvertices. The Graham-Pollak theorem asserts that $f_2(n)=n-1$. An easy\nconstruction shows that $f_r(n) \\leq (1+o(1))\\binom{n}{\\lfloor r/2 \\rfloor}$,\nand we write $c_r$ for the least number such that $f_r(n) \\leq c_r\n(1+o(1))\\binom{n}{\\lfloor r/2 \\rfloor}$.\n  It was known that $c_r < 1$ for each even $r \\geq 4$, but this was not known\nfor any odd value of $r$. In this short note, we prove that $c_{295}<1$. Our\nmethod also shows that $c_r \\rightarrow 0$, answering another open problem.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For a finitely generated group, there are two recent generalizations of the\nnotion of a quasiconvex subgroup of a word-hyperbolic group, namely a stable\nsubgroup and a Morse or strongly quasiconvex subgroup. Durham and Taylor\ndefined stability and proved stability is equivalent to convex cocompactness in\nmapping class groups. Another natural generalization of quasiconvexity is given\nby the notion of a Morse or strongly quasiconvex subgroup of a finitely\ngenerated group, studied recently by Tran and Genevois. In general, a subgroup\nis stable if and only if the subgroup is Morse and hyperbolic. In this paper,\nwe prove that two properties of being Morse and stable coincide for a subgroup\nof infinite index in the mapping class group of an oriented, connected, finite\ntype surface with negative Euler characteristic.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  An essential step to understanding protoplanetary evolution is the study of\ndisks that contain gaps or inner holes. The pretransitional disk around the\nHerbig star HD 169142 exhibits multi-gap disk structure, differentiated gas and\ndust distribution, planet candidates, and near-infrared fading in the past\ndecades, which make it a valuable target for a case study of disk evolution.\nUsing near-infrared interferometric observations with VLTI/PIONIER, we aim to\nstudy the dust properties in the inner sub-au region of the disk in the years\n2011-2013, when the object is already in its near-infrared faint state. We\nfirst performed simple geometric modeling to characterize the size and shape of\nthe NIR-emitting region. We then performed Monte-Carlo radiative transfer\nsimulations on grids of models and compared the model predictions with the\ninterferometric and photometric observations. We find that the observations are\nconsistent with optically thin gray dust lying at Rin ~ 0.07 au, passively\nheated to T ~ 1500 K. Models with sub-micron optically thin dust are excluded\nbecause such dust will be heated to much higher temperatures at similar\ndistance. The observations can also be reproduced with a model consisting of\noptically thick dust at Rin ~ 0.06 au, but this model is plausible only if\nrefractory dust species enduring ~2400 K exist in the inner disk.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We review topics in the theory of cellular automata and dynamical systems\nthat are related to the Moore-Myhill Garden of Eden theorem.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  How can a delivery robot navigate reliably to a destination in a new office\nbuilding, with minimal prior information? To tackle this challenge, this paper\nintroduces a two-level hierarchical approach, which integrates model-free deep\nlearning and model-based path planning. At the low level, a neural-network\nmotion controller, called the intention-net, is trained end-to-end to provide\nrobust local navigation. The intention-net maps images from a single monocular\ncamera and \"intentions\" directly to robot controls. At the high level, a path\nplanner uses a crude map, e.g., a 2-D floor plan, to compute a path from the\nrobot's current location to the goal. The planned path provides intentions to\nthe intention-net. Preliminary experiments suggest that the learned motion\ncontroller is robust against perceptual uncertainty and by integrating with a\npath planner, it generalizes effectively to new environments and goals.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We formulate a coarse-graining approach to the dynamics of\nmagnetohydrodynamic (MHD) fluids at a continuum of length-scales. In this\nmethodology, effective equations are derived for the observable velocity and\nmagnetic fields spatially-averaged at an arbitrary scale of resolution. The\nmicroscopic equations for the bare velocity and magnetic fields are\nrenormalized by coarse-graining to yield macroscopic effective equations that\ncontain both a subscale stress and a subscale electromotive force (EMF)\ngenerated by nonlinear interaction of eliminated fields and plasma motions. At\nlarge coarse-graining length-scales, the direct dissipation of invariants by\nmicroscopic mechanisms (such as molecular viscosity and Spitzer resistivity) is\nshown to be negligible. The balance at large scales is dominated instead by the\nsubscale nonlinear terms, which can transfer invariants across scales, and are\ninterpreted in terms of work concepts for energy and in terms of topological\nflux-linkage for the two helicities. An important application of this approach\nis to MHD turbulence, where the coarse-graining length $\\ell$ lies in the\ninertial cascade range. We show that in the case of sufficiently rough velocity\nand/or magnetic fields, the nonlinear inter-scale transfer need not vanish and\ncan persist to arbitrarily small scales. Although closed expressions are not\navailable for subscale stress and subscale EMF, we derive rigorous upper bounds\non the effective dissipation they produce in terms of scaling exponents of the\nvelocity and magnetic fields. These bounds provide exact constraints on\nphenomenological theories of MHD turbulence in order to allow the nonlinear\ncascade of energy and cross-helicity. On the other hand, we show that the\nforward cascade of magnetic helicity to asymptotically small scales is\nimpossible unless 3rd-order moments of either velocity or magnetic field become\ninfinite.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present analysis of near-infrared, high-resolution spectroscopy towards\nthe Flat-spectrum YSO (Young Stellar Object) ESO H$\\alpha$ 279a (1.5 solar\nmass) in the Serpens star forming region, at the distance of 429 pc. Using the\nImmersion GRating INfrared Spectrometer (IGRINS, R=45,000), we detect emission\nlines originating from the accretion channel flow, jet, and inner disk.\nSpecifically, we identify hydrogen Brackett series recombination, [Fe II], [Fe\nIII], [Fe IV], Ca I, Na I, H2, H2O and CO overtone emission lines. By modeling\nfive bands of CO overtone emission lines, and the symmetric double-peaked line\nprofile for Na I emission lines, we find that ESO H$\\alpha$ 279a has an\nactively accreting Keplerian disk. From our Keplerian disk model, we find that\nNa I emission lines originate between 0.04 AU and 1.00 AU, while CO overtone\nemission lines are from the outer part of disk, in the range between 0.22 AU\nand 3.00 AU. It reveals that the neutral atomic Na gas is a good tracer of the\ninnermost region of the actively accreting disk. We derive a mass accretion\nrate of 2-10x10^{-7} M_solar/yr from the measured Br_gamma emission luminosity\nof 1.78(+-0.31)x10^{31} erg/s.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper explains the periodicity of the Grover walk on finite graphs. We\ncharacterize the graphs to induce 2, 3, 4, 5-periodic Grover walk and obtain a\nnecessary condition of the graphs to induce an odd-periodic Grover walk.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A shadowable point for a flow is a point where the shadowing lemma holds for\npseudo-orbits passing through it. We prove that this concept satisfies the\nfollowing properties: the set of shadowable points is invariant and a\n$G_{\\delta}$ set. A flow has the pseudo-orbit tracing property if and only if\nevery point is shadowable. The chain recurrent and nonwandering sets coincide\nwhen every chain recurrent point is shadowable. The chain recurrent points\nwhich are shadowable are exactly those that can be are approximated by periodic\npoints when the flow is expansive. We study the relations between shadowable\npoints of a homeomorphism and the shadowable points of its suspension flow. We\ncharacterize the set of forward shadowable points for transitive flows and\nchain transitive flows. We prove that the geometric Lorenz attractor does not\nhave shadowable points. We show that in the presence of shadowable points chain\ntransitive flows are transitive and that transitivity is a necessary condition\nfor chain recurrent flows with shadowable points whenever the phase space is\nconnected. Finally, as an application these results we give concise proofs of\nsome well known theorems establishing that flows with POTP admitting some kind\nof recurrence are minimal. These results extends those presented in [10].\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Since the discovery of the accelerated expansion of the Universe, the\nconstraints on the equation of state $w_\\text{DE}$ of dark energy, the\nstress-energy component responsible for the acceleration, have tightened\nsignificantly. These constraints generally assume an equation of state that is\nslowly varying in time. We argue that there is good theoretical motivation to\nconsider \"monodromic\" scenarios with periodic modulations of the dark energy\npotential. We provide a simple parametrization of such models, and show that\nthese leave room for significant, periodic departures of $w_\\text{DE}$ from -1.\nMoreover, simple models with non-standard kinetic term result in interesting\nlarge-scale structure phenomenology beyond that of standard slow-roll dark\nenergy. All these scenarios are best constrained in a dedicated search, as\ncurrent analyses average over relatively wide redshift ranges.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove the explicit formula for sofic and Rokhlin entropy of actions\narising from some class of Gibbs measures. It provides a new set of examples\nwith sofic entropy independent of sofic approximations. It is particularilly\ninterresting, since in non-amenable case Rokhlin entropy was computed only in\ncase of Bernoulli actions and for some examples with zero Rokhlin entropy. As\nan example we show that our formula holds for the supercritical Ising model. We\nalso establish a criterion for uniqueness of Gibbs measure by means of\nf-invariant.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given a vector bundle $V$ over a curve $X$, we define and study a surjective\nrational map $\\mathrm{Hilb}^d (\\mathbb{P} V ) - \\mathrm{Quot}^{0, d} ( V^* )$\ngeneralising the natural map $\\mathrm{Sym}^d X \\to \\mathrm{Quot}^{0, d}\n({\\mathcal O}_X)$. We then give a generalisation of the geometric Riemann--Roch\ntheorem to vector bundles of higher rank over $X$. We use this to give a\ngeometric description of the tangent cone to the Brill--Noether locus $B^r_{r,\nd}$ at a suitable bundle $E$ with $h^0 (E) = r+n$. This gives a generalisation\nof the Riemann--Kempf singularity theorem. As a corollary, we show that the\n$n$th secant variety of the rank one locus of $\\mathbb{P} \\mathrm{End} E$ is\ncontained in the tangent cone.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the Grassmann manifold $G_k$ of all $k$-dimensional subspaces of\n${\\mathbb R}^n$. The Cartan embedding $G_k\\subset O(n)$ realizes $G_k$ as a\nsubspace of $Sl_n({\\mathbb R})$ and we study the decomposition $G_k=\\coprod_w\n(BwB\\cap G_k)$ inherited from the classical Bruhat decomposition. We prove that\nthis defines a CW structure on $G_k$ and determine the incidence numbers\nbetween cells.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The product moment covariance is a cornerstone of multivariate data analysis,\nfrom which one can derive correlations, principal components, Mahalanobis\ndistances and many other results. Unfortunately the product moment covariance\nand the corresponding Pearson correlation are very susceptible to outliers\n(anomalies) in the data. Several robust measures of covariance have been\ndeveloped, but few are suitable for the ultrahigh dimensional data that are\nbecoming more prevalent nowadays. For that one needs methods whose computation\nscales well with the dimension, are guaranteed to yield a positive semidefinite\ncovariance matrix, and are sufficiently robust to outliers as well as\nsufficiently accurate in the statistical sense of low variability. We construct\nsuch methods using data transformations. The resulting approach is simple, fast\nand widely applicable. We study its robustness by deriving influence functions\nand breakdown values, and computing the mean squared error on contaminated\ndata. Using these results we select a method that performs well overall. This\nalso allows us to construct a faster version of the DetectDeviatingCells method\n(Rousseeuw and Van den Bossche, 2018) to detect cellwise outliers, that can\ndeal with much higher dimensions. The approach is illustrated on genomic data\nwith 12,000 variables and color video data with 920,000 dimensions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a conditionally integrable potential, belonging to the\nbi-confluent Heun class, for which the Schr\\\"odinger equation is solved in\nterms of the confluent hypergeometric functions. The potential involves an\nattractive inverse square root term with arbitrary strength and a repulsive\ncentrifugal barrier core with the strength fixed to a constant. This is a\npotential well defined on the half-axis. Each of the fundamental solutions\ncomposing the general solution of the Schr\\\"odinger equation is written as an\nirreducible linear combination, with non-constant coefficients, of two\nconfluent hypergeometric functions. We present the explicit solution in terms\nof the non-integer order Hermite functions of scaled and shifted argument and\ndiscuss the bound states supported by the potential. We derive the exact\nequation for the energy spectrum and approximate that by a highly accurate\ntranscendental equation involving trigonometric functions. Finally, we\nconstruct an accurate approximation for the bound-state energy levels.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Pre-exposure prophylaxis (PrEP) consists in the use of an antiretroviral\nmedication to prevent the acquisition of HIV infection by uninfected\nindividuals and has recently demonstrated to be highly efficacious for HIV\nprevention. We propose a new epidemiological model for HIV/AIDS transmission\nincluding PrEP. Existence, uniqueness and global stability of the disease free\nand endemic equilibriums are proved. The model with no PrEP is calibrated with\nthe cumulative cases of infection by HIV and AIDS reported in Cape Verde from\n1987 to 2014, showing that it predicts well such reality. An optimal control\nproblem with a mixed state control constraint is then proposed and analyzed,\nwhere the control function represents the PrEP strategy and the mixed\nconstraint models the fact that, due to PrEP costs, epidemic context and\nprogram coverage, the number of individuals under PrEP is limited at each\ninstant of time. The objective is to determine the PrEP strategy that satisfies\nthe mixed state control constraint and minimizes the number of individuals with\npre-AIDS HIV-infection as well as the costs associated with PrEP. The optimal\ncontrol problem is studied analytically. Through numerical simulations, we\ndemonstrate that PrEP reduces HIV transmission significantly.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We develop a powerful new analytic method to construct complete non-compact\nG2-manifolds, i.e. Riemannian 7-manifolds (M,g) whose holonomy group is the\ncompact exceptional Lie group G2. Our construction starts with a complete\nnon-compact asymptotically conical Calabi-Yau 3-fold B and a circle bundle M\nover B satisfying a necessary topological condition. Our method then produces a\n1-parameter family of circle-invariant complete G2-metrics on M that collapses\nto the original Calabi-Yau metric on the base B as the parameter converges to\n0. The G2-metrics we construct have controlled asymptotic geometry at infinity,\nso-called asymptotically locally conical (ALC) metrics, and are the natural\nhigher-dimensional analogues of the ALF metrics that are well known in\n4-dimensional hyperk\\\"ahler geometry. We give two illustrations of the strength\nof our method. Firstly we use it to construct infinitely many diffeomorphism\ntypes of complete non-compact simply connected G2-manifolds; previously only a\nhandful of such diffeomorphism types was known. Secondly we use it to prove the\nexistence of continuous families of complete non-compact G2-metrics of\narbitrarily high dimension; previously only rigid or 1-parameter families of\ncomplete non-compact G2-metrics were known.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We use the linear sigma model with quarks to study the QCD phase diagram from\nthe point of view of chiral symmetry restoration. We compute the leading order\neffective potential for high and low temperatures and finite quark chemical\npotential, up to the contribution of the ring diagrams to account for the\nplasma screening effects. We fix the values of the model couplings using\nphysical values for the input parameters such as the vacuum pion and sigma\nmasses, the critical temperature at vanishing quark chemical potential and the\nconjectured end point value of the baryon chemical potential of the transition\nline at vanishing temperature. We also make the analysis for the same input\nparameters but with vanishing pion mass. We find that the critical end point\n(CEP) is located at low temperatures and high quark chemical potentials\n$(315<\\mu^{\\text{CEP}}<349\\ MeV,18< T^{\\text{CEP}}<45\\ MeV)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A robot that can carry out a natural-language instruction has been a dream\nsince before the Jetsons cartoon series imagined a life of leisure mediated by\na fleet of attentive robot helpers. It is a dream that remains stubbornly\ndistant. However, recent advances in vision and language methods have made\nincredible progress in closely related areas. This is significant because a\nrobot interpreting a natural-language navigation instruction on the basis of\nwhat it sees is carrying out a vision and language process that is similar to\nVisual Question Answering. Both tasks can be interpreted as visually grounded\nsequence-to-sequence translation problems, and many of the same methods are\napplicable. To enable and encourage the application of vision and language\nmethods to the problem of interpreting visually-grounded navigation\ninstructions, we present the Matterport3D Simulator -- a large-scale\nreinforcement learning environment based on real imagery. Using this simulator,\nwhich can in future support a range of embodied vision and language tasks, we\nprovide the first benchmark dataset for visually-grounded natural language\nnavigation in real buildings -- the Room-to-Room (R2R) dataset.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In Valiant's model of evolution, a class of representations is evolvable iff\na polynomial-time process of random mutations guided by selection converges\nwith high probability to a representation as $\\epsilon$-close as desired from\nthe optimal one, for any required $\\epsilon>0$. Several previous positive\nresults exist that can be related to evolving a vector space, but each former\nresult imposes disproportionate representations or restrictions on\n(re)initialisations, distributions, performance functions and/or the mutator.\nIn this paper, we show that all it takes to evolve a normed vector space is\nmerely a set that generates the space. Furthermore, it takes only\n$\\tilde{O}(1/\\epsilon^2)$ steps and it is essentially stable, agnostic and\nhandles target drifts that rival some proven in fairly restricted settings. Our\nalgorithm can be viewed as a close relative to a popular fifty-years old\ngradient-free optimization method for which little is still known from the\nconvergence standpoint: Nelder-Mead simplex method.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present an algorithmic embedded desingularization of arithmetic surfaces\nbearing in mind implementability. Our algorithm is based on work by\nCossart-Jannsen-Saito, though our variant uses a refinement of the order\ninstead of the Hilbert-Samuel function as a measure for the complexity of the\nsingularity. We particularly focus on aspects arising when working in mixed\ncharacteristics. Furthermore, we exploit the algorithm's natural parallel\nstructure rephrasing it in terms of Petri nets for use in the parallelization\nenvironment GPI-Space with {\\sc Singular} as computational back-end.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Americans with Disabilities Act (ADA) mandates that U.S. institutions of\nhigher education provide \"reasonable accommodations\" to students with\ndisabilities to ensure equal educational opportunities. However, despite the\nkey role of physics as a gateway to Science, Technology, Engineering and\nMathematics (STEM) studies, only limited resources exist for teaching physics\nto students who are blind or visually impaired. Here we share lessons from our\nexperience creating an accessible physics curriculum for a blind physics major.\nThe authors include the student himself, a blind physics B.S. who graduated\nfrom a different institution, a PhD chemist and consultant on STEM\naccessibility who is himself blind, and several sighted educators and course\nassistants who worked regularly with the students. Throughout this effort, we\nlearned that many of the principles of universal design described herein\nenhanced learning for all of our students.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Ultracold quantum gases provide a unique setting for studying and\nunderstanding the properties of interacting quantum systems. Here, we\ninvestigate a multi-component system of $^{87}$Rb--$^{39}$K Bose-Einstein\ncondensates (BECs) with tunable interactions both theoretically and\nexperimentally. Such multi-component systems can be characterized by their\nmiscibility, where miscible components lead to a mixed ground state and\nimmiscible components form a phase-separated state. Here we perform the first\nfull simulation of the dynamical expansion of this system including both BECs\nand thermal clouds, which allows for a detailed comparison with experimental\nresults. In particular we show that striking features emerge in time-of-flight\nfor BECs with strong interspecies repulsion, even for systems which were\nseparated in situ by a large gravitational sag. An analysis of the center of\nmass positions of the BECs after expansion yields qualitative agreement with\nthe homogeneous criterion for phase-separation, but reveals no clear transition\npoint between the mixed and the separated phases. Instead one can identify a\ntransition region, for which the presence of a gravitational sag is found to be\nadvantageous. Moreover we analyze the situation where only one component is\ncondensed and show that the density distribution of the thermal component also\nshow some distinct features. Our work sheds new light on the analysis of\nmulti-component systems after time-of-flight and will guide future experiments\non the detection of miscibility in these systems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A systematic review is made for the AA-, AB- and ABC-stacked graphites. The\ngeneralized tight-binding model, accompanied with the effective-mass\napproximation and the Kubo formula, is developed to investigate electronic and\noptical properties in the presence/absence of a uniform magnetic field. The\nunusual electronic properties cover the stacking-dependent Dirac-cone\nstructures, the significant energy widths along the stacking direction, the\nLandau subbands (LSs) crossing the Fermi level, the $B_0$-dependent LS energy\nspectra with crossings and anti-crossings, and the monolayer- or bilayer-like\nLandau wavefunctions. There exist the configuration-created special structures\nin density of states and optical spectra. Three kinds of graphites quite differ\nfrom one another in the available inter-LS excitation channels, including the\nnumber, frequency, intensity and structures of absorption peaks. The\ndimensional crossover presents the main similarities and differences between\ngraphites and graphenes; furthermore, the quantum confinement enriches the\nmagnetic quantization phenomena in carbon nanotubes and graphene nanoribbons.\nThe cooperative/competitive relations among the interlayer atomic interactions,\ndimensions and magnetic quantization are responsible for the diversified\nessential properties. Part of theoretical predictions are consistent with the\nexperimental measurements.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  High-accuracy absolute proper motions, radial velocities, and distances have\nnow been measured for a number of dwarf-galaxy companions of the Milky Way,\nmaking it possible to study their 3D dynamics. Galactic orbits for 11 such\ngalaxies (Fornax, Sagittarius, Ursa Minor, LMC, SMC, Sculptor, Sextans, Carina,\nDraco, Leo I, Leo II) have been derived using two previously refined models for\nthe Galactic potential with the Navarro-Frenk-White and Allen-Santill'an\nexpressions for the potential of the dark-matter halo, and two different masses\nfor the Galaxy within 200 kpc - 0.75x10^12 Mo and 1.45x10^12 Mo. The character\nof the orbits of most of these galaxies indicates that they are tightly\ngravitationally bound to the Milky Way, even with the lower-mass model for the\ngravitational potential. One exception is the most distant galaxy in the list,\nLeo I, whose orbit demonstrates that it is only weakly gravitationally bound,\neven using the higher-mass model of the gravitational potential.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We define a function, called s-multiplicity, that interpolates between\nHilbert-Samuel multiplicity and Hilbert-Kunz multiplicity by comparing powers\nof ideals to the Frobenius powers of ideals. The function is continuous in s,\nand its value is equal to Hilbert-Samuel multiplicity for small values of s and\nis equal to Hilbert-Kunz multiplicity for large values of s. We prove that it\nhas an Associativity Formula generalizing the Associativity Formulas for\nHilbert-Samuel and Hilbert-Kunz multiplicity. We also define a family of\nclosures such that if two ideals have the same s-closure then they have the\nsame s-multiplicity, and the converse holds under mild conditions. We describe\nthe s-multiplicity of monomial ideals in toric rings as a certain volume in\nreal space\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The detailed mathematical study of the recent paper by Sajjadi, Hunt and\nDrullion (2014) is pre- sented. The mathematical developement considered by\nthem, for unsteady growing monochro- matic waves is also extended to Stokes\nwaves. The present contribution also demonstrates agree- ment with the\npioneering work of Belcher and Hunt (1993) which is valid in the limit of the\ncomplex part of the wave phase speed \\c_i \\downarrow 0. It is further shown\nthat the energy-transfer parameter and the surface shear stress for a Stokes\nwave reverts to a monochromatic wave when the second harmonic is excluded.\nFurthermore, the present theory can be used to estimate the amount of energy\ntransferred to each component of nonlinear surface waves on deep water from a\nturbulent shear flow blowing over it. Finally, it is demonstrated that in the\npresence of turbulent eddy viscosity the Miles (1957) critical layer does not\nplay an important role. Thus, it is concluded that in the limit of zero growth\nrate the effect of the wave growth arises from the elevated critical layer by\nfinite turbulent diffusivity, so that the perturbed flow and the drag force is\ndetermined by the asymmetric and sheltering flow in the surface shear layer and\nits matched interaction with the upper region.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Ocean wave energy is a new renewable energy resource which is going to become\none of the reliable and alternative resources for fossil fuels during recent\ndecades. The majority of studies have focused on extract wave energy at an\neffective rate; whilst, there are a few studies to explore the hydrodynamic of\nwave and surge wave energy converters. In this study a 2D numerical model based\non RANS equations is closured with SST turbulence model employed to simulate\nthe hydrodynamic of the flap type wave energy devices. The results indicate\nthat a partially standing wave induced by the interaction of incident and\nreflected waves occurs in front of device due to its rotating movements.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Inspired by classic generative adversarial networks (GAN), we propose a novel\nend-to-end adversarial neural network, called SegAN, for the task of medical\nimage segmentation. Since image segmentation requires dense, pixel-level\nlabeling, the single scalar real/fake output of a classic GAN's discriminator\nmay be ineffective in producing stable and sufficient gradient feedback to the\nnetworks. Instead, we use a fully convolutional neural network as the segmentor\nto generate segmentation label maps, and propose a novel adversarial critic\nnetwork with a multi-scale $L_1$ loss function to force the critic and\nsegmentor to learn both global and local features that capture long- and\nshort-range spatial relationships between pixels. In our SegAN framework, the\nsegmentor and critic networks are trained in an alternating fashion in a\nmin-max game: The critic takes as input a pair of images, (original_image $*$\npredicted_label_map, original_image $*$ ground_truth_label_map), and then is\ntrained by maximizing a multi-scale loss function; The segmentor is trained\nwith only gradients passed along by the critic, with the aim to minimize the\nmulti-scale loss function. We show that such a SegAN framework is more\neffective and stable for the segmentation task, and it leads to better\nperformance than the state-of-the-art U-net segmentation method. We tested our\nSegAN method using datasets from the MICCAI BRATS brain tumor segmentation\nchallenge. Extensive experimental results demonstrate the effectiveness of the\nproposed SegAN with multi-scale loss: on BRATS 2013 SegAN gives performance\ncomparable to the state-of-the-art for whole tumor and tumor core segmentation\nwhile achieves better precision and sensitivity for Gd-enhance tumor core\nsegmentation; on BRATS 2015 SegAN achieves better performance than the\nstate-of-the-art in both dice score and precision.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Fusing satellite observations and station measurements to estimate\nground-level PM2.5 is promising for monitoring PM2.5 pollution. A\ngeo-intelligent approach, which incorporates geographical correlation into an\nintelligent deep learning architecture, is developed to estimate PM2.5.\nSpecifically, it considers geographical distance and spatiotemporally\ncorrelated PM2.5 in a deep belief network (denoted as Geoi-DBN). Geoi-DBN can\ncapture the essential features associated with PM2.5 from latent factors. It\nwas trained and tested with data from China in 2015. The results show that\nGeoi-DBN performs significantly better than the traditional neural network. The\ncross-validation R increases from 0.63 to 0.94, and RMSE decreases from 29.56\nto 13.68${\\mu}$g/m3. On the basis of the derived PM2.5 distribution, it is\npredicted that over 80% of the Chinese population live in areas with an annual\nmean PM2.5 of greater than 35${\\mu}$g/m3. This study provides a new perspective\nfor air pollution monitoring in large geographic regions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Deep Neural Networks (DNNs) often struggle with one-shot learning where we\nhave only one or a few labeled training examples per category. In this paper,\nwe argue that by using side information, we may compensate the missing\ninformation across classes. We introduce two statistical approaches for fusing\nside information into data representation learning to improve one-shot\nlearning. First, we propose to enforce the statistical dependency between data\nrepresentations and multiple types of side information. Second, we introduce an\nattention mechanism to efficiently treat examples belonging to the\n'lots-of-examples' classes as quasi-samples (additional training samples) for\n'one-example' classes. We empirically show that our learning architecture\nimproves over traditional softmax regression networks as well as\nstate-of-the-art attentional regression networks on one-shot recognition tasks.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Second-Harmonic Scatteringh (SHS) experiments provide a unique approach to\nprobe non-centrosymmetric environments in aqueous media, from bulk solutions to\ninterfaces, living cells and tissue. A central assumption made in analyzing SHS\nexperiments is that the each molecule scatters light according to a constant\nmolecular hyperpolarizability tensor $\\boldsymbol{\\beta}^{(2)}$. Here, we\ninvestigate the dependence of the molecular hyperpolarizability of water on its\nenvironment and internal geometric distortions, in order to test the hypothesis\nof constant $\\boldsymbol{\\beta}^{(2)}$. We use quantum chemistry calculations\nof the hyperpolarizability of a molecule embedded in point-charge environments\nobtained from simulations of bulk water. We demonstrate that both the\nheterogeneity of the solvent configurations and the quantum mechanical\nfluctuations of the molecular geometry introduce large variations in the\nnon-linear optical response of water. This finding has the potential to change\nthe way SHS experiments are interpreted: in particular, isotopic differences\nbetween H$_2$O and D$_2$O could explain recent second-harmonic scattering\nobservations. Finally, we show that a simple machine-learning framework can\npredict accurately the fluctuations of the molecular hyperpolarizability. This\nmodel accounts for the microscopic inhomogeneity of the solvent and represents\na first step towards quantitative modelling of SHS experiments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose an explicit mathematical construction and plausibility arguments\nfor how spacetime chirality and Lorentz generators emerge for minimal,\noff-shell 4D, $\\cal N$ = 1 supermultiplets by use of a 4.4.4.4 tesselation of\nRiemann surfaces based on plaquettes originating from Coxeter Group BC${}_4$\nadinkras.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  There is a long-standing belief that the modular tensor categories\n$\\mathcal{C}(\\mathfrak{g},k)$, for $k\\in\\mathbb{Z}_{\\geq1}$ and\nfinite-dimensional simple complex Lie algebras $\\mathfrak{g}$, contain\nexceptional connected \\'etale algebras at only finitely many levels $k$. This\npremise has known implications for the study of relations in the Witt group of\nnondegenerate braided fusion categories, modular invariants of conformal field\ntheories, and the classification of subfactors in the theory of von Neumann\nalgebras. Here we confirm this conjecture when $\\mathfrak{g}$ has rank 2,\ncontributing proofs and explicit bounds when $\\mathfrak{g}$ is of type $B_2$ or\n$G_2$, adding to the previously known positive results for types $A_1$ and\n$A_2$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given an $n \\times d$ matrix $A$, its Schatten-$p$ norm, $p \\geq 1$, is\ndefined as $\\|A\\|_p = \\left (\\sum_{i=1}^{\\textrm{rank}(A)}\\sigma_i(A)^p \\right\n)^{1/p}$, where $\\sigma_i(A)$ is the $i$-th largest singular value of $A$.\nThese norms have been studied in functional analysis in the context of\nnon-commutative $\\ell_p$-spaces, and recently in data stream and linear\nsketching models of computation. Basic questions on the relations between these\nnorms, such as their embeddability, are still open. Specifically, given a set\nof matrices $A^1, \\ldots, A^{\\operatorname{poly}(nd)} \\in \\mathbb{R}^{n \\times\nd}$, suppose we want to construct a linear map $L$ such that $L(A^i) \\in\n\\mathbb{R}^{n' \\times d'}$ for each $i$, where $n' \\leq n$ and $d' \\leq d$, and\nfurther, $\\|A^i\\|_p \\leq \\|L(A^i)\\|_q \\leq D_{p,q} \\|A^i\\|_p$ for a given\napproximation factor $D_{p,q}$ and real number $q \\geq 1$. Then how large do\n$n'$ and $d'$ need to be as a function of $D_{p,q}$?\n  We nearly resolve this question for every $p, q \\geq 1$, for the case where\n$L(A^i)$ can be expressed as $R \\cdot A^i \\cdot S$, where $R$ and $S$ are\narbitrary matrices that are allowed to depend on $A^1, \\ldots, A^t$, that is,\n$L(A^i)$ can be implemented by left and right matrix multiplication. Namely,\nfor every $p, q \\geq 1$, we provide nearly matching upper and lower bounds on\nthe size of $n'$ and $d'$ as a function of $D_{p,q}$. Importantly, our upper\nbounds are {\\it oblivious}, meaning that $R$ and $S$ do not depend on the\n$A^i$, while our lower bounds hold even if $R$ and $S$ depend on the $A^i$. As\nan application of our upper bounds, we answer a recent open question of Blasiok\net al. about space-approximation trade-offs for the Schatten $1$-norm, showing\nin a data stream it is possible to estimate the Schatten-$1$ norm up to a\nfactor of $D \\geq 1$ using $\\tilde{O}(\\min(n,d)^2/D^4)$ space.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The goal of nuSTORM is to provide well-defined neutrino beams for precise\nmeasurements of neutrino cross-sections and oscillations. The nuSTORM decay\nring is a compact racetrack storage ring with a circumference of ~480 m that\nincorporates large aperture (60 cm diameter) magnets. There are many challenges\nin the design. In order to incorporate the Orbit Combination Section (OCS),\nused for injecting the pion beam into the ring, a dispersion suppressor is\nneeded adjacent to the OCS. Concurrently, in order to maximize the number of\nuseful muon decays, strong bending dipoles are needed in the arcs to minimize\nthe arc length. These dipoles create strong chromatic effects, which need to be\ncorrected by nonlinear sextupole elements in the ring. In this paper, a FODO\nracetrack ring design and its optimization using sextupolar fields via both a\nGenetic Algorithm (GA) and a Simulated Annealing (SA) algorithm will be\ndiscussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Current recommender systems exploit user and item similarities by\ncollaborative filtering. Some advanced methods also consider the temporal\nevolution of item ratings as a global background process. However, all prior\nmethods disregard the individual evolution of a user's experience level and how\nthis is expressed in the user's writing in a review community. In this paper,\nwe model the joint evolution of user experience, interest in specific item\nfacets, writing style, and rating behavior. This way we can generate individual\nrecommendations that take into account the user's maturity level (e.g.,\nrecommending art movies rather than blockbusters for a cinematography expert).\nAs only item ratings and review texts are observables, we capture the user's\nexperience and interests in a latent model learned from her reviews, vocabulary\nand writing style. We develop a generative HMM-LDA model to trace user\nevolution, where the Hidden Markov Model (HMM) traces her latent experience\nprogressing over time -- with solely user reviews and ratings as observables\nover time. The facets of a user's interest are drawn from a Latent Dirichlet\nAllocation (LDA) model derived from her reviews, as a function of her (again\nlatent) experience level. In experiments with five real-world datasets, we show\nthat our model improves the rating prediction over state-of-the-art baselines,\nby a substantial margin. We also show, in a use-case study, that our model\nperforms well in the assessment of user experience levels.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Searches of neutrinoless double-beta decay require information on the value\nof the nuclear matrix elements that rule the process to plan and interpret\nexperiments. At present, however, even the matrix elements obtained with the\nmost reliable many-body approaches do not agree to each other better than a\nfactor two or three. A usual test of the many-body calculations is the\ncomparison to several nuclear observables, but so far no nuclear structure\nproperty has been found to show a good correlation to neutrinoless double-beta\ndecay. Here we propose that double charge-exchange experiments can offer a very\nvaluable tool to provide insights on neutrinoless double-beta decay. Double\ncharge-exchange reactions are being currently performed in various laboratories\nworldwide and aim to find the novel nuclear collectivity given by double\nGamow-Teller excitations. Our results suggest a good linear correlation between\ndouble Gamow-Teller transitions to the ground state of the final nucleus and\nneutrinoless double-beta decay nuclear matrix elements. The correlation seems\nrobust across $pf$-shell nuclei.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Linear regression is a fundamental and popular statistical method. There are\nvarious kinds of linear regression, such as mean regression and quantile\nregression. In this paper, we propose a new one called distribution regression,\nwhich allows broad-spectrum of the error distribution in the linear regression.\nOur method uses nonparametric technique to estimate regression parameters. Our\nstudies indicate that our method provides a better alternative than mean\nregression and quantile regression under many settings, particularly for\nasymmetrical heavy-tailed distribution or multimodal distribution of the error\nterm. Under some regular conditions, our estimator is $\\sqrt n$-consistent and\npossesses the asymptotically normal distribution. The proof of the asymptotic\nnormality of our estimator is very challenging because our nonparametric\nlikelihood function cannot be transformed into sum of independent and\nidentically distributed random variables. Furthermore, penalized likelihood\nestimator is proposed and enjoys the so-called oracle property with diverging\nnumber of parameters. Numerical studies also demonstrate the effectiveness and\nthe flexibility of the proposed method.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Determining unknotting numbers is a large and widely studied problem. We\nconsider the more general question of the unknotting number of a spatial graph.\nWe show the unknotting number of spatial graphs is subadditive. Let $g$ be an\nembedding of a planar graph $G$, then we show $u(g) \\geq \\max\\{u(s) |$ $s$ is a\nnon-overlapping set of constituents of $g\\}$.\n  Focusing on $\\theta$-curves, we determine the exact unknotting numbers of the\n$\\theta$-curves in the Litherland-Moriuchi Table. Additionally, we demonstrate\nunknotting crossing changes for all of the curves. In doing this we introduce\nnew methods for obstructing unknotting number $1$ in $\\theta$-curves.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose and experimentally demonstrate a photonic routing architecture\nthat can efficiently utilize the space of multi-plane (3D) photonic\nintegration. A wafer with three planes of amorphous silicon waveguides was\nfabricated and characterized, demonstrating $<3\\times10^{-4}$ dB loss per\nout-of-plane waveguide crossing, $0.05 \\pm 0.02 $ dB per interplane coupler,\nand microring resonators on three planes with a quality factors up to $8.2\n\\times 10^{4}$. We also explore a phase velocity mapping strategy to mitigate\nthe crosstalk between co-propagating waveguides on different planes. These\nresults expand the utility of 3D photonic integration for applications such as\noptical interconnects, neuromorphic computing and optical phased arrays.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Graph burning is one model for the spread of memes and contagion in social\nnetworks. The corresponding graph parameter is the burning number of a graph\n$G$, written $b(G)$, which measures the speed of the social contagion. While it\nis conjectured that the burning number of a connected graph of order $n$ is at\nmost $\\lceil \\sqrt{n} \\rceil$, this remains open in general and in many graph\nfamilies. We prove the conjectured bound for spider graphs, which are trees\nwith exactly one vertex of degree at least 3. To prove our result for spiders,\nwe develop new bounds on the burning number for path-forests, which in turn\nleads to a $\\frac 3 2$-approximation algorithm for computing the burning number\nof path-forests.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we show that the popular K-means clustering problem can\nequivalently be reformulated as a conic program of polynomial size. The arising\nconvex optimization problem is NP-hard, but amenable to a tractable\nsemidefinite programming (SDP) relaxation that is tighter than the current SDP\nrelaxation schemes in the literature. In contrast to the existing schemes, our\nproposed SDP formulation gives rise to solutions that can be leveraged to\nidentify the clusters. We devise a new approximation algorithm for K-means\nclustering that utilizes the improved formulation and empirically illustrate\nits superiority over the state-of-the-art solution schemes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  X-ray absorption spectra calculated within an effective one-electron approach\nhave to be broadened to account for the finite lifetime of the core hole. For\nGreen's function based methods this can be achieved either by adding a small\nimaginary part to the energy or by convoluting the spectra on the real axis\nwith a Lorentzian. We demonstrate on the case of Fe K and L2,3 spectra that\nthese procedures lead to identical results only for energies higher than few\ncore level widths above the absorption edge. For energies close to the edge,\nspurious spectral features may appear if too much weight is put on broadening\nvia the imaginary energy component. Special care should be taken for dichroic\nspectra at edges which comprise several exchange-split core levels, such as the\nL3 edge of 3d transition metals.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Large industrial systems that combine services and applications, have become\ntargets for cyber criminals and are challenging from the security, monitoring\nand auditing perspectives. Security log analysis is a key step for uncovering\nanomalies, detecting intrusion, and enabling incident response. The constant\nincrease of link speeds, threats and users, produce large volumes of log data\nand become increasingly difficult to analyse on a Central Processing Unit\n(CPU). This paper presents a massively parallel Graphics Processing Unit (GPU)\nLOg Processing (GLoP) library and can also be used for Deep Packet Inspection\n(DPI), using a prefix matching technique, harvesting the full power of\noff-the-shelf technologies. GLoP implements two different algorithm using\ndifferent GPU memory and is compared against CPU counterpart implementations.\nThe library can be used for processing nodes with single or multiple GPUs as\nwell as GPU cloud farms. The results show throughput of 20Gbps and demonstrate\nthat modern GPUs can be utilised to increase the operational speed of large\nscale log processing scenarios, saving precious time before and after an\nintrusion has occurred.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Electrical impedance tomography aims at reconstructing the interior\nelectrical conductivity from surface measurements of currents and voltages. As\nthe current-voltage pairs depend nonlinearly on the conductivity, impedance\ntomography leads to a nonlinear inverse problem. Often, the forward problem is\nlinearized with respect to the conductivity and the resulting linear inverse\nproblem is regarded as a subproblem in an iterative algorithm or as a simple\nreconstruction method as such. In this paper, we compare this basic\nlinearization approach to linearizations with respect to the resistivity or the\nlogarithm of the conductivity. It is numerically demonstrated that the\nconductivity linearization often results in compromised accuracy in both\nforward and inverse computations. Inspired by these observations, we present\nand analyze a new linearization technique which is based on the logarithm of\nthe Neumann-to-Dirichlet operator. The method is directly applicable to\ndiscrete settings, including the complete electrode model. We also consider\nFr\\'echet derivatives of the logarithmic operators. Numerical examples indicate\nthat the proposed method is an accurate way of linearizing the problem of\nelectrical impedance tomography.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Generative models are used in a wide range of applications building on large\namounts of contextually rich information. Due to possible privacy violations of\nthe individuals whose data is used to train these models, however, publishing\nor sharing generative models is not always viable. In this paper, we present a\nnovel technique for privately releasing generative models and entire\nhigh-dimensional datasets produced by these models. We model the generator\ndistribution of the training data with a mixture of $k$ generative neural\nnetworks. These are trained together and collectively learn the generator\ndistribution of a dataset. Data is divided into $k$ clusters, using a novel\ndifferentially private kernel $k$-means, then each cluster is given to separate\ngenerative neural networks, such as Restricted Boltzmann Machines or\nVariational Autoencoders, which are trained only on their own cluster using\ndifferentially private gradient descent. We evaluate our approach using the\nMNIST dataset, as well as call detail records and transit datasets, showing\nthat it produces realistic synthetic samples, which can also be used to\naccurately compute arbitrary number of counting queries.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  One of the fundamental applications for a practically useful system of money\nis remuneration. Information pertaining to the amount of compensation awarded\nto different individuals is often considered sensitive, commanding a certain\ndegree of privacy. As Bitcoin and similarly designed cryptocurrencies evolve\ninto a recognized medium of exchange for larger swaths of the world economy, an\nincreasing number of people will earn income in the form of blockchain-based\npayments. The nature of these transactions is such that the minute details of\nan affected individuals compensation package and spending habits will be\nexposed to public scrutiny. In some cases this violates cultural norms which\nrespect the confidentiality of salaries, yet in other cases it could be\nregarded as providing the benefits associated with greater transparency. In\nthis work we analyse the Bitcoin blockchain record of periodic payments\naccruing to an individual address in exchange for goods or services rendered.\nFor differing levels of available information we seek to determine the extent\nof insights that can be gleaned about the transacting counter-parties and the\nprivacy implications this entails.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given the set of paths through a digraph, the result of uniformly deleting\nsome vertices and identifying others along each path is coherent in such a way\nas to yield the set of paths through another digraph, called a \\emph{path\nabstraction} of the original digraph. The construction of path abstractions is\ndetailed and relevant basic results are established; generalizations are also\ndiscussed. Connections with random digraphs are also illustrated.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we consider the spectral properties of the bilayer graphene\nwith the local excitonic pairing interaction between the electrons and holes.\nWe consider the generalized Hubbard model, which includes both intralayer and\ninterlayer Coulomb interaction parameters. The solution of the excitonic gap\nparameter is used to calculate the electronic band structure, single-particle\nspectral functions, the hybridization gap, and the excitonic coherence length\nin the bilayer graphene. We show that the local interlayer Coulomb interaction\nis responsible for the semimetal-semiconductor transition in the double layer\nsystem, and we calculate the hybridization gap in the band structure above the\ncritical interaction value. The formation of the excitonic band gap is reported\nas the threshold process and the momentum distribution functions have been\ncalculated numerically. We show that in the weak coupling limit the system is\ngoverned by the Bardeen-Cooper-Schrieffer (BCS)-like pairing state. Contrary,\nin the strong coupling limit the excitonic condensate states appear in the\nsemiconducting phase, by forming the Dirac's pockets in the reciprocal space.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this note, we investigate the electromagnetic radiation emitted from a\nrevolving point charge in a compact space. If the point charge is circulating\nwith an angular frequency $\\omega_0$ on the $(x,y)$-plane at $z=0$ with\nboundary conditions, $x \\sim x+2 \\pi R$ and $y \\sim y+2\\pi R$, it emits\nradiation into the $z$-direction of $z$ in $ [-\\infty, +\\infty]$.\n  We find that the radiation shows discontinuities as a function of $\\omega_0\nR$ at which a new propagating mode with a different Fourier component appears.\nFor a small radius limit $\\omega_0 R \\ll 1$, all the Fourier modes except the\nzero mode on $(x,y)$-plane are killed, but an effect of squeezing the electric\nfield totally enhances the radiation. In the large volume limit $\\omega_0 R\n\\rightarrow \\infty$, the energy flux of the radiation reduces to the expected\nLarmor formula.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Two-dimensional (2-D) materials are of tremendous interest to integrated\nphotonics given their singular optical characteristics spanning light emission,\nmodulation, saturable absorption, and nonlinear optics. To harness their\noptical properties, these atomically thin materials are usually attached onto\nprefabricated devices via a transfer process. In this paper, we present a new\nroute for 2-D material integration with planar photonics. Central to this\napproach is the use of chalcogenide glass, a multifunctional material which can\nbe directly deposited and patterned on a wide variety of 2-D materials and can\nsimultaneously function as the light guiding medium, a gate dielectric, and a\npassivation layer for 2-D materials. Besides claiming improved fabrication\nyield and throughput compared to the traditional transfer process, our\ntechnique also enables unconventional multilayer device geometries optimally\ndesigned for enhancing light-matter interactions in the 2-D layers.\nCapitalizing on this facile integration method, we demonstrate a series of\nhigh-performance glass-on-graphene devices including ultra-broadband on-chip\npolarizers, energy-efficient thermo-optic switches, as well as graphene-based\nmid-infrared (mid-IR) waveguide-integrated photodetectors and modulators.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $(X, Y) = (X_n, Y_n)_{n \\geq 1}$ be the output process generated by a\nhidden chain $Z = (Z_n)_{n \\geq 1}$, where $Z$ is a finite state, aperiodic,\ntime homogeneous, and irreducible Markov chain. Let $LC_n$ be the length of the\nlongest common subsequences of $X_1, \\ldots, X_n$ and $Y_1, \\ldots, Y_n$. Under\na mixing hypothesis, a rate of convergence result is obtained for\n$\\mathbb{E}[LC_n]/n$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We analyze quasiperiodic partially synchronous states in an ensemble of\nStuart-Landau oscillators with global nonlinear coupling. We reveal two types\nof such dynamics: in the first case the time-averaged frequencies of\noscillators and of the mean field differ, while in the second case they are\nequal, but the motion of oscillators is additionally modulated. We describe\ntransitions from the synchronous state to both types of quasiperiodic dynamics,\nand a transition between two different quasiperiodic states. We present an\nexample of a bifurcation diagram, where we show the borderlines for all these\ntransitions, as well as domain of bistability.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A set of fully numerical algorithms for evaluating the four-dimensional\nsingular integrals arising from Galerkin surface integral equation methods over\nconforming quadrilateral meshes is presented. This work is an extension of\nDIRECTFN, which was recently developed for the case of triangular patches,\nutilizing in a same fashion a series of coordinate transformations together\nwith appropriate integration re-orderings. The resulting formulas consist of\nsufficiently smooth kernels and exhibit several favorable characteristics when\ncompared with the vast majority of the methods currently available. More\nspecifically, they can be applied---without modifications---to the following\nchallenging cases: 1) weakly and strongly singular kernels, 2) basis and\ntesting functions of arbitrary order, 3) planar and curvilinear patches, 4)\nproblem-specific Green functions (e.g. expressed in spectral integral form), 5)\nspectral convergence to machine precision. Finally, we show that the overall\nperformance of the fully numerical schemes can be further improved by a\njudicious choice of the integration order for each dimension.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Detection of objects in cluttered indoor environments is one of the key\nenabling functionalities for service robots. The best performing object\ndetection approaches in computer vision exploit deep Convolutional Neural\nNetworks (CNN) to simultaneously detect and categorize the objects of interest\nin cluttered scenes. Training of such models typically requires large amounts\nof annotated training data which is time consuming and costly to obtain. In\nthis work we explore the ability of using synthetically generated composite\nimages for training state-of-the-art object detectors, especially for object\ninstance detection. We superimpose 2D images of textured object models into\nimages of real environments at variety of locations and scales. Our experiments\nevaluate different superimposition strategies ranging from purely image-based\nblending all the way to depth and semantics informed positioning of the object\nmodels into real scenes. We demonstrate the effectiveness of these object\ndetector training strategies on two publicly available datasets, the\nGMU-Kitchens and the Washington RGB-D Scenes v2. As one observation, augmenting\nsome hand-labeled training data with synthetic examples carefully composed onto\nscenes yields object detectors with comparable performance to using much more\nhand-labeled data. Broadly, this work charts new opportunities for training\ndetectors for new objects by exploiting existing object model repositories in\neither a purely automatic fashion or with only a very small number of\nhuman-annotated examples.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We have studied the dissociation of $J/\\psi$-mesons in low energy\nproton-nucleus ($p+A$) collisions in the energy range of the future SIS100\naccelerator at Facility for Anti-proton and Ion Research (FAIR). According to\nthe results of our calculations, various scenarios of $J/\\psi$ absorption in\nnuclear matter show very distinct suppression patterns in the kinematic regime\nto be probed at FAIR. This suggests that the SIS100 energies are particularly\nsuited to shed light on the issue of interaction of $J/\\psi$ resonance in\nnuclear medium.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Nanoantennas for highly efficient excitation and manipulation of surface\nwaves at nanoscale are key elements of compact photonic circuits. However,\npreviously implemented designs employ plasmonic nanoantennas with high Ohmic\nlosses, relatively low spectral resolution, and complicated lithographically\nmade architectures. Here we propose an ultracompact and simple dielectric\nnanoantenna (silicon nanosphere) allowing for both directional launching of\nsurface plasmon polaritons on a thin gold film and their demultiplexing with a\nhigh spectral resolution. We show experimentally that mutual interference of\nmagnetic and electric dipole moments supported by the dielectric nanoantenna\nresults in opposite propagation of the excited surface waves whose wavelengths\ndiffer by less than 50 nm in the optical range. Broadband reconfigurability of\nthe nanoantennas operational range is achieved simply by varying the diameter\nof the silicon sphere. Moreover, despite subwavelength size ($<\\lambda/3$) of\nthe proposed nanoantennas, they demonstrate highly efficient and directional\nlaunching of surface waves both in the forward and backward directions with the\nmeasured front-to-back ratio having a contrast of almost two orders of\nmagnitude within a 50 nm spectral band. Our lithography-free design has great\npotential as highly efficient, low-cost, and ultracompact demultiplexer for\nadvanced photonic circuits.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  On the string of finite length, a (genomic) transposition is defined as the\noperation of exchanging two consecutive substrings. The minimum number of\ntranspositions needed to transform one into the other is the transposition\ndistance, that has been researched in recent years. In this paper, we study\ntransposition distances on circular binary strings. A circular binary string is\nthe string that consists of symbols $0$ and $1$ and regards its circular shifts\nas equivalent. The property of transpositions which partition strings is\nobserved. A lower bound on the transposition distance is represented in terms\nof partitions. An upper bound on the transposition distance follows covering of\nthe set of partitions. The transposition diameter is given with a necessary and\nsufficient condition.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We employ chordal decomposition to reformulate a large and sparse\nsemidefinite program (SDP), either in primal or dual standard form, into an\nequivalent SDP with smaller positive semidefinite (PSD) constraints. In\ncontrast to previous approaches, the decomposed SDP is suitable for the\napplication of first-order operator-splitting methods, enabling the development\nof efficient and scalable algorithms. In particular, we apply the alternating\ndirection method of multipliers (ADMM) to solve decomposed primal- and\ndual-standard-form SDPs. Each iteration of such ADMM algorithms requires a\nprojection onto an affine subspace, and a set of projections onto small PSD\ncones that can be computed in parallel. We also formulate the homogeneous\nself-dual embedding (HSDE) of a primal-dual pair of decomposed SDPs, and extend\na recent ADMM-based algorithm to exploit the structure of our HSDE. The\nresulting HSDE algorithm has the same leading-order computational cost as those\nfor the primal or dual problems only, with the advantage of being able to\nidentify infeasible problems and produce an infeasibility certificate. All\nalgorithms are implemented in the open-source MATLAB solver CDCS. Numerical\nexperiments on a range of large-scale SDPs demonstrate the computational\nadvantages of the proposed methods compared to common state-of-the-art solvers.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hysteresis characteristics of the crystal field diluted general Spin-S\n($S>1$) Blume-Capel model have been studied within the effective field\napproximation. Particular emphasis has been paid on the large negative valued\ncrystal field and low temperature region and it has been demonstrated for this\nregion that, rising dilution of the crystal field results in decreasing number\nof windowed hysteresis loops. The evolution of the multiple hysteresis loop\nwith the dilution of the crystal field has been investigated and physical\nmechanism behind this evolution has been given.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Motivated by recent advances in the categorification of quantum groups at\nprime roots of unity, we develop a theory of 2-representations for 2-categories\nenriched with a p-differential which satisfy finiteness conditions analogous to\nthose of finitary or fiat 2-categories. We construct cell 2-representations in\nthis setup, and consider 2-categories stemming from bimodules over a p-dg\ncategory in detail. This class is of particular importance in the\ncategorification of quantum groups, which allows us to apply our results to\ncyclotomic quotients of the categorifications of small quantum group of type\n$\\mathfrak{sl}_2$ at prime roots of unity by Elias-Qi [Advances in Mathematics\n288 (2016)]. Passing to stable 2-representations gives a way to construct\ntriangulated 2-representations, but our main focus is on working with p-dg\nenriched 2-representations that should be seen as a p-dg enhancement of these\ntriangulated ones.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We tackle the problem of selecting from among a large number of variables\nthose that are 'important' for an outcome. We consider situations where groups\nof variables are also of interest in their own right. For example, each\nvariable might be a genetic polymorphism and we might want to study how a trait\ndepends on variability in genes, segments of DNA that typically contain\nmultiple such polymorphisms. Or, variables might quantify various aspects of\nthe functioning of individual internet servers owned by a company, and we might\nbe interested in assessing the importance of each server as a whole on the\naverage download speed for the company's customers. In this context, to\ndiscover that a variable is relevant for the outcome implies discovering that\nthe larger entity it represents is also important. To guarantee meaningful and\nreproducible results, we suggest controlling the rate of false discoveries for\nfindings at the level of individual variables and at the level of groups.\nBuilding on the knockoff construction of Barber and Candes (2015) and the\nmultilayer testing framework of Barber and Ramdas (2016), we introduce the\nmultilayer knockoff filter (MKF). We prove that MKF simultaneously controls the\nFDR at each resolution and use simulations to show that it incurs little power\nloss compared to methods that provide guarantees only for the discoveries of\nindividual variables. We apply MKF to analyze a genetic dataset and find that\nit successfully reduces the number of false gene discoveries without a\nsignificant reduction in power.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For convex domains with $C^{1,\\epsilon}$ boundary we give a precise\ndescription of the automorphism group: if an orbit of the automorphism group\naccumulates on at least two different closed complex faces of the boundary,\nthen the automorphism group has finitely many components and the connected\ncomponent of the identity is the almost direct product of a compact group and a\nnon-compact connected simple Lie group with real rank one and finite center. In\nthis case, we also show the limit set is homeomorphic to a sphere and prove a\ngap theorem: either the domain is biholomorphic to the unit ball (and the limit\nset is the entire boundary) or the limit set has co-dimension at least two in\nthe boundary.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Taking as a hypothesis a form of the labour theory of value, and $without$\n$assuming$ $equilibrium$, we derive an equation that yields the profit-rate\n$\\pi$ as a function of time. For a mature economy, $\\pi(t)$ reduces to the\nproduct of two factors: ($i$) a certain $retarded$ $average$ of the sum of the\ngrowth-rates of productivity and of the size of the labour-force measured by\nhours worked, and ($ii$) the ratio of the current rate of surplus value to its\nown retarded average. We also suggest an empirical test of the equation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  These are lecture notes for a short course about spectral sequences that was\nheld at M\\'alaga, October 18--20 (2016), during the \"Fifth Young Spanish\nTopologists Meeting\". The approach was to illustrate the basic notions via\nfully computed examples arising from Algebraic Topology and Group Theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $p$ be a rational prime and $q$ a power of $p$. Let $\\wp$ be a monic\nirreducible polynomial of degree $d$ in $\\mathbf{F}_q[t]$. In this paper, we\ndefine an analogue of the Hodge-Tate map which is suitable for the study of\nDrinfeld modules over $\\mathbf{F}_q[t]$ and, using it, develop a geometric\ntheory of $\\wp$-adic Drinfeld modular forms similar to Katz's theory in the\ncase of elliptic modular forms. In particular, we show that for Drinfeld\nmodular forms with congruent Fourier coefficients at $\\infty$ modulo $\\wp^n$,\ntheir weights are also congruent modulo $(q^d-1)p^{\\lceil \\log_p(n)\\rceil}$,\nand that Drinfeld modular forms of level $\\Gamma_1(\\mathfrak{n})\\cap\n\\Gamma_0(\\wp)$, weight $k$ and type $m$ are $\\wp$-adic Drinfeld modular forms\nfor any tame level $\\mathfrak{n}$ with a prime factor of degree prime to $q-1$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The classical Kirszbraun theorem says that all $1$-Lipschitz functions\n$f:A\\longrightarrow \\mathbb{R}^n$, $A\\subset \\mathbb{R}^n$, with the Euclidean\nmetric have a $1$-Lipschitz extension to $\\mathbb{R}^n$. For metric spaces\n$X,Y$ we say that $Y$ is $X$-Kirszbraun if all $1$-Lipschitz functions\n$f:A\\longrightarrow Y$, $A\\subset X$, have a $1$-Lipschitz extension to~$X$. We\nanalyze the case when $X$ and $Y$ are graphs with the usual path metric. We\nprove that $\\mathbb{Z}^d$-Kirszbraun graphs are exactly graphs that satisfies a\ncertain Helly property. We also consider complexity aspects of these\nproperties.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We review experimental and theoretical efforts aimed at a detailed\nunderstanding of the recombination of electrons with highly-charged tungsten\nions characterised by an open 4f sub-shell. Highly-charged tungsten occurs as a\nplasma contaminant in ITER-like tokamak experiments, where it acts as an\nunwanted cooling agent. Modelling of the charge state populations in a plasma\nrequires reliable thermal rate coefficients for charge-changing electron\ncollisions. The electron recombination of medium-charged tungsten species with\nopen 4f sub-shells is especially challenging to compute reliably. Storage-ring\nexperiments have been conducted that yielded recombination rate coefficients at\nhigh energy resolution and well-understood systematics. Significant deviations\ncompared to simplified, but prevalent, computational models have been found. A\nnew class of ab-initio numerical calculations has been developed that provides\nreliable predictions of the total plasma recombination rate coefficients for\nthese ions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Cross-modality retrieval encompasses retrieval tasks where the fetched items\nare of a different type than the search query, e.g., retrieving pictures\nrelevant to a given text query. The state-of-the-art approach to cross-modality\nretrieval relies on learning a joint embedding space of the two modalities,\nwhere items from either modality are retrieved using nearest-neighbor search.\nIn this work, we introduce a neural network layer based on Canonical\nCorrelation Analysis (CCA) that learns better embedding spaces by analytically\ncomputing projections that maximize correlation. In contrast to previous\napproaches, the CCA Layer (CCAL) allows us to combine existing objectives for\nembedding space learning, such as pairwise ranking losses, with the optimal\nprojections of CCA. We show the effectiveness of our approach for\ncross-modality retrieval on three different scenarios (text-to-image,\naudio-sheet-music and zero-shot retrieval), surpassing both Deep CCA and a\nmulti-view network using freely learned projections optimized by a pairwise\nranking loss, especially when little training data is available (the code for\nall three methods is released at: https://github.com/CPJKU/cca_layer).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Automatic age estimation from real-world and unconstrained face images is\nrapidly gaining importance. In our proposed work, a deep CNN model that was\ntrained on a database for face recognition task is used to estimate the age\ninformation on the Adience database. This paper has three significant\ncontributions in this field. (1) This work proves that a CNN model, which was\ntrained for face recognition task, can be utilized for age estimation to\nimprove performance; (2) Over fitting problem can be overcome by employing a\npretrained CNN on a large database for face recognition task; (3) Not only the\nnumber of training images and the number subjects in a training database effect\nthe performance of the age estimation model, but also the pre-training task of\nthe employed CNN determines the performance of the model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The teleparallel formulation of gravity theories reveals close structural\nanalogies to electrodynamics, which are more hidden in their usual formulation\nin terms of the curvature of spacetime. We show how every locally Lorentz\ninvariant teleparallel theory of gravity with second order field equations can\nbe understood as built from a gravitational field strength and excitation\ntensor which are related to each other by a constitutive relation, analogous to\nthe axiomatic construction of theories of electrodynamics. We demonstrate how\nthe previously studied models of $f(\\mathbb{T})$ and\n$f(T_\\text{ax},T_\\text{ten},T_\\text{vec})$ gravity as well as teleparallel dark\nenergy can be formulated in this language. The advantage of this approach to\ngravity is that the field equations for different models all take the same\ncompact form and general results can be obtained. An important new such result\nwe find is a constraint which relates the field equations of the tetrad and the\nspin connection.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We give a criterion for complete reducibility of tensor product $V\\otimes Z$\nof two irreducible highest weight modules $V$ and $Z$ over a classical or\nquantum semi-simple group in terms of a contravariant symmetric bilinear form\non $V\\otimes Z$. This form is the product of the canonical contravariant forms\non $V$ and $Z$. Then $V\\otimes Z$ is completely reducible if and only if the\nform is non-degenerate when restricted to the sum of all highest weight\nsubmodules in $V\\otimes Z$ or equivalently to the span of singular vectors.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using the interpretation of certain generalised Donaldson-Thomas invariants,\nincluding stable pairs curve counts, as the monodromy of a flat connection on a\nformal principal bundle, we show that the conjectural Gopakumar-Vafa\ncontributions of all genera to the Gromov-Witten partition function appear in\nthe asymptotics of the corresponding flat sections. The Fourier-Laplace\nintegrals used to produce flat sections lead naturally to the GW/DT change of\nvariable -q = e^{i u}.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Associated to Legendrian links in the standard contact three-space, Ruling\npolynomials are Legendrian isotopy invariants, which also compute augmentation\nnumbers, that is, the points-counting of augmentation varieties for Legendrian\nlinks (up to a normalized factor) \\cite{HR15}. In this article, we generalize\nthis picture to Legendrian tangles, which are morally the pieces obtained by\ncutting Legendrian link fronts along 2 vertical lines. Moreover, we show that\nthe Ruling polynomials for Legendrian tangles satisfy the composition axiom. In\nthe special case of Legendrian knots, our arguments provide new proofs to the\nmain results in \\cite{HR15}. In the end, we also introduce generalized Ruling\npolynomials for Legendrian tangles, to account for non-acyclic augmentations in\nthe \"Ruling polynomials compute augmentation numbers\" picture.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The critical region of the hierarchical reference theory (HRT) is\ninvestigated further. This extends an earlier work by us where the critical\nproperties of the HRT were concluded indirectly via another accurate but\nsomewhat different theory, the self-consistent Ornstein-Zernike approximation\n(SCOZA), and numerical work. In the present work we perform our analysis\ndirectly upon the HRT partial differential equation to establish ordinary\ndifferential equations for the subleading scaling contributions. Again we find\nthat the HRT critical indices in three dimensions are simple rational numbers.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the asymptotic behaviour, as time goes to infinity, of the\nFisher-KPP equation $\\partial_t u=\\Delta u +u-u^2$ in spatial dimension $2$,\nwhen the initial condition looks like a Heaviside function. Thus the solution\nis, asymptotically in time, trapped between two planar critical waves whose\npositions are corrected by the Bramson logarithmic shift. The issue is whether,\nin this reference frame, the solutions will converge to a travelling wave, or\nwill exhibit more complex behaviours. We prove here that both convergence and\nnonconvergence may happen: the solution may converge towards one translate of\nthe planar wave, or oscillate between two of its translates. This relies on the\nbehaviour of the initial condition at infinity in the transverse direction.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the context of $2+1-$dimensional gravity coupled to a particular nonlinear\nelectrodynamics (NED), we obtain a class of traversable / Morris-Thorne type\nwormhole solutions. The problem is reduced to a single function dependence in\nwhich the shape function acts as generator to the wormholes. The field ansatz\nis pure magnetic and the nonlinear Lagrangian is $\\sqrt{F_{\\mu \\nu }F^{\\mu \\nu\n}}$ i.e. the square root of the Maxwell Lagrangian. In $2+1-$dimensions the\nsource-free pure magnetic non-linear Maxwell equation with square-root\nLagrangian is trivially satisfied. The exotic energy density is found\nexplicitly and the flare-out conditions are emphasized.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We analyze the collision of a high energy electron beam with an oscillating\nelectric and magnetic field configuration, which represents a three-dimensional\nstanding electromagnetic wave. The radiating electrons are stopped at the\ndistance of the order of or less than the electromagnetic wave wavelength, and\nbecome trapped near the electric field local maxima due to the nonlinear\ndependence of the radiation friction force on the electromagnetic field\nstrength, while the quantum effects on the radiation friction remain\nnegligible.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  One of the most crucial issues in data mining is to model human behaviour in\norder to provide personalisation, adaptation and recommendation. This usually\ninvolves implicit or explicit knowledge, either by observing user interactions,\nor by asking users directly. But these sources of information are always\nsubject to the volatility of human decisions, making utilised data uncertain to\na particular extent. In this contribution, we elaborate on the impact of this\nhuman uncertainty when it comes to comparative assessments of different data\nmining approaches. In particular, we reveal two problems: (1) biasing effects\non various metrics of model-based prediction and (2) the propagation of\nuncertainty and its thus induced error probabilities for algorithm rankings.\nFor this purpose, we introduce a probabilistic view and prove the existence of\nthose problems mathematically, as well as provide possible solution strategies.\nWe exemplify our theory mainly in the context of recommender systems along with\nthe metric RMSE as a prominent example of precision quality measures.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Chemical Master Equation (CME) is used to stochastically model\nbiochemical reaction networks, under the Markovian assumption. The low-order\nstatistical moments induced by the CME are often the key quantities that one is\ninterested in. However, in most cases, the moments equation is not closed; in\nthe sense that the first $n$ moments depend on the higher order moments, for\nany positive integer $n$. In this paper, we develop a moment closure technique\nin which the higher order moments are approximated by an affine function of the\nlower order moments. We refer to such functions as the affine Moment Closure\nFunctions (MCF) and prove that they are optimal in the worst-case context, in\nwhich no a priori information on the probability distribution is available.\nFurthermore, we cast the problem of finding the optimal affine MCF as a linear\nprogram, which is tractable. We utilize the affine MCFs to derive a finite\ndimensional linear system that approximates the low-order moments. We quantify\nthe approximation error in terms of the $% l_{\\infty }$ induced norm of some\nlinear system. Our results can be effectively used to approximate the low-order\nmoments and characterize the noise properties of the biochemical network under\nstudy.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  These proceedings are of interest to staff and students in accelerator\nlaboratories, university departments and companies working in or having an\ninterest in the field of new acceleration techniques. Following introductory\nlectures on plasma and laser physics, the course covers the different\ncomponents of a plasma wake accelerator and plasma beam systems. Topical\nseminars and an overview about alternative new techniques like dielectric\naccelerators are included. Lectures on the experimental studies and their\nlatest results, on diagnostic tools and state of the art wake acceleration\nfacilities, both present and planned, complement the theoretical part.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Active galactic nuclei (AGN), particularly the most luminous AGN, are\ncommonly assumed to be triggered through major mergers, however observational\nevidence for this scenario is mixed. To investigate any influence of galaxy\nmergers on AGN triggering and luminosities through cosmic time, we present a\nsample of 106 luminous X-ray selected type 1 AGN from the COSMOS survey. These\nAGN occupy a large redshift range (0.5 < z < 2.2) and two orders of magnitude\nin X-ray luminosity ($\\sim$10$^{43}$ - 10$^{45}$ erg s$^{-1}$). AGN hosts are\ncarefully mass and redshift matched to 486 control galaxies. A novel technique\nfor identifying and quantifying merger features in galaxies is developed,\nsubtracting GALFIT galaxy models and quantifying the residuals. Comparison to\nvisual classification confirms this measure reliably picks out disturbance\nfeatures in galaxies. No enhancement of merger features with increasing AGN\nluminosity is found with this metric, or by visual inspection. We analyse the\nredshift evolution of AGN associated with galaxy mergers and find no merger\nenhancement in lower redshift bins. Contrarily, in the highest redshift bin\n(z$\\sim$2) AGN are $\\sim$4 times more likely to be in galaxies exhibiting\nevidence of morphological disturbance compared to control galaxies, at 99%\nconfidence level ($\\sim$2.4$\\sigma$) from visual inspection. Since only\n$\\sim$15% of these AGN are found to be in morphologically disturbed galaxies,\nit is implied that major mergers at high redshift make a noticeable but\nsubdominant contribution to AGN fuelling. At low redshifts other processes\ndominate and mergers become a less significant triggering mechanism.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss a grand unified theory (GUT) based on an $SO(32)$ GUT gauge group\nbroken to its subgroups including a special subgroup. In the $SO(32)$ GUT on\nsix-dimensional (6D) orbifold space $M^4\\times T^2/\\mathbb{Z}_2$, one\ngeneration of the SM fermions can be embedded into a 6D bulk Weyl fermion in\nthe $SO(32)$ vector representation. We show that for a three generation model,\nall the 6D and 4D gauge anomalies in the bulk and on the fixed points are\ncanceled out without exotic chiral fermions at low energies.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Perturbatively around flat space, the scattering amplitudes of gravity are\nrelated to those of Yang-Mills by colour-kinematic duality, under which\ngravitational amplitudes are obtained as the 'double copy' of the corresponding\ngauge theory amplitudes. We consider the question of how to extend this\nrelationship to curved scattering backgrounds, focusing on certain 'sandwich'\nplane waves. We calculate the 3-point amplitudes on these backgrounds and find\nthat a notion of double copy remains in the presence of background curvature:\ngraviton amplitudes on a gravitational plane wave are the double copy of gluon\namplitudes on a gauge field plane wave. This is non-trivial in that it requires\na non-local replacement rule for the background fields and the momenta and\npolarization vectors of the fields scattering on the backgrounds. It must also\naccount for new 'tail' terms arising from scattering off the background. These\nencode a memory effect in the scattering amplitudes, which naturally double\ncopies as well.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We derive integrable equations starting from autonomous mappings with a\ngeneral form inspired by the multiplicative systems associated to the affine\nWeyl group E$_8^{(1)}$. Five such systems are obtained, three of which turn out\nto be linearisable and the remaining two are integrable in terms of elliptic\nfunctions. In the case of the linearisable mappings we derive nonautonomous\nforms which contain a free function of the dependent variable and we present\nthe linearisation in each case. The two remaining systems are deautonomised to\nnew discrete Painlev\\'e equations. We show that these equations are in fact\nspecial forms of much richer systems associated to the affine Weyl groups\nE$_7^{(1)}$ and E$_8^{(1)}$ respectively.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The imaging-Time-of-Propogation (iTOP) counter is a new type of ring-imaging\nCherenkov counter developed for particle identification at the Belle II\nexperiment. It consists of 16 modules arranged azimuthally around the beam\nline. Each module consists of one mirror, one prism and two quartz bar\nradiators. Here we describe the design, acceptance test, alignment, gluing and\nassembly of the optical components. All iTOP modules have been successfully\nassembled and installed in the Belle II detector by the middle of 2016. After\ninstallation, laser and cosmic ray data have been taken to test the performance\nof the modules. First results from these tests are presented.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $A$ be a finite set and $G$ a group. A closed subset $X$ of $A^G$ is\ncalled a subshift if the action of $G$ on $A^G$ preserves $X$. If $K$ is a\nclosed subset of $A^G$ such that membership in $K$ is determined by looking at\na fixed finite set of coordinates, and $X$ is the intersection of all\ntranslates of $K$ under the action of $G$, then $X$ is called a subshift of\nfinite type (SFT). If an SFT is nonempty and contains no finite $G$-orbits, it\nis said to be weakly aperiodic. A virtually cyclic group has no weakly\naperiodic SFT, and Carroll and Penland have conjectured that a group with no\nweakly aperiodic SFT must be virtually cyclic. Answering a question of Jeandel,\nwe show that lamplighters always admit weakly aperiodic SFTs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using algebraic methods, and motivated by the one variable case, we study a\nmultipoint interpolation problem in the setting of several complex variables.\nThe duality realized by the residue generator associated with an underlying\nGorenstein algebra, using the Lagrange interpolation polynomial, plays a key\nrole in the arguments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The massive stars that ionised the Universe have short lifetimes and can only\nbe studied near the time of formation, but any low mass stars that formed\ncontemporaneously might be observable in the local Universe today. We study the\nabundance pattern and spatial distribution of these `siblings of reionizers'\n(SoRs) in the EAGLE cosmological hydrodynamical simulation. SoRs tend to be\nenriched to super-solar levels in $\\alpha$-elements compared to iron. In {\\sc\neagle} galaxies resembling the Milky Way, $\\sim 40$ percent of carbon-enhanced\nmetal poor (CEMP) stars are SoRs. Conversely, $\\sim 10$ percent of all SoRs are\nCEMP stars. This fraction increases to $\\gtrsim 50$ percent for SoRs of\nmetallicity [Fe/H]$<-4$, and at such low metallicities, most of the CEMP stars\nare of CEMP-no subtype that are lacking neutron capture elements. Although\nthese numbers may well depend on the details of the physical models implemented\nin EAGLE, the trends we describe are robust as they result from the strong\nfeedback from star formation in early galaxies, itself a key ingredient of most\ncurrent models of galaxy formation. We further find that most SoRs today reside\nin halos with mass $M_h\\gtrapprox 10^{12}$ M$_\\odot$, and 50 percent of them\nare in the halo of their central galaxy (distance $>10$ kpc), mainly because\nthey were accreted onto their current host rather than formed in-situ. To a\ngood approximation, the SoRs are CEMP-no stars that reside in the stellar halos\nof massive galaxies, with nearly half of them contributing to the intracluster\nlight in groups and clusters.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Converting a noisy parallax measurement into a posterior belief over distance\nrequires inference with a prior. Usually this prior represents beliefs about\nthe stellar density distribution of the Milky Way. However, multi-band\nphotometry exists for a large fraction of the \\textsl{\\small{Gaia}}\n\\textsl{\\small{TGAS}} Catalog and is incredibly informative about stellar\ndistances. Here we use \\textsl{\\small{2MASS}} colors for 1.4 million\n\\textsl{\\small{TGAS}} stars to build a noise-deconvolved empirical prior\ndistribution for stars in color--magnitude space. This model contains no\nknowledge of stellar astrophysics or the Milky Way, but is precise because it\naccurately generates a large number of noisy parallax measurements under an\nassumption of stationarity; that is, it is capable of combining the information\nfrom many stars. We use the Extreme Deconvolution (\\textsl{\\small{XD}})\nalgorithm---an Empirical Bayes approximation to a full hierarchical model of\nthe true parallax and photometry of every star---to construct this prior. The\nprior is combined with a \\textsl{\\small{TGAS}} likelihood to infer a precise\nphotometric parallax estimate and uncertainty (and full posterior) for every\nstar. Our parallax estimates are more precise than the \\textsl{\\small{TGAS}}\ncatalog entries by a median factor of 1.2 (14% are more precise by a factor >2)\nand are more precise than previous Bayesian distance estimates that use spatial\npriors. We validate our parallax inferences using members of the Milky Way star\ncluster M67, which is not visible as a cluster in the \\textsl{\\small{TGAS}}\nparallax estimates, but appears as a cluster in our posterior parallax\nestimates. Our results, including a parallax posterior pdf for each of 1.4\nmillion \\textsl{\\small{TGAS}} stars, are available in companion electronic\ntables.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The author established the affine Orlicz Polya-Szego principle for\nlog-concave functions and conjectured that the principle can be extended to the\ngeneral Orlicz Sobolev functions. In this paper, we confirm this conjecture\ncompletely. An affine Orlicz Polya-Szego principle, which includes all the\nprevious affine Polya-Szego principles as special cases, is formulated and\nproved. As a consequence, an Orlicz-Petty projection inequality for star bodies\nis established.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Self-organized collective behaviour of active units is inspiring new designs\nof artificial swarms of micron-sized objects. However, active control at the\nnanoscale remains elusive. We have accurately solved the collective optofluidic\ndynamics of gold plasmonic 50 nm-radius nanoparticles moving in aqueous\nsolution under a nonconservative optical vortex lattice. Above a critical field\nintensity and concentration, the interplay between optical forces, thermal\nfluctuations and hydrodynamic pairing leads to a spontaneous transition towards\nsynchronised motion exhibiting a rich assortment of collective dynamics. The\ncritical phenomenon creates strong unidirectional currents of nanoparticles,\nreaching speeds of centimeters per second along the diagonals of the lattice.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report the peculiar chemical abundance patterns of eleven atypical Milky\nWay (MW) field red giant stars observed by the Apache Point Observatory\nGalactic Evolution Experiment (APOGEE). These atypical giants exhibit strong Al\nand N enhancements accompanied by C and Mg depletions, strikingly similar to\nthose observed in the so-called second-generation (SG) stars of globular\nclusters (GCs). Remarkably, we find low-Mg abundances ([Mg/Fe]$<$0.0) together\nwith strong Al and N overabundances in the majority (5/7) of the metal-rich\n([Fe/H]$\\gtrsim - 1.0$) sample stars, which is at odds with actual observations\nof SG stars in Galactic CGs of similar metallicities. This chemical pattern is\nunique and unprecedented among MW stars, posing urgent questions about its\norigin. These atypical stars could be former SG stars of dissolved GCs formed\nwith intrinsically lower abundances of Mg and enriched Al (subsequently\nself-polluted by massive AGB stars) or the result of exotic binary systems. We\nspeculate that the stars Mg-deficiency as well as the orbital properties\nsuggest that they could have an extragalactic origin. This discovery should\nguide future dedicated spectroscopic searches of atypical stellar chemical\npatterns in our Galaxy; a fundamental step forward to understand the Galactic\nformation and evolution.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we characterize the Fourier transformability of a strongly\nalmost periodic measure in terms of an integrability condition for its Fourier\nBohr series. We also provide a necessary and sufficient condition for a\nstrongly almost periodic measure to be a Fourier transform of a measure. We\ndiscuss the Fourier transformability of a measure on $\\RR^d$ in terms of its\nFourier transform as a tempered distribution. We conclude by looking at a large\nclass of such measures coming from the cut and project formalism.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Acoustic metasurfaces manipulate waves with specially designed structures and\nachieve properties that natural materials cannot offer. Similar surfaces work\nin audio frequency range as well and lead to marvelous acoustic phenomena that\ncan be perceived by human ears. Being intrigued by the famous Maoshan Bugle\nphenomenon, we investigate large scale metasurfaces consisting of periodic\nsteps of sizes comparable to the wavelength of audio frequency in both time and\nspace domains. We propose a theoretical method to calculate the scattered sound\nfield and find that periodic corrugated surfaces work as spatial filters and\nthe frequency selective character can only be observed at the same side as the\nincident wave. Maoshan Bugle phenomenon can be well explained with the method.\nFinally, we demonstrate that the proposed method can be used to design\nacoustical landscapes, which transform impulsive sound into famous trumpet\nsolos or other melodious sound.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study turbulent flows in pressure-driven ducts with square cross-section\nthrough direct numerical simulation in a wide enough range of Reynolds number\nto reach flow conditions which are representative of fully developed\nturbulence. Numerical simulations are carried out over extremely long\nintegration times to get adequate convergence of the flow statistics, and\nspecifically high-fidelity representation of the secondary motions which arise.\nThe intensity of the latter is found to be in the order of 1-2% of the bulk\nvelocity, and unaffected by Reynolds number variations. The smallness of the\nmean convection terms in the streamwise vorticity equation points to a simple\ncharacterization of the secondary flows, which in the asymptotic high-Re regime\nare found to be approximated with good accuracy by eigenfunctions of the\nLaplace operator. Despite their effect of redistributing the wall shear stress\nalong the duct perimeter, we find that secondary motions do not have large\ninfluence on the mean velocity field, which can be characterized with good\naccuracy as that resulting from the concurrent effect of four independent flat\nwalls, each controlling a quarter of the flow domain. As a consequence, we find\nthat parametrizations based on the hydraulic diameter concept, and\nmodifications thereof, are successful in predicting the duct friction\ncoefficient.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Two close parallel mirrors attract due to a small force (Casimir effect)\noriginating from the electromagnetic quantum vacuum uctuations of the\nelectromagnetic field. These vacuum uctuations can also induce motional forces\nexerted upon one mirror when the other one moves. Here we consider an\noptomechanical system consisting of two vibrating mirrors coupled to an optical\nresonator. We find that motional forces can determine noticeable coupling rates\nbetween the two spatially separated vibrating mirrors. We show that, by tuning\nthe two mechanical oscillators into resonance, energy is exchanged between them\nat the quantum level. This coherent motional coupling is enabled by the\nexchange of virtual photon pairs, originating from the dynamical Casimir\neffect. The process proposed here shows that the electromagnetic quantum vacuum\nis able to transfer mechanical energy somewhat like an ordinary uid. We show\nthat this system can also operate as a mechanical parametric down-converter\neven at very weak excitations. These results demonstrate that vacuuminduced\nmotional forces open up new possibilities for the development of optomechanical\nquantum technologies.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Exciton dissociation at heterojunctions in photovoltaic devices is not\ncompletely understood despite being fundamentally necessary to generate\nelectrical current. One of the fundamental issues for ab initio calculations is\nthat hybrid interfaces combining materials with Wannier-Mott excitons and those\nwith Frenkel excitons can easily require thousands of atoms to encompass the\nexciton-wave function. The problem is further exacerbated by a large\npermittivity difference at the interface, which requires meso-scale boundary\nconditions to accurately predict electrostatic potentials. For these reasons,\nwe have constructed a model of excited states at hybrid interfaces based on an\neffective mass Schroedinger equation. In this continuum model, carrier wave\nfunctions are represented by their envelope function rather than resolving the\natomic scale variations. Electrostatic interactions are accounted for using the\nPoisson equation. For our model system, we use a pentacene/silicon interface.\nBecause carrier mobility is low in pentacene relative to silicon, the hole is\nfrozen such that it only interacts with the electron though an immobile\npositive charge density. The inputs to this model are as follows: dielectric\npermittivities, electron effective masses, interfacial width, band alignment,\nand the hole wave function. We find that the energetic favorability of charge\ntransfer states relative to bulk excitons is most easily controlled by band\nalignment. However, when both states have similar energies, interface proximity\nand electrostatics become important secondary means of tuning the relative\nstability of these states.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In 1827, Colladon carried out a series of experiments in Lac Leman (Lake\nGeneva, Switzerland) to measure the speed of sound in water.\n  The purpose of our contribution is to treat this measurement as an inverse\nproblem, and show, by theory how to solve the latter. It is thus revealed under\nwhat circumstances it is legitimate to employ the time-of-flight scheme\nunderlying the Colladon experiments and how to bypass this scheme in order to\nfully account for the temporal and geometric characteristics of the source (of\nsound), the temporal characteristics of the received signal and the error\nincurred by the finite distance between the source and receiver.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The $\\bar{B}_{q}^{\\ast}$ ${\\to}$ $DP$, $DV$ weak decays are studied with the\nperturbative QCD approach, where $q$ $=$ $u$, $d$ and $s$; $P$ and $V$ denote\nthe ground $SU(3)$ pseudoscalar and vector meson nonet. It is found that the\nbranching ratios for the color-allowed $\\bar{B}_{q}^{\\ast}$ ${\\to}$\n$D_{q}{\\rho}^{-}$ decays can reach up to $10^{-9}$ or more, and should be\npromisingly measurable at the running LHC and forthcoming SuperKEKB experiments\nin the near future.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Social dilemmas are situations where individuals face a temptation to\nincrease their payoffs at a cost to total welfare. Building artificially\nintelligent agents that achieve good outcomes in these situations is important\nbecause many real world interactions include a tension between selfish\ninterests and the welfare of others. We show how to modify modern reinforcement\nlearning methods to construct agents that act in ways that are simple to\nunderstand, nice (begin by cooperating), provokable (try to avoid being\nexploited), and forgiving (try to return to mutual cooperation). We show both\ntheoretically and experimentally that such agents can maintain cooperation in\nMarkov social dilemmas. Our construction does not require training methods\nbeyond a modification of self-play, thus if an environment is such that good\nstrategies can be constructed in the zero-sum case (eg. Atari) then we can\nconstruct agents that solve social dilemmas in this environment.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In four spacetime dimensions there exist two off-shell formulations for the\nmassless multiplet of superspin $(s+\\frac 12)$, where $s=2,3, \\dots$. These\nsupersymmetric higher spin gauge theories, known as longitudinal and\ntransverse, are dual to each other and describe two massless fields of spin\n$(s+\\frac 12)$ and $(s+1)$ upon elimination of the auxiliary fields. They\nrespectively reduce, in the limiting case of $s=1$, to the linearised actions\nfor the old minimal and the $n=-1$ non-minimal ${\\cal N}=1$ supergravity\ntheories. Associated with these gauge massless theories are non-conformal\nhigher spin supercurrent multiplets which we describe. We demonstrate that the\nlongitudinal higher spin supercurrents are realised in the model for a massive\nchiral scalar superfield only if $s$ is odd, $s=2n+1$, with $n= 1,2, \\dots$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Modeling processes are the activities of capturing and representing processes\nand control of their dynamic behavior. Desired features of the model include\ncapture of relevant aspects of a real phenomenon, understandability, and\ncompleteness of static and dynamic specifications. This paper proposes a\ndiagrammatic language for engineering process modeling that provides an\nintegration tool for capturing the static description of processes, framing\ntheir behaviors in terms of events, and utilizing the resultant model for\ncontrolling processes. Without loss of generality, the focus of the paper is on\nprocess modeling in the area of computer engineering, and specifically, on\nmodeling of computer services. To demonstrate the viability of the method, the\nproposed model is applied to depicting flow of services in the Information\nTechnology department of a government ministry.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  It is shown that the computational efficiency of the discrete least-squares\n(DLS) approximation of solutions of stochastic elliptic PDEs is improved by\nincorporating a reduced-basis method into the DLS framework. The goal is to\nrecover the entire solution map from the parameter space to the finite element\nspace. To this end, first, a reduced-basis solution using a weak greedy\nalgorithm is constructed, then a DLS approximation is determined by evaluating\nthe reduced-basis approximation instead of the full finite element\napproximation. The main advantage of the new approach is that one only need\napply the DLS operator to the coefficients of the reduced-basis expansion,\nresulting in huge savings in both the storage of the DLS coefficients and the\nonline cost of evaluating the DLS approximation. In addition, the recently\ndeveloped quasi-optimal polynomial space is also adopted in the new approach,\nresulting in superior convergence rates for a wider class of problems than\nprevious analyzed. Numerical experiments are provided that illustrate the\ntheoretical results.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study a scenario where sterile neutrino (either warm or cold) dark matter\n(DM) is produced through (nonresonant) oscillations among right-handed\nneutrinos (RHNs) and can constitute the whole DM in the Universe, in contrast\nto the conventional sterile neutrino production through its mixing with the\nleft-handed neutrinos. The lightest RHN can be sterile neutrino DM whose mixing\nwith left-handed neutrinos is sufficiently small while heavier RHNs can have\nnon-negligible mixings with left-handed neutrinos to explain the neutrino\nmasses by the seesaw mechanism. We also demonstrate that, in our scenario, the\nproduction of sterile RHN DM from the decay of a heavier RHN is subdominant\ncompared with the RHN oscillation production due to the X-ray and small-scale\nstructure constraints.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A stochastic cumulant GW method is presented, allowing us to map the\nevolution of photoemission spectra, quasiparticle energies, lifetimes and\nemergence of collective excitations from molecules to bulk-like systems with up\nto thousands of valence electrons, including Si nanocrystals and nanoplatelet.\nThe quasiparticle energies rise due to their coupling with collective shake-up\n(plasmon) excitations, and this coupling leads to significant spectral weight\nloss (up to 50% for the low energy states), shortening the lifetimes and\nshifting the spectral features to lower energy by as much as 0.6 eV. Such\nfeatures are common to all the systems studied irrespective of their size and\nshape. For small and low dimensional systems the surface plasmon resonances\naffect the frequency of the collective excitation and position of the\nsatellites.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  High visibility temporal ghost imaging with classical light is possible when\nsuperbunching pseudothermal light is employed. In the numerical simulation, the\nvisibility of temporal ghost imaging with pseudothermal light equaling ($4.7\\pm\n0.2$)\\% can be increased to ($75\\pm 8$)\\% in the same scheme with superbunching\npseudothermal light. The reasons for the difference in visibility and quality\nof the retrieved images in different situations are discussed in detail. It is\nconcluded that high visibility and high quality temporal ghost image can be\nobtained by collecting large enough number of data points. The results are\nhelpful to understand the difference between ghost imaging with classical light\nand entangled photon pairs. The superbunching pseudothermal light can be\nemployed to improve the image quality in ghost imaging applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Presented is a Julia meta-program that discovers compact theories from data\nif they exist. It writes candidate theories in Julia and then validates:\ntossing the bad theories and keeping the good theories. Compactness is measured\nby a metric: such as the number of space-time derivatives. The underlying\nalgorithm is applicable to a wide variety of combinatorics problems and\ncompactness serves to cut down the search space.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we are concerned with the following type of elliptic problems:\n$$\n  (-\\Delta)^{\\alpha} u+a(x) u=\\frac{|u|^{2^*_{s}-2}u}{|x|^s}+k(x)|u|^{q-2}u,\nu\\,\\in\\,H^\\alpha({\\mathbb R}^N), $$ where $2<q< 2^*$, $0<\\alpha<1$,\n$0<s<2\\alpha$, $2^*_{s}=2(N-s)/(N-2\\alpha)$ is the critical Sobolev-Hardy\nexponent, $2^*=2N/(N-2\\alpha)$ is the critical Sobolev exponent, $a(x),k(x)\\in\nC({\\mathbb R}^N)$. Through a compactness analysis of the functional associated\nto the problem, we obtain the existence of positive solutions under certain\nassumptions on $a(x),k(x)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recent work has demonstrated the effectiveness of gradient descent for\ndirectly recovering the factors of low-rank matrices from random linear\nmeasurements in a globally convergent manner when initialized properly.\nHowever, the performance of existing algorithms is highly sensitive in the\npresence of outliers that may take arbitrary values. In this paper, we propose\na truncated gradient descent algorithm to improve the robustness against\noutliers, where the truncation is performed to rule out the contributions of\nsamples that deviate significantly from the {\\em sample median} of measurement\nresiduals adaptively in each iteration. We demonstrate that, when initialized\nin a basin of attraction close to the ground truth, the proposed algorithm\nconverges to the ground truth at a linear rate for the Gaussian measurement\nmodel with a near-optimal number of measurements, even when a constant fraction\nof the measurements are arbitrarily corrupted. In addition, we propose a new\ntruncated spectral method that ensures an initialization in the basin of\nattraction at slightly higher requirements. We finally provide numerical\nexperiments to validate the superior performance of the proposed approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider a full set of harmonics for the Stokes wave in deep water in the\nabsence of viscosity, and examine the role that higher harmonics play in\nmodifying the classical Benjamin-Feir instability. Using a representation of\nthe wave coefficients due to Wilton, a perturbation analysis shows that the\nStokes wave may become unbounded due to interactions between the $N^{th}$\nharmonic of the primary wave train and a set of harmonics of a disturbance. If\nthe frequency of the $n^{th}$ harmonic is denoted $ \\omega _{n} =\\omega \\left(\n{1 \\pm \\delta } \\right)$ then instability will occur if $$ 0<\\delta\n<\\frac{\\sqrt 2\\ k\\,n^ns_n }{\\left( {n-1} \\right)!} $$ subject to the\ndisturbance initially having sufficiently large amplitude. We show that,\nsubject to initial conditions, all lower harmonics will contribute to\ninstability as well, and we identify the frequency of the disturbance\ncorresponding to maximum growth rate.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using the parameterisation of the deformation space of GHMC anti-de Sitter\nstructures on $S \\times \\mathbb{R}$ by the cotangent bundle of the\nTeichm\\\"uller space of $S$, we study how some geometric quantities, such as the\nLorentzian Hausdorff dimension of the limit set, the width of the convex core\nand the H\\\"older exponent, degenerate along rays of quadratic differentials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work we establish the first linear convergence result for the\nstochastic heavy ball method. The method performs SGD steps with a fixed\nstepsize, amended by a heavy ball momentum term. In the analysis, we focus on\nminimizing the expected loss and not on finite-sum minimization, which is\ntypically a much harder problem. While in the analysis we constrain ourselves\nto quadratic loss, the overall objective is not necessarily strongly convex.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Asymmetry is unquestionably an important characteristic of the wireless\npropagation channel, which needs to be accurately modeled for wireless and\nmobile communications, 5G networks, and associated applications such as\nindoor/outdoor localization. This paper reports on the potential causes of\npropagation asymmetry. Practical channel measurements at Khalifa University\npremises proved that wireless channels are asymmetric in realistic scenarios.\nSome important conclusions and recommendation are also summarized.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A general formula is calculated for the connection of a central metric\nw.r.t.\\ a noncommutative spacetime of Lie-algebraic type. This is done by using\nthe framework of linear connections on central bi-modules. The general formula\nis further on used to calculate the corresponding Riemann tensor and prove the\ncorresponding Bianchi identities and certain symmetries that are essential to\nobtain a symmetric and divergenceless Einstein Tensor. In particular, the\nobtained Einstein Tensor is not equivalent to the sum of the noncommutative\nRiemann tensor and scalar, as in the commutative case, but in addition a\ntraceless term appears.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present an end-to-end imitation learning system for agile, off-road\nautonomous driving using only low-cost sensors. By imitating a model predictive\ncontroller equipped with advanced sensors, we train a deep neural network\ncontrol policy to map raw, high-dimensional observations to continuous steering\nand throttle commands. Compared with recent approaches to similar tasks, our\nmethod requires neither state estimation nor on-the-fly planning to navigate\nthe vehicle. Our approach relies on, and experimentally validates, recent\nimitation learning theory. Empirically, we show that policies trained with\nonline imitation learning overcome well-known challenges related to covariate\nshift and generalize better than policies trained with batch imitation\nlearning. Built on these insights, our autonomous driving system demonstrates\nsuccessful high-speed off-road driving, matching the state-of-the-art\nperformance.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  An investigation of the 200 $\\times$ 200 pixel 'superstamp' images of the\ncentres of the open clusters NGC 6791 and NGC 6819 allows for the\nidentification and study of many variable stars that were not included in the\nKepler target list. KIC 2569073 (V=14.22), is a particularly interesting\nvariable Ap star that we discovered in the NGC 6791 superstamp. With a\nrotational period of 14.67 days and 0.034-mag variability, it has one of the\nlargest peak-to-peak variations of any known Ap star. Colour photometry reveals\nan anti-phase correlation between the $B$ band, and the $V$, $R$ and $I$ bands.\nThis Ap star is a rotational variable, also known as an $\\alpha^2$ CVn, star,\nand is one of only a handful of Ap stars observed by Kepler. While no change in\nspot period or amplitude is observed within the 4-year Kepler timeseries, the\namplitude shows a large increase compared to ground-based photometry obtained\ntwo decades ago.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The output of a motor is work, while the output of a clock is information.\nHere it is discussed how a molecular motor can produce both, work and\ninformation, depending on the load. If the ratio of the backward and forward\nstepping rates of a molecular motor increases exponentially with load, the\nchange in free energy per step can be used to produce only work (at stall\nforce) or only timing information (at zero force), or anything in between.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For multi-level open quantum system, the interaction between different levels\ncould pose challenge to understand the quantum system both analytically and\nnumerically. In this work, we study the approximation of the dynamics of the\nAnderson-Holstein model, as a model of multi-level open quantum system, by\nRedfield and Lindblad equations. Both equations have a desirable property that\nif the density operators for different levels is diagonal initially, they\nremain to be diagonal for any time. Thanks to this nice property, the\nsemi-classical limit of both Redfield and Lindblad equations could be derived\nexplicitly; the resulting classical master equations share similar structures\nof transport and hopping terms. The Redfield and Lindblad equations are also\ncompared from the angle of time dependent perturbation theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove a Perron-Frobenius-Ruelle theorem for group extensions of\ntopological Markov chains based on a construction of $\\sigma$-finite conformal\nmeasures and give applications to the construction of harmonic functions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this article, we give some reviews concerning negative probabilities model\nand quasi-infinitely divisible at the beginning. We next extend Feller's\ncharacterization of discrete infinitely divisible distributions to signed\ndiscrete infinitely divisible distributions, which are discrete pseudo compound\nPoisson (DPCP) distributions with connections to the L\\'evy-Wiener theorem.\nThis is a special case of an open problem which is proposed by Sato(2014),\nChaumont and Yor(2012). An analogous result involving characteristic functions\nis shown for signed integer-valued infinitely divisible distributions. We show\nthat many distributions are DPCP by the non-zero p.g.f. property, such as the\nmixed Poisson distribution and fractional Poisson process. DPCP has some\nbizarre properties, and one is that the parameter $\\lambda $ in the DPCP class\ncannot be arbitrarily small.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The dispersion relation of graviton is a fundamental issue for fundamental\nphysics about gravity. In this paper we investigate how the modified dispersion\nrelation of graviton affects the cosmic microwave background (CMB) power\nspectra, in particular the B-mode polarization. Our results will be useful to\ntest the dispersion relation of graviton at the energy scale around $10^{-29}$\neV.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Simulations are attractive environments for training agents as they provide\nan abundant source of data and alleviate certain safety concerns during the\ntraining process. But the behaviours developed by agents in simulation are\noften specific to the characteristics of the simulator. Due to modeling error,\nstrategies that are successful in simulation may not transfer to their real\nworld counterparts. In this paper, we demonstrate a simple method to bridge\nthis \"reality gap\". By randomizing the dynamics of the simulator during\ntraining, we are able to develop policies that are capable of adapting to very\ndifferent dynamics, including ones that differ significantly from the dynamics\non which the policies were trained. This adaptivity enables the policies to\ngeneralize to the dynamics of the real world without any training on the\nphysical system. Our approach is demonstrated on an object pushing task using a\nrobotic arm. Despite being trained exclusively in simulation, our policies are\nable to maintain a similar level of performance when deployed on a real robot,\nreliably moving an object to a desired location from random initial\nconfigurations. We explore the impact of various design decisions and show that\nthe resulting policies are robust to significant calibration error.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The determination of $|V_{us}|$ from kaon semileptonic decays requires the\nvalue of the form factor $f_+(q^2=0)$ which can be calculated precisely on the\nlattice. We provide the one-loop partially quenched chiral perturbation theory\nexpressions both with and without including the effects of staggered quarks for\nall form factors at finite volume and with partially twisted boundary\nconditions for both the vector current and scalar density matrix elements at\nall $q^2$. We point out that at finite volume there are more form factors than\njust $f_+$ and $f_-$ for the vector current matrix element but that the Ward\nidentity is fully satisfied. The size of the finite-volume corrections at\npresent lattice sizes is small. This will help improve the lattice\ndetermination of $f_+(q^2=0)$ since the finite-volume error is the dominant\nerror source for some calculations. The size of the finite-volume corrections\nmay be estimated on a single lattice ensemble by comparing results for various\ntwist choices.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the impact of general conditions of theoretical stability and\ncosmological viability on dynamical dark energy models. As a powerful example,\nwe study whether minimally coupled, single field Quintessence models that are\nsafe from ghost instabilities, can source the CPL expansion history recently\nshown to be mildly favored by a combination of CMB (Planck) and Weak Lensing\n(KiDS) data. We find that in their most conservative form, the theoretical\nconditions impact the analysis in such a way that smooth single field\nQuintessence becomes significantly disfavored with respect to the standard LCDM\ncosmological model. This is due to the fact that these conditions cut a\nsignificant portion of the (w0;wa) parameter space for CPL, in particular\neliminating the region that would be favored by weak lensing data. Within the\nscenario of a smooth dynamical dark energy parametrized with CPL, weak lensing\ndata favors a region that would require multiple fields to ensure gravitational\nstability.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we consider the eigen-solutions of $-\\Delta u+ Vu=\\lambda u$,\nwhere $\\Delta$ is the Laplacian on a non-compact complete Riemannian manifold.\nWe develop Kato's methods on manifold and establish the growth of the\neigen-solutions as $r$ goes to infinity based on the asymptotical behaviors of\n$\\Delta r$ and $V(x)$, where $r=r(x)$ is the distance function on the manifold.\nAs applications, we prove several criteria of absence of eigenvalues of\nLaplacian, including a new proof of the absence of eigenvalues embedded into\nthe essential spectra of free Laplacian if the radial curvature of the manifold\nsatisfies $ K_{\\rm rad}(r)= -1+\\frac{o(1)}{r}$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a novel finite-difference time-domain (FDTD) scheme for the\nsolution of the Maxwell's equations in which linear dispersive effects are\npresent. The method uses high-order accurate approximations in space and time\nfor the dispersive Maxwell's equations written as a second-order vector wave\nequation with a time-history convolution term. The modified equation approach\nis combined with the recursive convolution (RC) method to develop high-order\napproximations accurate to any desired order in space and time.\nHigh-order-accurate centered approximations of the physical Maxwell interface\nconditions are derived for the dispersive setting in order to fully restore\naccuracy at discontinuous material interfaces. Second- and fourth-order\naccurate versions of the scheme are presented and implemented in two spatial\ndimensions for the case of the Drude linear dispersion model. The stability of\nthese schemes is analyzed. Finally, our approach is also amenable to\ncurvilinear numerical grids if used with appropriate generalized Laplace\noperator.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we study quantum stochastic differential equations (QSDEs) that\nare driven by strongly squeezed vacuum noise. We show that for strong squeezing\nsuch a QSDE can be approximated (via a limit in the strong sense) by a QSDE\nthat is driven by a single commuting noise process. We find that the\napproximation has an additional Hamiltonian term.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We review instrumentation for nuclear magnetic resonance (NMR) in zero and\nultra-low magnetic field (ZULF, below 0.1 $\\mu$T) where detection is based on a\nlow-cost, non-cryogenic, spin-exchange relaxation free (SERF) $^{87}$Rb atomic\nmagnetometer. The typical sensitivity is 20-30 fT/Hz$^{1/2}$ for signal\nfrequencies below 1 kHz and NMR linewidths range from Hz all the way down to\ntens of mHz. These features enable precision measurements of chemically\ninformative nuclear spin-spin couplings as well as nuclear spin precession in\nultra-low magnetic fields.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The basic concept of multi-dimensional limiting process (MLP) on unstructured\ngrids is inherited and modified for improving shock stabilities and reducing\nnumerical dissipation on smooth regions. A relaxed version of MLP condition,\nsimply named as weak-MLP, is proposed for reducing dissipation. Moreover, a\nstricter condition, that is the strict-MLP condition, is proposed to enhance\nthe numerical stability. The maximum/minimum principle is fulfilled by both the\nstrict- and weak-MLP condition. A differentiable pressure weight function is\napplied for the combination of two novel conditions, and thus the modified\nlimiter is named as MLP-pw(pressure-weighted). A series of numerical test cases\nshow that MLP-pw limiter has improved stability and convergence, especially in\nhypersonic simulations. Furthermore, the limiter also shows lower dissipation\nin regions without significant pressure transition. Therefore, MLP-pw limiter\ncan capture contact discontinuity and expansion accurately.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We theoretically investigate the chiral topological excitons emerging in the\nmonolayer transition metal dichalcogenides, where a bulk energy gap of valley\nexcitons is opened up by a position dependent external magnetic field. We find\ntwo emerging chiral topological nontrivial excitons states, which exactly\nconnects to the bulk topological properties, i.e., Chern number =2. The\ndependences of the spectrum of the chiral topological excitons on the width of\nthe magnetic field domain wall as well as the magnetic filed strength are\nnumerically revealed. The chiral topological valley excitons are not only\nimportant to the excitonic transport due to prevention of the backscattering,\nbut also give rise to the quantum coherent control in the optoelectronic\napplications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $A_g$ be an abelian variety of dimension $g$ and $p$-rank $\\lambda \\leq\n1$ over an algebraically closed field of characteristic $p>0$. We compute the\nnumber of homomorphisms from $\\pi_1^{\\text{\\'et}}(A_g,a)$ to $GL_n(\\mathbb\nF_q)$, where $q$ is any power of $p$. We show that for fixed $g$, $\\lambda$,\nand $n$, the number of such representations is polynomial in $q$, and give an\nexplicit formula for this polynomial. We show that the set of such\nhomomorphisms forms a constructible set, and use the geometry of this space to\ndeduce information about the coefficients and degree of the polynomial.\n  In the last section we prove a divisibility theorem about the number of\nhomomorphisms from certain semidirect products of profinite groups into finite\ngroups. As a corollary, we deduce that when $\\lambda=0$,\n\\[\\frac{\\#\\operatorname{Hom}(\\pi_1^{\\text{\\'et}}(A_g,a),GL_n(\\mathbb\nF_q))}{\\#GL_n(\\mathbb F_q)}\\] is a Laurent polynomial in $q$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hormozgan Province, located in the south of Iran, faces several challenges\nregarding water resources management. The first one is the discharge of a\nmassive volume of water to the Persian Gulf because of the concentration of the\nannual rainfalls in a short period of time and the narrow distance between the\nheadwater and the coast. The second one is the unbalanced development of\neconomic sectors in comparison with distribution of fresh water resources.\nFinally, long-term drought is also common in this area. The construction of a\ncarry-over dam (Esteghlal Dam) and several conveyance pipelines and withdrawing\nof the surface water and groundwater resources were considered as the solution\nto deal with those challenges. During recent drought, severe overdraft and\ninefficient use of recourses confirmed the fact that all done before are not\nenough. During this period, there was a tendency to store water in reservoir in\norder to meet the demand of the urban sector. Therefore, the agricultural\ndemand was the first victim of water allocation policy. It caused over\nexploitation of the groundwater resources (to meet the agricultural demand) and\nconsiderable losses (evaporation and leakage) from the reservoir. All of the\nabove-mentioned problems confirm the necessity of the development of a\nconjunctive use policy. In this paper, all demand related to the Esteghlal Dam\nand the Minab Aquifer (Bandarabbas City and agriculture in the Minab Plain)\nwere considered as the case study. The main objective was to find the best\napplicable conjunctive policy which as well guarantees the conservation of the\nMinab Aquifer. Alternative water allocation policies have been developed based\non the present capacities and the experience of local operating staff.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We apply a nonlinear mean-field dynamo model which includes a budget equation\nfor the dynamics of Wolf numbers to predict solar activity. This dynamo model\ntakes into account the algebraic and dynamic nonlinearities of the alpha\neffect, where the equation for the dynamic nonlinearity is derived from the\nconservation law for the magnetic helicity. The budget equation for the\nevolution of the Wolf number is based on a formation mechanism of sunspots\nrelated to the negative effective magnetic pressure instability. This\ninstability redistributes the magnetic flux produced by the mean-field dynamo.\nTo predict solar activity on the time scale of one month we use a method based\non a combination of the numerical solution of the nonlinear mean-field dynamo\nequations and the artificial neural network. A comparison of the results of the\nprediction of the solar activity with the observed Wolf numbers demonstrates a\ngood agreement between the forecast and observations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recently it was shown that in the dynamical model of Chua circuit both the\nclassical selfexcited and hidden chaotic attractors can be found. In this paper\nthe dynamics of the Chua circuit is revisited. The scenario of the chaotic\ndynamics development and the birth of selfexcited and hidden attractors is\nstudied. It is shown a pitchfork bifurcation in which a pair of symmetric\nattractors coexists and merges into one symmetric attractor through an\nattractormerging bifurcation and a splitting of a single attractor into two\nattractors. The scenario relating the subcritical Hopf bifurcation near\nequilibrium points and the birth of hidden attractors is discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Mid-infrared optical frequency combs are of significant interest for\nmolecular spectroscopy due to the large absorption of molecular vibrational\nmodes on one hand, and the ability to implement superior comb-based\nspectroscopic modalities with increased speed, sensitivity and precision on the\nother hand. Substantial advances in mid-infrared frequency comb generation have\nbeen made in recent years based on nonlinear frequency conversion,\nmicroresonator Kerr frequency combs, quantum cascade lasers and mode locking\nregimes. Here we demonstrate a simple, yet effective method for the direct\ngeneration of mid-infrared optical frequency combs in the region from\n${2.5-4~\\mu{\\rm m}}$, i.e. ${2500-4000~{\\rm cm}^{-1}}$ covering a large\nfraction of the functional group region, directly from a conventional and\ncompact erbium-fiber-based femtosecond laser in the telecommunication band\n(i.e. ${1.55~\\mu{\\rm m}}$). The wavelength conversion is based on dispersive\nwave generation within the supercontinuum process in large-cross-section and\ndispersion-engineered silicon nitride (${\\rm Si_3N_4}$) waveguides. The\nlong-wavelength dispersive wave, with its position lithographically determined,\nperforms as a mid-infrared frequency comb, whose coherence is demonstrated via\noptical heterodyne measurements. Such a simple and versatile approach to\nmid-infrared frequency comb generation is suitable for spectroscopic\napplications in the first mid-infrared atmospheric window. Moreover, the\ncompactness and simplicity of the approach have the potential to realize\ncompact dual-comb spectrometers. The generated combs have a fine teeth-spacing,\nmaking them also suitable for gas phase analysis.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In a multipartite random energy model, made of a number of coupled GREMs, we\ndetermine the joint law of the overlaps in terms of the ones of the single\nGREMs. This provides the simplest example of the so-called overlap\nsynchronisation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A theory describing the forces governing the self-assembly of nanoparticles\nat the solid-liquid interface is developed. In the process, new theoretical\nresults are derived to describe the effect that the field penetration of a\npoint-like particle, into an electrode, has on the image potential energy, and\npair interaction energy profiles at the electrode-electrolyte interface. The\napplication of the theory is demonstrated for gold and ITO electrode systems,\npromising materials for novel colour-tuneable electrovariable smart mirrors and\nmirror-window devices respectively. Model estimates suggest that\nelectrovariability is attainable in both systems and will act as a guide for\nfuture experiments. Lastly, the generalisability of the theory towards\nelectrovariable, nanoplasmonic systems suggests that it may contribute towards\nthe design of intelligent metamaterials with programmable properties.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We give a characterization of common zeros of a sequence of univariate\npolynomials $W_n(z)$ defined by a recurrence of order two with polynomial\ncoefficients, and with $W_0(z)=1$. Real common zeros for such polynomials with\nreal coefficients are studied further. This paper contributes to the study of\nroot distribution of recursive polynomial sequences.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Objective: A clinical decision support tool that automatically interprets\nEEGs can reduce time to diagnosis and enhance real-time applications such as\nICU monitoring. Clinicians have indicated that a sensitivity of 95% with a\nspecificity below 5% was the minimum requirement for clinical acceptance. We\npropose a highperformance classification system based on principles of big data\nand machine learning. Methods: A hybrid machine learning system that uses\nhidden Markov models (HMM) for sequential decoding and deep learning networks\nfor postprocessing is proposed. These algorithms were trained and evaluated\nusing the TUH EEG Corpus, which is the world's largest publicly available\ndatabase of clinical EEG data. Results: Our approach delivers a sensitivity\nabove 90% while maintaining a specificity below 5%. This system detects three\nevents of clinical interest: (1) spike and/or sharp waves, (2) periodic\nlateralized epileptiform discharges, (3) generalized periodic epileptiform\ndischarges. It also detects three events used to model background noise: (1)\nartifacts, (2) eye movement (3) background. Conclusions: A hybrid HMM/deep\nlearning system can deliver a low false alarm rate on EEG event detection,\nmaking automated analysis a viable option for clinicians. Significance: The TUH\nEEG Corpus enables application of highly data consumptive machine learning\nalgorithms to EEG analysis. Performance is approaching clinical acceptance for\nreal-time applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Our current knowledge of scholarly plagiarism is largely based on the\nsimilarity between full text research articles. In this paper, we propose an\ninnovative and novel conceptualization of scholarly plagiarism in the form of\nreuse of explicit citation sentences in scientific research articles. Note that\nwhile full-text plagiarism is an indicator of a gross-level behavior, copying\nof citation sentences is a more nuanced micro-scale phenomenon observed even\nfor well-known researchers. The current work poses several interesting\nquestions and attempts to answer them by empirically investigating a large\nbibliographic text dataset from computer science containing millions of lines\nof citation sentences. In particular, we report evidences of massive copying\nbehavior. We also present several striking real examples throughout the paper\nto showcase widespread adoption of this undesirable practice. In contrast to\nthe popular perception, we find that copying tendency increases as an author\nmatures. The copying behavior is reported to exist in all fields of computer\nscience; however, the theoretical fields indicate more copying than the applied\nfields.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the unitary representations of the non-compact real forms of the\ncomplex Lie superalgebra sl(n|m). Among them, only the real form su(p,q|m)\n(p+q=n) admits nontrivial unitary representations, and all such representations\nare of the highest-weight type (or the lowest-weight type). We extend the\nstandard oscillator construction of the unitary representations of non-compact\nLie superalgebras over standard Fock spaces to generalised Fock spaces which\nallows us to define the action of oscillator determinants raised to non-integer\npowers. We prove that the proposed construction yields all the unitary\nrepresentations including those with continuous labels. The unitary\nrepresentations can be diagrammatically represented by non-compact Young\ndiagrams. We apply our general results to the physically important case of\nfour-dimensional conformal superalgebra su(2,2|4) and show how it yields\nreadily its unitary representations including those corresponding to\nsupermultiplets of conformal fields with continuous (anomalous) scaling\ndimensions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we prove that the ascent of a weighted conditional expectation\noperator of the form of $M_wEM_u$ on $L^p$-spaces is always finite and is equal\nto 2. Also we get that under a weak condition the descent of $M_wEM_u$ is\nfinite and is equal to 2 too. Moreover, we give some necessary and sufficient\nconditions for $M_wE M_u$ to be power bounded. In the sequel we apply some\nresults in operator theory on ascent and descent to $M_wEM_u$. Finally we find\nthat $T=M_wEM_u$ is Cesaro bounded if and only if $\\widehat{T}$ is Cesaro\nbounded.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Nuclear magnetic resonance (NMR) shifts, if stripped off their uncertainties,\nmust hold key information about the electronic fluid in the cuprates. The early\nshift interpretation that favored a single-fluid scenario will be reviewed, as\nwell as recent experiments that reported its failure. Thereafter, based on\nliterature shift data for planar Cu a contrasting shift phenomenology for\ncuprate superconductors is developed, which is very different from the early\nview while being in agreement with all published data. For example, it will be\nshown that the hitherto used hyperfine scenario is inadequate as a large\nisotropic shift component is discovered. Furthermore, the changes of the\ntemperature dependences of the shifts above and below the superconducting\ntransitions temperature proceed according to a few rules that were not\ndiscussed before. It appears that there can be substantial spin shift at the\nlowest temperature if the magnetic field lies in the CuO$_2$ plane, which\npoints to a localization of spin in the $3d(x^2-y^2)$ orbital. A simple model\nis presented based on the most fundamental findings. The analysis must have new\nconsequences for theory of the cuprates.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Device-to-device (D2D) communication is a promising technology for the future\nwireless systems. It allows direct communication between devices, which\nprovides improvements in terms of delay, throughput and energy consumption.\nTherefore, it can contribute to achieving the ambitious requirements of future\n5G wireless system. In this sense, energy efficiency has become a key\nrequirement in the design of 5G technology. In this paper we analyze the\nenergy-efficiency improvement provided by D2D communications in an overlaying\nscenario, in the context of a realistic wireless network system. This analysis\ntakes into account the two D2D phases, discovery and communication. A\ncentralized architecture is considered to manage discovery, which is a key\nphase on D2D communications. Numerical evaluation shows improvement in terms of\nenergy-efficiency, reachable throughput and outage probability.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we discuss spherically symmetric wormhole solutions in\n$f(R,T)$ modified theory of gravity by introducing well-known non-commutative\ngeometry in terms of Gaussian and Lorentizian distributions of string theory.\nFor some analytic discussion, we consider an interesting model of $f(R,T)$\ngravity defined by $f(R,T)=f_{1}(R)+\\lambda T$. By taking two different choices\nfor the function $f_{1}(R)$, that is, $f_{1}(R)=R$ and $f_{1}(R)=R+\\alpha\nR^{2}+\\gamma R^{n}$, we discuss the possible existence of wormhole solutions.\nIn the presence of non-commutative Gaussian and Lorentizian distributions, we\nget exact and numerical solutions for both these models. By taking appropriate\nvalues of the free parameters, we discuss different properties of these\nwormhole models analytically and graphically. Further, using equilibrium\ncondition, it is found that these solutions are stable. Also, we discuss the\nphenomenon of gravitational lensing for the exact wormhole model and it is\nfound that the deflection angle diverges at wormhole throat.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Driven by growing interest in the sciences, industry, and among the broader\npublic, a large number of empirical studies have been conducted in recent years\nof the structure of networks ranging from the internet and the world wide web\nto biological networks and social networks. The data produced by these\nexperiments are often rich and multimodal, yet at the same time they may\ncontain substantial measurement error. In practice, this means that the true\nnetwork structure can differ greatly from naive estimates made from the raw\ndata, and hence that conclusions drawn from those naive estimates may be\nsignificantly in error. In this paper we describe a technique that circumvents\nthis problem and allows us to make optimal estimates of the true structure of\nnetworks in the presence of both richly textured data and significant\nmeasurement uncertainty. We give example applications to two different social\nnetworks, one derived from face-to-face interactions and one from self-reported\nfriendships.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In many areas of data mining, data is collected from humans beings. In this\ncontribution, we ask the question of how people actually respond to ordinal\nscales. The main problem observed is that users tend to be volatile in their\nchoices, i.e. complex cognitions do not always lead to the same decisions, but\nto distributions of possible decision outputs. This human uncertainty may\nsometimes have quite an impact on common data mining approaches and thus, the\nquestion of effective modelling this so called human uncertainty emerges\nnaturally.\n  Our contribution introduces two different approaches for modelling the human\nuncertainty of user responses. In doing so, we develop techniques in order to\nmeasure this uncertainty at the level of user inputs as well as the level of\nuser cognition. With support of comprehensive user experiments and large-scale\nsimulations, we systematically compare both methodologies along with their\nimplications for personalisation approaches. Our findings demonstrate that\nsignificant amounts of users do submit something completely different (action)\nthan they really have in mind (cognition). Moreover, we demonstrate that\nstatistically sound evidence with respect to algorithm assessment becomes quite\nhard to realise, especially when explicit rankings shall be built.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present detailed neutron scattering studies of the static and dynamic\nstripes in an optimally doped high-temperature superconductor,\nLa$_2$CuO$_{4+y}$. We find that the dynamic stripes do not disperse towards the\nstatic stripes in the limit of vanishing energy transfer. We conclude that the\ndynamic stripes observed in neutron scattering experiments are not the\nGoldstone modes associated with the broken symmetry of the simultaneously\nobserved static stripes, but rather that the signals originate from different\ndomains in the sample. These domains may be related by structural twinning, or\nmay be entirely different phases, where the static stripes in one phase are\npinned versions of the dynamic stripes in the other. Our results explain\nearlier observations of unusual dispersions in underdoped\nLa$_{2-x}$Sr$_x$CuO$_{4}$ ($x=0.07$) and La$_{2-x}$Ba$_x$CuO$_{4}$ ($x=0.095$).\nOur findings are relevant for all compounds exhibiting magnetic stripes, and\nmay thus be a vital part in unveiling the nature of high temperature\nsuperconductivity.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We extend the notion of intrinsic entropy for endomorphisms of Abelian groups\nto endomorphisms of modules over an Archimedean non-discrete valuation domain\n$R$, using the natural non-discrete length function introduced by Northcott and\nReufel for such a category of modules. We prove that this notion of entropy is\na length function for the category of $R[X]$-modules, it satisfies (a suitably\nadapted version of) the Intrinsic Algebraic Yuzvinski Formula and that it is\nessentially the unique invariant for $Mod(R[X])$ with these properties.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a variational multi-label segmentation algorithm based on a robust\nHuber loss for both the data and the regularizer, minimized within a convex\noptimization framework. We introduce a novel constraint on the common areas, to\nbias the solution towards mutually exclusive regions. We also propose a\nregularization scheme that is adapted to the spatial statistics of the residual\nat each iteration, resulting in a varying degree of regularization being\napplied as the algorithm proceeds: the effect of the regularizer is strongest\nat initialization, and wanes as the solution increasingly fits the data. This\nminimizes the bias induced by the regularizer at convergence. We design an\nefficient convex optimization algorithm based on the alternating direction\nmethod of multipliers using the equivalent relation between the Huber function\nand the proximal operator of the one-norm. We empirically validate our proposed\nalgorithm on synthetic and real images and offer an information-theoretic\nderivation of the cost-function that highlights the modeling choices made.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we consider reinsurance or risk sharing from a macroeconomic\npoint of view. Our aim is to find socially optimal reinsurance treaties. In our\nsetting we assume that there are $n$ insurance companies each bearing a certain\nrisk and one representative reinsurer. The optimization problem is to minimize\nthe sum of all capital requirements of the insurers where we assume that all\ninsurance companies use a form of Range-Value-at-Risk. We show that in case all\ninsurers use Value-at-Risk and the reinsurer's premium principle satisfies\nmonotonicity, then layer reinsurance treaties are socially optimal. For this\nresult we do not need any dependence structure between the risks. In the\ngeneral setting with Range-Value-at-Risk we obtain again the optimality of\nlayer reinsurance treaties under further assumptions, in particular under the\nassumption that the individual risks are positively dependent through the\nstochastic ordering. At the end, we discuss the difference between socially\noptimal reinsurance treaties and individually optimal ones by looking at a\nnumber of special cases.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We extend recently proposed mimetic dark matter (DM) and dust of dark energy\n(DE) models to a U(1)-charged gauged scalar field. This extension yields a mass\nto the photon via the Higgs mechanism. The square of this photon mass is\nproportional to the DM energy density. Thus dense DM environments can screen\nthe dark vector force. There is a substantial freedom in this gauged extension\nof the irrotational fluid-like DM. This freedom enables one to model the\nclassical London equation of superconductivity or to obtain the photon mass\nwhich remains constant during the matter-dominated \\'epoque.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We survey some of the progress made recently in the classification of von\nNeumann algebras arising from countable groups and their measure preserving\nactions on probability spaces. We emphasize results which provide classes of\n(W$^*$-superrigid) actions that can be completely recovered from their von\nNeumann algebras and II$_1$ factors that have a unique Cartan subalgebra. We\nalso present cocycle superrigidity theorems and some of their applications to\norbit equivalence. Finally, we discuss several recent rigidity results for von\nNeumann algebras associated to groups.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Due to the nature depending on only the gravitational field, microlensing, in\nprinciple, provides an important tool to detect faint and even dark brown\ndwarfs. However, the number of identified brown dwarfs is limited due to the\ndifficulty of the lens mass measurement that is needed to check the substellar\nnature of the lensing object. In this work, we report a microlensing brown\ndwarf discovered from the analysis of the gravitational binary-lens event\nOGLE-2014-BLG-1112. We identify the brown-dwarf nature of the lens companion by\nmeasuring the lens mass from the detections of both microlens-parallax and\nfinite-source effects. We find that the companion has a mass of $(3.03 \\pm\n0.78)\\times 10^{-2}\\ M_\\odot$ and it is orbiting a solar-type primary star with\na mass of $1.07 \\pm 0.28\\ M_\\odot$. The estimated projected separation between\nthe lens components is $9.63 \\pm 1.33$ au and the distance to the lens is $4.84\n\\pm 0.67$ kpc. We discuss the usefulness of space-based microlensing\nobservations in detecting brown dwarfs through the channel of binary-lens\nevents.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We make a proposal for gauge-invariant observables in perturbative quantum\ngravity in cosmological spacetimes, building on the recent work of Brunetti et\nal. [JHEP 08 (2016) 032]. These observables are relational, and are obtained by\nevaluating the field operator in a field-dependent coordinate system. We show\nthat it is possible to define this coordinate system such that the\nnon-localities inherent in any higher-order observable in quantum gravity are\ncausal, i.e., the value of the gauge-invariant observable at a point $x$ only\ndepends on the metric and inflation perturbations in the past light cone of\n$x$. We then construct propagators for the metric and inflaton perturbations in\na gauge adapted to that coordinate system, which simplifies the calculation of\nloop corrections, and give explicit expressions for relevant cases: matter- and\nradiation-dominated eras and slow-roll inflation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the dark matter phenomenology of non-minimal composite Higgs models\nwith $SO(7)$ broken to the exceptional group $G_2$. In addition to the Higgs,\nthree pseudo-Nambu-Goldstone bosons arise, one of which is electrically\nneutral. A parity symmetry is enough to ensure this resonance is stable. In\nfact, if the breaking of the Goldstone symmetry is driven by the fermion\nsector, this $\\mathbb{Z}_2$ symmetry is automatically unbroken in the\nelectroweak phase. In this case, the relic density, as well as the expected\nindirect, direct and collider signals are then uniquely determined by the value\nof the compositeness scale, $f$. Current experimental bounds allow to account\nfor a large fraction of the dark matter of the Universe if the dark matter\nparticle is part of an electroweak triplet. The totality of the relic abundance\ncan be accommodated if instead this particle is a composite singlet. In both\ncases, the scale $f$ and the dark matter mass are of the order of a few TeV.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a new method to qualify the goodness of fit parameter estimation\nof compound Wishart models. Our method based on the free deterministic\nequivalent Z-score, which we introduce in this paper. Furthermore, an\napplication to two dimensional autoregressive moving-average model is provided.\n  Our proposal method is a generalization of statistical hypothesis testing to\none dimensional moving average model based on fluctuations of real compound\nWishart matrices, which is a recent result by Hasegawa, Sakuma and Yoshida.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The classical spectral theorem completely describes self-adjoint operators on\nfinite dimensional inner product vector spaces as linear combinations of\northogonal projections onto pairwise orthogonal subspaces. We prove a similar\ntheorem for self-adjoint operators on finite dimensional symplectic vector\nspaces over perfect fields. We show that these operators decompose according to\na polarization, i.e. as the product of an operator on a lagrangian subspace and\nits dual on a complementary lagrangian. Moreover, if all the eigenvalues of the\noperator are in the base field, then there exist a Darboux basis such that the\nmatrix representation of the operator is two-by-two blocks block-diagonal,\nwhere the first block is in Jordan normal form and the second block is the\ntranspose of the first one.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Optical cavities provide high sensitivity to dispersion since their resonance\nfrequencies depend on the index of refraction. We present a direct, broadband,\nand accurate measurement of the modes of a high finesse cavity using an optical\nfrequency comb and a mechanical Fourier transform spectrometer with a kHz-level\nresolution. We characterize 16000 cavity modes spanning 16 THz of bandwidth in\nterms of center frequency, linewidth, and amplitude. We retrieve the group\ndelay dispersion of the cavity mirror coatings and pure N${_2}$ with 0.1\nfs${^2}$ precision and 1 fs${^2}$ accuracy, as well as the refractivity of the\n3{\\nu}1+{\\nu}3 absorption band of CO${_2}$ with 5 x 10${^{-12}}$ precision.\nThis opens up for broadband refractive index metrology and calibration-free\nspectroscopy of entire molecular bands.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study a model of a cyclic, spatially homogeneous, anisotropic 'mixmaster'\nuniverse of Bianchi type IX, containing a radiation field with non-comoving\n('tilted' with respect to the tetrad frame of reference) velocities and\nvorticity. We employ a combination of numerical and approximate analytic\nmethods to investigate the consequences of the second law of thermodynamics on\nthe evolution. We model a smooth cycle-to-cycle evolution of the mixmaster\nuniverse, bouncing at a finite minimum, by the device of adding a comoving\n'ghost' field with negative energy density. In the absence of a cosmological\nconstant, an increase in entropy, injected at the start of each cycle, causes\nan increase in the volume maxima, increasing approach to flatness, falling\nvelocities and vorticities, and growing anisotropy at the expansion maxima of\nsuccessive cycles. We find that the velocities oscillate rapidly as they evolve\nand change logarithmically in time relative to the expansion volume. When the\nconservation of momentum and angular momentum constraints are imposed, the\nspatial components of these velocities fall to smaller values when the entropy\ndensity increases, and vice versa. Isotropisation is found to occur when a\npositive cosmological constant is added because the sequence of oscillations\nends and the dynamics expand forever, evolving towards a quasi de Sitter\nasymptote with constant velocity amplitudes. The case of a single cycle of\nevolution with a negative cosmological constant added is also studied.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we explain in detail how receptive fields, effective receptive\nfields, and projective fields of neurons in different layers, convolution or\npooling, of a Convolutional Neural Network (CNN) are calculated. While our\nfocus here is on CNNs, the same operations, but in the reverse order, can be\nused to calculate these quantities for deconvolutional neural networks. These\nare important concepts, not only for better understanding and analyzing\nconvolutional and deconvolutional networks, but also for optimizing their\nperformance in real-world applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Radial vibrations of charge one hedgehog Skyrmions in the full Skyrme model\nare analysed. We investigate how the properties of the lowest resonance modes\n(quasi normal modes) - their frequencies and widths - depend on the form of the\npotential (value of the pion mass as well as the addition of further\npotentials) and on the inclusion of the sextic term. Then we consider the\ninverse problem, where certain values for the frequencies and widths are\nimposed, and the field theoretic Skyrme model potential giving rise to them is\nreconstructed. This latter method allows to reproduce the physical Roper\nresonances, as well as further physical properties of nucleons, with high\nprecision.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss the generation of small neutrino masses from d=7 1-loop diagrams.\nWe first systematically analyze all possible d=7 1-loop topologies. There is a\ntotal of 48 topologies, but only 8 of these can lead to \"genuine\" d=7 neutrino\nmasses. Here, we define genuine models to be models in which neither d=5 nor\nd=7 tree-level masses nor a d=5 1-loop mass appear, such that the d=7 1-loop is\nthe leading order contribution to the neutrino masses. All genuine models can\nthen be organized w.r.t. their particle content. We find there is only one\ndiagram with no representation larger than triplet, while there are 22 diagrams\nwith quadruplets. We briefly discuss three minimal example models of this kind.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The existence of strong solutions to general class of strongly coupled\nparabolic systems will be discussed. These systems can be degenerate or\nsingular as boundedness of theirs solutions are unavailable and not assummed.\nThe results greatly improve those in a recent papers\n\\cite{letrans,dleJFA,dleANS} as the systems can have quadratic growth in\ngradients. A unified proof for both cases is presented. Most importantly, the\nVMO assumption in \\cite{dleJFA,dleANS} will be replaced by a much versatile one\nthanks to a new local weighted Gagliardo-Nirenberg involving BMO norms.\nDegenerate and singular generalized SKT models in biology will be presented as\na nontrivial application of the main theorem.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Convolution Neural Network (CNN) has gained tremendous success in computer\nvision tasks with its outstanding ability to capture the local latent features.\nRecently, there has been an increasing interest in extending convolution\noperations to the non-Euclidean geometry. Although various types of convolution\noperations have been proposed for graphs or manifolds, their connections with\ntraditional convolution over grid-structured data are not well-understood. In\nthis paper, we show that depthwise separable convolution can be successfully\ngeneralized for the unification of both graph-based and grid-based convolution\nmethods. Based on this insight we propose a novel Depthwise Separable Graph\nConvolution (DSGC) approach which is compatible with the tradition convolution\nnetwork and subsumes existing convolution methods as special cases. It is\nequipped with the combined strengths in model expressiveness, compatibility\n(relatively small number of parameters), modularity and computational\nefficiency in training. Extensive experiments show the outstanding performance\nof DSGC in comparison with strong baselines on multi-domain benchmark datasets.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We explain the properties and clarify the meaning of quantum weak values\nusing only the basic notions of elementary quantum mechanics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Since there is now a growing wish by referees to judge the underpinning data\nfor a submitted article it is timely to provide a summary of the data\nevaluation checks required to be done by a referee. As these checks will vary\nfrom field to field this article focuses on the needs of biological X-ray\ncrystallography articles, which is the predominantly used method leading to\ndepositions in the PDB. The expected referee checks of data underpinning an\narticle are described with examples. These checks necessarily include that a\nreferee checks the PDB validation report for each crystal structure\naccompanying the article submission; this check whilst necessary is not\nsufficient for a complete evaluation. A referee would be expected to undertake\none cycle of model refinement of the authors biological macromolecule\ncoordinates against the authors processed diffraction data and look at the\nvarious validation checks of the model and Fo-Fc electron density maps in e.g.\nPhenix_refine and in COOT. If the referee deems necessary the diffraction data\nimages should be reprocessed (e.g. to a different diffraction resolution than\nthe authors submission). This can be requested to be done by the authors or if\nthe referee prefers can be undertaken directly by the referee themselves. A\nreferee wishing to do these data checks may wish to receive a certificate that\nthey have command of these data science skills. The organisation of such\nvoluntary certification training can e.g. be via those crystallography\nassociations duly recognised by the IUCr to issue such certificates.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper is concerned with inference in threshold regression models when\nthe practitioners do not know whether at the threshold point the true\nspecification has a kink or a jump. We nest previous works that assume either\ncontinuity or discontinuity at the threshold point and develop robust inference\nmethods on the parameters of the model, which are valid under both\nspecifications. In particular, we found that the parameter values under the\nkink restriction are irregular points of the Hessian matrix of the expected\nGaussian quasi-likelihood. This irregularity destroys the asymptotic normality\nand induces the non-standard cube root convergence rate for the threshold\nestimate. However, it also enables us to obtain the same asymptotic\ndistribution as in Hansen (2000) for the quasi-likelihood ratio statistic for\nthe unknown threshold up to an unknown scale parameter. We show that this scale\nparameter can be consistently estimated by a kernel method as long as no higher\norder kernel is used. Furthermore, we propose to construct confidence intervals\nfor the unknown threshold by bootstrap test inversion, also known as grid\nbootstrap. Finite sample performances of the grid bootstrap confidence\nintervals are examined through Monte Carlo simulations. We also implement our\nprocedure to an economic empirical application.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recently, it has been shown in [Jentzen, A., M\\\"uller-Gronbach, T., and\nYaroslavtseva, L., Commun. Math. Sci., 14, 2016] that there exists a system of\nautonomous stochastic differential equations (SDE) on the time interval $[0,T]$\nwith infinitely differentiable and bounded coefficients such that no strong\napproximation method based on evaluation of the driving Brownian motion at\nfinitely many fixed times in $[0,T]$, e.g. on an equidistant grid, can converge\nin absolute mean to the solution at the final time with a polynomial rate in\nterms of the number of Brownian motion values that are used. In the literature\non strong approximation of SDEs, polynomial error rate results are typically\nachieved under the assumption that the first order derivatives of the\ncoefficients of the equation satisfy a polynomial growth condition. This\nassumption is violated for the pathological SDEs from the above mentioned\nnegative result. However, in the present article we construct an SDE with\nsmooth coefficients that have first order derivatives of at most linear growth\nsuch that the solution at the final time can not be approximated with a\npolynomial rate, whatever method based on observations of the driving Brownian\nmotion at finitely many fixed times is used. Most interestingly, it turns out\nthat using a method that adjusts the number of evaluations of the driving\nBrownian motion to its actual path, the latter SDE can be approximated with\nrate 1 in terms of the average number of evaluations that are used. To the best\nof our knowledge, this is only the second example in the literature of an SDE\nfor which there exist adaptive methods that perform superior to non-adaptive\nones with respect to the convergence rate.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For a bipartite state with equal local dimension d, we prove that one can\nobtain work gain under Landauer's erasure process on one party in identically\nand independently distributed (iid) limit when the corresponding fully\nentangled fraction is larger than 1/d. By processing a given state to the\nmaximally mixed state, we give an approximation for the largest extractable\nwork with an error in the energy scale, which becomes negligible in the large\nsystem limit. As a step to link quantum thermodynamics and quantum nonlocality,\nwe also provide a simple picture to approximate the optimal work extraction and\nsuggest a potential thermodynamic interpretation of fully entangled fraction\nfor isotropic states.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Type II string theory and M-theory admit flux configurations that break\nsupersymmetry below the Kaluza-Klein scale. These backgrounds play a central\nrole in most models of the string landscape. I argue that the behavior of such\nbackgrounds at weak coupling is generically a rolling solution, not a static\nspace-time. Quantum corrections to the space-time potential are computed around\nthis classical time-dependent background. This is particularly important for\nnon-perturbative corrections. This change in perspective offers an explanation\nfor why there appear to be many effective field theory models that seemingly\nevade the known no-go theorems forbidding de Sitter space-times. This has\ninteresting implications for type IIB string landscape models.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  New cloud programming and deployment models pose challenges to software\napplication engineers who are looking, often in vain, for tools to automate any\nnecessary code adaptation and transformation. Function-as-a-Service interfaces\nare particular non-trivial targets when considering that most cloud\napplications are implemented in non-functional languages. Among the most widely\nused of these languages is Python. This starting position calls for an\nautomated approach to transform monolithic Python code into modular FaaS units\nby partially automated decomposition. Hence, this paper introduces and\nevaluates Lambada, a Python module to dynamically decompose, convert and deploy\nunmodified Python code into AWS Lambda functions. Beyond the tooling in the\nform of a measured open source prototype implementation, the paper contributes\na description of the algorithms and code rewriting rules as blueprints for\ntransformations of other scripting languages.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  By extending the Kac-Rice approach to manifolds of finite internal dimension,\nwe show that the mean number\n$\\left\\langle\\mathcal{N}_\\mathrm{tot}\\right\\rangle$ of all possible equilibria\n(i.e. force-free configurations, a.k.a. equilibrium points) of an elastic line\n(directed polymer), confined in a harmonic well and submitted to a quenched\nrandom Gaussian potential in dimension $d=1+1$, grows exponentially\n$\\left\\langle\\mathcal{N}_\\mathrm{tot}\\right\\rangle\\sim\\exp{(r\\,L)}$ with its\nlength $L$. The growth rate $r$ is found to be directly related to the\ngeneralised Lyapunov exponent (GLE) which is a moment-generating function\ncharacterising the large-deviation type fluctuations of the solution to the\ninitial value problem associated with the random Schr\\\"odinger operator of the\n1D Anderson localization problem. For strong confinement, the rate $r$ is small\nand given by a non-perturbative (instanton, Lifshitz tail-like) contribution to\nGLE. For weak confinement, the rate $r$ is found to be proportional to the\ninverse Larkin length of the pinning theory. As an application, identifying the\ndepinning with a landscape \"topology trivialization\" phenomenon, we obtain an\nupper bound for the depinning threshold $f_c$, in the presence of an applied\nforce, for elastic lines and $d$-dimensional manifolds, expressed through the\nmean modulus of the spectral determinant of the Laplace operators with a random\npotential. We also discuss the question of counting of stable equilibria.\nFinally, we extend the method to calculate the asymptotic number of equilibria\nat fixed energy (elastic, potential and total), and obtain the (annealed)\ndistribution of the energy density over these equilibria (i.e. force-free\nconfigurations). Some connections with the Larkin model are also established.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For a classical group $G$ and a Coxeter element $c$ of the Weyl group, it is\nknown that the coordinate ring $\\mathbb{C}[G^{e,c^2}]$ of the double Bruhat\ncell $G^{e,c^2}:=B\\cap B_-c^2B_-$ has a structure of cluster algebra of finite\ntype, where $B$ and $B_-$ are opposite Borel subgroups. In this article, we\nconsider the case $G$ is of type ${\\rm B}_r$, ${\\rm C}_r$ or ${\\rm D}_r$ and\ndescribe all the cluster variables in $\\mathbb{C}[G^{e,c^2}]$ as monomial\nrealizations of certain Demazure crystals.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we consider the following nonlinear elliptic equation with\nDirichlet boundary condition: $-\\Delta u=K(x)u^{\\frac{n+2}{n-2}},\\, u>0$ in\n$\\Omega,\\, u=0$ on $\\partial\\Omega$, where $\\Omega$ is a smooth bounded domain\nin $\\mathbb{R}^n,$ $n\\geqslant 4,$ and $K$ is a $\\mathcal{C}^1$-positive\nfunction in $\\bar{\\Omega}$. Under the assumption that the order of flatness at\neach critical point of $K$ is $\\beta \\in ]\\,n-2,\\,n[,$ we give precise\nestimates on the looses of the compactness, and we prove an existence result\nthrough an Euler-Hopf type formula.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A simple en,ex rule to mark the intersection points of 2D input polygon\ncontours separating the polygon interior from its exterior in the vicinity of\nthe intersections is presented. Its form is close to the original Greiner &\nHormann algorithm rule but encompasses degenerate intersections that are not\nself-intersections. It only uses local geometric information once the hand of\nthe two input contours is known. The approach foundation is the distinction\nbetween two features of the studied intersections: the geometric intersection\npoint and the assembling/concatenation point of the result contour/border. No\nspecial form of the intersection finding procedure is required.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study phase transitions in classical spin ice at nonzero magnetization, by\nintroducing a mean-field theory designed to capture the interplay between\nconfinement and topological constraints. The method is applied to a model of\nspin ice in an applied magnetic field along the [100] crystallographic\ndirection and yields a phase diagram containing the Coulomb phase as well as a\nset of magnetization plateaux. We argue that the lobe structure of the phase\ndiagram, strongly reminiscent of the Bose-Hubbard model, is generic to Coulomb\nspin liquids.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Tau-leaping is a family of algorithms for the approximate simulation of the\ndiscrete state continuous time Markov chains. Motivation for the development of\nsuch methods can be found, for instance, in the fields of chemical kinetics and\nsystems biology. It is known that the dynamical behavior of biochemical systems\nis often intrinsically stiff representing a serious challenge for their\nnumerical approximation. The naive extension of stiff deterministic solvers to\nstochastic integration often yields numerical solutions with either\nimpractically large relaxation times or incorrectly resolved covariance. In\nthis paper, we propose a splitting heuristic which helps to resolve some of\nthese issues. The proposed integrator contains a number of unknown parameters\nwhich are estimated for each particular problem from the moment equations of\nthe corresponding linearized system. We show that this method is able to\nreproduce the exact mean and variance of the linear scalar test equation and\ndemonstrates a good accuracy for the arbitrarily stiff systems at least in the\nlinear case. The numerical examples for both linear and nonlinear systems are\nalso provided and the obtained results confirm the efficiency of the considered\nsplitting approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  One promising trend in digital system integration consists of boosting\non-chip communication performance by means of silicon photonics, thus\nmaterializing the so-called Optical Networks-on-Chip (ONoCs). Among them,\nwavelength routing can be used to route a signal to destination by univocally\nassociating a routing path to the wavelength of the optical carrier. Such\nwavelengths should be chosen so to minimize interferences among optical\nchannels and to avoid routing faults. As a result, physical parameter selection\nof such networks requires the solution of complex constrained optimization\nproblems. In previous work, published in the proceedings of the International\nConference on Computer-Aided Design, we proposed and solved the problem of\ncomputing the maximum parallelism obtainable in the communication between any\ntwo endpoints while avoiding misrouting of optical signals. The underlying\ntechnology, only quickly mentioned in that paper, is Answer Set Programming\n(ASP). In this work, we detail the ASP approach we used to solve such problem.\n  Another important design issue is to select the wavelengths of optical\ncarriers such that they are spread across the available spectrum, in order to\nreduce the likelihood that, due to imperfections in the manufacturing process,\nunintended routing faults arise. We show how to address such problem in\nConstraint Logic Programming on Finite Domains (CLP(FD)).\n  This paper is under consideration for possible publication on Theory and\nPractice of Logic Programming.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using a network of cache enabled small cells, traffic during peak hours can\nbe reduced considerably through proactively fetching the content that is most\nprobable to be requested. In this paper, we aim at exploring the impact of\nproactive caching on an important metric for future generation networks,\nnamely, energy efficiency (EE). We argue that, exploiting the correlation in\nuser content popularity profiles in addition to the spatial repartitions of\nusers with comparable request patterns, can result in considerably improving\nthe achievable energy efficiency of the network. In this paper, the problem of\noptimizing EE is decoupled into two related subproblems. The first one\naddresses the issue of content popularity modeling. While most existing works\nassume similar popularity profiles for all users in the network, we consider an\nalternative caching framework in which, users are clustered according to their\ncontent popularity profiles. In order to showcase the utility of the proposed\nclustering scheme, we use a statistical model selection criterion, namely\nAkaike information criterion (AIC). Using stochastic geometry, we derive a\nclosed-form expression of the achievable EE and we find the optimal active\nsmall cell density vector that maximizes it. The second subproblem investigates\nthe impact of exploiting the spatial repartitions of users with comparable\nrequest patterns. After considering a snapshot of the network, we formulate a\ncombinatorial optimization problem that enables to optimize content placement\nsuch that the used transmission power is minimized. Numerical results show that\nthe clustering scheme enable to considerably improve the cache hit probability\nand consequently the EE compared with an unclustered approach. Simulations also\nshow that the small base station allocation algorithm results in improving the\nenergy efficiency and hit probability.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show that every ($P_6$, diamond, $K_4$)-free graph is $6$-colorable.\nMoreover, we give an example of a ($P_6$, diamond, $K_4$)-free graph $G$ with\n$\\chi(G) = 6$. This generalizes some known results in the literature.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A reliable, accurate, and affordable positioning service is highly required\nin wireless networks. In this paper, the novel Message Passing Hybrid\nLocalization (MPHL) algorithm is proposed to solve the problem of cooperative\ndistributed localization using distance and direction estimates. This hybrid\napproach combines two sensing modalities to reduce the uncertainty in\nlocalizing the network nodes. A statistical model is formulated for the\nproblem, and approximate minimum mean square error (MMSE) estimates of the node\nlocations are computed. The proposed MPHL is a distributed algorithm based on\nbelief propagation (BP) and Markov chain Monte Carlo (MCMC) sampling. It\nimproves the identifiability of the localization problem and reduces its\nsensitivity to the anchor node geometry, compared to distance-only or\ndirection-only localization techniques. For example, the unknown location of a\nnode can be found if it has only a single neighbor; and a whole network can be\nlocalized using only a single anchor node. Numerical results are presented\nshowing that the average localization error is significantly reduced in almost\nevery simulation scenario, about 50% in most cases, compared to the competing\nalgorithms.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report HST/ACS observations of two nearby gas-rich dwarf galaxies: DDO 161\nand UGCA 319. Their distances determined via the Tip of the Red Giant Branch\nare 6.03 (-0.21/+0.29) Mpc and 5.75+-0.18 Mpc, respectively. The galaxies form\nan isolated pair dynamically well separated from the nearest neighbors: KK 176\n(7.28+-0.29 Mpc) and NGC 5068 (5.16+-0.21 Mpc). All four galaxies have a bulk\nspatial peculiar velocity towards the Virgo cluster of ~158+-17 km/s in the\nLocal Group rest frame and ~330 km/s with respect to the cluster center.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The first goal of this paper is to construct examples of higher dimensional\ncontact manifolds with specific properties. Our main results in this direction\nare the existence of tight virtually overtwisted closed contact manifolds in\nall dimensions and the fact that every closed contact 3-manifold, which is not\n(smoothly) a rational homology sphere, contact--embeds with trivial normal\nbundle inside a hypertight closed contact 5-manifold. This uses known\nconstruction procedures by Bourgeois (on products with tori) and Geiges (on\nbranched covering spaces). We pass from these procedures to definitions; this\nallows to prove a uniqueness statement in the case of contact branched\ncoverings, and to study the global properties (such as tightness and\nfillability) of the results of both constructions without relying on any\nauxiliary choice in the procedures. A second goal allowed by these definitions\nis to study relations between these constructions and the notions of supporting\nopen book, as introduced by Giroux, and of contact fiber bundle, as introduced\nby Lerman. For instance, we give a definition of Bourgeois contact structures\non flat contact fiber bundles which is local, (strictly) includes the results\nof the Bourgeois construction, and allows to recover an isotopy class of\nsupporting open books on the fibers. This last point relies on a\nreinterpretation, inspired by an idea by Giroux, of supporting open books in\nterms of pairs of contact vector fields.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss the origin of Warburg's impedance in electrolytic cells containing\nonly one group of positive and one group of negative ions. Our analysis is\nbased on the Poisson-Nernst-Planck model, where the generation-recombination\nphenomenon is neglected. We show that to observe Warburg's like impedance the\ndiffusion coefficient of the positive ions has to differen from that of the\nnegative one, and furthermore that the electrodes have to be not blocking. We\nassume that the non-blocking properties of the electrodes can be described by\nmeans of an Ohmic model, where the charge exchange between the cell and the\nexternal circuit is described by means of an electrode conductivity. For\nsimplicity we consider a symmetric cell. However, our analysis can be easily\ngeneralized to more complicated situations, where the cell is not symmetric and\nthe charge exchange is described by Chang-Jaffe model, or by a linearized\nversion of Butler-Volmer equation. Our analysis allows to justify the\nexpression for Warburg's impedance proposed previously by several groups, based\non wrong assumptions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The provision of both wireless and wired services in the optical access\ndomain will be an important function for future passive optical networks (PON).\nWith the emergence of 5th generation (5G) mobile communications, a move toward\na dense deployment of small cell antenna sites, in conjunction with a cloud\nradio access network (C-RAN) architecture, is foreseen. This type of network\narchitecture greatly increases the requirement for high capacity mobile\nfronthaul and backhaul links. An efficient way of achieving such connectivity\nis to make use of wavelength division multiplexed (WDM) PON infrastructure\nwhere wireless and wired services may be converged for distribution. In this\nwork, for the first time, the convergence of 5G wireless candidate waveforms\nwith a single-carrier wired signal is demonstrated in a PON. Three bands of\nuniversally filtered orthogonal frequency division multiplexing (UF-OFDM) and\ngeneralized frequency division multiplexing (GFDM), are transmitted at an\nintermediate frequency in conjunction with a digital 10Gb/s pulse amplitude\nmodulation (PAM) signal in the downlink direction. Orthogonal frequency\ndivision multiplexing (OFDM) is also evaluated as a benchmark. Results show,\nfor each waveform, how performance varies due to the 5G channel spacing -\nindicating UF-OFDM's superiority in terms of PON convergence. Successful\ntransmission over 25km of fibre is also demonstrated for all waveforms.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In 1909 Borel defined normality as a notion of randomness of the digits of\nthe representation of a real number over certain base (fractional expansion).\nIf we think the representation of a number over a base as an infinite sequence\nof symbols from a finite alphabet $A$, we can define normality directly for\nwords of symbols of $A$: A word $x$ is normal to the alphabet $A$ if every\nfinite block of symbols from $A$ appears with the same asymptotic frequency in\n$x$ as every other block of the same length. Many examples of normal words have\nbeen found since its definition, being Champernowne in 1933 the first to show\nan explicit and simple instance. Moreover, it has been characterized how we can\nselect subsequences of a normal word $x$ preserving its normality, always\nleaving the alphabet $A$ fixed. In this work we consider the dual problem which\nconsists of inserting symbols in infinite positions of a given word, in such a\nway that normality is preserved. Specifically, given a symbol $s$ that is not\npresent on the original alphabet $A$ and given a word $x$ that is normal to the\nalphabet $A$ we solve how to insert the symbol $s$ in infinite positions of the\nword $x$ such that the resulting word is normal to the expanded alphabet $A\\cup\n\\{s\\}$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  An improved wetting boundary implementation strategy is proposed based on\nlattice Boltzmann color-gradient model in this paper. In this strategy, an\nextra interface force condition is demonstrated based on the diffuse interface\nassumption and is employed in contact line region. It has been validated by\nthree benchmark problems: static droplet wetting on a flat surface and a curved\nsurface, and dynamic capillary filling. Good performances are shown in all\nthree cases. Relied on the strict validation to our scheme, the viscous\nfingering phenomenon of immiscible fluids displacement in a two-dimensional\nchannel has been restudied in this paper. High viscosity ratio, wide range\ncontact angle, accurate moving contact line and mutual independence between\nsurface tension and viscosity are the obvious advantages of our model. We find\nthe linear relationship between the contact angle and displacement velocity or\nvariation of finger length. When the viscosity ratio is smaller than 20, the\ndisplacement velocity is increasing with increasing viscosity ratio and\nreducing capillary number, and when the viscosity ratio is larger than 20, the\ndisplacement velocity tends to a specific constant. A similar conclusion is\nobtained on the variation of finger length.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report on results of nonequilibrium transport measurements made on thin\nfilms of germanium-telluride (Ge_xTe) at cryogenic temperatures. Owing to a\nrather large deviation from stoichiometry (app. 10% of Ge vacancies), these\nfilms exhibit p-type conductivity with carrier-concentration N>10^20cm^(-3) and\ncan be made either in the diffusive or strongly-localized regime by a judicious\nchoice of preparation and post-treatment conditions. In both regimes the system\nshows persistent photoconductivity following excitation by a brief exposure to\ninfrared radiation. Persistent photoconductivity is also observed in GexTe\nsamples alloyed with Mn. However, in both Ge_xTe and GeMn_xTe_y the effect is\nmuch weaker than that observable in GeSb_xTe_y alloys suggesting that antimony\nplays an important role in the phenomenon. Structural studies of these films\nreveal an unusual degree of texture that is rarely realized in\nstrongly-disordered systems with high carrier-concentrations.\nAnderson-localized samples of Ge_xTe exhibit non-ergodic transport which are\ncharacteristic of intrinsic electron-glasses, including a well developed\nmemory-dip and slow relaxation of the excess conductance created in the excited\nstate. These results support the conjecture that electron-glass effects with\ninherently long relaxation times is a generic property of all\nAnderson-localized systems with large carrier-concentration.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The precise knowledge of the atomic order in monocrystalline alloys is\nfundamental to understand and predict their physical properties. With this\nperspective, we utilized laser-assisted atom probe tomography to investigate\nthe three-dimensional distribution of atoms in non-equilibrium epitaxial\nSn-rich group IV SiGeSn ternary semiconductors. Different atom probe\nstatistical analysis tools including frequency distribution analysis, partial\nradial distribution functions, and nearest neighbor analysis were employed in\norder to evaluate and compare the behavior of the three elements to their\nspatial distributions in an ideal solid solution. This atomistic-level analysis\nprovided clear evidence of an unexpected repulsive interaction between Sn and\nSi leading to the deviation of Si atoms from the theoretical random\ndistribution. This departure from an ideal solid solution is supported by first\nprincipal calculations and attributed to the tendency of the system to reduce\nits mixing enthalpy throughout the layer-by-layer growth process.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show that the $\\partial\\bar{\\partial}$-lemma holds for the non-K\\\"ahler\ncompact complex manifolds of dimension three with trivial canonical bundle\nconstructed by Clemens as deformations of Calabi-Yau threefolds contracted\nalong smooth rational curves with normal bundle of type $(-1, -1)$, at least on\nan open dense set in moduli. The proof uses the mixed Hodge structure on the\nsingular fibers and an analysis of the variation of the Hodge filtration for\nthe smooth fibers.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study a deformation of what we call hypergeometric fibrations. Its periods\nand K_1-regulators are described in terms of hypergeometric functions 3F2 in a\nvariable given by the deformation parameter.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present experimental phase functions of three types of millimeter-sized\ndust grains consisting of enstatite, quartz and volcanic material from Mount\nEtna, respectively. The three grains present similar sizes but different\nabsorbing properties. The measurements are performed at 527 nm covering the\nscattering angle range from 3 to 170 degrees. The measured phase functions show\ntwo well defined regions i) soft forward peaks and ii) a continuous increase\nwith the scattering angle at side- and back-scattering regions. This behavior\nat side- and back-scattering regions are in agreement with the observed phase\nfunctions for the Fomalhaut and HR 4796A dust rings. Further computations and\nmeasurements (including polarization) for millimeter sized-grains are needed to\ndraw some conclusions about the fluffy or compact structure of the dust grains.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate performance of approximations put forth in\n\\citeNP{[Malinovskii 2017a]} and \\citeNP{[Malinovskii 2017b]} for the\ndistribution of the time of first level $u$ crossing by the random process\n$\\homV{s}-cs$, $s>0$, where $\\homV{s}$ is compound renewal process. In the case\nof Exponential inter-renewal and jump size random variables, we compare the\napproximations with exact and with simulation results. In a few other cases\nincluding Erlang and Pareto inter-renewal and jump size random variables, where\nexact results are absent, we compare the approximations with simulation\nresults.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Symmetry breaking together with strong spin-orbit interaction give rise to\nmany exciting phenomena within condensed matter physics. A recent example is\nthe existence of chiral spin textures, which are observed in magnetic systems\nlacking inversion symmetry. These chiral spin textures, including domain walls\nand magnetic skyrmions, are both fundamentally interesting and technologically\npromising. For example, they can be driven very efficiently by electrical\ncurrents, and exhibit many new physical properties determined by their\nreal-space topological characteristics. Depending on the details of the\ncompeting interactions, these spin textures exist in different parameter\nspaces. However, the governing mechanism underlying their physical behaviors\nremain essentially the same. In this review article, the fundamental\ntopological physics underlying these chiral spin textures, the key factors for\nmaterials optimization, and current developments and future challenges will be\ndiscussed. In the end, a few promising directions that will advance the\ndevelopment of skyrmion based spintronics will be highlighted.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In order to be traversable, the static Lorentzian wormhole must be made out\nof some exotic matter that violates the weak energy condition. The quantized\nfields are the natural candidates as their stress-energy tensor, in many cases,\npossesses desired properties. In this paper we construct and examine the\nstress-energy tensor of the quantized massive scalar, spinor and vector fields\nin six static wormhole spacetimes. We find that in all considered cases the\nquantum fields violate the Morris-Thorne conditions and do not have the form\nnecessary to support the wormhole throat. This is in concord with the previous\nresults and indicates that the massive quantum fields make the wormholes less\noperable.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Majorization-minimization (MM) is a standard iterative optimization technique\nwhich consists in minimizing a sequence of convex surrogate functionals. MM\napproaches have been particularly successful to tackle inverse problems and\nstatistical machine learning problems where the regularization term is a\nsparsity-promoting concave function. However, due to non-convexity, the\nsolution found by MM depends on its initialization. Uniform initialization is\nthe most natural and often employed strategy as it boils down to penalizing all\ncoefficients equally in the first MM iteration. Yet, this arbitrary choice can\nlead to unsatisfactory results in severely under-determined inverse problems\nsuch as source imaging with magneto- and electro-encephalography (M/EEG). The\nframework of hierarchical Bayesian modeling (HBM) is an alternative approach to\nencode sparsity. This work shows that for certain hierarchical models, a simple\nalternating scheme to compute fully Bayesian maximum a posteriori (MAP)\nestimates leads to the exact same sequence of updates as a standard MM strategy\n(cf. the Adaptive Lasso). With this parallel outlined, we show how to improve\nupon these MM techniques by probing the multimodal posterior density using\nMarkov Chain Monte-Carlo (MCMC) techniques. Firstly, we show that these samples\ncan provide well-informed initializations that help MM schemes to reach better\nlocal minima. Secondly, we demonstrate how it can reveal the different modes of\nthe posterior distribution in order to explore and quantify the inherent\nuncertainty and ambiguity of such ill-posed inference procedure. In the context\nof M/EEG, each mode corresponds to a plausible configuration of neural sources,\nwhich is crucial for data interpretation, especially in clinical contexts.\nResults on both simulations and real datasets show how the number or the type\nof sensors affect the uncertainties on the estimates.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Technologies have become important part of our lives. The steps for\nintroducing ICTs in education vary from country to country. The Republic of\nMacedonia has invested with a lot in installment of hardware and software in\neducation and in teacher training. This research was aiming to determine the\nsituation of usage of databases of digital educational materials and to define\nrecommendation for future improvements. Teachers from urban schools were\ninterviewed with a questionnaire. The findings are several: only part of the\ninterviewed teachers had experience with databases of educational materials;\nall teachers still need capacity building activities focusing exactly on the\nuse and benefits from databases of educational materials; preferably capacity\nbuilding materials to be in Macedonian language; technical support and\nupgrading of software and materials should be performed on a regular basis.\nMost of the findings can be applied at both national and international level -\nwith all this implemented, application of ICT in education will have much\nbigger positive impact.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Landau's description of the excitations in a macroscopic system in terms of\nquasiparticles stands out as one of the highlights in quantum physics. It\nprovides an accurate description of otherwise prohibitively complex many-body\nsystems, and has led to the development of several key technologies. In this\npaper, we investigate theoretically the Landau effective interaction between\nquasiparticles, so-called Bose polarons, formed by impurity particles immersed\nin a Bose-Einstein condensate (BEC). In the limit of weak interactions between\nthe impurities and the BEC, we derive rigorous results for the effective\ninteraction. They show that it can be strong even for weak impurity-boson\ninteraction, if the transferred momentum/energy between the quasiparticles is\nresonant with a sound mode in the BEC. We then develop a diagrammatic scheme to\ncalculate the effective interaction for arbitrary coupling strengths, which\nrecovers the correct weak coupling results. Using this, we show that the Landau\neffective interaction in general is significantly stronger than that between\nquasiparticles in a Fermi gas, mainly because a BEC is more compressible than a\nFermi gas. The interaction is particularly large near the unitarity limit of\nthe impurity-boson scattering, or when the quasiparticle momentum is close to\nthe threshold for momentum relaxation in the BEC. Finally, we show how the\nLandau effective interaction leads to a sizeable shift of the quasiparticle\nenergy with increasing impurity concentration, which should be detectable with\npresent day experimental techniques.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Cloud Computing is a business model revolution more than a technological one.\nIt capitalized on various technologies that have proved themselves and reshaped\nthe use of computers by replacing their local use by a centralized one where\nshared resources are stored and managed by a third-party in a way transparent\nto end-users. With this new use came new needs and one of them is the need to\nsearch through Cloud services and select the ones that meet certain\nrequirements. To address this need, we have developed, in a previous work, the\nCloud Service Research and Selection System (CSRSS) which aims to allow Cloud\nusers to search through Cloud services in the database and find the ones that\nmatch their requirements. It is based on the Skyline and ELECTRE IS. In this\npaper, we improve the system by introducing 7 new dimensions related to QoS\nconstraints. Our work's main contribution is conceiving an Agent that uses both\nthe Skyline and an outranking method, called ELECTREIsSkyline, to determine\nwhich Cloud services meet better the users' requirements while respecting QoS\nproperties. We programmed and tested this method for a total of 10 dimensions\nand for 50 000 cloud services. The first results are very promising and show\nthe effectiveness of our approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study a class of 6d $\\mathcal{N}=(1,0)$ non-geometric vacua of the\n$\\text{Spin}(32)/\\mathbb Z_2$ heterotic string which can be understood as\nfibrations of genus-two curves over a complex one-dimensional base. The 6d\n$\\mathcal{N}=(1,0)$ theories living on the defects that arise when the\ngenus-two fiber degenerates at a point of the base are analyzed by dualizing to\nF-theory on elliptic K3-fibered non-compact Calabi-Yau threefolds. We consider\nall possible degenerations of genus-two curves and systematically attempt to\nresolve the singularities of the dual threefolds. As in the analogous\nnon-geometric vacua of the $E_8\\times E_8$ heterotic string, we find that many\nof the resulting dual threefolds contain singularities which do not admit a\ncrepant resolution. When the singularities can be resolved crepantly, we\ndetermine the emerging effective theories which turn out to be little string\ntheories at a generic point on their tensor branch. We also observe a form of\nduality in which theories living on distinct defects are the same.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Steiner Forest problem is among the fundamental network design problems.\nFinding tight linear programming bounds for the problem is the key for both\nfast Branch-and-Bound algorithms and good primal-dual approximations. On the\ntheoretical side, the best known bound can be obtained from an integer program\n[KLSv08]. It guarantees a value that is a (2-eps)-approximation of the integer\noptimum. On the practical side, bounds from a mixed integer program by Magnanti\nand Raghavan [MR05] are very close to the integer optimum in computational\nexperiments, but the size of the model limits its practical usefulness. We\ncompare a number of known integer programming formulations for the problem and\npropose three new formulations. We can show that the bounds from our two new\ncut-based formulations for the problem are within a factor of 2 of the integer\noptimum. In our experiments, the formulations prove to be both tractable and\nprovide better bounds than all other tractable formulations. In particular, the\nfactor to the integer optimum is much better than 2 in the experiments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The multi-commodity flow-cut gap is a fundamental parameter that affects the\nperformance of several divide \\& conquer algorithms, and has been extensively\nstudied for various classes of undirected graphs. It has been shown by Linial,\nLondon and Rabinovich \\cite{linial1994geometry} and by Aumann and Rabani\n\\cite{aumann1998log} that for general $n$-vertex graphs it is bounded by\n$O(\\log n)$ and the Gupta-Newman-Rabinovich-Sinclair conjecture\n\\cite{gupta2004cuts} asserts that it is $O(1)$ for any family of graphs that\nexcludes some fixed minor.\n  The flow-cut gap is poorly understood for the case of directed graphs. We\nshow that for uniform demands it is $O(1)$ on directed series-parallel graphs,\nand on directed graphs of bounded pathwidth. These are the first constant upper\nbounds of this type for some non-trivial family of directed graphs. We also\nobtain $O(1)$ upper bounds for the general multi-commodity flow-cut gap on\ndirected trees and cycles. These bounds are obtained via new embeddings and\nLipschitz quasipartitions for quasimetric spaces, which generalize analogous\nresults form the metric case, and could be of independent interest. Finally, we\ndiscuss limitations of methods that were developed for undirected graphs, such\nas random partitions, and random embeddings.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the Higgs mode of superfluid Bose gases in a three dimensional\noptical lattice, which emerges near the quantum phase transition to the Mott\ninsulator at commensurate fillings. Specifically, we consider responses of the\nHiggs mode to temporal modulations of the onsite interaction and the hopping\nenergy. In order to calculate the response functions including the effects of\nquantum and thermal fluctuations, we map the Bose-Hubbard model onto an\neffective pseudospin-one model and use a perturbative expansion based on the\nimaginary-time Green's function theory. We also include the effects of an\ninhomogeneous trapping potential by means of a local density approximation. We\nfind that the response function for the hopping modulation is equal to that for\nthe interaction modulation within our approximation. At the unit filling rate\nand in the absence of a trapping potential, we show that the Higgs mode can\nexist as a sharp resonance peak in the dynamical susceptibilities at typical\ntemperatures. However, the resonance peak is significantly broadened due to the\ntrapping potential when the modulations are applied globally to the entire\nsystem. We suggest that the Higgs mode can be detected as a sharp resonance\npeak by partial modulations around the trap center.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Resistive switching is one of the foremost candidates for building novel\ntypes of non-volatile random access memories. Any practical implementation of\nsuch a memory cell calls for a strong miniaturization, at which point\nfluctuations start playing a role that cannot be neglected. A detailed\nunderstanding of switching mechanisms and reliability is essential. For this\nreason, we formulate a particle model based on the stochastic motion of oxygen\nvacancies. It allows us to investigate fluctuations in the resistance states of\na switch with two active zones. The vacancies' dynamics is governed by a master\nequation. Upon the application of a voltage pulse, the vacancies travel\ncollectively through the switch. By deriving a generalized Burgers equation we\ncan interpret this collective motion as nonlinear traveling waves, and\nnumerically verify this result. Further, we define binary logical states by\nmeans of the underlying vacancy distributions, and establish a framework of\nwriting and reading such memory element with voltage pulses. Considerations\nabout the dis- criminability of these operations under fluctuations together\nwith the markedness of the resistive switching effect itself lead to the\nconclusion, that an intermediate vacancy number is optimal for performance.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Under a mild regularity condition we prove that the generator of the\ninterpolation of two C0-semigroups is the interpolation of the two generators.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We provide a quick overview of the class of $\\alpha$-weakly-quasi-convex\nproblems and its relationships with other problem classes. We show that the\npreviously known Sequential Subspace Optimization method retains its optimal\nconvergence rate when applied to minimization problems with smooth\n$\\alpha$-weakly-quasi-convex objectives. We also show that Nemirovski's\nconjugate gradients method of strongly convex minimization achieves its optimal\nconvergence rate under weaker conditions of $\\alpha$-weak-quasi-convexity and\nquad\\-ratic growth. Previously known results only capture the special case of\n1-weak-quasi-convexity or give convergence rates with worse dependence on the\nparameter $\\alpha$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The design of asymptotically minimax robust hypothesis testing is formalized\nfor the Bayesian and Neyman-Pearson tests of Type-I and Type-II. The\nuncertainty classes based on the KL-divergence, $\\alpha$-divergence,\nsymmetrized $\\alpha$-divergence, total variation distance, as well as the band\nmodel, moment classes and p-point classes are considered. Implications between\nsingle-sample-, all-sample- and asymptotic minimax robustness are derived.\nExistence and uniqueness of asymptotically minimax robust tests are proven\nusing Sion's minimax theorem and the Karush-Kuhn-Tucker multipliers. The least\nfavorable distributions and the corresponding robust likelihood ratio functions\nare derived in parametric forms, which can then be determined by solving a\nsystem of equations. The proposed theory proves that Dabak's design does not\nproduce any asymptotically minimax robust test. Furthermore, it also\ngeneralizes the earlier works by Huber and Kassam by allowing analytical\nderivations, hence, providing answers to the questions 'how?', which were left\nunanswered. Simulations are provided to exemplify and evaluate the theoretical\nderivations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Chapter 12 in High-Luminosity Large Hadron Collider (HL-LHC) : Preliminary\nDesign Report. The Large Hadron Collider (LHC) is one of the largest scientific\ninstruments ever built. Since opening up a new energy frontier for exploration\nin 2010, it has gathered a global user community of about 7,000 scientists\nworking in fundamental particle physics and the physics of hadronic matter at\nextreme temperature and density. To sustain and extend its discovery potential,\nthe LHC will need a major upgrade in the 2020s. This will increase its\nluminosity (rate of collisions) by a factor of five beyond the original design\nvalue and the integrated luminosity (total collisions created) by a factor ten.\nThe LHC is already a highly complex and exquisitely optimised machine so this\nupgrade must be carefully conceived and will require about ten years to\nimplement. The new configuration, known as High Luminosity LHC (HL-LHC), will\nrely on a number of key innovations that push accelerator technology beyond its\npresent limits. Among these are cutting-edge 11-12 tesla superconducting\nmagnets, compact superconducting cavities for beam rotation with ultra-precise\nphase control, new technology and physical processes for beam collimation and\n300 metre-long high-power superconducting links with negligible energy\ndissipation. The present document describes the technologies and components\nthat will be used to realise the project and is intended to serve as the basis\nfor the detailed engineering design of HL-LHC.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider double-winding, triple-winding and multiple-winding Wilson loops\nin the $SU(N)$ Yang-Mills gauge theory. We examine how the area law falloff of\nthe vacuum expectation value of a multiple-winding Wilson loop depends on the\nnumber of color $N$. In sharp contrast to the difference-of-areas law recently\nfound for a double-winding $SU(2)$ Wilson loop average, we show irrespective of\nthe spacetime dimensionality that a double-winding $SU(3)$ Wilson loop follows\na novel area law which is neither difference-of-areas nor sum-of-areas law for\nthe area law falloff and that the difference-of-areas law is excluded and the\nsum-of-areas law is allowed for $SU(N)$ ($N \\ge 4$), provided that the string\ntension obeys the Casimir scaling for the higher representations. Moreover, we\nextend these results to arbitrary multi-winding Wilson loops. Finally, we argue\nthat the area law follows a novel law, which is neither sum-of-areas nor\ndifference-of-areas law when $N\\ge 3$. In fact, such a behavior is exactly\nderived in the $SU(N)$ Yang-Mills theory in the two-dimensional spacetime.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, an optimal inequality involving the delta curvature is\nexposed. An application of Riemannian submersions dealing meteorology is\npresented. Some characterizations about the vertical motion and the horizontal\ndivergence are obtained.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We give instructions for the construction and operation of a simple apparatus\nfor performing optically detected magnetic resonance measurements on diamond\nsamples containing high concentrations of nitrogen-vacancy (NV) centers. Each\nNV center has a spin degree of freedom that can be manipulated and monitored by\na combination of visible and microwave radiation. We observe Zeeman shifts in\nthe presence of small external magnetic fields and describe a simple method to\noptically measure magnetic field strengths with a spatial resolution of several\nmicrons. The activities described are suitable for use in an advanced\nundergraduate lab course, powerfully connecting core quantum concepts to\ncutting edge applications. An even simpler setup, appropriate for use in more\nintroductory settings, is also presented.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a brief review of discrete structures in a finite Hilbert space,\nrelevant for the theory of quantum information. Unitary operator bases,\nmutually unbiased bases, Clifford group and stabilizer states, discrete Wigner\nfunction, symmetric informationally complete measurements, projective and\nunitary t--designs are discussed. Some recent results in the field are covered\nand several important open questions are formulated. We advocate a geometric\napproach to the subject and emphasize numerous links to various mathematical\nproblems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Model-based verification allows to express behavioral correctness conditions\nlike the validity of execution states, boundaries of variables or timing at a\nhigh level of abstraction and affirm that they are satisfied by a software\nsystem. However, this requires expressive models which are difficult and\ncumbersome to create and maintain by hand. This paper presents a framework that\nautomatically derives behavioral models from real-sized Java programs. Our\nframework builds on the EMF/ECore technology and provides a tool that creates\nan initial model from Java bytecode, as well as a series of transformations\nthat simplify the model and eventually output a timed-automata model that can\nbe processed by a model checker such as UPPAAL. The framework has the following\nproperties: (1) consistency of models with software, (2) extensibility of the\nmodel derivation process, (3) scalability and (4) expressiveness of models. We\nreport several case studies to validate how our framework satisfies these\nproperties.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In privacy amplification, two mutually trusted parties aim to amplify the\nsecrecy of an initial shared secret $X$ in order to establish a shared private\nkey $K$ by exchanging messages over an insecure communication channel. If the\nchannel is authenticated the task can be solved in a single round of\ncommunication using a strong randomness extractor; choosing a quantum-proof\nextractor allows one to establish security against quantum adversaries.\n  In the case that the channel is not authenticated, Dodis and Wichs (STOC'09)\nshowed that the problem can be solved in two rounds of communication using a\nnon-malleable extractor, a stronger pseudo-random construction than a strong\nextractor.\n  We give the first construction of a non-malleable extractor that is secure\nagainst quantum adversaries. The extractor is based on a construction by Li\n(FOCS'12), and is able to extract from source of min-entropy rates larger than\n$1/2$. Combining this construction with a quantum-proof variant of the\nreduction of Dodis and Wichs, shown by Cohen and Vidick (unpublished), we\nobtain the first privacy amplification protocol secure against active quantum\nadversaries.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The number of scientific articles has grown rapidly over the years and there\nare no signs that this growth will slow down in the near future. Because of\nthis, it becomes increasingly difficult to keep up with the latest developments\nin a scientific field. To address this problem, we present here an approach to\nhelp researchers learn about the latest developments and findings by extracting\nin a normalized form core claims from scientific articles. This normalized\nrepresentation is a controlled natural language of English sentences called\nAIDA, which has been proposed in previous work as a method to formally\nstructure and organize scientific findings and discourse. We show how such AIDA\nsentences can be automatically extracted by detecting the core claim of an\narticle, checking for AIDA compliance, and - if necessary - transforming it\ninto a compliant sentence. While our algorithm is still far from perfect, our\nresults indicate that the different steps are feasible and they support the\nclaim that AIDA sentences might be a promising approach to improve scientific\ncommunication in the future.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Introducing a new notion of generalized suitable weak solutions, we first\nprove validity of the energy inequality for such a class of weak solutions to\nthe Navier-Stokes equations in the whole space $\\mathbb{R}^n$. Although we need\ncertain growth condition on the pressure, we may treat the class even with\ninfinite energy quantity except for the initial velocity. We next handle the\nequation for vorticity in 2D unbounded domains. Under a certain condition on\nthe asymptotic behavior at infinity, we prove that the vorticity and its\ngradient of solutions are both globally square integrable. As their\napplications, Loiuville-type theorems are obtained.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Future wireless systems are expected to provide a wide range of services to\nmore and more users. Advanced scheduling strategies thus arise not only to\nperform efficient radio resource management, but also to provide fairness among\nthe users. On the other hand, the users' perceived quality, i.e., Quality of\nExperience (QoE), is becoming one of the main drivers within the schedulers\ndesign. In this context, this paper starts by providing a comprehension of what\nis QoE and an overview of the evolution of wireless scheduling techniques.\nAfterwards, a survey on the most recent QoE-based scheduling strategies for\nwireless systems is presented, highlighting the application/service of the\ndifferent approaches reported in the literature, as well as the parameters that\nwere taken into account for QoE optimization. Therefore, this paper aims at\nhelping readers interested in learning the basic concepts of QoE-oriented\nwireless resources scheduling, as well as getting in touch with its current\nresearch frontier.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate whether by synthesising superconductors that are tuned to a\ntopological, node-reconstruction transition point we could create\nsuperconducting wires that are intrinsically resilient to quenches. Recent work\nshows that the exponent characterising the temperature dependence of the\nspecific heat of a nodal superconductor is lowered over a region of the phase\ndiagram near topological transitions where nodal lines form or reconnect. Our\nidea is that the resulting enhancement of the low-temperature specific heat\ncould have potential application in the prevention of superconductor quenches.\nWe perform numerical simulations of a simplified superconductor quench model.\nResults show that decreasing the specific heat exponent can prevent a quench\nfrom occurring and improve quench resilience, though in our simple model the\neffects are small. Further work will be necessary to establish the practical\nfeasibility of this approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the last years, the ability of cold atoms experiments to explore\ncondensed- matter related questions has dramatically progressed. Transport\nexperiments, in particular, have expanded to the point that conductances and\nother transport coefficients can now be measured in a way directly analogous to\nsolid state physics, extending cold atoms based quantum simulations into the\ndomain of quantum electronic devices. In this topical review, we describe the\ntransport experiments performed with cold gases in the two terminals\nconfiguration, with an emphasis on the specific features of cold atomic gases\ncompared to solid state physics. We present the experimental techniques and the\nmain experimental findings, focusing on but not restricted to the recent\nexperiments performed in our group. We eventually discuss the perspectives\nopened by this approach, the main technical and conceptual challenges for\nfuture developments, and the potential applications as a quantum simulator for\ntransport phenomena and mesoscopic physics problems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $D$ be a nonnegative integer and ${\\mathbf{\\Theta}}\\subset S^1$ be a\nlacunary set of directions of order $D$. We show that the $L^p$ norms,\n$1<p<\\infty$, of the maximal directional Hilbert transform in the plane $$\nH_{{\\mathbf{\\Theta}}} f(x):= \\sup_{v\\in {\\mathbf{\\Theta}}}\n\\Big|\\mathrm{p.v.}\\int_{\\mathbb R }f(x+tv)\\frac{\\mathrm{d} t}{t}\\Big|, \\qquad x\n\\in {\\mathbb R}^2, $$ are comparable to\n$(\\log\\#{\\mathbf{\\Theta}})^\\frac{1}{2}$. For vector fields $\\mathsf{v}_D$ with\nrange in a lacunary set of of order $D$ and generated using suitable\ncombinations of truncations of Lipschitz functions, we prove that the truncated\nHilbert transform along the vector field $\\mathsf{v}_D$, $$ H_{\\mathsf{v}_D,1}\nf(x):= \\mathrm{p.v.} \\int_{ |t| \\leq 1 } f(x+t\\mathsf{v}_D(x))\n\\,\\frac{\\mathrm{d} t}{t}, $$ is $L^p$-bounded for all $1<p<\\infty$. These\nresults extend previous bounds of the first author with Demeter, and of Guo and\nThiele.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recognizing how objects interact with each other is a crucial task in visual\nrecognition. If we define the context of the interaction to be the objects\ninvolved, then most current methods can be categorized as either: (i) training\na single classifier on the combination of the interaction and its context; or\n(ii) aiming to recognize the interaction independently of its explicit context.\nBoth methods suffer limitations: the former scales poorly with the number of\ncombinations and fails to generalize to unseen combinations, while the latter\noften leads to poor interaction recognition performance due to the difficulty\nof designing a context-independent interaction classifier. To mitigate those\ndrawbacks, this paper proposes an alternative, context-aware interaction\nrecognition framework. The key to our method is to explicitly construct an\ninteraction classifier which combines the context, and the interaction. The\ncontext is encoded via word2vec into a semantic space, and is used to derive a\nclassification result for the interaction.\n  The proposed method still builds one classifier for one interaction (as per\ntype (ii) above), but the classifier built is adaptive to context via weights\nwhich are context dependent. The benefit of using the semantic space is that it\nnaturally leads to zero-shot generalizations in which semantically similar\ncontexts (subjectobject pairs) can be recognized as suitable contexts for an\ninteraction, even if they were not observed in the training set.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the mid-infrared (MIR) properties of galaxies in compact groups and\ntheir environmental dependence using the \\textit{Wide-field Infrared Survey\nExplorer (WISE)} data. We use a volume-limited sample of 670 compact groups and\ntheir 2175 member galaxies with $M_r< -19.77$ and $0.01<z<0.0741$, drawn from\n\\citet{sohn+16}, which were identified using a friends-of-friends algorithm.\nAmong the 2175 galaxies, 1541 galaxies are detected at \\textit{WISE} 12\n$\\micron$ with a signal-to-noise ratio greater than 3. Among the 1541 galaxies,\n433 AGN-host galaxies are identified by using both optical and MIR\nclassification scheme. Using the remaining 1108 non-AGN galaxies, we find that\nthe MIR $[3.4]-[12]$ colors of compact group early-type galaxies are on average\nbluer than those of cluster early-type galaxies. When compact groups have both\nearly- and late-type member galaxies, the MIR colors of the late-type members\nin those compact groups are bluer than the MIR colors of cluster late-type\ngalaxies. As compact groups are located in denser regions, they tend to have\nlarger early-type galaxy fractions and bluer MIR color galaxies. These trends\nare also seen for neighboring galaxies around compact groups. However, compact\ngroup member galaxies always have larger early-type galaxy fractions and bluer\nMIR colors than their neighboring galaxies. Our findings suggest that the\nproperties of compact group galaxies depend on both internal and external\nenvironments of compact groups, and that galaxy evolution is faster in compact\ngroups than in the central regions of clusters.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate Proca star (PS) solutions, namely boson star (BS) type\nsolutions for a complex vector field with mass and nonminimal coupling to the\nEinstein tensor. Irrespective of the existence of nonminimal coupling, PS\nsolutions are mini-BS type, but the inclusion of it changes properties. For\npositive nonminimal coupling parameters, PS solutions do not exist for central\namplitudes above some certain value due to the singular behavior of the\nevolution equations. For negative nonminimal coupling parameters, there is no\nsuch singular behavior but sufficiently enhanced numerical resolutions are\nrequested for larger amplitudes. Irrespective of the sign of the nonzero\nnonminimal coupling parameter, PSs with the maximal Arnowitt-Deser-Misner mass\nand Noether charge are gravitationally bound. Properties of PSs are very\nsimilar to those of BSs in scalar-tensor theories including healthy\nhigher-derivative terms.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider N=2 four dimensional field theories compactified on a two torus\nin the presence of a U(1) magnetic field. We discuss the restrictions leading\nto theories with (2,2) supersymmetry or (0,2) supersymmetry in two dimensions.\nThe field theories live on D5 branes wrapped on four cycles of Calabi-Yau\n3-folds or 4-folds described as resolved ADE singularities or resolved conifold\nfibered over a two torus.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We demonstrate midinfrared second-harmonic generation as a highly sensitive\nphonon spectroscopy technique that we exemplify using $\\alpha$-quartz (SiO$_2$)\nas a model system. A midinfrared free-electron laser provides direct access to\noptical phonon resonances ranging from $350\\ \\mathrm{cm}^{-1}$ to $1400\\\n\\mathrm{cm}^{-1}$. While the extremely wide tunability and high peak fields of\nan free-electron laser promote nonlinear spectroscopic studies---complemented\nby simultaneous linear reflectivity measurements---azimuthal scans reveal\ncrystallographic symmetry information of the sample. Additionally,\ntemperature-dependent measurements show how damping rates increase, phonon\nmodes shift spectrally and in certain cases disappear completely when\napproaching $T_c=846\\ \\mathrm{K}$ where quartz undergoes a structural phase\ntransition from trigonal $\\alpha$-quartz to hexagonal $\\beta$-quartz,\ndemonstrating the technique's potential for studies of phase transitions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  BBR is a new congestion-based congestion control algorithm proposed by\nGoogle. A BBR flow sequentially measures the bottleneck bandwidth and\nround-trip delay of the network pipe, and uses the measured results to govern\nits sending behavior, maximizing the delivery bandwidth while minimizing the\ndelay. However, our deployment in geo-distributed cloud servers reveals a\nsevere RTT fairness problem: a BBR flow with longer RTT dominates a competing\nflow with shorter RTT.\n  Somewhat surprisingly, our deployment of BBR on the Internet and an in-house\ncluster unearthed a consistent bandwidth disparity among competing flows. Long\nBBR flows are bound to seize bandwidth from short ones. Intrigued by this\nunexpected behavior, we ask, is the phenomenon intrinsic to BBR? how's the\nseverity? and what's the root cause? To this end, we conduct thorough\nmeasurements and develop a theoretical model on bandwidth dynamics. We find, as\nlong as the competing flows are of different RTTs, bandwidth disparities will\narise. With an RTT ratio of 10, even flow starvation can happen. We blame it on\nBBR's connivance at sending an excessive amount of data when probing bandwidth.\nSpecifically, the amount of data is in proportion to RTT, making long RTT flows\noverwhelming short ones. Based on this observation, we design a derivative of\nBBR that achieves guaranteed flow fairness, at the meantime without losing any\nmerits. We have implemented our proposed solution in Linux kernel and evaluated\nit through extensive experiments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hawking's area theorem is a fundamental result in black hole theory that is\nuniversally associated with the null energy condition. That this condition can\nbe weakened is illustrated by the formulation of a strengthened version of the\ntheorem based on an energy condition that allows for violations of the null\nenergy condition. With the semi-classical context in mind, some brief remarks\npertaining to the suitability of the area theorem and its energy condition are\nmade.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We conjecture that bounded generalised polynomial functions cannot be\ngenerated by finite automata, except for the trivial case when they are\nultimately periodic.\n  Using methods from ergodic theory, we are able to partially resolve this\nconjecture, proving that any hypothetical counterexample is periodic away from\na very sparse and structured set.\n  In particular, we show that for a polynomial $p(n)$ with at least one\nirrational coefficient (except for the constant one) and integer $m\\geq 2$, the\nsequence $\\lfloor p(n) \\rfloor \\bmod{m}$ is never automatic.\n  We also prove that the conjecture is equivalent to the claim that the set of\npowers of an integer $k\\geq 2$ is not given by a generalised polynomial.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We construct models of static spherical distributions of perfect fluid in\ntrace--free Einstein gravity theory. The equations governing the gravitational\nfield are equivalent to the standard Einstein's equations however, their\npresentation is manifestly different which motivates the question whether new\ninformation would emerge due to the nonlinearity of the field equations. The\nincompressible fluid assumption does not lead to the well known Schwarzschild\ninterior metric of Einstein gravity and a term denoting the presence of a\ncosmological constant is present on account of the integration process. The\nSchwarzschild interior is regained as a special case of a richer geometry. On\nthe other hand, when the Schwarzschild geometry is prescribed, a constant\ndensity fluid emerges consistent with the standard equations. A complete model\nof an isothermal fluid sphere with pressure and density obeying the inverse\nsquare law is obtained. Corrections to the model previously presented in the\nliterature by Saslaw {\\it {et al}} are exhibited. The isothermal ansatz does\nnot yield a constant gravitational potential in general but both potentials are\nposition dependent. Conversely, it is shown that assuming a constant $g_{rr}$\ngravitational potential does not yield an isothermal fluid in general as is the\ncase in standard general relativity. The results of the standard Einstein\nequations are special cases of the models reported here. Noteworthy is the fact\nthat whereas the previously reported isothermal solution was only of\ncosmological interest, the solution reported herein admit compact objects by\nvirtue of the fact that a pressure-free hypersurface exists. Finally we analyze\nthe consequences of selecting the Finch--Skea metric as the seed solution.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider a wide range of regularized stochastic minimization problems with\ntwo regularization terms, one of which is composed with a linear function. This\noptimization model abstracts a number of important applications in artificial\nintelligence and machine learning, such as fused Lasso, fused logistic\nregression, and a class of graph-guided regularized minimization. The\ncomputational challenges of this model are in two folds. On one hand, the\nclosed-form solution of the proximal mapping associated with the composed\nregularization term or the expected objective function is not available. On the\nother hand, the calculation of the full gradient of the expectation in the\nobjective is very expensive when the number of input data samples is\nconsiderably large. To address these issues, we propose a stochastic variant of\nextra-gradient type methods, namely \\textsf{Stochastic Primal-Dual Proximal\nExtraGradient descent (SPDPEG)}, and analyze its convergence property for both\nconvex and strongly convex objectives. For general convex objectives, the\nuniformly average iterates generated by \\textsf{SPDPEG} converge in expectation\nwith $O(1/\\sqrt{t})$ rate. While for strongly convex objectives, the uniformly\nand non-uniformly average iterates generated by \\textsf{SPDPEG} converge with\n$O(\\log(t)/t)$ and $O(1/t)$ rates, respectively. The order of the rate of the\nproposed algorithm is known to match the best convergence rate for first-order\nstochastic algorithms. Experiments on fused logistic regression and\ngraph-guided regularized logistic regression problems show that the proposed\nalgorithm performs very efficiently and consistently outperforms other\ncompeting algorithms.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Cosmological observations over past couple of decades favor our universe with\na tiny positive cosmological constant. Presence of cosmological constant not\nonly imposes theoretical challenges in gravitational wave physics, it has also\nobservational relevance. Inclusion of cosmological constant in linearized\ntheory of gravitational waves modifies the power radiated quadrupole formula.\nThere are two types of observations which can be impacted by the modified\nquadrupole formula. One is the orbital decay of an inspiraling binary and other\nis the modification of the waveform at the detector. Modelling a compact binary\nsystem in an elliptic orbit on de Sitter background we obtain energy and\nangular momentum radiation due to emission of gravitational waves. We also\ninvestigate evolution of orbital parameters under back reaction and its impact\non orbital decay rate. In the limit to circular orbit our result matches to\nthat obtained in ref. [26].\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce the concept of maximal dissipative measure-valued solution to\nthe complete Euler system. These are solutions that maximize the entropy\nproduction rate. We show that these solutions exist under fairly general\nhypotheses imposed on the data and constitutive relations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Cooperative games provide a framework to study cooperation among\nself-interested agents. They offer a number of solution concepts describing how\nthe outcome of the cooperation should be shared among the players.\nUnfortunately, computational problems associated with many of these solution\nconcepts tend to be intractable---NP-hard or worse. In this paper, we\nincorporate complexity measures recently proposed by Feige and Izsak (2013),\ncalled dependency degree and supermodular degree, into the complexity analysis\nof cooperative games. We show that many computational problems for cooperative\ngames become tractable for games whose dependency degree or supermodular degree\nare bounded. In particular, we prove that simple games admit efficient\nalgorithms for various solution concepts when the supermodular degree is small;\nfurther, we show that computing the Shapley value is always in FPT with respect\nto the dependency degree. Finally, we note that, while determining the\ndependency among players is computationally hard, there are efficient\nalgorithms for special classes of games.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The notion of gravitational radiation begins with electromagnetic radiation.\nIn 1887 Heinrich Hertz, working in one room, generated and received\nelectromagnetic radiation. Maxwell's equations describe the electromagnetic\nfield. The quanta of electromagnetic radiation are spin 1 photons. They are\nfundamental to atomic physics and quantum electrodynamics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report a polarized Raman scattering study of non-symmorphic topological\ninsulator KHgSb with hourglass-like electronic dispersion. Supported by\ntheoretical calculations, we show that the lattice of the previously assigned\nspace group $P6_3/mmc$ (No. 194) is unstable in KHgSb. While we observe one of\ntwo calculated Raman active E$_{2g}$ phonons of space group $P6_3/mmc$ at room\ntemperature, an additional A$_{1g}$ peak appears at 99.5 ~cm$^{-1}$ upon\ncooling below $T^*$ = 150 K, which suggests a lattice distortion. Several weak\npeaks associated with two-phonon excitations emerge with this lattice\ninstability. We also show that the sample is very sensitive to high temperature\nand high laser power, conditions under which it quickly decomposes, leading to\nthe formation of Sb. Our first-principles calculations indicate that space\ngroup $P6_3mc$ (No. 186), corresponding to a vertical displacement of the Sb\natoms with respect to the Hg atoms that breaks the inversion symmetry, is lower\nin energy than the presumed $P6_3/mmc$ structure and preserves the glide plane\nsymmetry necessary to the formation of hourglass fermions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The aim of this paper is to prove a counterpart of the Banach fixed point\nprinciple for mappings $f: \\ell_\\infty(X) \\to X$, where $X$ is a metric space\nand $\\ell_\\infty(X)$ is the space of all bounded sequences of elements\nfrom~$X$. Our result generalizes the theorem obtained by Miculescu and Mihail\nin 2008, who proved a~counterpart of the Banach principle for mappings\n$f:X^m\\to X$, where $X^m$ is the Cartesian product of $m$ copies of $X$. We\nalso compare our result with a recent one due to Secelean, who obtained a\nweaker assertion under less restrictive assumptions. We illustrate our result\nwith several examples and give an application.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A numerical semigroup is a subset of N containing 0, closed under addition\nand with finite complement in N. An important example of numerical semigroup is\ngiven by the Weierstrass semigroup at one point of a curve. In the theory of\nalgebraic geometry codes, Weierstrass semigroups are crucial for defining\nbounds on the minimum distance as well as for defining improvements on the\ndimension of codes. We present these applications and some theoretical problems\nrelated to classification, characterization and counting of numerical\nsemigroups.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The iterations of many first-order algorithms, when applied to minimizing\ncommon regularized regression functions, often resemble neural network layers\nwith pre-specified weights. This observation has prompted the development of\nlearning-based approaches that purport to replace these iterations with\nenhanced surrogates forged as DNN models from available training data. For\nexample, important NP-hard sparse estimation problems have recently benefitted\nfrom this genre of upgrade, with simple feedforward or recurrent networks\nousting proximal gradient-based iterations. Analogously, this paper\ndemonstrates that more powerful Bayesian algorithms for promoting sparsity,\nwhich rely on complex multi-loop majorization-minimization techniques, mirror\nthe structure of more sophisticated long short-term memory (LSTM) networks, or\nalternative gated feedback networks previously designed for sequence\nprediction. As part of this development, we examine the parallels between\nlatent variable trajectories operating across multiple time-scales during\noptimization, and the activations within deep network structures designed to\nadaptively model such characteristic sequences. The resulting insights lead to\na novel sparse estimation system that, when granted training data, can estimate\noptimal solutions efficiently in regimes where other algorithms fail, including\npractical direction-of-arrival (DOA) and 3D geometry recovery problems. The\nunderlying principles we expose are also suggestive of a learning process for a\nricher class of multi-loop algorithms in other domains.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The purpose of this article is to study the asymptotic expansion of\nRay-Singer analytic tosion associated with increasing powers p of a given\npositive line bundle. Here we prove that the asymptotic expansion associated to\na manifold contains only the terms of the form $p^{n-i} \\log p, p^{n-i}$ for\n$i$-natural. For the two leading terms it was proved by Bismut and Vasserot in\n1989. We will calculate the coefficients of the terms $p^{n-1} \\log p, p^{n-1}$\nin the Kahler case and thus answer the question posed in the recent work of\nKlevtsov, Ma, Marinescu and Wiegmann about quantuum Hall effect. Our second\nresult concerns the general asymptotic expansion of Ray-Singer analytic torsion\nfor an orbifold.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Ma\\~n\\'e (1979) proved that if a compact metric space admits an expansive\nhomeomorphism then it is finite dimensional. We generalize this theorem to\nmultiparameter actions. The generalization involves mean dimension theory,\nwhich counts \"averaged dimension\" of a dynamical system. We prove that if\n$T:\\mathbb{Z}^k\\times X\\to X$ is expansive and if $R:\\mathbb{Z}^{k-1}\\times\nX\\to X$ commutes with $T$ then $R$ has finite mean dimension. When $k=1$, this\nstatement reduces to Ma\\~{n}\\'{e}'s theorem. We also study several related\nissues, especially the connection with entropy theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using punctual gluing of $t$-structures, we construct an analogue of S.\nMorel's weight truncation functors (for certain weight profiles) in the setting\nof motivic sheaves. As an application we construct a canonical motivic analogue\nof the intersection complex for an arbitrary threefold over any field $k$. We\nare also able to recover certain invariants of singularities motivically.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report a comparison of the $1/T_1$ spin lattice relaxation rates (SLR) for\n$^9Li$ and $^8Li$ in Pt and SrTiO$_{3}$, in order to differentiate between\nmagnetic and electric quadrupolar relaxation mechanisms. In Pt, the ratio of\nthe $1/T_{1}$ spin relaxation rates $R_{Pt}$ was found to be 6.82(29), which is\nclose to but less than the theoretical limit of $\\sim7.68$ for pure magnetic\nrelaxation. In SrTiO$_{3}$ this ratio was found to be 2.7(3), which is close\nbut larger than the theoretical limit of $\\sim2.14$ expected for pure electric\nquadrupolar relaxation. These results bring new insight into the nature of the\nfluctuations in the local environment of implanted $^8Li$ observed by\n$\\beta$-NMR.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The goal of this paper is not to introduce a single algorithm or method, but\nto make theoretical steps towards fully understanding the training dynamics of\ngenerative adversarial networks. In order to substantiate our theoretical\nanalysis, we perform targeted experiments to verify our assumptions, illustrate\nour claims, and quantify the phenomena. This paper is divided into three\nsections. The first section introduces the problem at hand. The second section\nis dedicated to studying and proving rigorously the problems including\ninstability and saturation that arize when training generative adversarial\nnetworks. The third section examines a practical and theoretically grounded\ndirection towards solving these problems, while introducing new tools to study\nthem.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The relationship between the microstructure of a porous medium and the\nobserved flow distribution is still a puzzle. We resolve it with an analytical\nmodel, where the local correlations between adjacent pores, which determine the\ndistribution of flows propagated from one pore downstream, predict the flow\ndistribution. Numerical simulations of a two-dimensional porous medium verify\nthe model and clearly show the transition of flow distributions from\n$\\delta$-function-like via Gaussians to exponential with increasing disorder.\nComparison to experimental data further verifies our numerical approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss the effect of dissipation on heating which occurs in periodically\ndriven quantum many body systems. We especially focus on a periodically driven\nBose-Hubbard model coupled to an energy and particle reservoir. Without\ndissipation, this model is known to undergo parametric instabilities which can\nbe considered as an initial stage of heating. By taking the weak on-site\ninteraction limit as well as the weak system-reservoir coupling limit, we find\nthat parametric instabilities are suppressed if the dissipation is stronger\nthan the on-site interaction strength and stable steady states appear. Our\nresults demonstrate that periodically-driven systems can emit energy, which is\nabsorbed from external drivings, to the reservoir so that they can avoid\nheating.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The interplay between superconductivity and charge density waves (CDW) in\n$H$-NbSe2 is not fully understood despite decades of study. Artificially\nintroduced disorder can tip the delicate balance between two competing forms of\nlong-range order, and reveal the underlying interactions that give rise to\nthem. Here we introduce disorders by electron irradiation and measure in-plane\nresistivity, Hall resistivity, X-ray scattering, and London penetration depth.\nWith increasing disorder, $T_{\\textrm{c}}$ varies nonmonotonically, whereas\n$T_{\\textrm{CDW}}$ monotonically decreases and becomes unresolvable above a\ncritical irradiation dose where $T_{\\textrm{c}}$ drops sharply. Our results\nimply that CDW order initially competes with superconductivity, but eventually\nassists it. We argue that at the transition where the long-range CDW order\ndisappears, the cooperation with superconductivity is dramatically suppressed.\nX-ray scattering and Hall resistivity measurements reveal that the short-range\nCDW survives above the transition. Superconductivity persists to much higher\ndose levels, consistent with fully gapped superconductivity and moderate\ninterband pairing.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a new technique for reducing the dimension of the ambient space\nof low-degree polynomials in the Gaussian space while preserving their relative\ncorrelation structure, analogous to the Johnson-Lindenstrauss lemma. As\napplications, we address the following problems:\n  1. Computability of Approximately Optimal Noise Stable function over Gaussian\nspace: The goal is to find a partition of $\\mathbb{R}^n$ into $k$ parts, that\nmaximizes the noise stability. An $\\delta$-optimal partition is one which is\nwithin additive $\\delta$ of the optimal noise stability.\n  De, Mossel & Neeman (CCC 2017) raised the question of proving a computable\nbound on the dimension $n_0(\\delta)$ in which we can find an $\\delta$-optimal\npartition. While De et al. provide such a bound, using our new technique, we\nobtain improved explicit bounds on the dimension $n_0(\\delta)$.\n  2. Decidability of Non-Interactive Simulation of Joint Distributions: A\n\"non-interactive simulation\" problem is specified by two distributions $P(x,y)$\nand $Q(u,v)$: The goal is to determine if two players that observe sequences\n$X^n$ and $Y^n$ respectively where $\\{(X_i, Y_i)\\}_{i=1}^n$ are drawn i.i.d.\nfrom $P(x,y)$ can generate pairs $U$ and $V$ respectively (without\ncommunicating with each other) with a joint distribution that is arbitrarily\nclose in total variation to $Q(u,v)$. Even when $P$ and $Q$ are extremely\nsimple, it is open in several cases if $P$ can simulate $Q$.\n  In the special where $Q$ is a joint distribution over $\\{0,1\\} \\times\n\\{0,1\\}$, Ghazi, Kamath and Sudan (FOCS 2016) proved a computable bound on the\nnumber of samples $n_0(\\delta)$ that can be drawn from $P(x,y)$ to get\n$\\delta$-close to $Q$ (if it is possible at all). Recently De, Mossel & Neeman\nobtained such bounds when $Q$ is a distribution over $[k] \\times [k]$ for any\n$k \\ge 2$. We recover this result with improved explicit bounds on\n$n_0(\\delta)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Films of Cu-K-In-Se were co-evaporated at varied K/(K+Cu) compositions and\nsubstrate temperatures (with constant (K+Cu)/In ~ 0.85). Increased Na\ncomposition on the substrate's surface and decreased growth temperature were\nboth found to favor Cu1-xKxInSe2 (CKIS) alloy formation, relative to\nmixed-phase CuInSe2 + KInSe2 formation. Structures from X-ray diffraction\n(XRD), band gaps, resistivities, minority carrier lifetimes and carrier\nconcentrations from time-resolved photoluminescence were in agreement with\nprevious reports, where low K/(K+Cu) composition films exhibited properties\npromising for photovoltaic (PV) absorbers. Films grown at 400-500 C were then\nannealed to 600 C under Se, which caused K loss by evaporation in proportion to\ninitial K/(K+Cu) composition. Similar to growth temperature, annealing drove\nCKIS alloy consumption and CuInSe2 + KInSe2 production, as evidenced by high\ntemperature XRD. Annealing also decomposed KInSe2 and formed K2In12Se19. At\nhigh temperature the KInSe2 crystal lattice gradually contracted as temperature\nand time increased, as well as just time. Evaporative loss of K during\nannealing could accompany the generation of vacancies on K lattice sites, and\nmay explain the KInSe2 lattice contraction. This knowledge of Cu-K-In-Se\nmaterial chemistry may be used to predict and control minor phase impurities in\nCu(In,Ga)(Se,S)2 PV absorbers-where impurities below typical detection limits\nmay have played a role in recent world record PV efficiencies that utilized KF\npost-deposition treatments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the following paper we propose a model-theoretical way of comparing the\n\"strength\" of various truth theories which are conservative over PA.\n  Let $\\mathfrak{Th}$ denote the class of models of PA which admit an expansion\nto a model of theory Th. We show (combining some well known results and\noriginal ideas) that $$\\mathfrak{PA}\\supset \\mathfrak{TB}\\supset\n\\mathfrak{RS}\\supset \\mathfrak{UTB}\\supseteq\\mathfrak{CT^-},$$ where\n$\\mathfrak{PA}$ denotes simply the class of all models of PA and\n$\\mathfrak{RS}$ denotes the class of recursively saturated models of PA. Our\nmain original result is that every model of PA which admits an expansion to a\nmodel of CT${}^-$, admits also an expanion to a model of UTB. Moreover, as a\ncorollary to one of the results we conclude that UTB is not relatively\ninterpretable in TB, thus answering the question of Fujimoto.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This article develops a duality principle for non-linear elasticity. The\nresults are obtained through standard tools of convex analysis and the Legendre\ntransform concept. We emphasize the dual variational formulation is concave.\nMoreover, sufficient optimality conditions are also established.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Topological Data Analysis (TDA) is a novel statistical technique,\nparticularly powerful for the analysis of large and high dimensional data sets.\nMuch of TDA is based on the tool of persistent homology, represented visually\nvia persistence diagrams. In an earlier paper we proposed a parametric\nrepresentation for the probability distributions of persistence diagrams, and\nbased on it provided a method for their replication. Since the typical\nsituation for big data is that only one persistence diagram is available, these\nreplications allow for conventional statistical inference, which, by its very\nnature, requires some form of replication. In the current paper we continue\nthis analysis, and further develop its practical statistical methodology, by\ninvestigating a wider class of examples than treated previously.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the number of Galois Weierstrass points whose Weierstrass\nsemigroups are generated by two positive integers.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Evaporating droplets are known to show complex motion that has conventionally\nbeen explained by the Marangoni effect (flow induced by the gradient of surface\ntension). Here, we show that the droplet motion can be induced even in the\nabsence of the Marangoni effect due to the gradient of evaporation rate. We\nderive an equation for the velocity of a droplet subject to non-uniform\nevaporation rate and non-uniform surface tension placed on an inert substrate\nwhere the wettability is uniform and unchanged. The equation explains the\npreviously observed attraction-repulsion- chasing behaviors of evaporating\ndroplets.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Knowing a biomolecule's structure is inherently linked to and a prerequisite\nfor any detailed understanding of its function. Significant effort has gone\ninto developing technologies for structural characterization. These\ntechnologies do not directly provide 3D structures; instead they typically\nyield noisy and erroneous distance information between specific entities such\nas atoms or residues, which have to be translated into consistent 3D models.\n  Here we present an approach for this translation process based on\nmaxent-stress optimization. Our new approach extends the original graph drawing\nmethod for the new application's specifics by introducing additional\nconstraints and confidence values as well as algorithmic components. Extensive\nexperiments demonstrate that our approach infers structural models (i. e.,\nsensible 3D coordinates for the molecule's atoms) that correspond well to the\ndistance information, can handle noisy and error-prone data, and is\nconsiderably faster than established tools. Our results promise to allow domain\nscientists nearly-interactive structural modeling based on distance\nconstraints.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Large Magellanic Cloud (LMC) currently hosts around 23 high mass X-ray\nbinaries (HMXBs) of which most are Be/X-ray binaries. The LMC XMM-Newton survey\nprovided follow-up observations of previously known X-ray sources that were\nlikely HMXBs, as well as identifying new HMXB candidates. In total 19 candidate\nHMXBs were selected based on their X-ray hardness ratios. In this paper we\npresent red and blue optical spectroscopy, obtained with SALT and the SAAO\n1.9-m telescope, plus a timing analysis of the long term optical light curves\nfrom OGLE to confirm the nature of these candidates. We find that 9 of the\ncandidates are new Be/X-ray Binaries, substantially increasing the LMC Be/X-ray\nbinary population. Furthermore, we present the optical properties of these new\nsystems, both individually and as a group of all the BeXBs identified by the\nXMM-Newton survey of the LMC.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Polarized extinction and emission from dust in the interstellar medium (ISM)\nare hard to interpret, as they have a complex dependence on dust optical\nproperties, grain alignment and magnetic field orientation. This is\nparticularly true in molecular clouds. The data available today are not yet\nused to their full potential.\n  The combination of emission and extinction, in particular, provides\ninformation not available from either of them alone. We combine data from the\nscientific literature on polarized dust extinction with Planck data on\npolarized emission and we use them to constrain the possible variations in dust\nand environmental conditions inside molecular clouds, and especially\ntranslucent lines of sight, taking into account magnetic field orientation.\n  We focus on the dependence between \\lambda_max -- the wavelength of maximum\npolarization in extinction -- and other observables such as the extinction\npolarization, the emission polarization and the ratio of the two. We set out to\nreproduce these correlations using Monte-Carlo simulations where the relevant\nquantities in a dust model -- grain alignment, size distribution and magnetic\nfield orientation -- vary to mimic the diverse conditions expected inside\nmolecular clouds.\n  None of the quantities chosen can explain the observational data on its own:\nthe best results are obtained when all quantities vary significantly across and\nwithin clouds. However, some of the data -- most notably the stars with low\nemission-to-extinction polarization ratio -- are not reproduced by our\nsimulation. Our results suggest not only that dust evolution is necessary to\nexplain polarization in molecular clouds, but that a simple change in size\ndistribution is not sufficient to explain the data, and point the way for\nfuture and more sophisticated models.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Exploiting the powerful tool of strong gravitational lensing by galaxy\nclusters to study the highest-redshift Universe and cluster mass distributions\nrelies on precise lens mass modelling. In this work, we present the first\nattempt at modelling line-of-sight mass distribution in addition to that of the\ncluster, extending previous modelling techniques that assume mass distributions\nto be on a single lens plane. We focus on the Hubble Frontier Field cluster\nMACS J0416.1-2403, and our multi-plane model reproduces the observed image\npositions with a rms offset of ~0.53\". Starting from this best-fitting model,\nwe simulate a mock cluster that resembles MACS J0416.1-2403 in order to explore\nthe effects of line-of-sight structures on cluster mass modelling. By\nsystematically analysing the mock cluster under different model assumptions, we\nfind that neglecting the lensing environment has a significant impact on the\nreconstruction of image positions (rms ~0.3\"); accounting for line-of-sight\ngalaxies as if they were at the cluster redshift can partially reduce this\noffset. Moreover, foreground galaxies are more important to include into the\nmodel than the background ones. While the magnification factors of the lensed\nmultiple images are recovered within ~10% for ~95% of them, those ~5% that lie\nnear critical curves can be significantly affected by the exclusion of the\nlensing environment in the models (up to a factor of ~200). In addition,\nline-of-sight galaxies cannot explain the apparent discrepancy in the\nproperties of massive subhalos between MACS J0416.1-2403 and N-body simulated\nclusters. Since our model of MACS J0416.1-2403 with line-of-sight galaxies only\nreduced modestly the rms offset in the image positions, we conclude that\nadditional complexities, such as more flexible halo shapes, would be needed in\nfuture models of MACS J0416.1-2403.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Cherenkov Telescope Array is the main global project of ground-based\ngamma-ray astronomy for the coming decades. Performance will be significantly\nimproved relative to present instruments, allowing a new insight into the\nhigh-energy Universe [1]. The nominal CTA southern array will include a\nsub-array of seventy 4 m telescopes spread over a few square kilometers to\nstudy the sky at extremely high energies, with the opening of a new window in\nthe multi-TeV energy range. The Gamma-ray Cherenkov Telescope (GCT) is one of\nthe proposed telescope designs for that sub-array. The GCT prototype recorded\nits first Cherenkov light on sky in 2015. After an assessment phase in 2016,\nnew observations have been performed successfully in 2017. The GCT\ncollaboration plans to install its first telescopes and cameras on the CTA site\nin Chile in 2018-2019 and to contribute a number of telescopes to the\nsubsequent CTA production phase.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, a short-term load forecasting approach based network\nreconfiguration is proposed in a parallel manner. Specifically, a support\nvector regression (SVR) based short-term load forecasting approach is designed\nto provide an accurate load prediction and benefit the network reconfiguration.\nBecause of the nonconvexity of the three-phase balanced optimal power flow, a\nsecond-order cone program (SOCP) based approach is used to relax the optimal\npower flow problem. Then, the alternating direction method of multipliers\n(ADMM) is used to compute the optimal power flow in distributed manner.\nConsidering the limited number of the switches and the increasing computation\ncapability, the proposed network reconfiguration is solved in a parallel way.\nThe numerical results demonstrate the feasible and effectiveness of the\nproposed approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Er-doped phosphate glasses were fabricated by melt-quenching technique. The\nchanges in their thermal, structural and luminescence properties with the\naddition of Al2O3, TiO2 or ZnO were studied. Physical and thermal properties\nwere investigated through density measurement and differential thermal\nanalysis. Structural characterization was performed using the Raman and\nInfrared spectroscopy. In order to study the influence of the composition on\nthe luminescence properties of the glasses, the refractive index, the\nluminescence spectra and the lifetime values were measured. The results show\nthat with the addition of Al2O3 and TiO2 the phosphate network becomes more\nconnected increasing the glass transition temperature, whereas the addition of\nZnO does not show significant changes in the optical, thermal and structural\nproperties but it leads to a larger emission cross-section at 1540 nm as\ncompared to the other glasses. As the site of the Er3+ is not strongly affected\nby the change in the glass composition, we think that the emission properties\nof the glasses depend on the glass structure connectivity, which has an impact\non the Er3+ ions solubility.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss a common suspicion about reported financial data, in 10 industrial\nsectors of the 6 so called \"main developing countries\" over the time interval\n[2000-2014]. These data are examined through Benford's law first significant\ndigit and through distribution distances tests. It is shown that several\nvisually anomalous data have to be a priori removed. Thereafter, the\ndistributions much better follow the first digit significant law, indicating\nthe usefulness of a Benford's law test from the research starting line. The\nsame holds true for distance tests. A few outliers are pointed out.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We theoretically study resonance responses of flat surfaces and sharp edges\nof the nanostructures that support excitations of phonon-polaritons in\nmid-infrared range. We focus on two materials: silicon carbide that has a\nnearly isotropic permittivity and hexagonal boron nitride that has a strong\nanisotropy and spectral band with hyperbolic dispersion. We aim to predict\nscattering-type near-field optical microscope (s-SNOM) response and develop a\nmodeling approach that adequately describes the resonant behavior of the\nnanostructure with phonon-polaritons. The previously employed technique assumes\ndipole scattering from the tip and allows calculating s-SNOM signal in\ndifferent demodulation orders by modeling full structure, any tip positions,\nand vertical scans, which works well for the structures with only one hot spot,\ne.g. flat surfaces. In the structures of complex shapes, hot-spot places are\nunknown, and analysis of light absorption in the whole apex is the best way to\naccount for all hot spots and field enhancement. We show that calculation of\ndemodulation orders of light absorption in the tip is an alternative way to\npredict s-SNOM signal, and it is preferred for the structures of complex shapes\nwith strong resonances, where dipole approximation of the tip is not valid.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider two manifestations of non-positive curvature: acylindrical\nactions on hyperbolic spaces and quasigeodesic stability. We study these\nproperties for the class of hierarchically hyperbolic groups, which is a\ngeneral framework for studying many important families of groups, including\nmapping class groups, right-angled Coxeter and Artin groups, most 3-manifold\ngroups, and many others. A group that admits an acylindrical action on a\nhyperbolic space may admit many such actions on different hyperbolic spaces, so\nit is natural to search for a \"best\" one. The set of all cobounded acylindrical\nactions on hyperbolic spaces admits a natural poset structure; in this paper we\nprove that all hierarchically hyperbolic groups admit a unique action which is\nthe largest in this poset. The action we construct is also universal in the\nsense that every element which acts loxodromically in some acylindrical action\non a hyperbolic space does so in this one. Special cases of this result are\nthemselves new and interesting. For instance, this is the first proof that\nright-angled Coxeter groups admit universal acylindrical actions. The notion of\nquasigeodesic stability of subgroups provides a natural analogue of\nquasiconvexity outside the context of hyperbolic groups. We provide a complete\nclassification of stable subgroups of hierarchically hyperbolic groups,\ngeneralizing and extending results that are known for mapping class groups and\nright-angled Artin groups. We also provide a characterization of contracting\nquasigeodesics; interestingly, in this generality the proof is much simpler\nthan in the special cases where it was already known. In the appendix, it is\nverified that any space satisfying the a priori weaker property of being an\n\"almost hierarchically hyperbolic space\" is actually a hierarchically\nhyperbolic space. The results of the appendix are used to streamline the proofs\nin the main text.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Studying the behavior of crowds is vital for understanding and predicting\nhuman interactions in public areas. Research has shown that, under certain\nconditions, large groups of people can form collective behavior patterns: local\ninteractions between individuals results in global movements patterns. To\ndetect these patterns in a crowd, we assume each person is carrying an on-body\ndevice that acts a local proximity sensor, e.g., smartphone or bluetooth badge,\nand represent the texture of the crowd as a proximity graph. Our goal is\nextract information about crowds from these proximity graphs. In this work, we\nfocus on one particular type of pattern: lane formation. We present a formal\ndefinition of a lane, proposed a simple probabilistic model that simulates\nlanes moving through a stationary crowd, and present an automated\nlane-detection method. Our preliminary results show that our method is able to\ndetect lanes of different shapes and sizes. We see our work as an initial step\ntowards rich pattern recognition using proximity graphs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Cantor locus is the unique hyperbolic component, in the moduli space of\nquadratic rational maps ${\\bf rat}_2$, consisting of maps with totally\ndisconnected Julia sets. Whereas the Cantor locus is well understood, its\nboundary and dynamical relation to the boundary is not. In this paper we\nexplore the boundary of the Cantor locus near parabolic boundary points. We do\nthis by constructing a local parametrization, which fixes the dynamical\npositions of the critical values, relative to the parabolic basin of the\nquadratic polynomial $\\mathrm{P}_{\\omega_{p/q}}(z)=\\omega_{p/q} z+z^2$,\n$\\omega_{p/q}=e^{2\\pi ip/q}$. We characterize which pairs, of dynamical\npositions and parabolic boundary points, give rise to bounded and unbounded\nsequences in ${\\bf rat}_2$ respectively. Moreover, we show that this approach\ncontrols the dynamical postions of the critical values, for any limit point in\nthe bounded case, and for any limit point of a rescaled sequence of $q$th\niterates in the unbounded case.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show that two curves of Artin-Schreier type have a birational embedding\ninto a projective plane with two Galois points. As a consequence, all curves\nwith large automorphism groups in the classification list by Henn have a\nbirational embedding with two Galois points.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a strategy for large volume non-perturbative renormalization which\nalleviates the window problem by reducing cut-off effects. We perform a\nproof-of-concept study using position space renormalization scheme and the CLS\n$N_f=2+1$ ensembles generated at 5 different lattice spacings. We show that in\nthe advocated strategy results for the renormalization constants are to a large\nextend independent of the specific lattice direction used to define the\nrenormalization condition. Hence, very short lattice distances become\naccessible even on coarse lattices and the contact with perturbation theory can\nbe performed at much higher energy scales. Our results include\nnon-perturbatively estimated renormalization constants for quark bilinear\noperators in the scalar, pseudoscalar and axial-vector channels using position\nspace renormalization scheme which we subsequently translate to the\n$\\overline{\\mathrm{MS}}$ scheme perturbatively at $1.5$ GeV. Our proposal is\napplicable to other non-perturbative large volume renormalization schemes such\nas RI-MOM and its variants.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Feature selection has always been a critical step in pattern recognition, in\nwhich evolutionary algorithms, such as the genetic algorithm (GA), are most\ncommonly used. However, the individual encoding scheme used in various GAs\nwould either pose a bias on the solution or require a pre-specified number of\nfeatures, and hence may lead to less accurate results. In this paper, a tribe\ncompetition-based genetic algorithm (TCbGA) is proposed for feature selection\nin pattern classification. The population of individuals is divided into\nmultiple tribes, and the initialization and evolutionary operations are\nmodified to ensure that the number of selected features in each tribe follows a\nGaussian distribution. Thus each tribe focuses on exploring a specific part of\nthe solution space. Meanwhile, tribe competition is introduced to the evolution\nprocess, which allows the winning tribes, which produce better individuals, to\nenlarge their sizes, i.e. having more individuals to search their parts of the\nsolution space. This algorithm, therefore, avoids the bias on solutions and\nrequirement of a pre-specified number of features. We have evaluated our\nalgorithm against several state-of-the-art feature selection approaches on 20\nbenchmark datasets. Our results suggest that the proposed TCbGA algorithm can\nidentify the optimal feature subset more effectively and produce more accurate\npattern classification.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study 2d vortex sheets with unbounded support. First we show a version of\nthe Biot- Savart law related to a class of objects including such vortex\nsheets. Next, we give a formula associating the kinetic energy of a very\ngeneral class of ows with certain moments of their vorticities. It allows us to\nidentify a class of vortex sheets of unbounded support being only ?-finite\nmeasures (in particluar including measures \\omega such that \\omega(R2) =\n\\infty), but with locally finite kinetic energy. One of such examples are\ncelebrated Kaden approximations. We study them in details. In particular our\nestimates allow us to show that the kinetic energy of Kaden approximations in\nthe neighbourhood of an origin is dissipated, actually we show that the energy\nis pushed out of any ball centered in the origin of the Kaden spiral. The\nlatter result can be interpreted as an artificial viscosity in the center of a\nspiral.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the fillable array problem one must maintain an array A[1..n] of $w$-bit\nentries subject to random access reads and writes, and also a\n$\\texttt{fill}(\\Delta)$ operation which sets every entry of to some\n$\\Delta\\in\\{0,\\ldots,2^w-1\\}$. We show that with just one bit of redundancy,\ni.e. a data structure using $nw+1$ bits of memory,\n$\\texttt{read}/\\texttt{fill}$ can be implemented in worst case constant time,\nand $\\texttt{write}$ can be implemented in either amortized constant time\n(deterministically) or worst case expected constant (randomized). In the latter\ncase, we need to store an additional $O(\\log n)$ random bits to specify a\npermutation drawn from an $1/n^2$-almost pairwise independent family.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A key challenge facing the design of differential privacy in the\nnon-interactive setting is to maintain the utility of the released data. To\novercome this challenge, we utilize the Diaconis-Freedman-Meckes (DFM) effect,\nwhich states that most projections of high-dimensional data are nearly\nGaussian. Hence, we propose the RON-Gauss model that leverages the novel\ncombination of dimensionality reduction via random orthonormal (RON) projection\nand the Gaussian generative model for synthesizing differentially-private data.\nWe analyze how RON-Gauss benefits from the DFM effect, and present multiple\nalgorithms for a range of machine learning applications, including both\nunsupervised and supervised learning. Furthermore, we rigorously prove that (a)\nour algorithms satisfy the strong $\\epsilon$-differential privacy guarantee,\nand (b) RON projection can lower the level of perturbation required for\ndifferential privacy. Finally, we illustrate the effectiveness of RON-Gauss\nunder three common machine learning applications -- clustering, classification,\nand regression -- on three large real-world datasets. Our empirical results\nshow that (a) RON-Gauss outperforms previous approaches by up to an order of\nmagnitude, and (b) loss in utility compared to the non-private real data is\nsmall. Thus, RON-Gauss can serve as a key enabler for real-world deployment of\nprivacy-preserving data release.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work we present, for the first time, the non-perturbative\nrenormalization for the unpolarized, helicity and transversity quasi-PDFs, in\nan RI' scheme. The proposed prescription addresses simultaneously all aspects\nof renormalization: logarithmic divergences, finite renormalization as well as\nthe linear divergence which is present in the matrix elements of fermion\noperators with Wilson lines. Furthermore, for the case of the unpolarized\nquasi-PDFs, we describe how to eliminate the unwanted mixing with the twist-3\nscalar operator. We utilize perturbation theory for the one-loop conversion\nfactor that brings the renormalization functions to the MS-scheme at a scale of\n2 GeV. We also explain how to improve the estimates on the renormalization\nfunctions by eliminating lattice artifacts. The latter can be computed in\none-loop perturbation theory and to all orders in the lattice spacing. We apply\nthe methodology for the renormalization to an ensemble of twisted mass fermions\nwith Nf=2+1+1 dynamical light quarks, and a pion mass of around 375 MeV.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Epidemiological early warning systems for dengue fever rely on up-to-date\nepidemiological data to forecast future incidence. However, epidemiological\ndata typically requires time to be available, due to the application of\ntime-consuming laboratorial tests. This implies that epidemiological models\nneed to issue predictions with larger antecedence, making their task even more\ndifficult. On the other hand, online platforms, such as Twitter or Google,\nallow us to obtain samples of users' interaction in near real-time and can be\nused as sensors to monitor current incidence. In this work, we propose a\nframework to exploit online data sources to mitigate the lack of up-to-date\nepidemiological data by obtaining estimates of current incidence, which are\nthen explored by traditional epidemiological models. We show that the proposed\nframework obtains more accurate predictions than alternative approaches, with\nstatistically better results for delays greater or equal to 4 weeks.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Accurate and robust object state estimation enables successful object\nmanipulation. Visual sensing is widely used to estimate object poses. However,\nin a cluttered scene or in a tight workspace, the robot's end-effector often\noccludes the object from the visual sensor. The robot then loses visual\nfeedback and must fall back on open-loop execution.\n  In this paper, we integrate both tactile and visual input using a framework\nfor solving the SLAM problem, incremental smoothing and mapping (iSAM), to\nprovide a fast and flexible solution. Visual sensing provides global pose\ninformation but is noisy in general, whereas contact sensing is local, but its\nmeasurements are more accurate relative to the end-effector. By combining them,\nwe aim to exploit their advantages and overcome their limitations. We explore\nthe technique in the context of a pusher-slider system. We adapt iSAM's\nmeasurement cost and motion cost to the pushing scenario, and use an\ninstrumented setup to evaluate the estimation quality with different object\nshapes, on different surface materials, and under different contact modes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A $(p, q)$-leaper is a fairy chess piece that, from a square $a$, can move to\nany of the squares $a + (\\pm p, \\pm q)$ or $a + (\\pm q, \\pm p)$. Let $L$ be a\n$(p, q)$-leaper with $p + q$ odd and $C$ a cycle of $L$ within a $(p + q)\n\\times (p + q)$ chessboard. We show that there exists a second leaper $M$,\ndistinct from $L$, such that a Hamiltonian cycle $D$ of $M$ exists over the\nsquares of $C$. We give descriptions of $C$ and $M$ in terms of continued\nfractions. We introduce the notion of a direction graph, roughly a leaper graph\nfrom which all information has been abstracted away save for the directions of\nthe moves, and we study $C$ and $D$ in terms of direction graphs. We introduce\nthe notion of a dual generalized chessboard, a generalized chessboard $B$ of\nmore than one square such that the leaper graph of a leaper $L$ over $B$ is\nconnected and isomorphic to the leaper graph of a second leaper $M$, distinct\nfrom $L$, over $B$, and we give constructions for dual generalized chessboards.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the adsorption of a fluid in the grand canonical ensemble occurring\nat a planar heterogeneous wall which is decorated with a chemical stripe of\nwidth $L$. We suppose that the material of the stripe strongly preferentially\nadsorbs the liquid in contrast to the outer material which is only partially\nwet. This competition leads to the nucleation of a droplet of liquid on the\nstripe, the height $h_m$ and shape of which (at bulk two-phase coexistence) has\nbeen predicted previously using mesoscopic interfacial Hamiltonian theory. We\ntest these predictions using a microscopic Fundamental Measure Density\nFunctional Theory which incorporates short-ranged fluid-fluid and fully\nlong-ranged wall-fluid interactions. Our model functional accurately describes\npacking effects not captured by the interfacial Hamiltonian but still we show\nthat there is excellent agreement with the predictions $h_m\\approx L^{1/2}$ and\nfor the scaled circular shape of the drop even for $L$ as small as $50$\nmolecular diameters. For smaller stripes the droplet height is considerably\nlower than that predicted by the mesoscopic interfacial theory. Phase\ntransitions for droplet configurations occurring on substrates with multiple\nstripes are also discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  By a classical principle of probability theory, sufficiently thin\nsubsequences of general sequences of random variables behave like i.i.d.\\\nsequences. This observation not only explains the remarkable properties of\nlacunary trigonometric series, but also provides a powerful tool in many areas\nof analysis, such the theory of orthogonal series and Banach space theory. In\ncontrast to i.i.d.\\ sequences, however, the probabilistic structure of lacunary\nsequences is not permutation-invariant and the analytic properties of such\nsequences can change after rearrangement. In a previous paper we showed that\npermutation-invariance of subsequences of the trigonometric system and related\nfunction systems is connected with Diophantine properties of the index\nsequence. In this paper we will study permutation-invariance of subsequences of\ngeneral r.v.\\ sequences.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For multi-block alternating direction method of multipliers(ADMM), where the\nobjective function can be decomposed into multiple block components, we show\nthat with block symmetric Gauss-Seidel iteration, the algorithm will converge\nquickly. The method will apply a block symmetric Gauss-Seidel iteration in the\nprimal update and a linear correction that can be derived in view of Richard\niteration. We also establish the linear convergence rate for linear systems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Investigations of the origin and evolution of the Milky Way disk have long\nrelied on chemical and kinematic identification of its components to\nreconstruct our Galactic past. Difficulties in determining precise stellar ages\nhave restricted most studies to small samples, normally confined to the solar\nneighbourhood. Here we break this impasse with the help of asteroseismic\ninference and perform a chronology of the evolution of the disk throughout the\nage of the Galaxy. We chemically dissect the Milky Way disk population using a\nsample of red giant stars spanning out to 2~kpc in the solar annulus observed\nby the {\\it Kepler} satellite, with the added dimension of asteroseismic ages.\nOur results reveal a clear difference in age between the low- and high-$\\alpha$\npopulations, which also show distinct velocity dispersions in the $V$ and $W$\ncomponents. We find no tight correlation between age and metallicity nor\n[$\\alpha$/Fe] for the high-$\\alpha$ disk stars. Our results indicate that this\ncomponent formed over a period of more than 2~Gyr with a wide range of [M/H]\nand [$\\alpha$/Fe] independent of time. Our findings show that the kinematic\nproperties of young $\\alpha$-rich stars are consistent with the rest of the\nhigh-$\\alpha$ population and different from the low-$\\alpha$ stars of similar\nage, rendering support to their origin being old stars that went through a mass\ntransfer or stellar merger event, making them appear younger, instead of\nmigration of truly young stars formed close to the Galactic bar.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Models for financial risk often assume that underlying asset returns are\nstationary. However, there is strong evidence that multivariate financial time\nseries entail changes not only in their within-series dependence structure, but\nalso in the cross-sectional dependence among them. In particular, the stressed\nValue-at-Risk of a portfolio, a popularly adopted measure of market risk,\ncannot be gauged adequately unless such structural breaks are taken into\naccount in its estimation. We propose a method for consistent detection of\nmultiple change points in high-dimensional GARCH panel data set where both\nindividual GARCH processes and their correlations are allowed to change over\ntime. We prove its consistency in multiple change point estimation, and\ndemonstrate its good performance through simulation studies and an application\nto the Value-at-Risk problem on a real dataset. Our methodology is implemented\nin the R package segMGarch, available from CRAN.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The long-time existence and umbilicity estimates for compact, graphical\nsolutions to expanding curvature flows are deduced in Riemannian warped\nproducts of a real interval with a compact fibre. Notably we do not assume the\nambient manifold to be rotationally symmetric, nor the radial curvature to\nconverge, nor a lower bound on the ambient sectional curvature. The inverse\nspeeds are given by powers $p\\leq 1$ of a curvature function satisfying few\ncommon properties.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider locally thermal states (for two qubits) with certain amount of\nquantum entanglement present between them. Unlike previous protocols we show\nhow work can be extracted by performing local unitary operations on this state\nby allowing those two qubits to interact with thermal baths of different\ntemperatures, thereby gradually removing the entanglement between them till\nthey reach a direct product state. Also we demonstrate that, further work can\nbe extracted from this direct product state by performing global unitary\noperation, thereby establishing that work can be extracted from a system\ncomposed of locally thermal subsystems even after removing quantum correlations\nbetween them if the subsystems are thermalized at different temperatures. Also\nwe show that even if we consider a initial state where there is no entanglement\nbetween the two qubits, we can also extract work locally using our method.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper develops upper and lower bounds on the influence measure in a\nnetwork, more precisely, the expected number of nodes that a seed set can\ninfluence in the independent cascade model. In particular, our bounds exploit\nnonbacktracking walks, Fortuin-Kasteleyn-Ginibre (FKG) type inequalities, and\nare computed by message passing implementation. Nonbacktracking walks have\nrecently allowed for headways in community detection, and this paper shows that\ntheir use can also impact the influence computation. Further, we provide a knob\nto control the trade-off between the efficiency and the accuracy of the bounds.\nFinally, the tightness of the bounds is illustrated with simulations on various\nnetwork models.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present novel lower bounds on the mean square error (MSE) of the location\nestimation of an emitting source via a network where the sensors are deployed\nrandomly. The sensor locations are modeled as a homogenous Poisson point\nprocess. In contrast to previous bounds which are a function of the specific\nlocations of all the sensors, we present CRB-type bounds on the expected mean\nsquare error; that is, we first derive the CRB on the MSE as a function of the\nsensors' location, and then take expectation with respect to the distribution\nof the sensors' location. Thus, these bounds are not a function of a particular\nsensor configuration, but rather of the sensor statistics. Hence, these novel\nbounds can be evaluated prior to sensor deployment and provide insights into\ndesign issues such as the necessary sensor density, the effect of the channel\nmodel, the effect of the signal power, and others. The derived bounds are\nsimple to evaluate and provide a good prediction of the actual network\nperformance.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Studies were made of the 1-70 keV persistent spectra of fifteen magnetars as\na complete sample observed with Suzaku from 2006 to 2013. Combined with early\nNuSTAR observations of four hard X-ray emitters, nine objects showed a hard\npower-law emission dominating at $\\gtrsim$10 keV with the 15--60 keV flux of\n$\\sim$1-$11\\times 10^{-11}$ ergs s$^{-1}$ cm$^{-2}$. The hard X-ray luminosity\n$L_{\\rm h}$, relative to that of a soft-thermal surface radiation $L_{\\rm s}$,\ntends to become higher toward younger and strongly magnetized objects. Updated\nfrom the previous study, their hardness ratio, defined as $\\xi=L_{\\rm h}/L_{\\rm\ns}$, is correlated with the measured spin-down rate $\\dot{P}$ as $\\xi=0.62\n\\times (\\dot{P}/10^{-11}\\,{\\rm s}\\,{\\rm s}^{-1})^{0.72}$, corresponding with\npositive and negative correlations of the dipole field strength $B_{\\rm d}$\n($\\xi \\propto B_{\\rm d}^{1.41}$) and the characteristic age $\\tau_{\\rm c}$\n($\\xi \\propto \\tau_{\\rm c}^{-0.68}$), respectively. Among our sample, five\ntransients were observed during X-ray outbursts, and the results are compared\nwith their long-term 1-10 keV flux decays monitored with Swift/XRT and\nRXTE/PCA. Fading curves of three bright outbursts are approximated by an\nempirical formula used in the seismology, showing a $\\sim$10-40 d plateau\nphase. Transients show the maximum luminosities of $L_{\\rm s}$$\\sim$$10^{35}$\nerg s$^{-1}$, which is comparable to those of the persistently bright ones, and\nfade back to $\\lesssim$$10^{32}$ erg s$^{-1}$. Spectral properties are\ndiscussed in a framework of the magnetar hypothesis.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider the weakly asymmetric exclusion process with $N=L/2$ particles on\na periodic lattice of $L$ sites, and hopping rates $1$ and $q=1-\\mu/\\sqrt{L}$\nrespectively in the forward and in the backward direction. Using Bethe ansatz,\nwe obtain a systematic perturbative expansion of the spectral gap near $\\mu=0$\nby solving order by order a simple functional equation. A key point is that\nwhen $\\mu\\to0$, Bethe roots at a distance $1/\\sqrt{L}$ from the edge of the\nFermi sea should not be considered as a continuum, but converge instead at\nlarge $L$ to the complex zeroes of $1+\\mathrm{erf}(x)$ after a rescaling by\n$\\sqrt{L}$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Monoclonal antibodies constitute one of the most important strategies to\ntreat patients suffering from cancers such as hematological malignancies and\nsolid tumors. In order to guarantee the quality of those preparations prepared\nat hospital, quality control has to be developed. The aim of this study was to\nexplore a noninvasive, nondestructive, and rapid analytical method to ensure\nthe quality of the final preparation without causing any delay in the process.\nWe analyzed four mAbs (Inlfiximab, Bevacizumab, Ramucirumab and Rituximab)\ndiluted at therapeutic concentration in chloride sodium 0.9% using Raman\nspectroscopy. To reduce the prediction errors obtained with traditional\nchemometric data analysis, we explored a data-driven approach using statistical\nmachine learning methods where preprocessing and predictive models are jointly\noptimized. We prepared a data analytics workflow and submitted the problem to a\ncollaborative data challenge platform called Rapid Analytics and Model\nPrototyping (RAMP). This allowed to use solutions from about 300 data\nscientists during five days of collaborative work. The prediction of the four\nmAbs samples was considerably improved with a misclassification rate and the\nmean error rate of 0.8% and 4%, respectively.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper presents a distributed control strategy for air conditioning loads\n(ACLs) to participate in the scheme of mitigating microgrid tie-line power\nfluctuations. The concept of baseline load is emphasized for ACL control in\nthis paper. To obtain the target aggregated power of ACLs, an algorithm based\non the principle of low-pass filter (LPF) is derived. For better robustness of\nthe control strategy, feedback of the states of indoor temperatures is\nintroduced for baseline load correction. A transactive control method is then\nput forward to allocate the target aggregated power to each ACL. This method\ncan satisfy customers' differentiated requirements for comfort, protect the\nprivacy and enhance the security of the controlled appliances. For the\nmicrogrid control center, it can simplify the downlink control and avoid\nmeasuring the power of uncontrolled loads which reduces the implementation\ncost. Simulation results shows ACLs can effectively provide microgrid tie-line\nsmoothing services using the proposed method.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The variations of the frequencies of the low-degree acoustic oscillations in\nthe Sun induced by magnetic activity show a dependence with radial order. The\nfrequency shifts are observed to increase towards higher-order modes to reach a\nmaximum of about 0.8 muHz over the 11-yr solar cycle. A comparable frequency\ndependence is also measured in two other main-sequence solar-like stars, the\nF-star HD49933, and the young 1-Gyr-old solar analog KIC10644253, although with\ndifferent amplitudes of the shifts of about 2 muHz and 0.5 muHz respectively.\nOur objective here is to extend this analysis to stars with different masses,\nmetallicities, and evolutionary stages. From an initial set of 87 Kepler\nsolar-like oscillating stars with already known individual p-mode frequencies,\nwe identify five stars showing frequency shifts that can be considered reliable\nusing selection criteria based on Monte Carlo simulations and on the\nphotospheric magnetic activity proxy Sph. The frequency dependence of the\nfrequency shifts of four of these stars could be measured for the l=0 and l=1\nmodes individually. Given the quality of the data, the results could indicate\nthat a different physical source of perturbation than in the Sun is dominating\nin this sample of solar-like stars.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Computing the number of realizations of a minimally rigid graph is a\nnotoriously difficult problem. Towards this goal, for graphs that are minimally\nrigid in the plane, we take advantage of a recently published algorithm, which\nis the fastest available method, although its complexity is still exponential.\nCombining computational results with the theory of constructing new rigid\ngraphs by gluing, we give a new lower bound on the maximal possible number of\n(complex) realizations for graphs with a given number of vertices. We extend\nthese ideas to rigid graphs in three dimensions and we derive similar lower\nbounds, by exploiting data from extensive Gr\\\"obner basis computations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The quiescent periodic photometric modulations of two low-inclination\ncataclysmic variables observed in Kepler K2 Campaigns 0 and 1, KZ Gem and TW\nVir, are investigated. A phase-correcting method was successfully used to\ndetect the orbital modulations of KZ Gem and TW Vir and improve their orbital\nperiods. The light curve morphologies of both CVs were further analyzed by\ndefining flux ratios and creating colormaps. KZ Gem shows ellipsoidal\nmodulations with an orbital period of 0.22242(1) day, twice the period listed\nin the updated RK catalogue (Edition 7.24). With this newly determined period,\nKZ Gem is no longer a CV in the period gap, but a long-period CV. A part of the\nquiescent light curve of TW Vir that had the highest stability was used to\ndeduce its improved orbital period of 0.182682(3) day. The flat patterns shown\nin the colormaps of the flux ratios for KZ Gem demonstrate the stability of\ntheir orbital modulations, while TW Vir show variable orbital modulations\nduring the K2 datasets. In TW Vir, the single versus double-peaked nature of\nthe quiescent orbital variations before and after superoutburst may be related\nto the effect of the superoutburst on the accretion disk.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Cryptographic protocols are the backbone of our information society. This\nincludes two-party protocols which offer protection against distrustful\nplayers. Such protocols can be built from a basic primitive called oblivious\ntransfer. We present and experimentally demonstrate here the first quantum\nprotocol for oblivious transfer for optical continuous-variable systems, and\nprove its security in the noisy-storage model. This model allows to establish\nsecurity by sending more quantum signals than an attacker can reliably store\nduring the protocol. The security proof is based on new uncertainty relations\nwhich we derive for continuous-variable systems, that differ from the ones used\nin quantum key distribution. We experimentally demonstrate the proposed\noblivious transfer protocol for various channel losses by using entangled\ntwo-mode squeezed states measured with balanced homodyne detection. Our work\nenables the implementation of arbitrary two-party quantum cryptographic\nprotocols with continuous-variable communication systems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  It is assumed that heat-assisted magnetic recording (HAMR) is the recording\ntechnique of the future. For pure hard magnetic grains in high density media\nwith an average diameter of $5$nm and a height of $10$nm the switching\nprobability is not sufficiently high for the use in bit-patterned media. Using\na bilayer structure with 50$\\%$ hard magnetic material with low Curie\ntemperature and 50$\\%$ soft magnetic material with high Curie temperature to\nobtain more than 99.2$\\%$ switching probability, leads to very large jitter. We\npropose an optimized material composition to reach a switching probability of\n$P_{\\mathrm{switch}}>99.2\\%$ and simultaneously achieve the narrow transition\njitter of pure hard magnetic material. Simulations with a continuous laser spot\nwere performed with the atomistic simulation program VAMPIRE for a single\ncylindrical recording grain with a diameter of 5nm and a height of 10nm.\nDifferent configurations of soft magnetic material and different amounts of\nhard and soft magnetic material were tested and discussed. Within our analysis,\na composition with 20$\\%$ soft magnetic and $80\\%$ hard magnetic material\nreaches the best results with a switching probability\n$P_{\\mathrm{switch}}>99.2\\%$, an off-track jitter parameter\n$\\sigma_{\\mathrm{off},80/20}=14.2$K and a down-track jitter parameter\n$\\sigma_{\\mathrm{down},80/20}=0.49$nm.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Coherent quantum control over many-particle quantum systems requires high\nfidelity dynamics. One way of achieving this is to use adiabatic schemes where\nthe system follows an instantaneous eigenstate of the Hamiltonian over\ntimescales that do not allow transitions to other states. This, however, makes\ncontrol dynamics very slow. Here we introduce another concept that takes\nadvantage of preventing unwanted transitions in fermionic systems by using\nPauli blocking: excitations from a protected ground state to higher-lying\nstates are avoided by adding a layer of buffer fermions, such that the\nprotected fermions cannot make a transition to higher lying excited states\nbecause these are already occupied. This allows to speed-up adiabatic\nevolutions of the system. We do a thorough investigation of the technique, and\ndemonstrate its power by applying it to high fidelity transport, trap expansion\nand splitting in ultracold atoms systems in anharmonic traps. Close analysis of\nthese processes also leads to insights into the structure of the orthogonality\ncatastrophe phenomenon.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $G$ be a higher rank semisimple linear algebraic group over a\nnon-Archimedean local field. The simplicial complexes corresponding to any\nsequence of pairwise non-conjugate irreducible lattices in $G$ are\nBenjamini-Schramm convergent to the Bruhat-Tits building. Convergence of the\nrelative Plancherel measures and normalized Betti numbers follows. This extends\nthe work of Abert, Bergeron, Biringer, Gelander, Nokolov, Raimbault and Samet\nfrom real Lie groups to linear groups over arbitrary local fields. Along the\nway, various results concerning Invariant Random Subgroups and in particular a\nvariant of the classical Borel density theorem are also extended.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We perform three dimensional (3D) ideal magnetohydrodynamic (MHD) simulations\nto study the parametric decay instability of Alfven waves in turbulent plasmas\nand explore its possible applications in the solar wind. We find that, over a\nbroad range of parameters in background turbulence amplitudes, the parametric\ndecay instability of an Alfven wave with various amplitudes can still occur,\nthough its growth rate in turbulent plasmas tends to be lower than both the\ntheoretical linear theory prediction and that in the non-turbulent situations.\nSpatial - temporal FFT analyses of density fluctuations produced by the\nparametric decay instability match well with the dispersion relation of the\nslow MHD waves. This result may provide an explanation of the generation\nmechanism of slow waves in the solar wind observed at 1 AU. It further\nhighlights the need to explore the effects of density variations in modifying\nthe turbulence properties as well as in heating the solar wind plasmas.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Biometric techniques are often used as an extra security factor in\nauthenticating human users. Numerous biometrics have been proposed and\nevaluated, each with its own set of benefits and pitfalls. Static biometrics\n(such as fingerprints) are geared for discrete operation, to identify users,\nwhich typically involves some user burden. Meanwhile, behavioral biometrics\n(such as keystroke dynamics) are well suited for continuous, and sometimes more\nunobtrusive, operation. One important application domain for biometrics is\ndeauthentication, a means of quickly detecting absence of a previously\nauthenticated user and immediately terminating that user's active secure\nsessions. Deauthentication is crucial for mitigating so called Lunchtime\nAttacks, whereby an insider adversary takes over (before any inactivity timeout\nkicks in) authenticated state of a careless user who walks away from her\ncomputer. Motivated primarily by the need for an unobtrusive and continuous\nbiometric to support effective deauthentication, we introduce PoPa, a new\nhybrid biometric based on a human user's seated posture pattern. PoPa captures\na unique combination of physiological and behavioral traits. We describe a low\ncost fully functioning prototype that involves an office chair instrumented\nwith 16 tiny pressure sensors. We also explore (via user experiments) how PoPa\ncan be used in a typical workplace to provide continuous authentication (and\ndeauthentication) of users. We experimentally assess viability of PoPa in terms\nof uniqueness by collecting and evaluating posture patterns of a cohort of\nusers. Results show that PoPa exhibits very low false positive, and even lower\nfalse negative, rates. In particular, users can be identified with, on average,\n91.0% accuracy. Finally, we compare pros and cons of PoPa with those of several\nprominent biometric based deauthentication techniques.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Consideration of the latest experimental data on the searches for extended\nsector of Higgs bosons produced at the LHC at a center-of-mass energy of 13\nTeV, allows for computer modeling of the properties of supersymmetric particles\nwithin 2HDM model. The experimental restrictions on model parameters accounted\nin FeynHiggs code that is implemented in SusHi program, gave us the possibility\nto calculate the cross sections and branching fractions for three mechanisms of\nproduction and decay of Higgs bosons: 1) pp$\\rightarrow H\\rightarrow\\tau\\tau$,\n2) pp$\\rightarrow A\\rightarrow Zh\\rightarrow llbb$, 3) pp$\\rightarrow\nH\\rightarrow hh\\rightarrow bb\\tau\\tau$ at a center-of-mass energy of 14 TeV.\nThe considered computer modelling make it possible to draw conclusions about\nthe need to take into account the b-associated production process of Higgs\nbosons for fermionic decay channel at large values of tan$\\beta$. Differential\ncross sections with respect to the Higgs transverse momentum $p_t$ and\npseudorapidity $\\eta$ are calculated and the peculiarities of the kinematics of\nthe Higgs boson decay products are recognized.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The insulin sensitivity (IS) of the human body changes with a circadian\nrhythm. This adds to the time-varying feature of the glucose metabolism process\nand places challenges on the blood glucose (BG) control of patients with Type 1\nDiabetes Mellitus. This paper presents a Model Predictive Controller that takes\nthe periodic IS into account, in order to enhance BG control. The future effect\nof the IS is predicted using a machine learning technique, namely, a customized\nGaussian Process (GP), based on historical training data. The training data for\nthe GP is continuously updated during closed-loop control, which enables the\ncontrol scheme to learn and adapt to intra-individual and inter-individual\nchanges of the circadian IS rhythm. The necessary state information is provided\nby an Unscented Kalman Filter. The closed-loop performance of the proposed\ncontrol scheme is evaluated for different scenarios (including fasting,\nannounced meals and skipped meals) through in silico studies on simulation\nmodels of G\\\"ottingen Minipigs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The gang of bandits (GOB) model \\cite{cesa2013gang} is a recent contextual\nbandits framework that shares information between a set of bandit problems,\nrelated by a known (possibly noisy) graph. This model is useful in problems\nlike recommender systems where the large number of users makes it vital to\ntransfer information between users. Despite its effectiveness, the existing GOB\nmodel can only be applied to small problems due to its quadratic\ntime-dependence on the number of nodes. Existing solutions to combat the\nscalability issue require an often-unrealistic clustering assumption. By\nexploiting a connection to Gaussian Markov random fields (GMRFs), we show that\nthe GOB model can be made to scale to much larger graphs without additional\nassumptions. In addition, we propose a Thompson sampling algorithm which uses\nthe recent GMRF sampling-by-perturbation technique, allowing it to scale to\neven larger problems (leading to a \"horde\" of bandits). We give regret bounds\nand experimental results for GOB with Thompson sampling and epoch-greedy\nalgorithms, indicating that these methods are as good as or significantly\nbetter than ignoring the graph or adopting a clustering-based approach.\nFinally, when an existing graph is not available, we propose a heuristic for\nlearning it on the fly and show promising results.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Cross-modal retrieval has drawn wide interest for retrieval across different\nmodalities of data. However, existing methods based on DNN face the challenge\nof insufficient cross-modal training data, which limits the training\neffectiveness and easily leads to overfitting. Transfer learning is for\nrelieving the problem of insufficient training data, but it mainly focuses on\nknowledge transfer only from large-scale datasets as single-modal source domain\nto single-modal target domain. Such large-scale single-modal datasets also\ncontain rich modal-independent semantic knowledge that can be shared across\ndifferent modalities. Besides, large-scale cross-modal datasets are very\nlabor-consuming to collect and label, so it is significant to fully exploit the\nknowledge in single-modal datasets for boosting cross-modal retrieval. This\npaper proposes modal-adversarial hybrid transfer network (MHTN), which to the\nbest of our knowledge is the first work to realize knowledge transfer from\nsingle-modal source domain to cross-modal target domain, and learn cross-modal\ncommon representation. It is an end-to-end architecture with two subnetworks:\n(1) Modal-sharing knowledge transfer subnetwork is proposed to jointly transfer\nknowledge from a large-scale single-modal dataset in source domain to all\nmodalities in target domain with a star network structure, which distills\nmodal-independent supplementary knowledge for promoting cross-modal common\nrepresentation learning. (2) Modal-adversarial semantic learning subnetwork is\nproposed to construct an adversarial training mechanism between common\nrepresentation generator and modality discriminator, making the common\nrepresentation discriminative for semantics but indiscriminative for modalities\nto enhance cross-modal semantic consistency during transfer process.\nComprehensive experiments on 4 widely-used datasets show its effectiveness and\ngenerality.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A two-party key agreement problem with public discussion, known as the source\nmodel problem, is considered. By relating key agreement to hypothesis testing,\na new coding scheme is developed that yields a sufficient condition to achieve\na positive secret-key (SK) rate in terms of R\\'enyi divergence. The merits of\nthis coding scheme are illustrated by applying it to an erasure model for Eve's\nside information, and by deriving an upper bound on Eve's erasure probabilities\nfor which the SK capacity is zero. This bound strictly improves on the best\nknown single-letter lower bound on the SK capacity. Moreover, the bound is\ntight when Alice's or Bob's source is binary, which extends a previous result\nfor a doubly symmetric binary source. The results motivate a new measure for\nthe correlation between two random variables, which is of independent interest.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a method to carry out electrical and opto-electronic measurements\non 2D materials using carbon fiber microprobes to directly make electrical\ncontacts to the 2D materials without damaging them. The working principle of\nthis microprobing method is illustrated by measuring transport in MoS2 flakes\nin vertical (transport in the out-of-plane direction) and lateral (transport\nwithin the crystal plane) configurations, finding performances comparable to\nthose reported for MoS2 devices fabricated by conventional lithographic\nprocess. We also show that this method can be used with other 2D materials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For spectrally negative L\\'evy processes, adapting an approach from\n\\cite{BoLi:sub1} we identify joint\n  Laplace transforms involving local times evaluated at either the first\npassage times, or independent exponential times, or inverse local times. The\nLaplace transforms are expressed in terms of the associated scale functions.\n  Connections are made with the permanental process and the Markovian loop soup\nmeasure.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recently, there have been increasing demands to construct compact deep\narchitectures to remove unnecessary redundancy and to improve the inference\nspeed. While many recent works focus on reducing the redundancy by eliminating\nunneeded weight parameters, it is not possible to apply a single deep\narchitecture for multiple devices with different resources. When a new device\nor circumstantial condition requires a new deep architecture, it is necessary\nto construct and train a new network from scratch. In this work, we propose a\nnovel deep learning framework, called a nested sparse network, which exploits\nan n-in-1-type nested structure in a neural network. A nested sparse network\nconsists of multiple levels of networks with a different sparsity ratio\nassociated with each level, and higher level networks share parameters with\nlower level networks to enable stable nested learning. The proposed framework\nrealizes a resource-aware versatile architecture as the same network can meet\ndiverse resource requirements. Moreover, the proposed nested network can learn\ndifferent forms of knowledge in its internal networks at different levels,\nenabling multiple tasks using a single network, such as coarse-to-fine\nhierarchical classification. In order to train the proposed nested sparse\nnetwork, we propose efficient weight connection learning and channel and layer\nscheduling strategies. We evaluate our network in multiple tasks, including\nadaptive deep compression, knowledge distillation, and learning class\nhierarchy, and demonstrate that nested sparse networks perform competitively,\nbut more efficiently, compared to existing methods.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper is devoted to an investigation of Euclidean wormholes made by\nfuzzy instantons. We investigate the Euclidean path integral in anti-de Sitter\nspace. In Einstein gravity, we introduce a scalar field with a potential.\nBecause of the analyticity, there is a contribution of complex-valued\ninstantons, so-called fuzzy instantons. If we have a massless scalar field,\nthen we obtain Euclidean wormholes, where the probabilities become smaller and\nsmaller as the size of the throat becomes larger and larger. If we introduce a\nnon-trivial potential, then in order to obtain a non-zero tunneling rate, we\nneed to tune the shape of the potential. With the $O(4)$ symmetry, after the\nanalytic continuation to the Lorentzian time, the wormhole throat should expand\nto infinity. However, by adding mass, one may obtain an instant wormhole that\nshould eventually collapse to the event horizon. The existence of Euclidean\nwormholes is related to the stability or unitarity issues of anti-de Sitter\nspace. We are not conclusive yet, but we carefully comment on these physical\nproblems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This work outlines the novel application of the empirical analysis of\ncausation, presented by Kutach, to the study of information theory and its role\nin physics. The central thesis of this paper is that causation and information\nare identical functional tools for distinguishing controllable correlations,\nand that this leads to a consistent view, not only of information theory, but\nalso of statistical physics and quantum information. This approach comes\nwithout the metaphysical baggage of declaring information a fundamental\ningredient in physical reality and exorcises many of the otherwise puzzling\nproblems that arise from this view-point, particularly obviating the problem of\n`excess baggage' in quantum mechanics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We compute the exact value of the squared condition number for the polynomial\neigenvalue problem, when the input matrices have entries coming from the\nstandard complex Gaussian distribution, showing that in general this problem is\nquite well conditioned.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the symmetry reduction of nonlinear partial differential equations\nwhich are used for describing diffusion processes in nonhomogeneous medium. We\nfind ansatzes reducing partial differential equations to systems of ordinary\ndifferential equations. The ansatzes are constructed by using operators of\nLie-B\\\"acklund symmetry of third order ordinary differential equation. The\nmethod gives the possibility to find solutions which cannot be obtained by\nvirtue of classical Lie method. Such solutions have been constructed for\nnonlinear diffusion equations which are invariant with respect to\none-parameter, two-parameter and three-parameter Lie groups of point\ntransformations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We provide a framework for obtaining error bounds for linear conic problems\nwithout assuming constraint qualifications or regularity conditions. The key\naspects of our approach are the notions of amenable cones and facial residual\nfunctions. For amenable cones, it is shown that error bounds can be expressed\nas a composition of facial residual functions. The number of compositions is\nrelated to the facial reduction technique and the singularity degree of the\nproblem. In particular, we show that symmetric cones are amenable and compute\nfacial residual functions. From that, we are able to furnish a new H\\\"olderian\nerror bound, thus extending and shedding new light on an earlier result by\nSturm on semidefinite matrices. We also provide error bounds for the\nintersection of amenable cones, this will be used to provided error bounds for\nthe doubly nonnegative cone.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Inducing magnetism into topological insulators is intriguing for utilizing\nexotic phenomena such as the quantum anomalous Hall effect (QAHE) for\ntechnological applications. While most studies have focused on doping magnetic\nimpurities to open a gap at the surface-state Dirac point, many undesirable\neffects have been reported to appear in some cases that makes it difficult to\ndetermine whether the gap opening is due to the time-reversal symmetry breaking\nor not. Furthermore, the realization of the QAHE has been limited to low\ntemperatures. Here we have succeeded in generating a massive Dirac cone in a\nMnBi2Se4 /Bi2Se3 heterostructure which was fabricated by self-assembling a\nMnBi2Se4 layer on top of the Bi2Se3 surface as a result of the co-deposition of\nMn and Se. Our experimental results, supported by relativistic ab initio\ncalculations, demonstrate that the fabricated MnBi2Se4 /Bi2Se3 heterostructure\nshows ferromagnetism up to room temperature and a clear Dirac-cone gap opening\nof ~100 meV without any other significant changes in the rest of the band\nstructure. It can be considered as a result of the direct interaction of the\nsurface Dirac cone and the magnetic layer rather than a magnetic proximity\neffect. This spontaneously formed self-assembled heterostructure with a massive\nDirac spectrum, characterized by a nontrivial Chern number C = -1, has a\npotential to realize the QAHE at significantly higher temperatures than\nreported up to now and can serve as a platform for developing future \"\ntopotronics\" devices.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we find an equation that relates the Ricci curvature of a\nriemannian manifold $M$ and the second fundamental forms of two orthogonal\nfoliations of complementary dimensions, $\\mathcal{F}$ and $\\mathcal{F}^{\\bot}$,\ndefined on $M$. Using this equation, we show a sufficient condition for the\nmanifold M to be locally a riemannian product of the leaves of $\\mathcal{F}$\nand $\\mathcal{F}^{\\bot}$, if one of the foliations is totally umbilical. We\nalso prove an integral formula for such foliations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We demonstrate that the stray magnetic field generated beneath magnetic\nvortex cores can be used to generate nano-scale, localized pinning sites for\nmagnetic domain walls in an underlying, perpendicularly magnetized nanostrip.\nMoreover, the pinning strength can be tuned by toggling the vortex core\npolarity. Indeed, switching the core polarity so that it is aligned with the\nmagnetization of the expanding domain (rather than against it) can be used to\nreduce the vortex-mediated wall depinning field by between 40% and 90%,\ndepending on the system geometry. Significant reductions in the depinning field\ncan also be obtained in narrow strips by shifting the core away from the\nstrip's center.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Results of a search for physics beyond the Standard Model in events\ncontaining an energetic photon and large missing transverse momentum with the\nATLAS detector at the Large Hadron Collider are reported. As the number of\nevents observed in data, corresponding to an integrated luminosity of 36.1\n$\\textrm fb^{-1}$ of proton-proton collisions at a centre-of-mass energy of 13\nTeV, is in agreement with the Standard Model expectations, exclusion limits in\nmodels where dark-matter candidates are pair-produced are determined. For\ndark-matter production via an axial-vector or a vector mediator in the\ns-channel, this search excludes mediator masses below 750-1200 GeV for\ndark-matter candidate masses below 230-480 GeV at 95% confidence level,\ndepending on the couplings. In an effective theory of dark-matter production,\nthe limits restrict the value of the suppression scale $M_{*}$ to be above 790\nGeV at 95% confidence level. A limit is also reported on the production of a\nhigh-mass scalar resonance by processes beyond the Standard Model, in which the\nresonance decays to $Z\\gamma$ and the Z boson subsequently decays into\nneutrinos.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Gravitational waves encode invaluable information about the nature of the\nrelatively unexplored extreme gravity regime, where the gravitational\ninteraction is strong, non-linear and highly dynamical. Recent gravitational\nwave observations by advanced LIGO have provided the first glimpses into this\nregime, allowing for the extraction of new inferences on different aspects of\ntheoretical physics. For example, these detections provide constraints on the\nmass of the graviton, Lorentz violation in the gravitational sector, the\nexistence of large extra dimensions, the temporal variability of Newton's\ngravitational constant, and modified dispersion relations of gravitational\nwaves. Many of these constraints, however, are not yet competitive with\nconstraints obtained, for example, through Solar System observations or binary\npulsar observations. In this paper, we study the degree to which theoretical\nphysics inferences drawn from gravitational wave observations will strengthen\nwith detections from future detectors. We consider future ground-based\ndetectors, such as the LIGO-class expansions A+, Voyager, Cosmic Explorer and\nthe Einstein Telescope, as well as various configurations the space-based\ndetector LISA. We find that space-based detectors will place constraints on\nGeneral Relativity up to 12 orders of magnitude more stringently than current\naLIGO bounds, but these space-based constraints are comparable to those\nobtained with the ground-based Cosmic Explorer or the Einstein Telescope. We\nalso generically find that improvements in the instrument sensitivity band at\nlow frequencies lead to large improvements in certain classes of constraints,\nwhile sensitivity improvements at high frequencies lead to more modest gains.\nThese results strengthen the case for the development of future detectors,\nwhile providing additional information that could be useful in future design\ndecisions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We characterize a multi tier network with classical macro cells, and multi\nradio access technology (RAT) small cells, which are able to operate in\nmicrowave and millimeter-wave (mm-wave) bands. The small cells are assumed to\nbe deployed along roads modeled as a Poisson line process. This\ncharacterization is more realistic as compared to the classical Poisson point\nprocesses typically used in literature. In this context, we derive the\nassociation and RAT selection probabilities of the typical user under various\nsystem parameters such as the small cell deployment density and mm-wave antenna\ngain, and with varying street densities. Finally, we calculate the signal to\ninterference plus noise ratio (SINR) coverage probability for the typical user\nconsidering a tractable dominant interference based model for mm-wave\ninterference. Our analysis reveals the need of deploying more small cells per\nstreet in cities with more streets to maintain coverage, and highlights that\nmm-wave RAT in small cells can help to improve the SINR performance of the\nusers.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A new generation of interferometric instruments is emerging which aim to use\nintensity mapping of redshifted $21\\,$cm radiation to measure the large-scale\nstructure of the Universe at $z\\simeq 1-2$ over wide areas of sky. While these\ninstruments typically have limited angular resolution, they cover huge volumes\nand thus can be used to provide large samples of rare objects. In this paper we\nstudy how well such instruments could find spatially extended large-scale\nstructures, such as cosmic voids, using a matched filter formalism. Such a\nformalism allows us to work in Fourier space, the natural space for\ninterferometers, and to study the impact of finite $u-v$ coverage, noise and\nforegrounds on our ability to recover voids. We find that in the absence of\nforegrounds such instruments would provide enormous catalogs of voids, with\nhigh completeness, but that control of foregrounds is key to realizing this\ngoal.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  As the driving force of crowdsourcing is the interaction among participants,\nvarious incentive mechanisms have been proposed to attract sufficient\nparticipants. However, the existing works assume that all the providers always\nmeet the deadline and the task value accordingly remains constant. To bridge\nthe gap of such impractical assumption, we model the heterogeneous punctuality\nbehavior of providers and the task value depreciation of requesters. Based on\nthose models, we propose an Expected Social Welfare Maximizing (ESWM) mechanism\nthat aims to maximize the expected social welfare in polynomial time.\nSimulation results show that our heuristic-based mechanism achieves higher\nexpected social welfare and platform utility via attracting more participants.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the quasi-stationary behavior of multidimensional processes absorbed\nwhen one of the coordinates vanishes. Our results cover competitive or weakly\ncooperative Lotka-Volterra birth and death processes and Feller diffusions with\ncompetitive Lotka-Volterra interaction. To this aim, we develop original\nnon-linear Lyapunov criteria involving two Lyapunov functions, which apply to\ngeneral Markov processes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We describe a new framework for fitting jump models to a sequence of data.\nThe key idea is to alternate between minimizing a loss function to fit multiple\nmodel parameters, and minimizing a discrete loss function to determine which\nset of model parameters is active at each data point. The framework is quite\ngeneral and encompasses popular classes of models, such as hidden Markov models\nand piecewise affine models. The shape of the chosen loss functions to minimize\ndetermine the shape of the resulting jump model.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The concepts of unitary evolution matrices and associative memory have\nboosted the field of Recurrent Neural Networks (RNN) to state-of-the-art\nperformance in a variety of sequential tasks. However, RNN still have a limited\ncapacity to manipulate long-term memory. To bypass this weakness the most\nsuccessful applications of RNN use external techniques such as attention\nmechanisms. In this paper we propose a novel RNN model that unifies the\nstate-of-the-art approaches: Rotational Unit of Memory (RUM). The core of RUM\nis its rotational operation, which is, naturally, a unitary matrix, providing\narchitectures with the power to learn long-term dependencies by overcoming the\nvanishing and exploding gradients problem. Moreover, the rotational unit also\nserves as associative memory. We evaluate our model on synthetic memorization,\nquestion answering and language modeling tasks. RUM learns the Copying Memory\ntask completely and improves the state-of-the-art result in the Recall task.\nRUM's performance in the bAbI Question Answering task is comparable to that of\nmodels with attention mechanism. We also improve the state-of-the-art result to\n1.189 bits-per-character (BPC) loss in the Character Level Penn Treebank (PTB)\ntask, which is to signify the applications of RUM to real-world sequential\ndata. The universality of our construction, at the core of RNN, establishes RUM\nas a promising approach to language modeling, speech recognition and machine\ntranslation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Naimark's problem asks whether a C*-algebra that has only one irreducible\n*-representation up to unitary equivalence is isomorphic to the C*-algebra of\ncompact operators on some (not necessarily separable) Hilbert space. This\nproblem has been solved in special cases, including separable C*-algebras and\nType I C*-algebras. However, in 2004 Akemann and Weaver used the diamond\nprinciple to construct a C*-algebra with $\\aleph_1$ generators that is a\ncounterexample to Naimark's Problem. More precisely, they showed that the\nstatement \"There exists a counterexample to Naimark's Problem that is generated\nby $\\aleph_1$ elements.\" is independent of the axioms of ZFC. Whether Naimark's\nproblem itself is independent of ZFC remains unknown. In this paper we examine\nNaimark's problem in the setting of graph C*-algebras, and show that it has an\naffirmative answer for (not necessarily separable) AF graph C*-algebras as well\nas for C*-algebras of graphs in which each vertex emits a countable number of\nedges.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Text line detection and localization is a crucial step for full page document\nanalysis, but still suffers from heterogeneity of real life documents. In this\npaper, we present a new approach for full page text recognition. Localization\nof the text lines is based on regressions with Fully Convolutional Neural\nNetworks and Multidimensional Long Short-Term Memory as contextual layers. In\norder to increase the efficiency of this localization method, only the position\nof the left side of the text lines are predicted. The text recognizer is then\nin charge of predicting the end of the text to recognize. This method has shown\ngood results for full page text recognition on the highly heterogeneous Maurdor\ndataset.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Internet of things (IoT) will make it possible to interconnect and\nsimultaneously control distributed electrical loads. Various technical and\nregulatory concerns have been raised that IoT-operated loads are being deployed\nwithout appropriately considering and systematically addressing potential\ncyber-security challenges. Hence, one can envision a hypothetical scenario when\nan ensemble of IoT-controlled loads can be hacked with malicious intentions of\ncompromising operations of the electrical grid. Under this scenario, the\nattacker would use geographically distributed IoT-controlled loads to alternate\ntheir net power injections into the electrical grid in such a way that may\ndisrupt normal grid operations.\n  This paper presents a modeling framework to analyze grid impacts of\ndistributed cyber-attacks on IoT-controlled loads. This framework is used to\ndemonstrate how a hypothetical distributed cyber-attack propagates from the\ndistribution electrical grid, where IoT-controlled loads are expected to be\ninstalled, to the transmission electrical grid. The techno-economic\ninteractions between the distribution and transmission electrical grids are\naccounted for by means of bilevel optimization. The case study is carried out\non the modified versions of the 3-area IEEE Reliability Test System (RTS) and\nthe IEEE 13-bus distribution feeder. Our numerical results demonstrate that the\nseverity of such attacks depends on the penetration level of IoT-controlled\nloads and the strategy of the attacker.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Meta-analysis, because of both logistical convenience and statistical\nefficiency, is widely popular for synthesizing information on common parameters\nof interest across multiple studies. We propose developing a generalized\nmeta-analysis approach for combining information on multivariate regression\nparameters across multiple different studies which have varying level of\ncovariate information. Using algebraic relationships between regression\nparameters in different dimensions, we specify a set of moment equations for\nestimating parameters of a maximal model through information available from\nsets of parameter estimates from a series of reduced models available from the\ndifferent studies. The specification of the equations requires a reference\ndataset to estimate the joint distribution of the covariates. We propose to\nsolve these equations using the generalized method of moments approach, with\nthe optimal weighting of the equations taking into account uncertainty\nassociated with estimates of the parameters of the reduced models. We describe\nextensions of the iterated reweighted least square algorithm for fitting\ngeneralized linear regression models using the proposed framework. Based on the\nsame moment equations, we also propose a diagnostic test for detecting\nviolation of underlying model assumptions, such as those arising due to\nheterogeneity in the underlying study populations. Methods are illustrated\nusing extensive simulation studies and a real data example involving the\ndevelopment of a breast cancer risk prediction model using disparate risk\nfactor information from multiple studies.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a common envelope jets supernova scenario for the enigmatic\nsupernova iPTF14hls where a neutron star that spirals-in inside the envelope of\na massive giant star accretes mass and launches jets that power the ejection of\nthe circumstellar shell and a few weeks later the explosion itself. To account\nfor the kinetic energy of the circumstellar gas and the explosion, the neutron\nstar should accrete a mass of approximately 0.3 solar masses. The tens of solar\nmasses of circumstellar gas that accounts for some absorption lines is ejected\nwhile the neutron star orbits for about one to several weeks inside the\nenvelope of the giant star. In the last hours of the interaction the neutron\nstar merges with the core, accretes mass, and launches jets that eject the core\nand the inner envelope to form the explosion itself and the medium where the\nsupernova photosphere resides. The remaining neutron star accretes fallback gas\nand further powers the supernova. We attribute the 1954 pre-explosion outburst\nto an eccentric orbit and temporary mass accretion by the neutron star at\nperiastron passage prior to the onset of the common envelope phase.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We obtain several estimates for trilinear form with double Kloosterman sums.\nIn particular, these bounds show the existence of nontrivial cancellations\nbetween such sums.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Parity games play an important role in model checking and synthesis. In their\npaper, Calude et al. have shown that these games can be solved in\nquasi-polynomial time. We show that their algorithm can be implemented\nefficiently: we use their data structure as a progress measure, allowing for a\nbackward implementation instead of a complete unravelling of the game. To\nachieve this, a number of changes have to be made to their techniques, where\nthe main one is to add power to the antagonistic player that allows for\ndetermining her rational move without changing the outcome of the game. We\nprovide a first implementation for a quasi-polynomial algorithm, test it on\nsmall examples, and provide a number of side results, including minor\nalgorithmic improvements, a quasi bi-linear complexity in the number of states\nand edges for a fixed number of colours, and matching lower bounds for the\nalgorithm of Calude et al.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Transferring graphene flakes onto hexagonal boron nitride (h-BN) has been the\nmost popular approach for the fabrication of graphne/h-BN heterostructures so\nfar. The orientation between graphene and h-BN lattices, however, are not\ncontrollable and the h-BN/graphene interfaces are prone to be contaminated\nduring this elaborate process. Direct synthesis of graphene on h-BN is an\nalternative and rapidly growing approach. Synthesized graphene via such\napproaches is personally tailored to conform to each specific h-BN flakes,\nhence the limitations of conventional fabrication approaches are overcome.\nReported processes paved the initial steps to improve the scalablity of the\ndevice fabrication for industrial applications. Reviewing the developments in\nthe field, from the birth point to the current status is the focus of this\nletter. We show how the field has been developed to overcome the existing\nchallenges one after the other and discuss where the field is heading to.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hot Jupiters receive strong stellar irradiation, producing equilibrium\ntemperatures of $1000 - 2500 \\ \\mathrm{Kelvin}$. Incoming irradiation directly\nheats just their thin outer layer, down to pressures of $\\sim 0.1 \\\n\\mathrm{bars}$. In standard irradiated evolution models of hot Jupiters,\npredicted transit radii are too small. Previous studies have shown that deeper\nheating -- at a small fraction of the heating rate from irradiation -- can\nexplain observed radii. Here we present a suite of evolution models for HD\n209458b where we systematically vary both the depth and intensity of internal\nheating, without specifying the uncertain heating mechanism(s). Our models\nstart with a hot, high entropy planet whose radius decreases as the convective\ninterior cools. The applied heating suppresses this cooling. We find that very\nshallow heating -- at pressures of $1 - 10 \\ \\mathrm{bars}$ -- does not\nsignificantly suppress cooling, unless the total heating rate is $\\gtrsim 10\\%$\nof the incident stellar power. Deeper heating, at $100 \\ \\mathrm{bars}$,\nrequires heating at only $1\\%$ of the stellar irradiation to explain the\nobserved transit radius of $1.4 R_{\\rm Jup}$ after 5 Gyr of cooling. In\ngeneral, more intense and deeper heating results in larger hot Jupiter radii.\nSurprisingly, we find that heat deposited at $10^4 \\ \\mathrm{bars}$ -- which is\nexterior to $\\approx 99\\%$ of the planet's mass -- suppresses planetary cooling\nas effectively as heating at the center. In summary, we find that relatively\nshallow heating is required to explain the radii of most hot Jupiters, provided\nthat this heat is applied early and persists throughout their evolution.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  New and more reliable distances and proper motions of a large number of stars\nin the Tycho-Gaia Astrometric Solution (TGAS) catalogue allow to calculate the\nlocal matter density distribution more precisely than earlier. We devised a\nmethod to calculate the stationary gravitational potential distribution\nperpendicular to the Galactic plane by comparing the vertical probability\ndensity distribution of a sample of observed stars with the theoretical\nprobability density distribution computed from their vertical coordinates and\nvelocities. We applied the model to idealised test stars and to the real\nobservational samples. Tests with two mock datasets proved that the method is\nviable and provides reasonable results. Applying the method to TGAS data we\nderived that the total matter density in the Solar neighbourhood is $0.09\\pm\n0.02 \\text{M}_\\odot\\text{pc}^{-3}$ being consistent with the results from\nliterature. The matter surface density within $|z|\\le 0.75 \\text{kpc}$ is\n$42\\pm 4 \\text{M}_\\odot\\text{pc}^{-2}$. This is slightly less than the results\nderived by other authors but within errors is consistent with previous\nestimates. Our results show no firm evidence for significant amount of dark\nmatter in the Solar neighbourhood. However, we caution that our calculations at\n$|z| \\leq 0.75$ kpc rely on an extrapolation from the velocity distribution\nfunction calculated at $|z| \\leq 25$ pc. This extrapolation can be very\nsensitive to our assumption that the stellar motions are perfectly decoupled in\nR and z, and to our assumption of equilibrium. Indeed, we find that $\\rho (z)$\nwithin $|z|\\le 0.75$ kpc is asymmetric with respect to the Galactic plane at\ndistances $|z| = 0.1-0.4$ kpc indicating that the density distribution may be\ninfluenced by density perturbations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Ultrasound (US) is the most commonly used liver imaging modality worldwide.\nDue to its low cost, it is increasingly used in the follow-up of cancer\npatients with metastases localized in the liver. In this contribution, we\npresent the results of an interactive segmentation approach for liver\nmetastases in US acquisitions. A (semi-) automatic segmentation is still very\nchallenging because of the low image quality and the low contrast between the\nmetastasis and the surrounding liver tissue. Thus, the state of the art in\nclinical practice is still manual measurement and outlining of the metastases\nin the US images. We tackle the problem by providing an interactive\nsegmentation approach providing real-time feedback of the segmentation results.\nThe approach has been evaluated with typical US acquisitions from the clinical\nroutine, and the datasets consisted of pancreatic cancer metastases. Even for\ndifficult cases, satisfying segmentations results could be achieved because of\nthe interactive real-time behavior of the approach. In total, 40 clinical\nimages have been evaluated with our method by comparing the results against\nmanual ground truth segmentations. This evaluation yielded to an average Dice\nScore of 85% and an average Hausdorff Distance of 13 pixels.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We model interaction of photons, pseudoscalars and vector mesons within the\nresonance chiral symmetric theory with the SU(3) breaking. The couplings of the\nmodel are fitted to the experimental data. Within the developed model we\npredict the light-by-light contributions to the muon anomalous magnetic moment\n$a_{\\mu}^P = (82.8 \\pm 3.4)\\times 10^{-11}$. The error covers also the model\ndependence within the class of models considered in this paper. The model was\nimplemented into the Monte Carlo event generator Ekhara to simulate the\nreactions $e^+e^-\\to e^+e^- P$, $P=\\pi^0,\\eta,\\eta'$ and into the Monte Carlo\nevent generator Phokhara to simulate the reactions $e^+e^-\\to P\\gamma(\\gamma)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper provides a brief overview of dynamo scaling relationships for the\ndegree of equipartition between magnetic and kinetic energies. Three basic\napproaches are adopted to explore these scaling relationships, with a first\nlook at two simple models: one assuming magnetostrophy and another that\nincludes the effects of inertia. Next, a third scaling relationship is derived\nthat utilizes the assumptions that the dynamo possesses two integral spatial\nscales and that it is driven by the balance of buoyancy work and ohmic\ndissipation as studied in Davidson 2013. The results of which are then compared\nto a suite of convective dynamo simulations that possess a fully convective\ndomain with a weak density stratification and that captured the behavior of the\nresulting dynamo for a range of convective Rossby numbers (Augustson et al.\n2016).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We derive an explicit formula for the scalar curvature over a two-torus with\na Dirac operator conformally rescaled by a globally diagonalizable matrix. We\nshow that the Gauss-Bonnet theorem holds and extend the result to all Riemann\nsurfaces with Dirac operators modified in the same way.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Understanding how ideas relate to each other is a fundamental question in\nmany domains, ranging from intellectual history to public communication.\nBecause ideas are naturally embedded in texts, we propose the first framework\nto systematically characterize the relations between ideas based on their\noccurrence in a corpus of documents, independent of how these ideas are\nrepresented. Combining two statistics --- cooccurrence within documents and\nprevalence correlation over time --- our approach reveals a number of different\nways in which ideas can cooperate and compete. For instance, two ideas can\nclosely track each other's prevalence over time, and yet rarely cooccur, almost\nlike a \"cold war\" scenario. We observe that pairwise cooccurrence and\nprevalence correlation exhibit different distributions. We further demonstrate\nthat our approach is able to uncover intriguing relations between ideas through\nin-depth case studies on news articles and research papers.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Social Choice theory generalizes voting on one proposal to ranking multiple\nproposals. Yet, while a vote on a single proposal has the status quo (Reality)\nas a default, Reality has been forsaken during this generalization. Here, we\npropose to restore this default social state and to incorporate Reality\nexplicitly into Social Choice. We show that doing so gives rise to a new\ntheory, complete with its domain restrictions, voting rules with their\nReality-aware axiomatic properties, and certain game-theoretic aspects. In\nparticular, we show how Reality can be used in a principled way to break\nCondorcet cycles and develop an efficient Reality-aware Condorcet-consistent\nagenda. We then discuss several applications of Reality-Aware Social Choice.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We construct finitely generated simple algebras with prescribed growth types,\nwhich can be arbitrarily taken from a large variety of (super-polynomial)\ngrowth types. This (partially) answers a question raised by the author in a\nrecent paper.\n  Our construction goes through a construction of finitely generated\njust-infinite, primitive monomial algebras with prescribed growth type, from\nwhich we construct uniformly recurrent infinite words with subword complexity\nhaving the same growth type.\n  We also discuss the connection between entropy of algebras and their\nhomomorphic images, as well as the degrees of their generators of free\nsubalgebras.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The paper examines the prominent algorithm D-MORPH to search for the optimal\ncontrol of a quantum system in order to implement desired unitary evolution of\nthe quantum system at the final time, and reveals new mathematical expressions\nfor various orders' corrections to the algorithm, that include information\nabout the commutators of the system's Hamiltonian. Inclusion of such\ncorrections results in faster optimal quantum control's search with high\nprecision, i.e. allows saving of computational resources.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  High-dimensional representations, such as radial basis function networks or\ntile coding, are common choices for policy evaluation in reinforcement\nlearning. Learning with such high-dimensional representations, however, can be\nexpensive, particularly for matrix methods, such as least-squares temporal\ndifference learning or quasi-Newton methods that approximate matrix step-sizes.\nIn this work, we explore the utility of sketching for these two classes of\nalgorithms. We highlight issues with sketching the high-dimensional features\ndirectly, which can incur significant bias. As a remedy, we demonstrate how to\nuse sketching more sparingly, with only a left-sided sketch, that can still\nenable significant computational gains and the use of these matrix-based\nlearning algorithms that are less sensitive to parameters. We empirically\ninvestigate these algorithms, in four domains with a variety of\nrepresentations. Our aim is to provide insights into effective use of sketching\nin practice.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Demand response aims to stimulate electricity consumers to modify their loads\nat critical time periods. In this paper, we consider signals in demand response\nprograms as a binary treatment to the customers and estimate the average\ntreatment effect, which is the average change in consumption under the demand\nresponse signals. More specifically, we propose to estimate this effect by\nlinear regression models and derive several estimators based on the different\nmodels. From both synthetic and real data, we show that including more\ninformation about the customers does not always improve estimation accuracy:\nthe interaction between the side information and the demand response signal\nmust be carefully modeled. In addition, we compare the traditional linear\nregression model with the modified covariate method which models the\ninteraction between treatment effect and covariates. We analyze the variances\nof these estimators and discuss different cases where each respective estimator\nworks the best. The purpose of these comparisons is not to claim the\nsuperiority of the different methods, rather we aim to provide practical\nguidance on the most suitable estimator to use under different settings. Our\nresults are validated using data collected by Pecan Street and EnergyPlus.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The algorithmic Markov condition states that the most likely causal direction\nbetween two random variables X and Y can be identified as that direction with\nthe lowest Kolmogorov complexity. Due to the halting problem, however, this\nnotion is not computable.\n  We hence propose to do causal inference by stochastic complexity. That is, we\npropose to approximate Kolmogorov complexity via the Minimum Description Length\n(MDL) principle, using a score that is mini-max optimal with regard to the\nmodel class under consideration. This means that even in an adversarial\nsetting, such as when the true distribution is not in this class, we still\nobtain the optimal encoding for the data relative to the class.\n  We instantiate this framework, which we call CISC, for pairs of univariate\ndiscrete variables, using the class of multinomial distributions. Experiments\nshow that CISC is highly accurate on synthetic, benchmark, as well as\nreal-world data, outperforming the state of the art by a margin, and scales\nextremely well with regard to sample and domain sizes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Kennedy and O'Hagan (2001) propose a model for calibrating some unknown\nparameters in a computer model and estimating the discrepancy between the\ncomputer output and physical response. This model is known to have certain\nidentifiability issues. Tuo and Wu (2016) show that there are examples for\nwhich the Kennedy-O'Hagan method renders unreasonable results in calibration.\nIn spite of its unstable performance in calibration, the Kennedy-O'Hagan\napproach has a more robust behavior in predicting the physical response. In\nthis work, we present some theoretical analysis to show the consistency of\npredictor based on their calibration model in the context of radial basis\nfunctions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, by utilizing the idea of stabilizer codes, we give some\nrelationships between one local unitary representation of braid group in\nN-qubit tensor space and the corresponding entanglement properties of the\nN-qubit pure state $|\\Psi\\rangle$, where the N-qubit state $|\\Psi\\rangle$ is\nobtained by applying the braiding operation on the natural basis. Specifically,\nwe show that the separability of $|\\Psi\\rangle=\\mathcal{B}|0\\rangle^{\\otimes\nN}$ is closely related to the diagrammatic version of the braid operator\n$\\mathcal{B}$. This may provide us more insights about the topological\nentanglement and quantum entanglement.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Boron carbide thin films of different thicknesses deposited by ion beam\nsputtering were studied. The deposited films were characterized by grazing\nincidence hard x-ray reflectivity (GIXR), resonant soft x-ray reflectivity\n(RSXR), x-ray photo electron spectroscopy (XPS), resonant Rutherford\nbackscattering spectrometry (RRBS), and time of flight secondary ion mass\nspectrometry (TOF-SIMS). An in-depth profile of the chemical elements\nconstitute the films is reconstructed based on analysis of reflectivity curves\nmeasured in the vicinity of B K-edge. The composition of films is closely\ndependent on film thickness. Boron to Carbon (B/C) ratio reaches to ~4 as the\nthickness of deposited films increases. The B/C ratio estimated from RSXR\nmeasurements are in agreement with the RRBS measurements. TOF-SIMS data also\nsuggested that decrease in boron content with decrease in film thickness. XPS\nmeasurements confirm the presence of little amount of B atoms on the surface of\nlow thickness film.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We compute the fluxes of radio photons from conversion of axion-like particle\ndark matter in cosmic magnetic fields. We find that for axion-like particle\nmasses around $10^{-6}\\,$eV and effective coupling constants to photons\n$g_{a\\gamma}\\gtrsim10^{-13}\\,{\\rm GeV}^{-1}$ strongly magnetized nearby stellar\nwinds may give detectable line-like radio photon signals, although predicted\nfluxes are highly uncertain due to the poorly known structure of the magnetic\nfields. Nevertheless, it may be worth while to conduct a dedicated search in\nthe direction of such sources. When combined with a possible future laboratory\ndetection of axion-like dark matter such observations may in turn provide\ninformation on the small scale magnetic field structure in such objects.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The paper deals with the Bond Graph (BG) modeling and the model validation of\na brazed-plate heat exchanger. This device is an important part of a\nmechanically pumped cooling loop. A thermo hydraulic BG model is developed and\ncompared with experimental data. Optimization is performed to determine the\nbest value of the convection heat exchange coefficients to be fixed in the\nmodel.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a robust control architecture for the whole-body motion control\nof torque controlled robots with arms and legs. The method is based on the\nrobust control of contact forces in order to track a planned Center of Mass\ntrajectory. Its appeal lies in the ability to guarantee robust stability and\nperformance despite rigid body model mismatch, actuator dynamics, delays,\ncontact surface stiffness, and unobserved ground profiles. Furthermore, we\nintroduce a task space decomposition approach which removes the coupling\neffects between contact force controller and the other non-contact controllers.\nFinally, we verify our control performance on a quadruped robot and compare its\nperformance to a standard inverse dynamics approach on hardware.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the effect of dynamical tides associated with the excitation of\ngravity waves in an interior radiative region of the central star on orbital\nevolution in observed systems containing Hot Jupiters. We consider WASP-43,\nOgle-tr-113, WASP-12, and WASP-18 which contain stars on the main sequence\n(MS). For these systems there are observational estimates regarding the rate of\nchange of the orbital period. We also investigate Kepler-91 which contains an\nevolved giant star. We adopt the formalism of Ivanov et al. for calculating the\norbital evolution.\n  For the MS stars we determine expected rates of orbital evolution under\ndifferent assumptions about the amount of dissipation acting on the tides,\nestimate the effect of stellar rotation for the two most rapidly rotating stars\nand compare results with observations. All cases apart from possibly WASP-43\nare consistent with a regime in which gravity waves are damped during their\npropagation over the star. However, at present this is not definitive as\nobservational errors are large. We find that although it is expected to apply\nto Kepler-91, linear radiative damping cannot explain this dis- sipation regime\napplying to MS stars. Thus, a nonlinear mechanism may be needed.\n  Kepler-91 is found to be such that the time scale for evolution of the star\nis comparable to that for the orbit. This implies that significant orbital\ncircularisation may have occurred through tides acting on the star.\nQuasi-static tides, stellar winds, hydrodynamic drag and tides acting on the\nplanet have likely played a minor role.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For a congruence subgroup $\\Gamma$, we define the notion of\n$\\Gamma$-equivalence on binary quadratic forms which is the same as proper\nequivalence if $\\Gamma = \\mathrm{SL}_2(\\mathbb Z)$. We develop a theory on\n$\\Gamma$-equivalence such as the finiteness of $\\Gamma$-reduced forms, the\nisomorphism between $\\Gamma_0(N)$-form class group and the ideal class group,\n$N$-representation of integers, and $N$-genus of binary quadratic forms. As an\napplication, we deal with representations of integers by binary quadratic forms\nunder certain congruence condition on variables.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Through analysis of variable temperature neutron powder diffraction data, we\npresent solutions for the magnetic structures of SrMn$_7$O$_{12}$,\nCdMn$_7$O$_{12}$, and PbMn$_7$O$_{12}$ in all long-range ordered phases. The\nthree compounds were found to have magnetic structures analogous to that\nreported for CaMn$_7$O$_{12}$. They all feature a higher temperature lock-in\nphase with \\emph{commensurate} magneto-orbital coupling, and a delocked,\nmulti-\\textbf{k} magnetic ground state where \\emph{incommensurate}\nmagneto-orbital coupling gives rise to a constant-moment magnetic helix with\nmodulated spin helicity. CdMn$_7$O$_{12}$ represents a special case in which\nthe orbital modulation is commensurate with the crystal lattice and involves\nstacking of fully and partially polarized orbital states. Our results provide a\nrobust confirmation of the phenomenological model for magneto-orbital coupling\npreviously presented for CaMn$_7$O$_{12}$. Furthermore, we show that the model\nis universal to the $A^{2+}$ quadruple perovskite manganites synthesised to\ndate, and that it is tunable by selection of the $A$-site ionic radius.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  When one integrates the q-exponential function of Tsallis' so as to get the\npartition function $Z$, a gamma function inevitably emerges. Consequently,\npoles arise. We investigate here here the thermodynamic significance of these\npoles in the case of $n$ classical harmonic oscillators (HO). Given that this\nis an exceedingly well known system, any new feature that may arise can safely\nbe attributed to the poles' effect. We appeal to the mathematical tools used in\n[EPJB 89, 150 (2016) and arXiv:1702.03535 (2017)], and obtain both bound and\nunbound states. In the first case, we are then faced with a classical Einstein\ncrystal. We also detect what might be interpreted as pseudo gravitational\neffects.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Detailed chemical abundances of two stars in the intermediate-age Large\nMagellanic Cloud (LMC) globular cluster NGC~1718 are presented, based on high\nresolution spectroscopic observations with the MIKE spectrograph. The detailed\nabundances confirm NGC~1718 to be a fairly metal-rich cluster, with an average\n[Fe/H] ~ -0.55+/-0.01. The two red giants appear to have primordial O, Na, Mg,\nand Al abundances, with no convincing signs of a composition difference between\nthe two stars---hence, based on these two stars, NGC~1718 shows no evidence for\nhosting multiple populations. The Mg abundance is lower than Milky Way field\nstars, but is similar to LMC field stars at the same metallicity. The previous\nclaims of very low [Mg/Fe] in NGC~1718 are therefore not supported in this\nstudy. Other abundances (Si, Ca, Ti, V, Mn, Ni, Cu, Rb, Y, Zr, La, and Eu) all\nfollow the LMC field star trend, demonstrating yet again that (for most\nelements) globular clusters trace the abundances of their host galaxy's field\nstars. Similar to the field stars, NGC~1718 is found to be mildly deficient in\nexplosive $\\alpha$-elements, but moderately to strongly deficient in O, Na, Mg,\nAl, and Cu, elements which form during hydrostatic burning in massive stars.\nNGC~1718 is also enhanced in La, suggesting that it was enriched in ejecta from\nmetal-poor AGB stars.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For a primitive Dirichlet character $\\chi$ modulo $q$, we define\n$M(\\chi)=\\max_{t } |\\sum_{n \\leq t} \\chi(n)|$. In this paper, we study this\nquantity for characters of a fixed odd order $g\\geq 3$. Our main result\nprovides a further improvement of the classical P\\'{o}lya-Vinogradov inequality\nin this case. More specifically, we show that for any such character $\\chi$ we\nhave $$M(\\chi)\\ll_{\\varepsilon} \\sqrt{q}(\\log q)^{1-\\delta_g}(\\log\\log\nq)^{-1/4+\\varepsilon},$$ where $\\delta_g := 1-\\frac{g}{\\pi}\\sin(\\pi/g)$. This\nimproves upon the works of Granville and Soundararajan and of Goldmakher.\nFurthermore, assuming the Generalized Riemann hypothesis (GRH) we prove that $$\nM(\\chi) \\ll \\sqrt{q} \\left(\\log_2 q\\right)^{1-\\delta_g} \\left(\\log_3\nq\\right)^{-\\frac{1}{4}}\\left(\\log_4 q\\right)^{O(1)}, $$ where $\\log_j$ is the\n$j$-th iterated logarithm. We also show unconditionally that this bound is best\npossible (up to a power of $\\log_4 q$). One of the key ingredients in the proof\nof the upper bounds is a new Hal\\'asz-type inequality for logarithmic mean\nvalues of completely multiplicative functions, which might be of independent\ninterest.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove an enumerative formula for the algebraic Euler characteristic of\nBrill-Noether varieties, parametrizing degree d and rank r linear series on a\ngeneral genus g curve, with ramification profiles specified at up to two\ngeneral points. Up to sign, this Euler characteristic is the number of standard\nset-valued tableaux of a certain skew shape with g labels. We use a flat\ndegeneration via the Eisenbud-Harris theory of limit linear series, relying on\nmoduli-theoretic advances of Osserman and Murray-Osserman; the count of\nset-valued tableaux is an explicit enumeration of strata of this degeneration.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let T1, T2,.... Tk be spanning trees in a graph G. If for any pair of\nvertices u and v of G, the paths between u and v in every Ti( 0 < i < k+1) do\nnot contain common edges then T1, T2,.... Tk are called edge-disjoint spanning\ntrees in G. The design of multiple edge-disjoint spanning trees has\napplications to the reliable communication protocols. The n-dimensional\naugmented cube, denoted as AQn, a variation of the hypercube, possesses some\nproperties superior to those of the hypercube. For AQn (n > 2), construction of\nn-1 edge-disjoint spanning trees is given the result is optimal with respect to\nthe number of edge-disjoint spanning trees.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This study presents an innovative method for reducing the number of rating\nscale items without predictability loss. The \"area under the re- ceiver\noperator curve method\" (AUC ROC) is used to implement in the\nRatingScaleReduction package posted on CRAN. Several cases have been used to\nillustrate how the stepwise method has reduced the number of rating scale items\n(variables).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present ongoing investigations of a four-dimensional lattice field theory\nwith four massless reduced staggered fermions coupled through an\nSU(4)-invariant four-fermion interaction. As in previous studies of\nfour-fermion and Higgs--Yukawa models with different lattice fermion\ndiscretizations, we observe a strong-coupling phase in which the system\ndevelops a mass gap without breaking any lattice symmetry. This symmetric\nstrong-coupling phase is separated from the symmetric weak-coupling phase by a\nnarrow region of four-fermi coupling in which the system exhibits long-range\ncorrelations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The spreading of a cap-shaped spherical droplet of non-Newtonian power-law\nliquids on a flat and a spherical rough and textured substrate is theoretically\nstudied in the capillary-controlled spreading regime. A droplet whose scale is\nmuch larger than that of the roughness of substrate is considered. The\nequilibrium contact angle on a rough substrate is modeled by the Wenzel and the\nCassie-Baxter model. Only the viscous energy dissipation within the droplet\nvolume is considered, and that within the texture of substrate by imbibition is\nneglected. Then, the energy balance approach is adopted to derive the evolution\nequation of the contact angle. When the equilibrium contact angle vanishes, the\nrelaxation of dynamic contact angle $\\theta$ of a droplet obeys a power law\ndecay $\\theta \\sim t^{-\\alpha}$ except for the Newtonian and the non-Newtonian\nshear-thinning liquid of the Wenzel model on a spherical substrate. The\nspreading exponent $\\alpha$ of the non-Newtonian shear-thickening liquid of the\nWenzel model on a spherical substrate is larger than others. The relaxation of\nthe Newtonian liquid of the Wenzel model on a spherical substrate is even\nfaster showing the exponential relaxation. The relaxation of the non-Newtonian\nshear-thinning liquid of Wenzel model on a spherical substrate is fastest and\nfinishes within a finite time. Thus, the topography (roughness) and the\ntopology (flat to spherical) of substrate accelerate the spreading of droplet.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we study the effects of super-light brane world perturbative\nmodes on structure formation in our universe. As these modes modify the large\ndistance behavior of Newtonian potential, they effect the clustering of a\nsystem of galaxies. So, we explicitly calculate the clustering of galaxies\ninteracting through such a modified Newtonian potential. We use a suitable\napproximation for analyzing this system of galaxies, and discuss the validity\nof such approximations. We observe that such corrections also modify the virial\ntheorem for such a system of galaxies.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove local well-posedness for the gravity water waves equations without\nsurface tension, with initial velocity field in $H^s$, $s > \\frac{d}{2} + 1 -\n\\mu$, where $\\mu = \\frac{1}{10}$ in the case $d = 1$ and $\\mu = \\frac{1}{5}$ in\nthe case $d \\geq 2$, extending previous results of Alazard-Burq-Zuily. The\nimprovement primarily arises in two areas. First, we perform an improved\nanalysis of the regularity of the change of variables from Eulerian to\nLagrangian coordinates. Second, we perform a time-interval length optimization\nof the localized Strichartz estimates.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We address the problem of interactively controlling the workspace of a mobile\nrobot to ensure a human-aware navigation. This is especially of relevance for\nnon-expert users living in human-robot shared spaces, e.g. home environments,\nsince they want to keep the control of their mobile robots, such as vacuum\ncleaning or companion robots. Therefore, we introduce virtual borders that are\nrespected by a robot while performing its tasks. For this purpose, we employ a\nRGB-D Google Tango tablet as human-robot interface in combination with an\naugmented reality application to flexibly define virtual borders. We evaluated\nour system with 15 non-expert users concerning accuracy, teaching time and\ncorrectness and compared the results with other baseline methods based on\nvisual markers and a laser pointer. The experimental results show that our\nmethod features an equally high accuracy while reducing the teaching time\nsignificantly compared to the baseline methods. This holds for different border\nlengths, shapes and variations in the teaching process. Finally, we\ndemonstrated the correctness of the approach, i.e. the mobile robot changes its\nnavigational behavior according to the user-defined virtual borders.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the entropy dynamics of a dephasing model, where a two-level system\n(TLS) is coupled with a squeezed thermal bath via non-demolition interaction.\nThis model is exactly solvable, and the time dependent states of both the TLS\nand its bath can be obtained exactly. Based on these states, we calculate the\nentropy dynamics of both the TLS and the bath, and find that the dephasing rate\nof the system relies on the squeezing phase of the bath. In zero temperature\nand high temperature limits, we prove that both the system and bath entropy\nincreases monotonically. Moreover, we find that the dephasing rate of the\nsystem relies on the squeezing phase of the bath, and this phase dependence\ncannot be precisely derived from the Born-Markovian approximation which is\nwidely adopted in open quantum systems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given a non-convex twice continuously differentiable cost function with\nLipschitz continuous gradient, we prove that all of block coordinate gradient\ndescent, block mirror descent and proximal block coordinate descent converge to\na local minimizer, almost surely with random initialization. Furthermore, we\nshow that these results also hold true even for the cost functions with\nnon-isolated critical points.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This is the translation into English of the introduction, conclusion, and the\nlist of references of the review on massive primordial black holes, which is\nsubmitted in Russian to Uspekhi Fizicheskikh Nauk (Physics-Uspekhi). If\naccepted, this review is translated into English by the Journal and published\nin Russian and a little later in English.\n  The review concerns the recent astronomical data which show that massive\nprimordial black holes play much more significant role in the universe than it\nwas previously believed. This is true both for the the contemporary and the\nearly universe at the red-shifts about 10. The mechanism, proposed in 1993, of\nprimordial creation of heavy and superheavy black holes in the very early\nuniverse is discussed. This mechanism predicts the log-normal mass spectrum of\nthe primordial black holes, which became very popular during the last couple of\nyears. The proposed mechanism presents a natural explanation of a large amount\nof the recent observational data, which do not fit the standard cosmology and\nastrophysics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a proof-of-principle experiment to encode one logical qubit in\nnoise protected subspace of three identical spins in a methyl group. The\nsymmetry analysis of the wavefunction shows that this fermionic system exhibits\na symmetry correlation between the spatial degree of freedom and the spin\ndegree of freedom. We show that one can use this correlation to populate the\nnoiseless subsystem by relying on the interaction between the electric dipole\nmoment of the methyl group with a circularly polarized microwave field. Logical\ngates are implemented by controlling both the intensity and phase of the\napplied field.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show how to predict the basic word-order facts of a novel language given\nonly a corpus of part-of-speech (POS) sequences. We predict how often direct\nobjects follow their verbs, how often adjectives follow their nouns, and in\ngeneral the directionalities of all dependency relations. Such typological\nproperties could be helpful in grammar induction. While such a problem is\nusually regarded as unsupervised learning, our innovation is to treat it as\nsupervised learning, using a large collection of realistic synthetic languages\nas training data. The supervised learner must identify surface features of a\nlanguage's POS sequence (hand-engineered or neural features) that correlate\nwith the language's deeper structure (latent trees). In the experiment, we\nshow: 1) Given a small set of real languages, it helps to add many synthetic\nlanguages to the training data. 2) Our system is robust even when the POS\nsequences include noise. 3) Our system on this task outperforms a grammar\ninduction baseline by a large margin.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show that compact Riemannian three-manifolds with negative sectional\ncurvature possess closed minimal surfaces of arbitrarily high Morse index.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Cognitive inference of user demographics, such as gender and age, plays an\nimportant role in creating user profiles for adjusting marketing strategies and\ngenerating personalized recommendations because user demographic data is\nusually not available due to data privacy concerns. At present, users can\nreadily express feedback regarding products or services that they have\npurchased. During this process, user demographics are concealed, but the data\nhas never yet been successfully utilized to contribute to the cognitive\ninference of user demographics. In this paper, we investigate the inference\npower of user ratings data, and propose a simple yet general cognitive\ninference model, called rating to profile (R2P), to infer user demographics\nfrom user provided ratings. In particular, the proposed R2P model can achieve\nthe following: 1. Correctly integrate user ratings into model training. 2.Infer\nmultiple demographic attributes of users simultaneously, capturing the\nunderlying relevance between different demographic attributes. 3. Train its two\ncomponents, i.e. feature extractor and classifier, in an integrated manner\nunder a supervised learning paradigm, which effectively helps to discover\nuseful hidden patterns from highly sparse ratings data. We introduce how to\nincorporate user ratings data into the research field of cognitive inference of\nuser demographic data, and detail the model development and optimization\nprocess for the proposed R2P. Extensive experiments are conducted on two\nreal-world ratings datasets against various compared state-of-the-art methods,\nand the results from multiple aspects demonstrate that our proposed R2P model\ncan significantly improve on the cognitive inference performance of user\ndemographic data.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We outline polarization fringe predictions derived from a new application of\nthe Berreman calculus for the Daniel K. Inouye Solar Telescope (DKIST) retarder\noptics. The DKIST retarder baseline design used 6 crystals, single-layer\nanti-reflection coatings, thick cover windows and oil between all optical\ninterfaces. This new tool estimates polarization fringes and optic Mueller\nmatrices as functions of all optical design choices. The amplitude and period\nof polarized fringes under design changes, manufacturing errors, tolerances and\nseveral physical factors can now be estimated. This tool compares well with\nobservations of fringes for data collected with the SPINOR spectropolarimeter\nat the Dunn Solar Telescope using bi-crystalline achromatic retarders as well\nas laboratory tests. With this new tool, we show impacts of design decisions on\npolarization fringes as impacted by anti-reflection coatings, oil refractive\nindices, cover window presence and part thicknesses. This tool helped DKIST\ndecide to remove retarder cover windows and also recommends reconsideration of\ncoating strategies for DKIST. We anticipate this tool to be essential in\ndesigning future retarders for mitigation of polarization and intensity fringe\nerrors in other high spectral resolution astronomical systems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This article determines and characterizes the minimal number of actuators\nneeded to ensure structural controllability of a linear system under structural\nalterations that can severe the connection between any two states. We assume\nthat initially the system is structurally controllable with respect to a given\nset of controls, and propose an efficient system-synthesis mechanism to find\nthe minimal number of additional actuators required for resilience of the\nsystem w.r.t such structural changes. The effectiveness of this approach is\ndemonstrated by using standard IEEE power networks.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we investigate the asymptotic behavior of the colored Jones\npolynomials and the Turaev-Viro invariants for the figure eight knot. More\nprecisely, we consider the $M$-th colored Jones polynomials evaluated at\n$(N+1/2)$-th root of unity with a fixed limiting ratio, $s$, of $M$ and\n$(N+1/2)$. We find out the asymptotic expansion formula (AEF) of the colored\nJones polynomials of the figure eight knot with $s$ close to $1$. Nonetheless,\nwe show that the exponential growth rate of the colored Jones polynomials of\nthe figure eight knot with $s$ close to $1/2$ is strictly less than those with\n$s$ close to $1$. It is known that the Turaev Viro invariant of the figure\neight knot can be expressed in terms of a sum of its colored Jones polynomials.\nOur results show that this sum is asymptotically equal to the sum of the terms\nwith $s$ close to 1. As an application of the asymptotic behavior of the\ncolored Jones polynomials, we obtain the asymptotic expansion formula for the\nTuraev-Viro invariants of the figure eight knot. Finally, we suggest a possible\ngeneralization of our approach so as to relate the AEF for the colored Jones\npolynomials and the AEF for the Turaev-Viro invariants for general hyperbolic\nknots.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the number of prime polynomials of degree $n$ over $\\mathbb{F}_q$ in\nwhich the $i^{th}$ coefficient is either preassigned to be $a_i \\in\n\\mathbb{F}_q$ or outside a small set $S_i \\subset \\mathbb{F}_q$. This serves as\na function field analogue of a recent work of Maynard, which counts integer\nprimes that do not have specific digits in their base-$q$ expansion. Our work\nrelates to Pollack's and Ha's work, which count the amount of prime polynomials\nwith $\\ll \\sqrt{n}$ and $\\ll n$ preassigned coefficients, respectively. Our\nresult demonstrates how one can prove asymptotics of the number of prime\npolynomials with different types of constraints to each coefficient.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Dynamic evidence logics are logics for reasoning about the evidence and\nevidence-based beliefs of agents in a dynamic environment. In this paper, we\nintroduce a family of logics for reasoning about relational evidence: evidence\nthat involves an orderings of states in terms of their relative plausibility.\nWe provide sound and complete axiomatizations for the logics. We also present\nseveral evidential actions and prove soundness and completeness for the\nassociated dynamic logics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Although time-dependent random media with short range correlations lead to\n(possibly biased) normal tracer diffusion, anomalous fluctuations occur away\nfrom the most probable direction. This was pointed out recently in 1D lattice\nrandom walks, where statistics related to the 1D Kardar- Parisi-Zhang (KPZ)\nuniversality class, i.e. the GUE Tracy Widom distribution, were shown to arise.\nHere we provide a simple picture for this correspondence, directly in the\ncontinuum as well as for lattice models, which allows to study arbitrary space\ndimension and to predict a variety of universal distributions. In $d = 1$ we\npredict and verify numerically the emergence of the GOE Tracy-Widom\ndistribution for the fluctuations of the transition probability. In $d = 3$ we\npredict a phase transition from Gaussian fluctuations to 3D-KPZ type\nfluctuations as the bias is increased. We predict KPZ universal distributions\nfor the arrival time of a first particle from a cloud diffusing in such media.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  An electron cloud instability might limit the intensity in the Fermilab\nRecycler after the PIP-II upgrade. A multibunch instability typically develops\nin the horizontal plane within a hundred turns and, in certain conditions,\nleads to beam loss. Recent studies have indicated that the instability is\ncaused by an electron cloud, trapped in the Recycler index dipole magnets. We\ndeveloped an analytical model of an electron cloud driven instability with the\nelectrons trapped in combined function dipoles. The resulting instability\ngrowth rate of about 30 revolutions is consistent with experimental\nobservations and qualitatively agrees with the simulation in the PEI code. The\nmodel allows an estimation of the instability rate for the future intensity\nupgrades.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In machine learning and neuroscience, certain computational structures and\nalgorithms are known to yield disentangled representations without us\nunderstanding why, the most striking examples being perhaps convolutional\nneural networks and the ventral stream of the visual cortex in humans and\nprimates. As for the latter, it was conjectured that representations may be\ndisentangled by being flattened progressively and at a local scale. An attempt\nat a formalization of the role of invariance in learning representations was\nmade recently, being referred to as I-theory. In this framework and using the\nlanguage of differential geometry, we show that pooling over a group of\ntransformations of the input contracts the metric and reduces its curvature,\nand provide quantitative bounds, in the aim of moving towards a theoretical\nunderstanding on how to disentangle representations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We outline an approach to the inverse problem of Calder\\'on that highlights\nthe role of microlocal normal forms and propagation of singularities and\nextends a number of earlier results also in the anisotropic case. The main\nresult states that from the boundary measurements it is possible to recover\nintegrals of the unknown coefficient over certain two-dimensional manifolds\ncalled good bicharacteristic leaves. This reduces the Calder\\'on problem into\nsolving a linear integral geometry problem (inversion of a bicharacteristic\nleaf transform).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Ultra-faint galaxies are hosted by small dark matter halos with shallow\ngravitational potential wells, hence their star formation activity is more\nsensitive to feedback effects. The shape of the faint-end of the high-$z$\ngalaxy luminosity function (LF) contains important information on star\nformation and its interaction with the reionization process during the Epoch of\nReionization (EoR). High-$z$ galaxies with $M_{\\rm UV}\\gtrsim-17$ have only\nrecently become accessible thanks to the Frontier Fields (FFs) survey combining\ndeep {\\it HST} imaging and the gravitational lensing effect. In this paper we\ninvestigate the faint-end of the LF at redshift $>$5 using the data of FFs\nclusters Abell 2744 (A2744), MACSJ0416.1-2403 (M0416), MACSJ0717.5+3745 (M0717)\nand MACSJ1149.5+2223 (M1149). We analyze both an empirical and a\nphysically-motivated LF model to obtain constraints on a possible turn-over of\nLF at faint magnitudes. In the empirical model the LF drops fast when the\nabsolute UV magnitude $M_{\\rm UV}$ is much larger than a turn-over absolute UV\nmagnitude $M_{\\rm UV}^{\\rm T}$. We obtain $M_{\\rm UV}^{\\rm T}\\gtrsim-14.6 $\n(15.2) at 1 (2) $\\sigma$ confidence level (C.L.) for $z\\sim6$. In the\nphysically-motivated analytical model, star formation in halos with circular\nvelocity below $v_c^*$ is fully quenched if these halos are located in ionized\nregions. Using updated lensing models and new additional FFs data, we\nre-analyze previous constraints on $v_c^*$ and $f_{\\rm esc}$ presented by\nCastellano et al. 2016a (C16a) using a smaller dataset. We obtain new\nconstraints on $v_c^*\\lesssim 59$ km s$^{-1}$ and $f_{\\rm esc}\\lesssim 56\\%$\n(both at 2$\\sigma$ C.L.) and conclude that there is no turn-over detected so\nfar from the analyzed FFs data. Forthcoming {\\it JWST} observations will be key\nto tight these constraints further.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  So far the study of black hole perturbations has been mostly focussed upon\nthe classical black holes with singularities at the origin and hidden by event\nhorizon. Compared to that, the regular black holes are a completely new class\nof solutions arising out of modification of general theory of relativity by\ncoupling gravity to an external form of matter. Therefore it is extremely\nimportant to study the behaviour of such regular black holes under different\ntypes of perturbations. Recently a new regular Bardeen black hole solution with\na de Sitter branch has been proposed by Fernando. We compute the quasi-normal\n(QN) frequencies for the regular Bardeen de Sitter (BdS) black hole due to\nmassless and massive scalar field perturbations as well as the massless Dirac\nperturbations. We analyze the behaviour of both real and imaginary parts of\nquasinormal frequencies by varying different parameters of the theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present non-critical Bianchi type $I$ string cosmology solutions in the\npresence of central charge deficit term $\\Lambda$. The leading order string\nframe curvature appears to be in the high curvature limit $R\\alpha'\\gtrsim1$,\nwhich underlines the necessity of including higher order $\\alpha'$-corrections.\nWe give new solutions of two-loop (order $\\alpha'$) $\\beta$-function equations\nof $\\sigma$-model with non-zero $\\Lambda$ and dilaton field in both cases of\nabsence and presence of spatially homogeneous $H$-field ($H=dB$). Also, the\nevolution of solutions is studied in the Einstein frame, where the string\neffective action can transform to Gauss-Bonnet gravity model coupled to the\ndilaton field with potential. We study explicit examples in order $\\alpha'$\nwith chosen values of appeared constants in the solutions and discuss the\ncosmological implications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We perform a systematic search for long-term extreme variability quasars\n(EVQs) in the overlapping Sloan Digital Sky Survey (SDSS) and 3-Year Dark\nEnergy Survey (DES) imaging, which provide light curves spanning more than 15\nyears. We identified ~1000 EVQs with a maximum g band magnitude change of more\nthan 1 mag over this period, about 10% of all quasars searched. The EVQs have\nL_bol~10^45-10^47 erg/s and L/L_Edd~0.01-1. Accounting for selection effects,\nwe estimate an intrinsic EVQ fraction of ~30-50% among all g<~22 quasars over a\nbaseline of ~15 years. These EVQs are good candidates for so-called\n\"changing-look quasars\", where a spectral transition between the two types of\nquasars (broad-line and narrow-line) is observed between the dim and bright\nstates. We performed detailed multi-wavelength, spectral and variability\nanalyses for the EVQs and compared to their parent quasar sample. We found that\nEVQs are distinct from a control sample of quasars matched in redshift and\noptical luminosity: (1) their UV broad emission lines have larger equivalent\nwidths; (2) their Eddington ratios are systematically lower; and (3) they are\nmore variable on all timescales. The intrinsic difference in quasar properties\nfor EVQs suggest that internal processes associated with accretion are the main\ndriver for the observed extreme long-term variability. However, despite their\ndifferent properties, EVQs seem to be in the tail of a continuous distribution\nof quasar properties, rather than standing out as a distinct population. We\nspeculate that EVQs are normal quasars accreting at relatively low accretion\nrates, where the accretion flow is more likely to experience instabilities that\ndrive the factor of few changes in flux on multi-year timescales.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recently, there is a series of reports by Wang et al. on the\nsuperconductivity in K-doped p-terphenyl (KxC18H14) with the transition\ntemperatures range from 7 to 123 Kelvin. Identifying the structural and bonding\ncharacter is the key to understand the superconducting phases and the related\nproperties. Therefore we carried out an extensive study on the crystal\nstructures with different doping levels and investigate the thermodynamic\nstability, structural, electronic, and magnetic properties by the\nfirst-principles calculations. Our calculated structures capture most features\nof the experimentally observed X-ray diffraction patterns. The K doping\nconcentration is constrained to within the range of 2 and 3. The obtained\nformation energy indicates that the system at x = 2.5 is more stable. The\nstrong ionic bonding interaction is found in between K atoms and organic\nmolecules. The charge transfer accounts for the metallic feature of the doped\nmaterials. For a small amount of charge transferred, the tilting force between\nthe two successive benzenes drives the system to stabilize at the\nantiferromagnetic ground state, while the system exhibits non-magnetic behavior\nwith increasing charge transfer. The multiformity of band structures near the\nFermi level indicates that the driving force for superconductivity is\ncomplicated.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Finding hot topics in scholarly fields can help researchers to keep up with\nthe latest concepts, trends, and inventions in their field of interest. Due to\nthe rarity of complete large-scale scholarly data, earlier studies target this\nproblem based on manual topic extraction from a limited number of domains, with\ntheir focus solely on a single feature such as coauthorship, citation\nrelations, and etc. Given the compromised effectiveness of such predictions, in\nthis paper we use a real scholarly dataset from Microsoft Academic Graph, which\nprovides more than 12000 topics in the field of Computer Science (CS),\nincluding 1200 venues, 14.4 million authors, 30 million papers and their\ncitation relations over the period of 1950 till now. Aiming to find the topics\nthat will trend in CS area, we innovatively formalize a hot topic prediction\nproblem where, with joint consideration of both inter- and intra-topical\ninfluence, 17 different scientific features are extracted for comprehensive\ndescription of topic status. By leveraging all those 17 features, we observe\ngood accuracy of topic scale forecasting after 5 and 10 years with R2 values of\n0.9893 and 0.9646, respectively. Interestingly, our prediction suggests that\nthe maximum value matters in finding hot topics in scholarly fields, primarily\nfrom three aspects: (1) the maximum value of each factor, such as authors'\nmaximum h-index and largest citation number, provides three times the amount of\ninformation than the average value in prediction; (2) the mutual influence\nbetween the most correlated topics serve as the most telling factor in\nlong-term topic trend prediction, interpreting that those currently exhibiting\nthe maximum growth rates will drive the correlated topics to be hot in the\nfuture; (3) we predict in the next 5 years the top 100 fastest growing (maximum\ngrowth rate) topics that will potentially get the major attention in CS area.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For split reductive algebraic groups, we determine the connected components\nof closed affine Deligne-Lusztig varieties of arbitrary parahoric level.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $e_n$ be the connective cover of the Morava $E$-theory spectrum $E_n$ of\nheight $n$. In this paper we compute its homology $H_*(e_n;\\mathbb{F}_p)$ for\nany prime $p$ and $n \\leq 4$ up to possible multiplicative extensions. In order\nto accomplish this we show that the K\\\"unneth spectral sequence based on an\n$E_3$-algebra $R$ is multiplicative when the $R$-modules in question are\ncommutative $S$-algebras. We then apply this result by working over $BP$ which\nis known to be an $E_4$-algebra.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The cosmological constraining power of modern galaxy cluster catalogs can be\nimproved by obtaining low-scatter mass proxy measurements for even a small\nfraction of sources. In the context of large upcoming surveys that will reveal\nthe cluster population down to the group scale and out to high redshifts,\nefficient strategies for obtaining such mass proxies will be valuable. In this\nwork, we use high-quality weak lensing and X-ray mass estimates for massive\nclusters in current X-ray selected catalogs to revisit the scaling relations of\nthe projected, center-excised X-ray luminosity ($L_{ce}$), which previous work\nsuggests correlates tightly with total mass. Our data confirm that this is the\ncase, with $L_{ce}$ having an intrinsic scatter at fixed mass comparable to\nthat of gas mass, temperature or $Y_X$. Compared to these other proxies,\nhowever, $L_{ce}$ is less susceptible to systematic uncertainties due to\nbackground modeling, and can be measured precisely with shorter exposures. This\nopens up the possibility of using $L_{ce}$ to estimate masses for large numbers\nof clusters discovered by new X-ray surveys (e.g. eROSITA) directly from the\nsurvey data, as well as for clusters discovered at other wavelengths, with\nrelatively short follow-up observations. We describe a simple procedure for\nmaking such estimates from X-ray surface brightness data, and comment on the\nspatial resolution required to apply this method as a function of cluster mass\nand redshift. We also explore the potential impact of Chandra and XMM-Newton\nfollow-up observations over the next decade on dark energy constraints from new\ncluster surveys.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we present tensor-based linear and nonlinear models for\nhyperspectral data classification and analysis. By exploiting principles of\ntensor algebra, we introduce new classification architectures, the weight\nparameters of which satisfies the {\\it rank}-1 canonical decomposition\nproperty. Then, we introduce learning algorithms to train both the linear and\nthe non-linear classifier in a way to i) to minimize the error over the\ntraining samples and ii) the weight coefficients satisfies the {\\it rank}-1\ncanonical decomposition property. The advantages of the proposed classification\nmodel is that i) it reduces the number of parameters required and thus reduces\nthe respective number of training samples required to properly train the model,\nii) it provides a physical interpretation regarding the model coefficients on\nthe classification output and iii) it retains the spatial and spectral\ncoherency of the input samples. To address issues related with linear\nclassification, characterizing by low capacity, since it can produce rules that\nare linear in the input space, we introduce non-linear classification models\nbased on a modification of a feedforward neural network. We call the proposed\narchitecture {\\it rank}-1 Feedfoward Neural Network (FNN), since their weights\nsatisfy the {\\it rank}-1 caconical decomposition property. Appropriate learning\nalgorithms are also proposed to train the network. Experimental results and\ncomparisons with state of the art classification methods, either linear (e.g.,\nSVM) and non-linear (e.g., deep learning) indicates the outperformance of the\nproposed scheme, especially in cases where a small number of training samples\nare available. Furthermore, the proposed tensor-based classfiers are evaluated\nagainst their capabilities in dimensionality reduction.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We describe new Hi-GAL based maps of the entire Galactic Plane, obtained\nusing continuum data in the wavelength range 70-500 $\\mu$m. These maps are\nderived with the PPMAP procedure, and therefore represent a significant\nimprovement over those obtained with standard analysis techniques. Specifically\nthey have greatly improved resolution (12 arcsec) and, in addition to more\naccurate integrated column densities and mean dust temperatures, they give\ntemperature-differential column densities, i.e., separate column density maps\nin twelve distinct dust temperature intervals, along with the corresponding\nuncertainty maps. The complete set of maps is available on-line. We briefly\ndescribe PPMAP and present some illustrative examples of the results. These\ninclude (a) multi-temperature maps of the Galactic HII region W5-E, (b) the\ntemperature decomposition of molecular cloud column-density probability\ndistribution functions, and (c) the global variation of mean dust temperature\nas a function of Galactocentric distance. Amongst our findings are: (i) a\nstrong localised temperature gradient in W5-E in a direction orthogonal to that\ntowards the ionising star, suggesting an alternative heating source and\nproviding possible guidance for models of the formation of the bubble complex,\nand (ii) the overall radial profile of dust temperature in the Galaxy shows a\nmonotonic decrease, broadly consistent both with models of the interstellar\nradiation field and with previous estimates at lower resolution. However, we\nalso find a central temperature plateau within ~ 6 kpc of the Galactic centre,\noutside of which is a pronounced steepening of the radial profile. This\nbehaviour may reflect the greater proportion of molecular (as opposed to\natomic) gas in the central region of the Galaxy.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the pulsational properties of rapidly rotating main-sequence B-type\nstars using linear non-adiabatic analysis of non-radial low-frequency modes\ntaking into account the effect of rotation. We compare the properties of\nprograde sectoral $g$ and retrograde $r$ modes excited by the $\\kappa$\nmechanism at the Fe opacity peak with the newly discovered period-luminosity\nrelation that is obeyed by a group of fast-rotating B-type stars in the young\nopen cluster NGC 3766. The observed relation consists of two sequences in the\nperiod versus magnitude diagram, at periods shorter than 0.5 days. We find that\nthis property is consistent with similar period-luminosity relations predicted\nfor excited sectoral prograde $g$-modes of azimuthal orders $m=-1$ and $m=-2$\nin fast-rotating stars along an isochrone. We further show that some of the\nrapidly rotating stars that have photometric variability with periods longer\nthan a day may be caused by $r$-mode pulsation predicted to be excited in these\nstars. One fast-rotating star, in particular, shows both short and long periods\nthat can be explained by the simultaneous excitation of $g$- and $r$-mode\npulsations in models of fast-rotating stars.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Three-dimensional gravitational cloaking is known to require exotic matter\nand energy sources, which makes it arguably physically unrealizable. On the\nother hand, typical astronomical observations are performed using\none-dimensional paraxial line of sight geometries. We demonstrate that\nunidirectional line of sight gravitational cloaking does not require exotic\nmatter, and it may occur in multiple natural astronomical scenarios which\ninvolve gravitational lensing. In particular, recently discovered double\ngravitational lens SDSSJ0946+1006 together with the Milky Way appear to form a\nnatural paraxial cloak. A natural question to ask, then, is how much matter in\nthe universe may be hidden from view by such natural gravitational cloaks. It\nis estimated that the total volume hidden from an observer by gravitational\ncloaking may reach about 1% of the total volume of the visible universe.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a semantic identification attack, in which an adversary uses\nsemantic signals about the pages visited in one browsing session to identify\nother browsing sessions launched by the same user. Current user fingerprinting\nmethods fail when a single machine is used by multiple users (e.g., in\ncybercafes or spaces with public computers) as these methods fingerprint\ndevices, not individuals. We demonstrate how an adversary can employ a SIA to\nsuccessfully fingerprint users on public or shared machines and identify them\nacross browsing sessions. We additionally describe and evaluate possible\ncountermeasures to prevent identification.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Simulating high-weight Hamiltonians can convert local noise on the original\nHamiltonian into undesirable nonlocal noise on the simulated Hamiltonian. Here\nwe show how starting from two-local Hamiltonian in the presence of\nnon-Markovian noise, a desired computation can be simulated as well as\nprotected using fast pulses, while maintaining an energy gap against the errors\ncreated in the process.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We explore the ability of word embeddings to capture both semantic and\nmorphological similarity, as affected by the different types of linguistic\nproperties (surface form, lemma, morphological tag) used to compose the\nrepresentation of each word. We train several models, where each uses a\ndifferent subset of these properties to compose its representations. By\nevaluating the models on semantic and morphological measures, we reveal some\nuseful insights on the relationship between semantics and morphology.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A new approach to description of hadron spectroscopy is proposed. By\nassumption, the form of spectrum is dictated by the trace of energy momentum\ntensor in QCD. This provides the relativistic and renormalization invariance of\nhadron masses. The constructed scheme is applied to the light mesons for which\ntwo complementary interpretations are worked out. The first one represents an\n\"atomic\" structure of resonances above 1 GeV in which the quanta of\nnon-perturbative gluon contributions are quantified via an effective formation\nof quasiparticles representing likely gluon analogues of positronium. This\npicture allows to build a \"periodic table of the hadronic elements\", i.e. to\nclassify hadrons, in some sense, in analogy with Mendeleev table in chemistry.\nThe classification does not require introduction of the orbital angular\nmomentum associated with hadron constituents. The Regge and radial trajectories\nemerge in a natural way. The second interpretation is based on a \"collisional\"\nnature of some (or many) hadrons, specifically of scalar resonances below 1\nGeV. Here the role of quasiparticles is played by another hadron. This picture\nin particular leads to a simple explanation of the puzzling scalar sector below\n1 GeV with correct predictions for masses and dominant decay modes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show that a possible resolution to the stabilization of an extra spatial\ndimension (radion) can be obtained solely in the context of gravitational\ndynamics itself without the necessity of introducing any external stabilizing\nfield. In this scenario the stabilized value of the radion field gets\ndetermined in terms of the parameters appearing in the higher curvature\ngravitational action. Furthermore, the mass of the radion field and its\ncoupling to the standard model fields are found to be in the weak scale\nimplying possible signatures in the TeV scale colliders. Some resulting\nimplications are also discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The current generation of experiments aiming to detect the neutral hydrogen\nsignal from the Epoch of Reionisation (EoR) is likely to be limited by\nsystematic effects associated with removing foreground sources from target\nfields. In this paper we develop a model for the compact foreground sources in\none of the target fields of the MWA's EoR key science experiment: the `EoR1'\nfield. The model is based on both the MWA's GLEAM survey and GMRT 150 MHz data\nfrom the TGSS survey, the latter providing higher angular resolution and better\nastrometric accuracy for compact sources than is available from the MWA alone.\nThe model contains 5049 sources, some of which have complicated morphology in\nMWA data, Fornax A being the most complex. The higher resolution data show that\n13% of sources that appear point-like to the MWA have complicated morphology\nsuch as double and quad structure, with a typical separation of 33~arcsec. We\nderive an analytic expression for the error introduced into the EoR\ntwo-dimensional power spectrum due to peeling close double sources as single\npoint sources and show that for the measured source properties, the error in\nthe power spectrum is confined to high $k_\\bot$ modes that do not affect the\noverall result for the large-scale cosmological signal of interest. The\nbrightest ten mis-modelled sources in the field contribute 90% of the power\nbias in the data, suggesting that it is most critical to improve the models of\nthe brightest sources. With this hybrid model we reprocess data from the EoR1\nfield and show a maximum of 8% improved calibration accuracy and a factor of\ntwo reduction in residual power in $k$-space from peeling these sources.\nImplications for future EoR experiments including the SKA are discussed in\nrelation to the improvements obtained.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We calculate the one-loop contributions to the polarization operator for\nscalar quantum electrodynamics in different external electromagnetic and\ngravitational fields. In the case of gravity, de-Sitter space and its different\npatches were considered. It is shown that the Debye mass appears only in the\ncase of alpha-vacuum in the Expanding Poincare Patch. It can be shown either by\ndirect computations or by using analytical and casual properties of the\nde-Sitter space. Also, the case of constant electric field is considered and\nthe Debye mass is calculated.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A new search strategy for the detection of the elusive dark matter (DM) axion\nis proposed. The idea is based on streaming DM axions, whose flux might get\ntemporally enormously enhanced due to gravitational lensing. This can happen if\nthe Sun or some planet (including the Moon) is found along the direction of a\nDM stream propagating towards the Earth location. The experimental requirements\nto the axion haloscope are a wide-band performance combined with a fast axion\nrest mass scanning mode, which are feasible. Once both conditions have been\nimplemented in a haloscope, the axion search can continue parasitically almost\nas before. Interestingly, some new DM axion detectors are operating wide-band\nby default. In order not to miss the actually unpredictable timing of a\npotential short duration signal, a network of co-ordinated axion antennae is\nrequired, preferentially distributed world-wide. The reasoning presented here\nfor the axions applies to some degree also to any other DM candidates like the\nWIMPs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A computationally-efficient method for evaluating friction in molecular\nrotary bearings is presented. This method estimates drag from fluctuations in\nmolecular dynamics simulations via the fluctuation-dissipation theorem. This is\neffective even for simulation times short compared to a bearing's energy\ndamping time and for rotation speeds comparable to or below typical thermal\nvalues. We apply this method to two molecular rotary bearings of similar size\nat 300K: previously studied nested (9,9)/(14,14) double-walled carbon nanotubes\nand a hypothetical rotary joint consisting of single acetylenic bonds in a\nrigid diamondoid housing. The acetylenic joint has a rotational frictional drag\ncoefficient of $2 \\times 10^{-35}\\,\\mbox{kg m${}^2$/s}$. The friction for the\nnested nanotubes is 120 times larger, comparable to values reported by previous\nstudies. This fluctuation-based method could evaluate dissipation in a variety\nof molecular systems with similarly rigid and symmetric bearings.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Pulsars have been invoked to explain the origin of recently observed\nhigh-energy Galactic cosmic-ray positrons. Since the positron propagation\ndistance decreases with energy, the number of pulsars that can contribute to\nthe observed positrons decreases from $O(10^3)$ for positron energies\n$E\\gtrsim10$ GeV to only a few for $E \\gtrsim 500$ GeV. Thus, if pulsars\nexplain these positrons, the positron energy spectrum should become\nincreasingly bumpy at higher energies. Here we present a power-spectrum\nanalysis that can be applied to seek such spectral features in the energy\nspectrum for cosmic-ray positrons and for the energy spectrum of the combined\nelectron/positron flux. We account for uncertainties in the pulsar distribution\nby generating hundreds of simulated spectra from pulsar distributions\nconsistent with current observational constraints. Although the current AMS-02\ndata do not exhibit evidence for spectral features, we find that such features\nwould be detectable in $\\simeq 10\\%$ of our simulations, with 20 years of\nAMS-02 data or three years of DAMPE measurements on the electron-plus-positron\nflux.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  How to effectively approximate real-valued parameters with binary codes plays\na central role in neural network binarization. In this work, we reveal an\nimportant fact that binarizing different layers has a widely-varied effect on\nthe compression ratio of network and the loss of performance. Based on this\nfact, we propose a novel and flexible neural network binarization method by\nintroducing the concept of layer-wise priority which binarizes parameters in\ninverse order of their layer depth. In each training step, our method selects a\nspecific network layer, minimizes the discrepancy between the original\nreal-valued weights and its binary approximations, and fine-tunes the whole\nnetwork accordingly. During the iteration of the above process, it is\nsignificant that we can flexibly decide whether to binarize the remaining\nfloating layers or not and explore a trade-off between the loss of performance\nand the compression ratio of model. The resulting binary network is applied for\nefficient pedestrian detection. Extensive experimental results on several\nbenchmarks show that under the same compression ratio, our method achieves much\nlower miss rate and faster detection speed than the state-of-the-art neural\nnetwork binarization method.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $f\\in\\mathbb{Z}[X]$ be quadratic or cubic polynomial. We prove that there\nexists an integer $G_f\\geq 2$ such that for every integer $k\\geq G_f$ one can\nfind infinitely many integers $n\\geq 0$ with the property that none of\n$f(n+1),f(n+2),\\dots,f(n+k)$ is coprime to all the others. This extends\nprevious results on linear polynomials and, in particular, on consecutive\nintegers.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Heating induced by the noise postulated in wave function collapse models\nleads to a lower bound to the temperature of solid objects. For the noise\nparameter values $\\lambda ={\\rm coupling~strength}\\sim 10^{-8} {\\rm s}^{-1}$\nand $r_C ={\\rm correlation~length} \\sim 10^{-5} {\\rm cm}$, which were suggested\n\\cite{adler1} to make latent image formation an indicator of wave function\ncollapse and which are consistent with the recent experiment of Vinante et al.\n\\cite{vin}, the effect may be observable. For metals, where the heat\nconductivity is proportional to the temperature at low temperatures, the lower\nbound (specifically for RRR=30 copper) is $\\sim 5\\times 10^{-11} (L/r_C) $K,\nwith L the size of the object. For the thermal insulator Torlon 4203, the\ncomparable lower bound is $\\sim 3 \\times 10^{-6} (L/r_c)^{0.63}$ K. We first\ngive a rough estimate for a cubical metal solid, and then give an exact\nsolution of the heat transfer problem for a sphere.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show how the one-mode pseudo-bosonic ladder operators provide concrete\nexamples of nilpotent Lie algebras of dimension five. It is the first time that\nan algebraic-geometric structure of this kind is observed in the context of\npseudo-bosonic operators. Indeed we don't find the well known Heisenberg\nalgebras, which are involved in several quantum dynamical systems, but\ndifferent Lie algebras which may be decomposed in the sum of two abelian Lie\nalgebras in a prescribed way. We introduce the notion of semidirect sum (of Lie\nalgebras) for this scope and find that it describes very well the behaviour of\npseudo-bosonic operators in many quantum models.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A selective classifier (f,g) comprises a classification function f and a\nbinary selection function g, which determines if the classifier abstains from\nprediction, or uses f to predict. The classifier is called\npointwise-competitive if it classifies each point identically to the best\nclassifier in hindsight (from the same class), whenever it does not abstain.\nThe quality of such a classifier is quantified by its rejection mass, defined\nto be the probability mass of the points it rejects. A \"fast\" rejection rate is\nachieved if the rejection mass is bounded from above by O(1/m) where m is the\nnumber of labeled examples used to train the classifier (and O hides\nlogarithmic factors). Pointwise-competitive selective (PCS) classifiers are\nintimately related to disagreement-based active learning and it is known that\nin the realizable case, a fast rejection rate of a known PCS algorithm (called\nConsistent Selective Strategy) is equivalent to an exponential speedup of the\nwell-known CAL active algorithm.\n  We focus on the agnostic setting, for which there is a known algorithm called\nLESS that learns a PCS classifier and achieves a fast rejection rate (depending\non Hanneke's disagreement coefficient) under strong assumptions. We present an\nimproved PCS learning algorithm called ILESS for which we show a fast rate\n(depending on Hanneke's disagreement coefficient) without any assumptions. Our\nrejection bound smoothly interpolates the realizable and agnostic settings. The\nmain result of this paper is an equivalence between the following three\nentities: (i) the existence of a fast rejection rate for any PCS learning\nalgorithm (such as ILESS); (ii) a poly-logarithmic bound for Hanneke's\ndisagreement coefficient; and (iii) an exponential speedup for a new\ndisagreement-based active learner called ActiveiLESS.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the last years, various extensions of {\\omega}-regular languages have been\nproposed in the literature, including {\\omega}B-regular ({\\omega}-regular\nlanguages extended with boundedness), {\\omega}S-regular ({\\omega}-regular\nlanguages extended with strict unboundedness), and {\\omega}BS-regular languages\n(the combination of {\\omega}B- and {\\omega}S-regular ones). While the first two\nclasses satisfy a generalized closure property, namely, the complement of an\n{\\omega}B-regular (resp., {\\omega}S-regular) language is an {\\omega}S-regular\n(resp., {\\omega}B-regular) one, the last class is not closed under\ncomplementation. The existence of non-{\\omega}BS-regular languages that are the\ncomplements of some {\\omega}BS-regular ones and express fairly natural\nproperties of reactive systems motivates the search for other well-behaved\nclasses of extended {\\omega}-regular languages. In this paper, we introduce the\nclass of {\\omega}T-regular languages, that includes meaningful languages which\nare not {\\omega}BS-regular. We first define it in terms of {\\omega}T-regular\nexpressions. Then, we introduce a new class of automata (counter-check\nautomata) and we prove that (i) their emptiness problem is decidable in PTIME\nand (ii) they are expressive enough to capture {\\omega}T-regular languages\n(whether or not {\\omega}T-regular languages are expressively complete with\nrespect to counter-check automata is still an open problem). Finally, we\nprovide an encoding of {\\omega}T-regular expressions into S1S+U.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A number of recent estimates of the total luminosities of galaxies in the\nSDSS are significantly larger than those reported by the SDSS pipeline. This is\nbecause of a combination of three effects: one is simply a matter of defining\nthe scale out to which one integrates the fit when defining the total\nluminosity, and amounts on average to < 0.1 mags even for the most luminous\ngalaxies. The other two are less trivial and tend to be larger; they are due to\ndifferences in how the background sky is estimated and what model is fit to the\nsurface brightness profile. We show that PyMorph sky estimates are fainter than\nthose of the SDSS DR7 or DR9 pipelines, but are in excellent agreement with the\nestimates of Blanton et al. (2011). Using the SDSS sky biases luminosities by\nmore than a few tenths of a magnitude for objects with half-light radii > 7\narcseconds. In the SDSS main galaxy sample these are typically luminous\ngalaxies, so they are not necessarily nearby. This bias becomes worse when\nallowing the model more freedom to fit the surface brightness profile. When\nPyMorph sky values are used, then two component Sersic-Exponential fits to\nE+S0s return more light than single component deVaucouleurs fits (up to ~0.2\nmag), but less light than single Sersic fits (0.1 mag). Finally, we show that\nPyMorph fits of Meert et al. (2015) to DR7 data remain valid for DR9 images.\nOur findings show that, especially at large luminosities, these PyMorph\nestimates should be preferred to the SDSS pipeline values.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The aim of this paper is to characterize the notion of internal category\n(groupoid) in the category of Leibniz algebras and investigate the properties\nof well-known notions such as covering groupoid and groupoid operations\n(actions) in this category. Further, for a fixed internal groupoid $G$, we\nprove that the category of covering groupoids of $G$ and the category of\ninternal groupoid actions of $G$ on Leibniz algebras are equivalent. Finally we\ninterpret the corresponding notion of covering groupoids in the category of\ncrossed modules of Leibniz algebras.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Mitigating Supply-Demand mismatch is critical for smooth power grid\noperation. Traditionally, load curtailment techniques such as Demand Response\n(DR) have been used for this purpose. However, these cannot be the only\ncomponent of a net-load balancing framework for Smart Grids with high PV\npenetration. These grids can sometimes exhibit supply surplus causing\nover-voltages. Supply curtailment techniques such as Volt-Var Optimizations are\ncomplex and computationally expensive. This increases the complexity of\nnet-load balancing systems used by the grid operator and limits their\nscalability. Recently new technologies have been developed that enable the\nrapid and selective connection of PV modules of an installation to the grid.\nTaking advantage of these advancements, we develop a unified optimal net-load\nbalancing framework which performs both load and solar curtailment. We show\nthat when the available curtailment values are discrete, this problem is\nNP-hard and develop bounded approximation algorithms for minimizing the\ncurtailment cost. Our algorithms produce fast solutions, given the tight timing\nconstraints required for grid operation. We also incorporate the notion of\nfairness to ensure that curtailment is evenly distributed among all the nodes.\nFinally, we develop an online algorithm which performs net-load balancing using\nonly data available for the current interval. Using both theoretical analysis\nand practical evaluations, we show that our net-load balancing algorithms\nprovide solutions which are close to optimal in a small amount of time.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using in situ grazing-incidence x-ray scattering, we have measured the\ndiffuse scattering from islands that form during layer-by-layer growth of GaN\nby metal-organic vapor phase epitaxy on the (1010) m-plane surface. The diffuse\nscattering is extended in the (0001) in-plane direction in reciprocal space,\nindicating a strong anisotropy with islands elongated along [1 $\\overline{2}$\n10] and closely spaced along [0001]. This is confirmed by atomic force\nmicroscopy of a quenched sample. Islands were characterized as a function of\ngrowth rate G and temperature. The island spacing along [0001] observed during\nthe growth of the first monolayer obeys a power-law dependence on growth rate\nG$^{-n}$, with an exponent $n = 0.25 \\pm 0.02$. Results are in agreement with\nrecent kinetic Monte Carlo simulations, indicating that elongated islands\nresult from the dominant anisotropy in step edge energy and not from surface\ndiffusion anisotropy. The observed power-law exponent can be explained using a\nsimple steady-state model, which gives n = 1/4.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Inspired by recent successes using single-stranded DNA tiles to produce\ncomplex structures, we develop a two-step coarse-graining approach that uses\ndetailed thermodynamic calculations with oxDNA, a nucleotide-based model of\nDNA, to parametrize a coarser kinetic model that can reach the time and length\nscales needed to study the assembly mechanisms of these structures. We test the\nmodel by performing a detailed study of the assembly pathways for a\ntwo-dimensional target structure made up of 334 unique strands each of which\nare 42 nucleotides long. Without adjustable parameters, the model reproduces a\ncritical temperature for the formation of the assembly that is close to the\ntemperature at which assembly first occurs in experiments. Furthermore, the\nmodel allows us to investigate in detail the nucleation barriers and the\ndistribution of critical nucleus shapes for the assembly of a single target\nstructure. The assembly intermediates are compact and highly connected\n(although not maximally so) and classical nucleation theory provides a good fit\nto the height and shape of the nucleation barrier at temperatures close to\nwhere assembly first occurs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Business process models describe the way of working in an organization.\nTypically, business process models distinguish between the normal flow of work\nand exceptions to that normal flow. However, they often present an idealized\nview. This means that unexpected exceptions - exceptions that are not modelled\nin the business process model - can also occur in practice. This has an effect\non the efficiency of the organization, because information systems are not\ndeveloped to handle unexpected exceptions. This paper studies the relation\nbetween the occurrence of exceptions and operational performance. It does this\nby analyzing the execution logs of business processes from five organizations,\nclassifying execution paths as normal or exceptional. Subsequently, it analyzes\nthe differences between normal and exceptional paths. The results show that\nexceptions are related to worse operational performance in terms of a longer\nthroughput time and that unexpected exceptions relate to a stronger increase in\nthroughput time than expected exceptions.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We define Wick-rotations by considering pseudo-Riemannian manifolds as real\nslices of a holomorphic Riemannian manifold. From a frame bundle viewpoint\nWick-rotations between different pseudo-Riemannian spaces can then be studied\nthrough their structure groups which are real forms of the corresponding\ncomplexified Lie group (different real forms $O(p,q)$ of the complex Lie group\n$O(n,\\mathbb{C})$). In this way, we can use real GIT (geometric invariant\ntheory) to derive several new results regarding the existence, and\nnon-existence, of such Wick-rotations. As an explicit example, we Wick rotate a\nknown $G_2$-holonomy manifold to a pseudo-Riemannian manifold with split-$G_2$\nholonomy.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Most successful deep learning algorithms for action recognition extend models\ndesigned for image-based tasks such as object recognition to video. Such\nextensions are typically trained for actions on single video frames or very\nshort clips, and then their predictions from sliding-windows over the video\nsequence are pooled for recognizing the action at the sequence level. Usually\nthis pooling step uses the first-order statistics of frame-level action\npredictions. In this paper, we explore the advantages of using higher-order\ncorrelations; specifically, we introduce Higher-order Kernel (HOK) descriptors\ngenerated from the late fusion of CNN classifier scores from all the frames in\na sequence. To generate these descriptors, we use the idea of kernel\nlinearization. Specifically, a similarity kernel matrix, which captures the\ntemporal evolution of deep classifier scores, is first linearized into kernel\nfeature maps. The HOK descriptors are then generated from the higher-order\nco-occurrences of these feature maps, and are then used as input to a\nvideo-level classifier. We provide experiments on two fine-grained action\nrecognition datasets and show that our scheme leads to state-of-the-art\nresults.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper presents a novel technique that allows for both computationally\nfast and sufficiently plausible simulation of vehicles with non-deformable\ntracks. The method is based on an effect we have called Contact Surface Motion.\nA comparison with several other methods for simulation of tracked vehicle\ndynamics is presented with the aim to evaluate methods that are available\noff-the-shelf or with minimum effort in general-purpose robotics simulators.\nThe proposed method is implemented as a plugin for the open-source\nphysics-based simulator Gazebo using the Open Dynamics Engine.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Identifying disease genes from human genome is an important and fundamental\nproblem in biomedical research. Despite many publications of machine learning\nmethods applied to discover new disease genes, it still remains a challenge\nbecause of the pleiotropy of genes, the limited number of confirmed disease\ngenes among whole genome and the genetic heterogeneity of diseases. Recent\napproaches have applied the concept of 'guilty by association' to investigate\nthe association between a disease phenotype and its causative genes, which\nmeans that candidate genes with similar characteristics as known disease genes\nare more likely to be associated with diseases. However, due to the imbalance\nissues (few genes are experimentally confirmed as disease related genes within\nhuman genome) in disease gene identification, semi-supervised approaches, like\nlabel propagation approaches and positive-unlabeled learning, are used to\nidentify candidate disease genes via making use of unknown genes for training -\ntypically in the scenario of a small amount of confirmed disease genes (labeled\ndata) with a large amount of unknown genome (unlabeled data). The performance\nof Disease gene prediction models are limited by potential bias of single\nlearning models and incompleteness and noise of single biological data sources,\ntherefore ensemble learning models are applied via combining multiple diverse\nbiological sources and learning models to obtain better predictive performance.\nIn this thesis, we propose three computational models for identifying candidate\ndisease genes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove upper bounds on the sum of Betti numbers of tropical prevarieties in\ndense and sparse settings. In the dense setting the bound is in terms of the\nvolume of Minkowski sum of Newton polytopes of defining tropical polynomials,\nor, alternatively, via the maximal degree of these polynomials. In sparse\nsetting, the bound involves the number of the monomials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We carried out line survey observations at the 26-30 GHz band toward the four\nhigh-mass star-forming regions containing hot cores, G10.30-0.15, G12.89+0.49,\nG16.86-2.16, and G28.28-0.36, with the Robert C. Byrd Green Bank Telescope. We\nhave detected HC5N from all of the sources, and HC7N from the three sources,\nexcept for G10.30-0.15. We further conducted observations of HC5N at the 42-46\nGHz and 82-103 GHz bands toward the three sources, G12.89+0.49, G16.86-2.16,\nand G28.28-0.36, with the Nobeyama 45 m radio telescope. The rotational lines\nof HC5N with the high excitation energies (Eu/k=63-100 K), which are hardly\nexcited in the cold dark clouds, have been detected from the three sources. The\nrotational temperatures of HC5N are found to be 13-20 K in the three sources.\nThe detection of the lines with the high excitation energies and the derived\nrotational temperatures indicate that HC5N exists in the warm gas within\n0.07-0.1 pc radii around massive young stellar objects. The column densities of\nHC5N in the three sources are derived to be (2.0+-2.8)*10^(13) cm-2 . We\ncompare the ratios between N(HC5N) the column density of HC5N and W(CH3OH) the\nintegrated intensity of the thermal CH3OH emission line among the three\nhigh-mass star-forming regions. We found a possibility of the chemical\ndifferentiation in the three high-mass star-forming regions; G28.28-0.36 shows\nthe largest N (HC5N)/W (CH3OH) ratio of > 8.0*10^(14) in units of (K km s-1 )-1\ncm-2 , while G12.89+0.49 and G16.86-2.16 show the smaller values (~2*10^(13) ).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  With a rapidly increasing number of devices connected to the internet, big\ndata has been applied to various domains of human life. Nevertheless, it has\nalso opened new venues for breaching users' privacy. Hence it is highly\nrequired to develop techniques that enable data owners to privatize their data\nwhile keeping it useful for intended applications. Existing methods, however,\ndo not offer enough flexibility for controlling the utility-privacy trade-off\nand may incur unfavorable results when privacy requirements are high. To tackle\nthese drawbacks, we propose a compressive-privacy based method, namely RUCA\n(Ratio Utility and Cost Analysis), which can not only maximize performance for\na privacy-insensitive classification task but also minimize the ability of any\nclassifier to infer private information from the data. Experimental results on\nCensus and Human Activity Recognition data sets demonstrate that RUCA\nsignificantly outperforms existing privacy preserving data projection\ntechniques for a wide range of privacy pricings.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We construct a monoidal category $\\mathscr{C}_{w,v}$ which categorifies the\ndoubly-invariant algebra $^{N'(w)}\\mathbb{C}[N]^{N(v)}$ associated with Weyl\ngroup elements $w$ and $v$. It gives, after a localization, the coordinate\nalgebra $\\mathbb{C}[\\mathcal{R}_{w,v}]$ of the open Richardson variety\nassociated with $w$ and $v$. The category $\\mathscr{C}_{w,v}$ is realized as a\nsubcategory of the graded module category of a quiver Hecke algebra $R$. When\n$v= \\mathrm{id}$, $\\mathscr{C}_{w,v}$ is the same as the monoidal category\nwhich provides a monoidal categorification of the quantum unipotent coordinate\nalgebra $A_q(\\mathfrak{n}(w))_{\\mathbb{Z}[q,q^{-1}]}$ given by\nKang-Kashiwara-Kim-Oh. We show that the category $\\mathscr{C}_{w,v}$ contains\nspecial determinantial modules $\\mathsf{M}(w_{\\le k}\\Lambda, v_{\\le k}\\Lambda)$\nfor $k=1, \\ldots, \\ell(w)$, which commute with each other. When the quiver\nHecke algebra $R$ is symmetric, we find a formula of the degree of $R$-matrices\nbetween the determinantial modules $\\mathsf{M}(w_{\\le k}\\Lambda, v_{\\le\nk}\\Lambda)$. When it is of finite $ADE$ type, we further prove that there is an\nequivalence of categories between $\\mathscr{C}_{w,v}$ and $\\mathscr{C}_u$ for\n$w,u,v \\in \\mathsf{W}$ with $w = vu$ and $\\ell(w) = \\ell(v) + \\ell(u)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper proposes a real-time embedded fall detection system using a\nDVS(Dynamic Vision Sensor) that has never been used for traditional fall\ndetection, a dataset for fall detection using that, and a DVS-TN(DVS-Temporal\nNetwork). The first contribution is building a DVS Falls Dataset, which made\nour network to recognize a much greater variety of falls than the existing\ndatasets that existed before and solved privacy issues using the DVS. Secondly,\nwe introduce the DVS-TN : optimized deep learning network to detect falls using\nDVS. Finally, we implemented a fall detection system which can run on\nlow-computing H/W with real-time, and tested on DVS Falls Dataset that takes\ninto account various falls situations. Our approach achieved 95.5% on the\nF1-score and operates at 31.25 FPS on NVIDIA Jetson TX1 board.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider the problem of streaming kernel regression, when the observations\narrive sequentially and the goal is to recover the underlying mean function,\nassumed to belong to an RKHS. The variance of the noise is not assumed to be\nknown. In this context, we tackle the problem of tuning the regularization\nparameter adaptively at each time step, while maintaining tight confidence\nbounds estimates on the value of the mean function at each point. To this end,\nwe first generalize existing results for finite-dimensional linear regression\nwith fixed regularization and known variance to the kernel setup with a\nregularization parameter allowed to be a measurable function of past\nobservations. Then, using appropriate self-normalized inequalities we build\nupper and lower bound estimates for the variance, leading to Bersntein-like\nconcentration bounds. The later is used in order to define the adaptive\nregularization. The bounds resulting from our technique are valid uniformly\nover all observation points and all time steps, and are compared against the\nliterature with numerical experiments. Finally, the potential of these tools is\nillustrated by an application to kernelized bandits, where we revisit the\nKernel UCB and Kernel Thompson Sampling procedures, and show the benefits of\nthe novel adaptive kernel tuning strategy.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We measure the gravitational lensing signal around satellite galaxies in a\nsample of galaxy clusters at $z<0.15$ by combining high-quality imaging data\nfrom the Canada-France-Hawaii Telescope with a large sample of\nspectroscopically-confirmed cluster members. We use extensive image simulations\nto assess the accuracy of shape measurements of faint, background sources in\nthe vicinity of bright satellite galaxies. We find a small but significant\nbias, as light from the lenses makes the shapes of background galaxies appear\nradially aligned with the lens. We account for this bias by applying a\ncorrection that depends on both lens size and magnitude. We also correct for\ncontamination of the source sample by cluster members. We use a\nphysically-motivated definition of subhalo mass, namely the mass bound to the\nsubhalo, $m_\\mathrm{bg}$, similar to definitions used by common subhalo finders\nin numerical simulations. Binning the satellites by stellar mass we provide a\ndirect measurement of the subhalo-to-stellar-mass relation, $\\log\nm_\\mathrm{bg}/\\mathrm{M}_\\odot = (11.54\\pm0.05) +\n(0.95\\pm0.10)\\log[m_\\star/(2\\times10^{10}\\mathrm{M}_\\odot)]$. This best-fitting\nrelation implies that, at a stellar mass\n$m_\\star\\sim3\\times10^{10}\\,\\mathrm{M}_\\odot$, subhalo masses are roughly 50\nper cent of those of central galaxies, and this fraction decreases at higher\nstellar masses. We find some evidence for a sharp change in the\ntotal-to-stellar mass ratio around the clusters' scale radius, which could be\ninterpreted as galaxies within the scale radius having suffered more strongly\nfrom tidal stripping, but remain cautious regarding this interpretation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We implement a spatially fixed mesh refinement under spherical symmetry for\nthe characteristic formulation of General Relativity. The\nCourant-Friedrich-Levy (CFL) condition lets us deploy an adaptive resolution in\n(retarded-like) time, even for the nonlinear regime. As test cases, we\nreplicate the main features of the gravitational critical behavior and the\nspacetime structure at null infinity using the Bondi mass and the News\nfunction. Additionally, we obtain the global energy conservation for an extreme\nsituation, i.e. in the threshold of the black hole formation. In principle, the\ncalibrated code can be used in conjunction with an ADM 3+1 code to confirm the\ncritical behavior recently reported in the gravitational collapse of a massless\nscalar field in an asymptotic anti-de Sitter spacetime. For the scenarios\nstudied, the fixed mesh refinement offers improved runtime and results\ncomparable to code without mesh refinement.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A strong certification process is required to insure the safety of airplanes,\nand more specifically the robustness of avionics applications. To implement\nthis process, the development of avionics software must follow long and costly\nprocedures. Most of these procedures have to be reexecuted each time the\nsoftware is modified. In this paper, we propose a framework to reduce the cost\nand time impact of a software modification. With this new approach, the piece\nof software likely to change is isolated from the rest of the application, so\nit can be certified independently. This helps the system integrator to adapt an\navionics application to the specificities of the target airplane, without the\nneed for a new certification of the application.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We develop a unifying framework for Bayesian nonparametric regression to\nstudy the rates of contraction with respect to the integrated $L_2$-distance\nwithout assuming the regression function space to be uniformly bounded. The\nframework is very flexible and can be applied to a wide class of nonparametric\nprior models. Three non-trivial applications of the proposed framework are\nprovided: The finite random series regression of an $\\alpha$-H\\\"older function,\nwith adaptive rates of contraction up to a logarithmic factor; The un-modified\nblock prior regression of an $\\alpha$-Sobolev function, with adaptive-and-exact\nrates of contraction; The Gaussian spline regression of an $\\alpha$-H\\\"older\nfunction, with the near-optimal posterior contraction. These applications serve\nas generalization or complement of their respective results in the literature.\nExtensions to the fixed-design regression problem and sparse additive models in\nhigh dimensions are discussed as well.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A close connection of reverse plane partitions with an integrable dynamical\nsystem called the discrete two-dimensional (2D) Toda molecule is clarified. It\nis shown that a multiplicative partition function for reverse plane partition\nof arbitrary shape with bounded parts can be obtained from each non-vanishing\nsolution to the discrete 2D Toda molecule. As an example a partition function\nwhich generalizes MacMahon's triple product formula as well as Gansner's\nmulti-trace generating function is derived from a specific solution to the\ndynamical system.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A F0 and voicing status estimation algorithm for high quality speech\nanalysis/synthesis is proposed. This problem is approached from a different\nperspective that models the behavior of feature extractors under noise, instead\nof directly modeling speech signals. Under time-frequency locality assumptions,\nthe joint distribution of extracted features and target F0 can be characterized\nby training a bank of Gaussian mixture models (GMM) on artificial data\ngenerated from Monte-Carlo simulations. The trained GMMs can then be used to\ngenerate a set of conditional distributions on the predicted F0, which are then\ncombined and post-processed by Viterbi algorithm to give a final F0 trajectory.\nEvaluation on CSTR and CMU Arctic speech databases shows that the proposed\nmethod, trained on fully synthetic data, achieves lower gross error rates than\nstate-of-the-art methods.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The center of mass dynamics of cold atoms and the Bose-Einstein condensate in\none dimensional optical lattice is considered both in the absence and in the\npresence of external forcing. We discuss three situations for matter waves:\nfirst, the cold atoms; second, sufficiently dilute condensate where the\ndynamics are governed by the single particle wave packet dynamics; third,\nstrong interaction regime, where, inter-atomic interaction can no longer be\nignored. The analytical formalism developed for the two regimes, namely, deep\noptical lattice and shallow optical lattice. Parametric dependencies of energy\nspectrum and classical period, revival time and super revival are explained for\nthe two regimes.\n  The dynamics of condensate in driven optical lattice crystal are analyzed by\nstudying dynamical stability of the condensate. The stability is determined by\nthe dispersion behavior of the condensate excited in driven optical lattice.\nThe recurrence behavior of the condensate close to the nonlinear resonances is\nanalyzed as a function of time for delicate recurrences which take place for\ninstance when lattice is weakly perturbed and robust recurrences which may\nmanifest themselves for sufficiently strong external driving force.\n  The analysis is not only valid for dilute condensate but also applicable for\nstrongly interacting homogeneous condensate provided, the external modulation\ncauses no significant change in density profile of the condensate. We explain\nparametric dependence of the dynamical recurrence times which can easily be\nrealized in laboratory experiments. In addition, we find a good agreement\nbetween the obtained analytical results and numerical calculations. The\nstability of condensate is also explored in driven optical lattice numerically.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using the notion of contiguity of simplicial maps, we adapt Farber's\ntopological complexity to the realm of simplicial complexes. We show that, for\na finite simplicial complex $K$, our discretized concept recovers the\ntopological complexity of the realization $\\|K\\|$. Our approach is well suited\nfor designing and implementing algorithms that search for optimal motion\nplanners for autonomous systems in real-life applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we extend and analyze the nonperturbative\nMaxwell-Schr\\\"odinger-Plasma (MASP) model. This model was proposed to describe\nthe high order optical nonlinearities, and the low density free electron plasma\ngenerated by a laser pulse propagating in a gas. The MASP model is based on\nnonasymptotic, ab-initio equations, and accurately uses self-consistent\ndescription of micro (quantum)- and macro (field)- variables. However, its\nmajor drawback is a high computational cost, which in practice means that only\nshort propagation lengths can be calculated. In order to reduce this cost, we\nstudy the MASP models enriched by a macroscopic evolution equation for\npolarization, from its simplest version in a form of transport equation, to\nmore complex nonlinear variants. We show that homogeneous transport equation is\na more universal tool to simulate the high harmonic spectra at shorter times\nand/or at a lower computational cost, while the nonlinear equation could be\nuseful for modeling the pulse profiles when the ionization level is moderate.\nThe gain associated with the considered modifications of the MASP model, being\nexpressed in reduction of computational time and the number of processors\ninvolved, is of 2-3 orders of magnitude.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In tunnel junctions between ferromagnets and heavy elements with strong spin\norbit coupling the magnetoresistance is often dominated by tunneling\nanisotropic magnetoresistance (TAMR). This makes conventional DC spin injection\ntechniques impractical for determining the spin relaxation time ($\\tau_s$).\nHere, we show that this obstacle for measurements of $\\tau_s$ can be overcome\nby 2nd harmonic spin-injection-magnetoresistance (SIMR). In the 2nd harmonic\nsignal the SIMR is comparable in magnitude to TAMR, thus enabling Hanle-induced\nSIMR as a powerful tool to directly determine $\\tau_s$. Using this approach we\ndetermined the spin relaxation time of Pt and Ta and their temperature\ndependences. The spin relaxation in Pt seems to be governed by Elliott-Yafet\nmechanism due to a constant resistivity $\\times$spin relaxation time product\nover a wide temperature range.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we present a novel localized Generative Adversarial Net (GAN)\nto learn on the manifold of real data. Compared with the classic GAN that {\\em\nglobally} parameterizes a manifold, the Localized GAN (LGAN) uses local\ncoordinate charts to parameterize distinct local geometry of how data points\ncan transform at different locations on the manifold. Specifically, around each\npoint there exists a {\\em local} generator that can produce data following\ndiverse patterns of transformations on the manifold. The locality nature of\nLGAN enables local generators to adapt to and directly access the local\ngeometry without need to invert the generator in a global GAN. Furthermore, it\ncan prevent the manifold from being locally collapsed to a dimensionally\ndeficient tangent subspace by imposing an orthonormality prior between\ntangents. This provides a geometric approach to alleviating mode collapse at\nleast locally on the manifold by imposing independence between data\ntransformations in different tangent directions. We will also demonstrate the\nLGAN can be applied to train a robust classifier that prefers locally\nconsistent classification decisions on the manifold, and the resultant\nregularizer is closely related with the Laplace-Beltrami operator. Our\nexperiments show that the proposed LGANs can not only produce diverse image\ntransformations, but also deliver superior classification performances.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We measure the hyperfine structure of the $5p^65d$ ${}^2D_{3/2}$, $5p^65d$\n${}^2D_{5/2}$, $5p^64f$ ${}^2F^o_{5/2}$, and $5p^64f$ ${}^2F^o_{7/2}$ levels in\ndoubly-ionized lanthanum (La III; La$^{2+}$) in a hollow cathode lamp using\noptogalvanic spectroscopy. Analysis of the observed spectra allows us to\ndetermine the hyperfine $A$ coefficients for these levels to be\n$A_{D3/2}=412(4)$ MHz, $A_{D5/2}=20(5)$ MHz, $A_{F5/2}=319(2)$ MHz, and\n$A_{F7/2}=155(4)$ MHz; and provide estimates for the hyperfine $B$ coefficients\nas $B_{D3/2}=105(29)$ MHz, $B_{D5/2}=157(40)$ MHz, $B_{F5/2}=-2(53)$ MHz, and\n$B_{F7/2}=171(51)$ MHz.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  For scalar semilinear wave equations, we analyze the interaction of two\n(distorted) plane waves at an interface between media of different nonlinear\nproperties. We show that new waves are generated from the nonlinear\ninteractions, which might be responsible for the observed nonlinear effects in\napplications. Also, we show that the incident waves and the nonlinear responses\ndetermine the location of the interface and some information of the nonlinear\nproperties of the media. In particular, for the case of a jump discontinuity at\nthe interface, we can determine the magnitude of the jump.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The present tutorial provides an overview of the time-dependent configuration\ninteraction singles (\\acs{TDCIS}) scheme applied to nonlinear ionization over a\nbroad photon-energy range. The efficient propagation of the wave function and\nthe calculation of photoelectron spectra within this approach are described and\ndemonstrated in various applications. Above-threshold ionization of argon and\nxenon in the extreme ultraviolet energy range is investigated as an example. A\nparticular focus is put on the xenon $4d$ giant dipole resonance and the\ninformation that nonlinear ionization can provide about resonance substructure.\nFurthermore, above-threshold ionization is studied in the x-ray regime and the\nintensity regime, at which multiphoton ionization starts to play a role at hard\nx-ray photon energies, is identified.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the effects of small static defects in the spacetime manifold.\nThe presence of the defects leads to a modification of the scalar field\ntwo-point function in Klein-Gordon theory. We calculate the energy-momentum\ntensor and discuss the possible mass generation for the scalar field in single\nand multiple defect spacetimes. We also extend these results to the photon\nfield and show that, as a result of the interaction with the defects, the\nphoton dispersion relations are modified.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The formation of self-organised structures that resist shear deformation have\nbeen discussed in the context of shear jamming and thickening[1-3], with\nfrictional forces playing a key role. However, shear induces geometric features\nnecessary for jamming even in frictionless packings[4]. We analyse conditions\nfor jamming in such assemblies by solving force and torque balance conditions\nfor their contact geometry. We demonstrate, and validate with frictional\nsimulations, that the isostatic condition for mean contact number Z = D + 1\n(for spatial dimension D = 2, 3) holds at jamming for both finite and infinite\nfriction, above the random loose packing density. We show that the shear\njamming threshold satisfies the marginal stability condition recently proposed\nfor jamming in frictionless systems[5]. We perform rigidity percolation\nanalysis[6,7] for D = 2 and find that rigidity percolation precedes shear\njamming, which however coincides with the percolation of over-constrained\nregions, leading to the identification of an intermediate phase analogous to\nthat observed in covalent glasses[8].\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We review the component Lagrangian construction of the supersymmetric higher\nspin models in three dimensional (3D) Minkowski and anti de Sitter (AdS)\nspaces. The approach is based on the frame-like gauge invariant formulation,\nwhere massive higher spin fields are realized through a system of massless\nones. We develop a supersymmetric generalization of this formulation to the\nLagrangian construction of the on-shell N=1, 3D higher spin supermultiplets. In\n3D Minkowski space we show that the massive supermultiplets can be constructed\nfrom one extended massless supermultiplet by adding the mass terms to the\nLagrangian and the corresponding corrections to the supertransformations of the\nfermionic fields. In 3D AdS space we construct massive supermultiplets using a\nformulation of the massive fields in terms of the set of gauge invariant\nobjects (curvatures) in the process of their consistent supersymmetric\ndeformation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report the first results from a search for transiting warm Jupiter\nexoplanets - gas giant planets receiving stellar irradiation below about $10^8$\nerg s$^{-1}$ cm$^{-2}$, equivalent to orbital periods beyond about 10 days\naround Sun-like stars. We have discovered two transiting warm Jupiter\nexoplanets initially identified as transiting candidates in ${\\it K2}$\nphotometry. K2-114b has a mass of $1.85^{+0.23}_{-0.22}\\ M_J$, a radius of\n$0.942^{+0.032}_{-0.020}\\ R_J$, and an orbital period of 11.4 days. K2-115b has\na mass of $0.84^{+0.18}_{-0.20}\\ M_J$, a radius of $1.115^{+0.057}_{-0.061}\\\nR_J$, and an orbital period of 20.3 days. Both planets are among the longest\nperiod transiting gas giant planets with a measured mass, and they are orbiting\nrelatively old host stars. Both planets are not inflated as their radii are\nconsistent with theoretical expectations. Their position in the planet radius -\nstellar irradiation diagram is consistent with the scenario where the radius -\nirradiation correlation levels off below about 10$^8$ erg s$^{-1}$ cm$^{-2}$,\nsuggesting that for warm Jupiters the stellar irradiation does not play a\nsignificant role in determining the planet radius. We also report our\nidentification of another ${\\it K2}$ transiting warm Jupiter candidate, EPIC\n212504617, as a false positive.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A common issue encountered in photoemission electron sources used in electron\naccelerators is the transverse inhomogeneity of the laser distribution\nresulting from the laser-amplification process and often use of frequency up\nconversion in nonlinear crystals. A inhomogeneous laser distribution on the\nphotocathode produces charged beams with lower beam quality. In this paper, we\nexplore the possible use of microlens arrays (fly-eye light condensers) to\ndramatically improve the transverse uniformity of the drive laser pulse on UV\nphotocathodes. We also demonstrate the use of such microlens arrays to generate\ntransversely-modulated electron beams and present a possible application to\ndiagnose the properties of a magnetized beam.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we present a regular black hole solution, in the context of\nscale-dependent General Relativity, satisfying the weak energy condition. The\nsource of this solution is an anisotropic effective energy-momentum tensor\nwhich appears when the scale dependence of the theory is turned-on. In this\nsense, the solution can be considered as a semiclassical extension of the\nSchwarzschild one.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Finding the conditions that foster synchronization in networked oscillatory\nsystems is critical to understanding a wide range of biological and mechanical\nsystems. However, the conditions proved in the literature for synchronization\nin nonlinear systems with linear coupling, such as has been used to model\nneuronal networks, are in general not strict enough to accurately determine the\nsystem behavior. We leverage contraction theory to derive new sufficient\nconditions for cluster synchronization in terms of the network structure, for a\nnetwork where the intrinsic nonlinear dynamics of each node may differ. Our\nresult requires that network connections satisfy a cluster-input-equivalence\ncondition, and we explore the influence of this requirement on network\ndynamics. For application to networks of nodes with neuronal spiking dynamics,\nwe show that our new sufficient condition is tighter than those found in\nprevious analyses which used nonsmooth Lyapunov functions. Improving the\nanalytical conditions for when cluster synchronization will occur based on\nnetwork configuration is a significant step toward facilitating understanding\nand control of complex oscillatory systems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Choreographies are widely used for the specification of concurrent and\ndistributed software architectures. Since asynchronous communications are\nubiquitous in real-world systems, previous works have proposed different\napproaches for the formal modelling of asynchrony in choreographies. Such\napproaches typically rely on ad-hoc syntactic terms or semantics for capturing\nthe concept of messages in transit, yielding different formalisms that have to\nbe studied separately.\n  In this work, we take a different approach, and show that such extensions are\nnot needed to reason about asynchronous communications in choreographies.\nRather, we demonstrate how a standard choreography calculus already has all the\nneeded expressive power to encode messages in transit (and thus asynchronous\ncommunications) through the primitives of process spawning and name mobility.\nThe practical consequence of our results is that we can reason about real-world\nsystems within a choreography formalism that is simpler than those hitherto\nproposed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Envisioned for fifth generation (5G) systems, millimeter-wave (mmWave)\ncommunications are under very active research worldwide. Although pencil beams\nwith accurate beamtracking may boost the throughput of mmWave systems, this\nposes great challenges in the design of radio resource allocation for highly\nmobile users. In this paper, we propose a joint adaptive beam-frequency\nallocation algorithm that takes into account the position uncertainty inherent\nto high mobility and/or unstable users as, e.g., Unmanned Aerial Vehicles\n(UAV), for whom this is a major problem. Our proposed method provides an\noptimized beamwidth selection under quality of service (QoS) requirements for\nmaximizing system proportional fairness, under user position uncertainty. The\nrationale of our scheme is to adapt the beamwidth such that the best trade-off\namong system performance (narrower beam) and robustness to uncertainty (wider\nbeam) is achieved. Simulation results show that the proposed method largely\nenhances the system performance compared to reference algorithms, by an\nappropriate adaptation of the mmWave beamwidths, even under severe\nuncertainties and imperfect channel state information (CSIs).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We develop an explicit theory of Kummer varieties associated to Jacobians of\nhyperelliptic curves of genus 3, over any field $k$ of characteristic $\\neq 2$.\nIn particular, we provide explicit equations defining the Kummer variety\n$\\mathcal K$ as a subvariety of $\\mathbb P^7$, together with explicit\npolynomials giving the duplication map on $\\mathcal K$. A careful study of the\ndegenerations of this map then forms the basis for the development of an\nexplicit theory of heights on such Jacobians when $k$ is a number field. We use\nthis input to obtain a good bound on the difference between naive and canonical\nheight, which is a necessary ingredient for the explicit determination of the\nMordell-Weil group. We illustrate our results with two examples.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we review previously developed coarse-grained (CG) particle\nmodels for biological membrane and red blood cells (RBCs) and discuss the\nadvantages of the CG particle method over the continuum and atomic simulations\non modeling biological phenomena. CG particle models can largely increase the\nlength scale and time scale of atomic simulations by eliminating fast degrees\nof freedom while preserving the mesoscopic structures and properties of the\nsimulated system. One the other hand, CG particle models can be used to capture\nmicrostructural alternations in diseased RBCs and simulate topological changes\nof biological membrane and RBCs, which are major challenges to typical\ncontinuum representations of membrane and RBCs. The power and versatility of\nthe CG particle methods are demonstrated through simulating the dynamical\nprocesses involving significant topological changes, such as lipid\nself-assembly, vesicle fusion and membrane budding.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the stability of the horizon in a warped anti-de Sitter black\nhole based on the three-dimensional new massive gravity by particle absorption.\nIf a particle moving towards the black hole enters its outer horizon, the black\nhole changes because it absorbs conserved quantities of the particle. This\nvariation is constrained by the equations of motion for the particle. We prove\nboth the irreducibility of the entropy and stability of the horizon for the\nblack hole through this process. However, the instability of the horizon is\nfound in a near-extremal black hole by considering its second-order expansion.\nWe resolve this instability by applying an adiabatic process for the\nabsorption. Further, we show that the stability has the physical counterpart to\nthe energy spectrum of the Virasoro generator via the warped anti-de\nSitter/warped conformal field theory correspondence.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove that for bounded and convex domains in arbitrary dimensions, the\nMaxwell constants are bounded from below and above by Friedrichs' and\nPoincare's constants, respectively. Especially, the second positive Maxwell\neigenvalues in ND are bounded from below by the square root of the second\nNeumann-Laplace eigenvalue.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Network Function Virtualization (NFV) shed new light for the design,\ndeployment, and management of cloud networks. Many network functions such as\nfirewalls, load balancers, and intrusion detection systems can be virtualized\nby servers. However, network operators often have to sacrifice programmability\nin order to achieve high throughput, especially at networks' edge where complex\nnetwork functions are required.\n  Here, we design, implement, and evaluate Hybrid Modular Switch (HyMoS). The\nhybrid hardware/software switch is designed to meet requirements for modern-day\nNFV applications in providing high-throughput, with a high degree of\nprogrammability. HyMoS utilizes P4-compatible Network Interface Cards (NICs),\nPCI Express interface and CPU to act as line cards, switch fabric, and fabric\ncontroller respectively. In our implementation of HyMos, PCI Express interface\nis turned into a non-blocking switch fabric with a throughput of hundreds of\nGigabits per second.\n  Compared to existing NFV infrastructure, HyMoS offers modularity in hardware\nand software as well as a higher degree of programmability by supporting a\nsuperset of P4 language.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using the language of the Geometric Algebra, we recast the massless Dirac\nbispinor as a set of Lorentz scalar, bivector, and pseudoscalar fields that\nobey a generalized form of Maxwell's equations of electromagnetism. The\nspinor's unusual 4-pi rotation symmetry is seen to be a mathematical artifact\nof the projection of these fields onto an abstract vector space, and not a\nphysical property of the dynamical fields themselves. We also find a deeper\nunderstanding of the spin angular momentum and other Dirac field bilinears in\nterms of these fields and their corresponding analogues in classical\nelectromagnetism.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Applications that envisage utilizing the orbital angular momentum (OAM) at\nthe single photon level assume that the OAM degrees of freedom that the photons\ninherit from the classical wave solutions are orthogonal. To test this critical\nassumption, we quantize the beam-like solutions of the vector Helmholtz\nequation from first principles to delineate its elementary quantum mechanical\ndegrees of freedom. We show that although the beam-photon operators do not in\ngeneral satisfy the canonical commutation relations, implying that the photon\nstates they create are not orthogonal, the states are nevertheless bona fide\neigenstates of the number and Hamiltonian operators. The explicit\nrepresentation for the photon operators presented in this work forms a natural\nbasis to study light-matter interactions and quantum information processing at\nthe single photon level.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Strong light absorption, coupled with moderate carrier transport properties,\nmakes two-dimensional (2-D) layered transition metal dichalcogenide (TMD)\nsemiconductors promising candidates for low intensity photodetection\napplications. However, the performance of these devices is severely\nbottlenecked by slow response with persistent photocurrent due to long lived\ncharge trapping, and nonreliable characteristics due to undesirable ambience\nand substrate effects. Here we demonstrate ultra-high specific detectivity (D*)\nof 3.2x10^14 Jones and responsivity (R) of 5.77x10^4 AW-1 at an optical power\ndensity (P_op) of 0.26 Wm-2 and external bias (V_ext) of -0.5 V in an indium\ntin oxide (ITO)/MoS2/copper oxide (Cu2O)/Au vertical multi-heterojunction\nphotodetector exhibiting small carrier transit time. The active MoS2 layer\nbeing encapsulated by carrier collection layers allows us to achieve negligible\ntrap assisted persistent photocurrent and repeatable characteristics over large\nnumber of cycles. We also achieved a large D*>10^14 Jones at zero external bias\ndue to the built-in field of the asymmetric photodetector. Benchmarking the\nperformance against existing reports in literature shows a pathway for\nachieving reliable and highly sensitive photodetectors for ultra-low intensity\nphotodetection applications.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A recently proposed covariant chiral effective field theory approach is\napplied to study strangeness $S=-1$ hyperon-nucleon interactions at leading\norder. 12 low energy constants are introduced by Lorentz invariance, which is\ndifferent from the heavy baryon approach, where only five appear. The\nKadyshevsky equation is employed to iterate the chiral potentials. A quite\nsatisfactory description of the 36 hyperon-nucleon scattering data is obtained\nwith $\\chi^2\\simeq 17$, which is comparable with the next-to-leading order\nheavy baryon approach. The results hint at a more efficient way to construct\nthe chiral potentials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using wide spectral range in situ spectroscopic ellipsometry with systematic\nultra high vacuum annealing and in situ exposure to oxygen, we report the\ncomplex dielectric function of MoS$_2$ isolating the environmental effects and\nrevealing the crucial role of unpassivated and passivated sulphur vacancies.\nThe spectral weights of the A ($1.92$ eV) and B ($2.02$ eV) exciton peaks in\nthe dielectric function reduce significantly upon annealing, accompanied by\nspectral weight transfer in a broad energy range. Interestingly, the original\nspectral weights are recovered upon controlled oxygen exposure. This tunability\nof the excitonic effects is likely due to passivation and reemergence of the\ngap states in the bandstructure during oxygen adsorption and desorption,\nrespectively, as indicated by ab initio density functional theory calculation\nresults. This work unravels and emphasizes the important role of adsorbed\noxygen in the optical spectra and many-body interactions of MoS$_2$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a method to construct Riesz MRA on local fields of positive\ncharacteristic and corresponding scaling step functions that generate it.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Many new physics scenarios beyond the Standard Model often necessitate the\nexistence of a (light) neutral scalar $H$, which might couple to the charged\nleptons in a flavor violating way, while evading all existing constraints. We\nshow that such scalars could be effectively produced at future lepton\ncolliders, either on-shell or off-shell depending on their mass, and induce\nlepton flavor violating (LFV) signals, i.e. $e^+ e^- \\to \\ell_\\alpha^\\pm\n\\ell_\\beta^\\mp (+H)$ with $\\alpha\\neq \\beta$. We find that a large parameter\nspace of the scalar mass and the LFV couplings can be probed, well beyond the\ncurrent low-energy constraints in the lepton sector. In particular, a\nscalar-loop induced explanation of the longstanding muon $g-2$ anomaly can be\ndirectly tested in the on-shell mode.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Cauchy problem for the Schr\\\"odinger equations is studied with\ntime-dependent potentials growing polynomially in the spatial direction. First\nthe existence and the uniqueness of solutions are shown in the weighted Sobolev\nspaces. In addition, we suppose that our potentials are depending on a\nparameter. Secondly it is shown that if potentials depend continuously and\ndifferentiably on the parameter, the solutions to the Schr\\\"odinger equations\nrespectively become continuous and differentiable with respect to its\nparameter.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we construct a generalized Kane model with a new coupling term\nbetween itinerant electron spins and local magnetic moments of\nanti-ferromagnetic ordering in order to describe the low energy effective\nphysics in a large family of anti-ferromagnetic half-Heusler materials.\nTopological properties of this generalized Kane model is studied and a large\nvariety of topological phases, including Dirac semimetal phase, Weyl semimetal\nphase, nodal line semimetal phase, type-B triple point semimetal phase,\ntopological mirror (or glide) insulating phase and anti-ferromagnetic\ntopological insulating phase, are identified in different parameter regions of\nour effective models. In particular, we find that the system is always driven\ninto the anti-ferromagnetic topological insulator phase once a bulk band gap is\nopen, irrespective of the magnetic moment direction, thus providing a robust\nrealization of anti-ferromagentic topological insulators. Furthermore, we\ndiscuss the possible realization of these topological phases in realistic\nanti-ferromagnetic half-Heusler materials. Our effective model provides a basis\nfor the future study of physical phenomena in this class of materials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a blueprint for building a fault-tolerant universal quantum\ncomputer with Rydberg atoms. Our scheme, which is based on the surface code,\nuses individually-addressable optically-trapped atoms as qubits and exploits\nelectromagnetically induced transparency to perform the multi-qubit gates\nrequired for error correction and computation. We discuss the advantages and\nchallenges of using Rydberg atoms to build such a quantum computer, and we\nperform error correction simulations to obtain an error threshold for our\nscheme. Our findings suggest that Rydberg atoms are a promising candidate for\nquantum computation, but gate fidelities need to improve before fault-tolerant\nuniversal quantum computation can be achieved.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper revisits recognition of natural image pleasantness by employing\ndeep convolutional neural networks and affordable eye trackers. There exist\nseveral approaches to recognize image pleasantness: (1) computer vision, and\n(2) psychophysical signals. For natural images, computer vision approaches have\nnot been as successful as for abstract paintings and is lagging behind the\npsychophysical signals like eye movements. Despite better results, the\nscalability of eye movements is adversely affected by the sensor cost. While\nthe introduction of affordable sensors have helped the scalability issue by\nmaking the sensors more accessible, the application of such sensors in a\nloosely controlled human-computer interaction setup is not yet studied for\naffective image tagging. On the other hand, deep convolutional neural networks\nhave boosted the performance of vision-based techniques significantly in recent\nyears. To investigate the current status in regard to affective image tagging,\nwe (1) introduce a new eye movement dataset using an affordable eye tracker,\n(2) study the use of deep neural networks for pleasantness recognition, (3)\ninvestigate the gap between deep features and eye movements. To meet these\nends, we record eye movements in a less controlled setup, akin to daily\nhuman-computer interaction. We assess features from eye movements, visual\nfeatures, and their combination. Our results show that (1) recognizing natural\nimage pleasantness from eye movement under less restricted setup is difficult\nand previously used techniques are prone to fail, and (2) visual class\ncategories are strong cues for predicting pleasantness, due to their\ncorrelation with emotions, necessitating careful study of this phenomenon. This\nlatter finding is alerting as some deep learning approaches may fit to the\nclass category bias.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Additive cyclic codes over Galois rings were investigated in previous works.\nIn this paper, we investigate the same problem but over a more general ring\nfamily, finite commutative chain rings. When we focus on non-Galois finite\ncommutative chain rings, we observe two different kinds of additivity. One of\nthem is a natural generalization of the previous studies, whereas the other one\nhas some unusual properties especially while constructing dual codes. We\ninterpret the reasons of such properties and illustrate our results giving\nconcrete examples.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Search-based testing is widely used to find bugs in models of complex\nCyber-Physical Systems. Latest research efforts have improved this approach by\ncasting it as a falsification procedure of formally specified temporal\nproperties, exploiting the robustness semantics of Signal Temporal Logic. The\nscaling of this approach to highly complex engineering systems requires\nefficient falsification procedures, which should be applicable also to black\nbox models. Falsification is also exacerbated by the fact that inputs are often\ntime-dependent functions. We tackle the falsification of formal properties of\ncomplex black box models of Cyber-Physical Systems, leveraging machine learning\ntechniques from the area of Active Learning. Tailoring these techniques to the\nfalsification problem with time-dependent, functional inputs, we show a\nconsiderable gain in computational effort, by reducing the number of model\nsimulations needed. The goodness of the proposed approach is discussed on a\nchallenging industrial-level benchmark from automotive.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider three fundamental classes of compact almost homogeneous manifolds\nand show that the complements of singular complex orbits in such manifolds are\nendowed with plurisubharmonic exhaustions satisfying complex homogeneous\nMonge-Amp\\`ere equations. This extends to a new family of mixed type examples\nvarious classical results on parabolic spaces and complexifications of\nsymmetric spaces. Rigidity results on complex spaces modeled on such new\nexamples are given.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the computation of canonical bases of sets of univariate relations\n$(p_1,\\ldots,p_m) \\in \\mathbb{K}[x]^{m}$ such that $p_1 f_1 + \\cdots + p_m f_m\n= 0$; here, the input elements $f_1,\\ldots,f_m$ are from a quotient\n$\\mathbb{K}[x]^n/\\mathcal{M}$, where $\\mathcal{M}$ is a $\\mathbb{K}[x]$-module\nof rank $n$ given by a basis $\\mathbf{M}\\in\\mathbb{K}[x]^{n\\times n}$ in\nHermite form. We exploit the triangular shape of $\\mathbf{M}$ to generalize a\ndivide-and-conquer approach which originates from fast minimal approximant\nbasis algorithms. Besides recent techniques for this approach, we rely on\nhigh-order lifting to perform fast modular products of polynomial matrices of\nthe form $\\mathbf{P}\\mathbf{F} \\bmod \\mathbf{M}$.\n  Our algorithm uses $O\\tilde{~}(m^{\\omega-1}D + n^{\\omega} D/m)$ operations in\n$\\mathbb{K}$, where $D = \\mathrm{deg}(\\det(\\mathbf{M}))$ is the\n$\\mathbb{K}$-vector space dimension of $\\mathbb{K}[x]^n/\\mathcal{M}$,\n$O\\tilde{~}(\\cdot)$ indicates that logarithmic factors are omitted, and\n$\\omega$ is the exponent of matrix multiplication. This had previously only\nbeen achieved for a diagonal matrix $\\mathbf{M}$. Furthermore, our algorithm\ncan be used to compute the shifted Popov form of a nonsingular matrix within\nthe same cost bound, up to logarithmic factors, as the previously fastest known\nalgorithm, which is randomized.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a non-symmetric operad $\\mathcal{N}$, whose dimension in degree\n$n$ is given by the Catalan number $c_{n-1}$. It arises naturally in the study\nof coalgebra structures defined on compatible associative algebras. We prove\nthat any free compatible associative algebra admits a compatible infinitesimal\nbialgebra structure, whose subspace of primitive elements is a\n$\\mathcal{N}$-algebra. The data $({\\rm As},{\\rm As}^2, \\mathcal{N})$ is a good\ntriple of operads, in J.-L. Loday's sense. Our construction induces another\ntriple of operads $({\\rm As},{\\rm As}_2,{\\rm As})$, where ${\\rm As}_2$ is the\noperad of matching dialgebras. Motivated by A. Goncharov's Hopf algebra of\npaths $P(S)$, we introduce the notion of bi-matching dialgebras and show that\nthe Hopf algebra $P(S)$ is a bi-matching dialgebras.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Network translation has recently been used to establish steady state\nproperties of mass action systems by corresponding the given system to a\ngeneralized one which is either dynamically or steady state equivalent. In this\nwork we further use network translation to identify network structures which\ngive rise to the well-studied property of absolute concentration robustness in\nthe corresponding mass action systems. In addition to establishing the capacity\nfor absolute concentration robustness, we show that network translation can\noften provide a method for deriving the steady state value of the robust\nspecies. We furthermore present a MILP algorithm for the identification of\ntranslated chemical reaction networks that improves on previous approaches,\nallowing for easier application of the theory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The mixed Hydrogen and Helium (H + He) spectrum with a clear steepening at\n$\\sim 700$ TeV has been detected by ARGO-YBJ experiments. In this paper, we\ndemonstrate that the observed H + He spectrum can be well reproduced with the\nmodel of cosmic rays escaping from the supernova remnants (SNRs) in our Galaxy.\nIn this model, particles are accelerated in a SNR through a non-linear\ndiffusive shock acceleration mechanism and three components of high energy\nlight nuclei escaped from the SNR are considered. It should be noted that the\nproton spectrum observed by KASCADE can be also explained by this model given a\nhigher acceleration efficiency.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Two basic routes for planetesimal formation have been proposed over the last\nfew decades. One is a classical \"slow-growth\" scenario. Another one is particle\nconcentration models, in which small pebbles are concentrated locally and then\ncollapse gravitationally to form planetesimals. Both types of models make\ncertain predictions for the size spectrum and internal structure of newly-born\nplanetesimals. We use these predictions as input to simulate collisional\nevolution of debris discs left after the gas dispersal. The debris disc\nemission as a function of a system's age computed in these simulations is\ncompared with several Spitzer and Herschel debris disc surveys around A-type\nstars. We confirm that the observed brightness evolution for the majority of\ndiscs can be reproduced by classical models. Further, we find that it is\nequally consistent with the size distribution of planetesimals predicted by\nparticle concentration models - provided the objects are loosely bound \"pebble\npiles\" as these models also predict. Regardless of the assumed planetesimal\nformation mechanism, explaining the brightest debris discs in the samples\nuncovers a \"disc mass problem.\" To reproduce such discs by collisional\nsimulations, a total mass of planetesimals of up to ~1000 Earth masses is\nrequired, which exceeds the total mass of solids available in the\nprotoplanetary progenitors of debris discs. This may indicate that stirring was\ndelayed in some of the bright discs, that giant impacts occurred recently in\nsome of them, that some systems may be younger than previously thought, or that\nnon-collisional processes contribute significantly to the dust production.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this note, we obtain a full characterization of radial Carleson measures\nfor the Hilbert-Hardy space on tube domains over symmetric cones. For large\nderivatives, we also obtain a full characterization of the measures for which\nthe corresponding embedding operator is continuous. Restricting to the case of\nlight cones of dimension three, we prove that by freezing one or two variables,\nthe problem of embedding derivatives of the Hilbert-Hardy space into Lebesgue\nspaces reduces to the characterization of Carleson measures for Hilbert-Bergman\nspaces of the upper-half plane or the product of two upper-half planes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We have recently extended the scalar-pseudoscalar sector of a generalized NJL\nLagrangian that includes all NLO non derivative interactions in Nc counting\n(including explicit symmetry breaking ones) in order to incorporate the spin 1\nmesons in the low-lying ground state of QCD [1]. Upon bosonization, the well\nknown mixing of the scalar-vector and of the pseudoscalar- axial-vector fields\noccurs in the quadratic part of the Lagrangian. We show that a linearized\ndiagonalization of these terms can be effected in a completely general way\nwithout compromising the underlying symmetries of the Lagrangian [2]. The\nresulting spin 1 mass spectra evidence a relation involving only the vector and\naxial-vector meson masses and the constituent quark masses. We discuss the\ndominant role of this relation in the fits and we show that the model may be\nfitted to accommodate to a very good accuracy the 4 low-lying meson spectra.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We lay foundations of the subject in the title, on which we build in another\npaper devoted to isometries in spaces of K\\\"ahler metrics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Central Compact Objects (CCOs) are a handful of sources located close to the\ngeometrical center of young supernova remnants. They only show thermal-like,\nsoft X-ray emission and have no counterparts at any other wavelength. While the\nfirst observed CCO turned out to be a very peculiar magnetar, discovery that\nthree members of the family are weakly magnetised Isolated Neutron Stars (INSs)\nset the basis for an interpretation of the class. However, the phenomeology of\nCCOs and their relationship with other classes of INSs, possibly ruled by\nsupernova fall-back accretion, are still far from being well understood.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present in this article a survey of recent results in value distribution\ntheory for the Gauss maps of several classes of immersed surfaces in space\nforms, for example, minimal surfaces in Euclidean $n$-space ($n$=3 or 4),\nimproper affine spheres in the affine 3-space and flat surfaces in hyperbolic\n3-space. In particular, we elucidate the geometric background of their results.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a unified product embedded representation that is optimized for\nthe task of retrieval-based product recommendation. To this end, we introduce a\nnew way to fuse modality-specific product embeddings into a joint product\nembedding, in order to leverage both product content information, such as\ntextual descriptions and images, and product collaborative filtering signal. By\nintroducing the fusion step at the very end of our architecture, we are able to\ntrain each modality separately, allowing us to keep a modular architecture that\nis preferable in real-world recommendation deployments. We analyze our\nperformance on normal and hard recommendation setups such as cold-start and\ncross-category recommendations and achieve good performance on a large product\nshopping dataset.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study a class of stably projectionless simple C*-algebras which may be\nviewed as having generalized tracial rank one in analogy with the unital case.\nSome structural question concerning these simple C*-algebras are studied. The\npaper also serves as a technical support for the classification of separable\nstably projectionless simple amenable Jiang-Su stable C*-algebras.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A scheme to generate highly collimated $\\gamma$-ray pulse is proposed for the\nproduction of muon and electron pairs in $\\gamma-\\gamma$ collider. The\n$\\gamma$-ray pulse, with high conversion efficiency, can be produced as the\nresult of electron phase-locked acceleration in longitudinal electric field\nthrough the interaction between an ultra-intense laser pulse and a narrow tube\ntarget. Numerical simulation shows that 18\\% energy of a 10-PW laser pulse is\ntransferred into the forward $\\gamma$-rays in a divergence angle less than $\n3^\\circ$. The $\\gamma$-ray pulse is applied in $\\gamma-\\gamma$ collider, in\nwhich muon pairs can be produced and electron pairs can be enhanced by more\nthan 3 orders of magnitude. This scheme, which could be realized with the\ncoming 10PW class laser pulses, would allow the observation of a\n$\\gamma-\\gamma$ collider for electron and muon pairs in laboratory.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss the unique spin evolution of the young X-ray pulsar PSR\nJ0537-6910, a system in which the regular spin down is interrupted by glitches\nevery few months. Drawing on the complete timing data from the Rossi X-ray\nTiming Explorer (RXTE, from 1999-2011), we argue that a trend in the\ninter-glitch behaviour points to an effective braking index close to $n=7$,\nmuch larger than expected. This value is interesting because it would accord\nwith the neutron star spinning down due to gravitational waves from an unstable\nr-mode. We discuss to what extent this, admittedly speculative, scenario may be\nconsistent and if the associated gravitational-wave signal would be within\nreach of ground based detectors. Our estimates suggest that one may, indeed, be\nable to use future observations to test the idea. Further precision timing\nwould help enhance the achievable sensitivity and we advocate a joint observing\ncampaign between the Neutron Star Interior Composition ExploreR (NICER) and the\nLIGO-Virgo network.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The synchronization process inherent to the Bitcoin network gives rise to an\ninfinite-server model with the unusual feature that customers interact. Among\nthe closed-form characteristics that we derive for this model is the busy\nperiod distribution which, counterintuitively, does not depend on the arrival\nrate. We explain this by exploiting the equivalence between two specific\nservice disciplines, which is also used to derive the model's stationary\ndistribution. Next to these closed-form results, the second major contribution\nconcerns an asymptotic result: a fluid limit in the presence of service delays.\nSince fluid limits arise under scalings of the law-of-large-numbers type, they\nare usually deterministic, but in the setting of the model discussed in this\npaper the fluid limit is random (more specifically, of growth-collapse type).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this theoretical study, we explore the manner in which the quantum\ncorrection due to weak localization is suppressed in weakly-disordered\ngraphene, when it is subjected to the application of a non-zero voltage. Using\na nonequilibrium Green function approach, we address the scattering generated\nby the disorder up to the level of the maximally crossed diagrams, hereby\ncapturing the interference among different, impurity-defined, Feynman paths.\nOur calculations of the charge current, and of the resulting differential\nconductance, reveal the logarithmic divergence typical of weak localization in\nlinear transport. The main finding of our work is that the applied voltage\nsuppresses the weak localization contribution in graphene, by introducing a\ndephasing time that decreases inversely with increasing voltage.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Evaluating expression of the Human epidermal growth factor receptor 2 (Her2)\nby visual examination of immunohistochemistry (IHC) on invasive breast cancer\n(BCa) is a key part of the diagnostic assessment of BCa due to its recognised\nimportance as a predictive and prognostic marker in clinical practice. However,\nvisual scoring of Her2 is subjective and consequently prone to inter-observer\nvariability. Given the prognostic and therapeutic implications of Her2 scoring,\na more objective method is required. In this paper, we report on a recent\nautomated Her2 scoring contest, held in conjunction with the annual PathSoc\nmeeting held in Nottingham in June 2016, aimed at systematically comparing and\nadvancing the state-of-the-art Artificial Intelligence (AI) based automated\nmethods for Her2 scoring. The contest dataset comprised of digitised whole\nslide images (WSI) of sections from 86 cases of invasive breast carcinoma\nstained with both Haematoxylin & Eosin (H&E) and IHC for Her2. The contesting\nalgorithms automatically predicted scores of the IHC slides for an unseen\nsubset of the dataset and the predicted scores were compared with the 'ground\ntruth' (a consensus score from at least two experts). We also report on a\nsimple Man vs Machine contest for the scoring of Her2 and show that the\nautomated methods could beat the pathology experts on this contest dataset.\nThis paper presents a benchmark for comparing the performance of automated\nalgorithms for scoring of Her2. It also demonstrates the enormous potential of\nautomated algorithms in assisting the pathologist with objective IHC scoring.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a description of vacuum polarization in a circular Dirac quantum\ndot in two spatial dimensions assuming $\\alpha$ - the relative strength of the\nCoulomb interaction small enough to render an approximation with a single\nelectron (hole) lowest energy level relevant. Applying this approximation, we\nfind that for $ \\alpha_c \\approx 1.05$ the lowest level is half-filled\nirrespective of the number of flavors that are present. The ground state can be\nrepresented as a superposition of particular (even number) excitonic states\nwhich constitute an excitonic cloud that evolves in a crossover manner. The\nground state is degenerate with an intervalley excitonic state at $ \\alpha_c\n\\approx 1.05$, a critical strength, that in our approximation marks a point\nwith single electron and exciton resonances.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Consider the classical Gaussian unitary ensemble of size $N$ and the real\nWishart ensemble $W_N(n,I)$. In the limits as $N \\to \\infty$ and $N/n \\to\n\\gamma > 0$, the expected number of eigenvalues that exit the upper bulk edge\nis less than one, 0.031 and 0.170 respectively, the latter number being\nindependent of $\\gamma$. These statements are consequences of quantitative\nbounds on tail sums of eigenvalues outside the bulk which are established here\nfor applications in high dimensional covariance matrix estimation.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Complex networked systems are an integral part of today's support\ninfrastructures. Due to their importance, these systems become more and more\nthe target for cyber-attacks, suffering a notable number of security incidents.\nAlso, they are subject to regulation by national and international legislation.\nAn operator of such an infrastructure or system is responsible for ensuring its\nsecurity and correct functioning in order to satisfy customers. In addition,\nthe entire process of risk and quality control needs to be efficient and\nmanageable. This short paper introduces the Compliance, Risk Assessment and\nSecurity Testing Improvement Profiling (CRSTIP) scheme. CRSTIP is an evaluation\nscheme that enables assessing the maturity of security assessment processes,\ntaking into consideration systematic use of formalisms, integration and\ntool-support in the areas of compliance assessment, security risk assessment\nand security testing. The paper describes the elements of the scheme and their\napplication to one of the case studies of the RASEN research project.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Stability and chemistry, both exohedral and endohedral, of fullerenes are\ncritically dependent on the distribution of their obligatory 12 pentagonal\nfaces. It is well known that there are infinitely many IPR-fullerenes and that\nthe pentagons in these fullerenes can be at an arbitrarily large distance from\neach other. IPR-fullerenes can be described as fullerenes in which each\nconnected cluster of pentagons has size 1. In this paper we study the\ncombinations of cluster sizes that can occur in fullerenes and whether the\nclusters can be at an arbitrarily large distance from each other. For each\npossible partition of the number 12, we are able to decide whether the\npartition describes the sizes of pentagon clusters in a possible fullerene, and\nstate whether the different clusters can be at an arbitrarily large distance\nfrom each other. We will prove that all partitions with largest cluster of size\n5 or less can occur in an infinite number of fullerenes with the clusters at an\narbitrarily large distance of each other, that 9 partitions occur in only a\nfinite number of fullerene isomers and that 15 partitions do not occur at all\nin fullerenes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Classical engines turn thermal resources into work, which is maximized for\nreversible operations. The quantum realm has expanded the range of useful\noperations beyond energy conversion, and incoherent resources beyond thermal\nreservoirs. This is the case of entanglement generation in a driven-dissipative\nprotocol, which we hereby analyze as a continuous quantum machine. We show that\nfor such machines the more irreversible the process the larger the concurrence.\nMaximal concurrence and entropy production are reached for the hot reservoir\nbeing at negative effective temperature, beating the limits set by classic\nthermal operations on an equivalent system.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study large-scale kinematic dynamo action of steady mirror-antisymmetric\nflows of incompressible fluid, that involve small spatial scales only, by\nasymptotic methods of the multiscale stability theory. It turns out that, due\nto the magnetic $\\alpha$-effect in such flows, the large-scale mean field\nexperiences harmonic oscillations in time on the scale O($\\varepsilon t$)\nwithout growth or decay. Here $\\varepsilon$ is the spatial scale ratio and $t$\nis the fast time of the order of the flow turnover time. The interaction of the\naccompanying fluctuating magnetic field with the flow gives rise to an\nanisotropic magnetic eddy diffusivity, whose dependence on the direction of the\nlarge-scale wave vector generically exhibits a singular behaviour, and thus to\nnegative eddy diffusivity for whichever molecular magnetic diffusivity.\nConsequently, such flows always act as kinematic dynamos on the time scale\nO($\\varepsilon^2t$); for the directions at which eddy diffusivity is infinite,\nthe large-scale mean-field growth rate is finite on the scale\nO($\\varepsilon^{3/2}t$). We investigate numerically this dynamo mechanism for\ntwo sample flows.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss channel surfaces in the context of Lie sphere geometry and\ncharacterise them as certain $\\Omega_{0}$-surfaces. Since $\\Omega_{0}$-surfaces\npossess a rich transformation theory, we study the behaviour of channel\nsurfaces under these transformations. Furthermore, by using certain Dupin\ncyclide congruences, we characterise Ribaucour pairs of channel surfaces.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This article introduces a k-Inflated Negative Binomial mixture\ndistribution/regression model as a more flexible alternative to zero-inflated\nPoisson distribution/regression model. An EM algorithm has been employed to\nestimate the model's parameters. Then, such new model along with a Pareto\nmixture model have been employed to design an optimal rate--making system.\nNamely, this article employs number/size of reported claims of Iranian third\nparty insurance dataset. Then, it employs the k-Inflated Negative Binomial\nmixture distribution/regression model as well as other well developed counting\nmodels along with a Pareto mixture model to model frequency/severity of\nreported claims in Iranian third party insurance dataset. Such numerical\nillustration shows that: ({\\bf 1}) the k-Inflated Negative Binomial mixture\nmodels provide more fair rate/pure premiums for policyholders under a\nrate--making system; and ({\\bf 2}) in the situation that number of reported\nclaims uniformly distributed in past experience of a policyholder (for instance\n$k_1=1$ and $k_2=1$ instead of $k_1=0$ and $k_2=2$). The rate/pure premium\nunder the k-Inflated Negative Binomial mixture models are more appealing and\nacceptable.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider tissue P systems working on vesicles of multisets with the very\nsimple operations of insertion, deletion, and substitution of single objects.\nWith the whole multiset being enclosed in a vesicle, sending it to a target\ncell can be indicated in those simple rules working on the multiset. As\nderivation modes we consider the sequential mode, where exactly one rule is\napplied in a derivation step, and the set maximal mode, where in each\nderivation step a non-extendable set of rules is applied. With the set maximal\nmode, computational completeness can already be obtained with tissue P systems\nhaving a tree structure, whereas tissue P systems even with an arbitrary\ncommunication structure are not computationally complete when working in the\nsequential mode. Adding polarizations (-1, 0, 1 are sufficient) allows for\nobtaining computational completeness even for tissue P systems working in the\nsequential mode.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the fluid transport of particles, it is generally expected that heavy\nparticles carried by a laminar fluid flow moving downward will also move\ndownward. We establish a theory to show, however, that particles can be\ndynamically levitated and lifted by interacting vortices in such flows, thereby\nmoving against gravity and the asymptotic direction of the flow, even when they\nare orders of magnitude denser than the fluid. The particle levitation is\nrigorously demonstrated for potential flows and supported by simulations for\nviscous flows. We suggest that this counterintuitive effect has potential\nimplications for the air-transport of water droplets and the lifting of\nsediments in water.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider the two-variable fragment of first-order logic with one\ndistinguished binary predicate constrained to be interpreted as a transitive\nrelation. The finite satisfiability problem for this logic is shown to be\ndecidable, in triply exponential non-deterministic time. The complexity falls\nto doubly exponential non-deterministic time if the distinguished binary\npredicate is constrained to be interpreted as a partial order.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Deep learning methods can play a crucial role in anomaly detection,\nprediction, and supporting decision making for applications like personal\nhealth-care, pervasive body sensing, etc. However, current architecture of deep\nnetworks suffers the privacy issue that users need to give out their data to\nthe model (typically hosted in a server or a cluster on Cloud) for training or\nprediction. This problem is getting more severe for those sensitive health-care\nor medical data (e.g fMRI or body sensors measures like EEG signals). In\naddition to this, there is also a security risk of leaking these data during\nthe data transmission from user to the model (especially when it's through\nInternet). Targeting at these issues, in this paper we proposed a new\narchitecture for deep network in which users don't reveal their original data\nto the model. In our method, feed-forward propagation and data encryption are\ncombined into one process: we migrate the first layer of deep network to users'\nlocal devices, and apply the activation functions locally, and then use\n\"dropping activation output\" method to make the output non-invertible. The\nresulting approach is able to make model prediction without accessing users'\nsensitive raw data. Experiment conducted in this paper showed that our approach\nachieves the desirable privacy protection requirement, and demonstrated several\nadvantages over the traditional approach with encryption / decryption\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Time Projection Chamber (TPC) has been chosen as the main tracking system in\nseveral high-flux and high repetition rate experiments. These include on-going\nexperiments such as ALICE and future experiments such as PANDA at FAIR and ILC.\nDifferent $\\mathrm{R}\\&\\mathrm{D}$ activities were carried out on the adoption\nof Gas Electron Multiplier (GEM) as the gas amplification stage of the\nALICE-TPC upgrade version. The requirement of low ion feedback has been\nestablished through these activities. Low ion feedback minimizes distortions\ndue to space charge and maintains the necessary values of detector gain and\nenergy resolution. In the present work, Garfield simulation framework has been\nused to study the related physical processes occurring within single, triple\nand quadruple GEM detectors. Ion backflow and electron transmission of\nquadruple GEMs, made up of foils with different hole pitch under different\nelectromagnetic field configurations (the projected solutions for the ALICE\nTPC) have been studied. Finally a new triple GEM detector configuration with\nlow ion backflow fraction and good electron transmission properties has been\nproposed as a simpler GEM-based alternative suitable for TPCs for future\ncollider experiments.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We discuss the design of state-of-the-art numerical methods for molecular\ndynamics, focusing on the demands of soft matter simulation, where the purposes\ninclude sampling and dynamics calculations both in and out of equilibrium. We\ndiscuss the characteristics of different algorithms, including their essential\nconservation properties, the convergence of averages, and the accuracy of\nnumerical discretizations. Formulations of the equations of motion which are\nsuited to both equilibrium and nonequilibrium simulation include Langevin\ndynamics, dissipative particle dynamics (DPD), and the more recently proposed\n\"pairwise adaptive Langevin\" (PAdL) method, which, like DPD but unlike Langevin\ndynamics, conserves momentum and better matches the relaxation rate of\norientational degrees of freedom. PAdL is easy to code and suitable for a\nvariety of problems in nonequilibrium soft matter modeling, our simulations of\npolymer melts indicate that this method can also provide dramatic improvements\nin computational efficiency. Moreover we show that PAdL gives excellent control\nof the relaxation rate to equilibrium. In the nonequilibrium setting, we\nfurther demonstrate that while PAdL allows the recovery of accurate shear\nviscosities at higher shear rates than are possible using the DPD method at\nidentical timestep, it also outperforms Langevin dynamics in terms of stability\nand accuracy at higher shear rates.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Data Cleaning refers to the process of detecting and fixing errors in the\ndata. Human involvement is instrumental at several stages of this process,\ne.g., to identify and repair errors, to validate computed repairs, etc. There\nis currently a plethora of data cleaning algorithms addressing a wide range of\ndata errors (e.g., detecting duplicates, violations of integrity constraints,\nmissing values, etc.). Many of these algorithms involve a human in the loop,\nhowever, this latter is usually coupled to the underlying cleaning algorithms.\nThere is currently no end-to-end data cleaning framework that systematically\ninvolves humans in the cleaning pipeline regardless of the underlying cleaning\nalgorithms. In this paper, we highlight key challenges that need to be\naddressed to realize such a framework. We present a design vision and discuss\nscenarios that motivate the need for such a framework to judiciously assist\nhumans in the cleaning process. Finally, we present directions to implement\nsuch a framework.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce a new optimization procedure for Euclidean path integrals which\ncompute wave functionals in conformal field theories (CFTs). We optimize the\nbackground metric in the space on which the path integration is performed.\nEquivalently this is interpreted as a position-dependent UV cutoff. For\ntwo-dimensional CFT vacua, we find the optimized metric is given by that of a\nhyperbolic space and we interpret this as a continuous limit of the conjectured\nrelation between tensor networks and Anti--de Sitter (AdS)/conformal field\ntheory (CFT) correspondence. We confirm our procedure for excited states, the\nthermofield double state, the Sachdev-Ye-Kitaev model and discuss its extension\nto higher-dimensional CFTs. We also show that when applied to reduced density\nmatrices, it reproduces entanglement wedges and holographic entanglement\nentropy. We suggest that our optimization prescription is analogous to the\nestimation of computational complexity.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  CuAl2O4 is a normal spinel oxide having quantum spin, S=1/2 for Cu2+. It is a\nrather unique feature that the Cu2+ ions of CuAl2O4 sit at a tetrahedral\nposition, not like the usual octahedral position for many oxides. At low\ntemperatures, it exhibits all the thermodynamic evidence of a quantum spin\nglass. For example, the polycrystalline CuAl2O4 shows a cusp centered at ~2 K\nin the low-field dc magnetization data and a clear frequency dependence in the\nac magnetic susceptibility while it displays logarithmic relaxation behavior in\na time dependence of the magnetization. At the same time, there is a peak at\n~2.3 K in the heat capacity, which shifts towards higher temperature with\nmagnetic fields. On the other hand, there is no evidence of new superlattice\npeaks in the high-resolution neutron powder diffraction data when cooled from\n40 to 0.4 K. This implies that there is no long-ranged magnetic order down to\n0.4 K, thus confirming a spin glass-like ground state for CuAl2O4.\nInterestingly, there is no sign of structural distortion either although Cu2+\nis a Jahn-Teller active ion. Thus, we claim that an orbital liquid state is the\nmost likely ground state in CuAl2O4. Of further interest, it also exhibits a\nlarge frustration parameter, f = Theta_CW/Tm ~67, one of the largest values\nreported for spinel oxides. Our observations suggest that CuAl2O4 should be a\nrare example of a frustrated quantum spin glass with a good candidate for an\norbital liquid state.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We develop a general framework for the open dynamics of an ensemble of\nquantum particles subject to spacetime fluctuations about the flat background.\nAn arbitrary number of interacting bosonic and fermionic particles are\nconsidered. A systematic approach to the generation of gravitational waves in\nthe quantum domain is presented that recovers known classical limits in terms\nof the quadrupole radiation formula and backreaction dissipation. Classical\ngravitational emission and absorption relations are quantized into their\nquantum field theoretical counterparts in terms of the corresponding operators\nand quantum ensemble averages. Certain arising consistency issues related to\nfactor ordering have been addressed and resolved. Using the theoretical\nformulation established here with numerical simulations in the quantum regime,\nwe discuss potential new effects including decoherence through the spontaneous\nemission of gravitons and collectively amplified radiation of gravitational\nwaves by correlated quantum particles.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The five-dimensional quadrupole collective model based on energy density\nfunctionals (EDF) has often been employed to treat long-range correlations\nassociated with shape fluctuations in nuclei. Our goal is to derive the\ncollective inertial functions in the collective Hamiltonian by the local\nquasiparticle random phase approximation (QRPA) that correctly takes into\naccount time-odd mean-field effects. Currently, practical framework to perform\nthe QRPA calculation with the modern EDFs on the $(\\beta,\\gamma)$ deformation\nspace is not available. Toward this goal, we develop an efficient numerical\nmethod to perform the QRPA calculation on the $(\\beta,\\gamma)$ deformation\nspace based on the Skyrme EDF. We use the finite amplitude method (FAM) for\nefficient calculation of QRPA strength functions for multipole external fields.\nWe construct a computational code of FAM-QRPA in the three-dimensional\nCartesian coordinate space to handle triaxially deformed superfluid nuclei. We\nvalidate our new code by comparing our results with former QRPA calculations\nfor axially symmetric nuclei. Isoscalar quadrupole strength functions in\ntriaxial superfluid nuclei, ${}^{110}$Ru and ${}^{190}$Pt, are obtained within\na reasonable computational cost. QRPA calculations for triaxially deformed\nsuperfluid nuclei based on the Skyrme EDF are achieved with the help of FAM.\nThis is an important step toward the microscopic calculation of collective\ninertial functions of the local QRPA.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  An important yet challenging problem in understanding indoor scene is\nrecovering indoor frame structure from a monocular image. It is more difficult\nwhen occlusions and illumination vary, and object boundaries are weak. To\novercome these difficulties, a new approach based on line segment refinement\nwith two constraints is proposed. First, the line segments are refined by four\nconsecutive operations, i.e., reclassifying, connecting, fitting, and voting.\nSpecifically, misclassified line segments are revised by the reclassifying\noperation, some short line segments are joined by the connecting operation, the\nundetected key line segments are recovered by the fitting operation with the\nhelp of the vanishing points, the line segments converging on the frame are\nselected by the voting operation. Second, we construct four frame models\naccording to four classes of possible shooting angles of the monocular image,\nthe natures of all frame models are introduced via enforcing the cross ratio\nand depth constraints. The indoor frame is then constructed by fitting those\nrefined line segments with related frame model under the two constraints, which\njointly advance the accuracy of the frame. Experimental results on a collection\nof over 300 indoor images indicate that our algorithm has the capability of\nrecovering the frame from complex indoor scenes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We show a decomposition into the sum of a martingale and a deterministic\nquantity for time averages of the solutions to non-autonomous SDEs and for\ndiscrete-time Markov processes. In the SDE case the martingale has an explicit\nrepresentation in terms of the gradient of the associated semigroup or\ntransition operator. We show how the results can be used to obtain quenched\nGaussian concentration inequalities for time averages and to provide insights\ninto the Averaging principle for two-timescale processes.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $\\Omega$ be a pseudoconvex domain in $\\mathbb C^n$ satisfying an\n$f$-property for some function $f$. We show that the Bergman metric associated\nto $\\Omega$ has the lower bound $\\tilde g(\\delta_\\Omega(z)^{-1})$ where\n$\\delta_\\Omega(z)$ is the distance from $z$ to the boundary $\\partial\\Omega$\nand $\\tilde g$ is a specific function defined by $f$. This refines\nKhanh-Zampieri's work in \\cite{KZ12} with reducing the smoothness assumption of\nthe boundary.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We settle the complexity of the Independent Set Reconfiguration problem on\nbipartite graphs under all three commonly studied reconfiguration models. We\nshow that under the token jumping or token addition/removal model the problem\nis NP-complete. For the token sliding model, we show that the problem remains\nPSPACE-complete.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider resonances associated with excited eigenvalues of the cavity of a\ngeneral Helmholtz resonator with straight neck. Under the assumption that the\nneck stays away from the nodal set of the corresponding eigenstate, we\ngeneralise the optimal exponential lower bound on the width of the resonance,\nthat we have obtained in a previous paper for the ground resonance only.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Limited search and access patterns over Web archives have been well\ndocumented. One of the key reasons is the lack of understanding of the user\naccess patterns over such collections, which in turn is attributed to the lack\nof effective search interfaces. Current search interfaces for Web archives are\n(a) either purely navigational or (b) have sub-optimal search experience due to\nineffective retrieval models or query modeling. We identify that external\nlongitudinal resources, such as social bookmarking data, are crucial sources to\nidentify important and popular websites in the past. To this extent we present\nTempas, a tag-based temporal search engine for Web archives.\n  Websites are posted at specific times of interest on several external\nplatforms, such as bookmarking sites like Delicious. Attached tags not only act\nas relevant descriptors useful for retrieval, but also encode the time of\nrelevance. With Tempas we tackle the challenge of temporally searching a Web\narchive by indexing tags and time. We allow temporal selections for search\nterms, rank documents based on their popularity and also provide meaningful\nquery recommendations by exploiting tag-tag and tag-document co-occurrence\nstatistics in arbitrary time windows. Finally, Tempas operates as a fairly\nnon-invasive indexing framework. By not dealing with contents from the actual\nWeb archive it constitutes an attractive and low-overhead approach for quick\naccess into Web archives.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A low rank matrix X has been contaminated by uniformly distributed noise,\nmissing values, outliers and corrupt entries. Reconstruction of X from the\nsingular values and singular vectors of the contaminated matrix Y is a key\nproblem in machine learning, computer vision and data science. In this paper we\nshow that common contamination models (including arbitrary combinations of\nuniform noise,missing values, outliers and corrupt entries) can be described\nefficiently using a single framework. We develop an asymptotically optimal\nalgorithm that estimates X by manipulation of the singular values of Y , which\napplies to any of the contamination models considered. Finally, we find an\nexplicit signal-to-noise cutoff, below which estimation of X from the singular\nvalue decomposition of Y must fail, in a well-defined sense.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The law of statistical physics dictates that generic closed quantum many-body\nsystems initialized in nonequilibrium will thermalize under their own dynamics.\nHowever, the emergence of many-body localization (MBL) owing to the interplay\nbetween interaction and disorder, which is in stark contrast to Anderson\nlocalization that only addresses noninteracting particles in the presence of\ndisorder, greatly challenges this concept because it prevents the systems from\nevolving to the ergodic thermalized state. One critical evidence of MBL is the\nlong-time logarithmic growth of entanglement entropy, and a direct observation\nof it is still elusive due to the experimental challenges in multiqubit\nsingle-shot measurement and quantum state tomography. Here we present an\nexperiment of fully emulating the MBL dynamics with a 10-qubit superconducting\nquantum processor, which represents a spin-1/2 XY model featuring programmable\ndisorder and long-range spin-spin interactions. We provide essential signatures\nof MBL, such as the imbalance due to the initial nonequilibrium, the violation\nof eigenstate thermalization hypothesis, and, more importantly, the direct\nevidence of the long-time logarithmic growth of entanglement entropy. Our\nresults lay solid foundations for precisely simulating the intriguing physics\nof quantum many-body systems on the platform of large-scale multiqubit\nsuperconducting quantum processors.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose a high order finite difference linear scheme combined with a high\norder bound preserving maximum-principle-preserving (MPP) flux limiter to solve\nthe incompressible flow system. For such problem with highly oscillatory\nstructure but not strong shocks, our approach seems to be less dissipative and\nmuch less costly than a WENO type scheme, and has high resolution due to a\nHermite reconstruction. Spurious numerical oscillations can be controlled by\nthe MPP flux limiter. Numerical tests are performed for the Vlasov-Poisson\nsystem, the 2D guiding-center model and the incompressible Euler system. The\ncomparison between the linear and WENO type schemes will demonstrate the good\nperformance of our proposed approach.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove that the group of almost-automorphisms of the infinite rooted\nregular $d$-ary tree $\\mathcal{T}_d$ arises naturally as the Thompson-like\ngroup of a so called $d$-ary cloning system. A similar phenomenon occurs for\nany R\\\"over-Nekrashevych group $V_d(G)$, for $G\\le Aut(\\mathcal{T}_d)$ a\nself-similar group. We use this framework to expand on work of Belk and\nMatucci, who proved that the R\\\"over group, using the Grigorchuk group for $G$,\nis of type $F_\\infty$. Namely, we find some natural conditions on subgroups of\n$G$ to ensure that $V_d(G)$ is of type $F_\\infty$, and in particular we prove\nthis for all $G$ in the infinite family of \\v{S}uni\\'c groups. We also prove\nthat if $G$ is itself of type $F_\\infty$ then so is $V_d(G)$, and that every\nfinitely generated virtually free group is self-similar, so in particular every\nfinitely generated virtually free group $G$ yields a type $F_\\infty$\nR\\\"over-Nekrashevych group $V_d(G)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recollect that Heron's formula for the area of a triangle given its sides has\na counterpart given the medians instead, which carries an extra factor of\n$\\frac{4}{3}$. On the one hand, we formulate the pair of these in Linear\nAlgebra terms, showing that they are related by a sides-to-medians involution\n$J$, which we find to furthermore commute with the `Heron map' $H$ as visible\nin the expanded version of Heron. Upon further casting the pair of these in\nterms of mass-weighted Jacobi coordinates, we find moreover that they are\nplaced on an exactly equal footing, the factor of $\\frac{4}{3}$ having now\ncancelled out. This motivates the `Heron--Jacobi' version of Heron's formulae,\nfor mass-weighted area in terms of mass-weighted sides and mass-weighted\nmedians respectively.\n  On the other hand, we show that diagonalizing the Heron map $H$ provides new\nderivations of, firstly, the famous Hopf map, and, secondly, of Kendall's\nTheorem that the space of triangles is a sphere. This occurs by the\n`Heron--Hopf' version of Heron's formula simplifying down to none other than\nthe on-sphere condition. Thus we establish that -- both an important fibre\nbundle model, and a foundational theorem of Shape Theory: a widely applicable\nDifferential Geometry and Topology topic -- arise together as consequences of\njust Heron's formula, Stewart's Theorem, and some elementary Linear Algebra\nmanipulations. This working also accounts for the extra factor of 4 in the Hopf\ncoordinate that is elsewise equal to the mass-weighted area in the 3-body\nproblem context. It finally offers a new interpretation of the shape-theoretic\nellipticity and anisoscelesness which realize the other two Hopf quantities: as\neigenvectors shared by the Heron map $H$ and the sides-to-medians involution\n$J$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We construct semi-classical string solutions of the Schr\\\"odinger $Sch_5\n\\times S^5$ spacetime, which is conjectured to be the gravity dual of a\nnon-local dipole-deformed CFT. They are the counterparts of the giant magnon\nand spiky string solutions of the undeformed $AdS_5 \\times S^5$ to which they\nflow when the deformation parameter is turned off. They live in an $S^3$\nsubspace of the five-sphere along the directions of which the $B$-field has\nnon-zero components having also extent in the $Sch_5$ part of the metric.\nFinally, we speculate on the form of the dual field theory operators.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We propose to interpret the DAMPE electron excess at 1.5 TeV through scalar\nor Dirac fermion dark matter (DM) annihilation with doubly charged scalar\nmediators that have lepton-specific Yukawa couplings. Hierarchy of such\nlepton-specific Yukawa couplings is generated through the Froggatt-Nielsen\nmechanism, so that the dark matter annihilation products can be dominantly\nelectrons. Stringent constraints from LEP2 on intermediate vector boson\nproduction can be evaded in our scenarios. In the case of scalar DM, we discuss\none scenario with DM annihilating directly to leptons and the other scenario\nwith DM annihilating to scalar mediators followed by their decays. We also\ndiscuss the Breit-Wigner resonant enhancement and the Sommerfeld enhancement in\ncase that the s-wave annihilation process is small or helicity suppressed. With\nboth types of enhancement, constraints on the parameters can be relaxed and new\nways for model building will be open in explaining the DAMPE results.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We evaluate a one-loop, two-point, massless Feynman integral $I_{D,m}(p,q)$\nrelevant for perturbative field theoretic calculations in strongly anisotropic\n$d=D+m$ dimensional spaces given by the direct sum $\\mathbb R^D\\oplus\\mathbb\nR^m$. Our results are valid in the whole convergence region of the integral for\ngeneric (non-integer) co-dimensions $D$ and $m$. We obtain series expansions of\n$I_{D,m}(p,q)$ in terms of powers of the variable $X:=4p^2/q^4$, where $p=|\\bm\np|$, $q=|\\bm q|$, $\\bm p\\in\\mathbb R^D$, $\\bm q\\in\\mathbb R^m$, and in terms of\ngeneralised hypergeometric functions $_3F_2(-X)$, when $X<1$. These are\nsubsequently analytically continued to the complementary region $X\\ge 1$. The\nasymptotic expansion in inverse powers of $X^{1/2}$ is derived. The correctness\nof the results is supported by agreement with previously known special cases\nand extensive numerical calculations.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The energy dispersion of fermions or bosons vanishes in momentum space if\ndestructive quantum interference occurs in a frustrated Kagome lattice with\nonly nearest-neighbour (NN) hopping. A discrete flat band (FB) without any\ndispersion is consequently formed, promising emergence of fractional quantum\nHall states (FQHS) at high temperatures. Here, we report experimental\nrealization of a FB with possible nontrivial topology in an electronic Kagome\nlattice on a twisted multilayer silicene. The electrons are localized in the\nKagome lattice due to quantum destructive interference, and thus, their kinetic\nenergy is quenched, which gives rise to a FB peak in density of states. A\nrobust and pronounced one-dimensional edge state has been revealed at Kagome\nedge, which resides at higher energy than the FB. Our observations of the FB\nand the exotic edge state in electronic Kagome lattice open up the possibility\ntowards the realization of fractional Chern insulators in two-dimensional\nmaterials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Time delays pose an important challenge in networked control systems, which\nare now ubiquitous. Focusing on switched systems, we introduce a framework that\nprovides an upper bound for errors caused by switching delays. Our framework is\nbased on approximate bisimulation, a notion that has been previously utilized\nmainly for symbolic (discrete) abstraction of state spaces. Notable in our\nframework is that, in deriving an approximate bisimulation and thus an error\nbound, we use a simple incremental stability assumption (namely {\\delta}-GUAS)\nthat does not itself refer to time delays. That this is the same assumption\nused for state-space discretization enables a two-step workflow for control\nsynthesis for switched systems, in which a single Lyapunov-type stability\nwitness serves for two different purposes of state discretization and coping\nwith time delays. We demonstrate the proposed framework with a boost DC-DC\nconverter, a common example of switched systems.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Excited configurations of hydrogen in the oxyhydride BaTiO$_{3-x}$H$_x$\n($x=0.1-0.5$), which are considered to be involved in its hydrogen transport\nand exchange processes, were investigated by positive muon spin relaxation\n($\\mu^+$SR) spectroscopy using muonium (Mu) as a pseudoisotope of hydrogen.\nMuons implanted into the BaTiO$_{3-x}$H$_x$ perovskite lattice were mainly\nfound in two qualitatively different metastable states. One was assigned to a\nhighly mobile interstitial protonic state, which is commonly observed in\nperovskite oxides. The other was found to form an entangled two\nspin-$\\frac{1}{2}$ system with the nuclear spin of an H$^-$ ion at the anion\nsite. The structure of the (H,Mu) complex agrees well with that of a\nneutralized center containing two H$^-$ ions at a doubly charged oxygen\nvacancy, which was predicted to form in the SrTiO$_{3-\\delta}$ perovskite\nlattice by a computational study [Y. Iwazaki $et$ $al$., APL Materials 2,\n012103 (2014)]. Above 100 K, interstitial Mu$^+$ diffusion and retrapping to a\ndeep defect were observed, which could be a rate-limiting step of macroscopic\nMu/H transport in the BaTiO$_{3-x}$H$_x$ lattice.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Let $G$ be a smooth connected linear algebraic group and $X$ be a $G$-torsor.\nTotaro asked: if $X$ admits a zero-cycle of degree $d \\geq 1$, then does $X$\nhave a closed \\'etale point of degree dividing $d$? While the literature\ncontains affirmative answers in some special cases, we give an example to show\nthat the answer is negative in general.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present the results of a survey of several tens of dense high mass star\nforming (HMSF) cores in three transitions of the SO molecule at 30 and 100 GHz\nwith the 100-m Effelsberg and 20-m Onsala radio telescopes. The physical\nparameters of the cores are estimated from the line ratios and column\ndensities. Relative abundances are derived as well.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Background. Conventional phylogenetic clustering approaches rely on arbitrary\ncutpoints applied a posteriori to phylogenetic estimates. Although in practice,\nBayesian and bootstrap-based clustering tend to lead to similar estimates, they\noften produce conflicting measures of confidence in clusters. The current study\nproposes a new Bayesian phylogenetic clustering algorithm, which we refer to as\nDM-PhyClus, that identifies sets of sequences resulting from quick transmission\nchains, thus yielding easily-interpretable clusters, without using any ad hoc\ndistance or confidence requirement. Results. Simulations reveal that DM-PhyClus\ncan outperform conventional clustering methods, as well as the Gap procedure, a\npure distance-based algorithm, in terms of mean cluster recovery. We apply\nDM-PhyClus to a sample of real HIV-1 sequences, producing a set of clusters\nwhose inference is in line with the conclusions of a previous thorough\nanalysis. Conclusions. DM-PhyClus, by eliminating the need for cutpoints and\nproducing sensible inference for cluster configurations, can facilitate\ntransmission cluster detection. Future efforts to reduce incidence of\ninfectious diseases, like HIV-1, will need reliable estimates of transmission\nclusters. It follows that algorithms like DM-PhyClus could serve to better\ninform public health strategies.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The shock wave instability induced when interacting with a small waviness on\nan interface was investigated analytically and numerically. The perturbation to\nthe shock was phenomenologically treated assuming this as the consequence of\nthe shock refraction. The instability develops in the form of wave-like\nstretchings into the lower density medium followed with the loss of stability\nin the flow behind it, and eventually evolving into an intense vortex\nstructure. The instability mode is aperiodical and unconditional, and either a\ntransition to another stable state or continuous development as a secondary\nflow is possible. Among other interesting features are: a similarity law in the\nspatial and temporal evolution of the perturbations with respect to the\ninterface curvature; the instability locus independence of the gas density\ndistribution thus identifying the interface conditions as the sole triggering\nfactor; the role of the density gradient in the instability evolution\ndiscriminating between qualitatively different outcomes; and the possibility of\ndecay via non-viscous dumping mechanisms. The phenomenological connection\nbetween the shock and the interface stability is discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the interplay between disorder and superconducting pairing for\na one-dimensional $p$-wave superconductor subject to slowly varying\nincommensurate potentials with mobility edges. With amplitude increments of the\nincommensurate potentials, the system can undergo a transition from a\ntopological phase to a topologically trivial localized phase. Interestingly, we\nfind that there are four mobility edges in the spectrum when the strength of\nthe incommensurate potential is below a critical threshold, and a novel\ntopologically nontrivial localized phase emerges in a certain region. We reveal\nthis energy-dependent metal-insulator transition by applying several numerical\ndiagnostic techniques, including the inverse participation ratio, the density\nof states and the Lyapunov exponent. Nowadays, precise control of the\nbackground potential and the $p$-wave superfluid can be realized in the\nultracold atomic systems, we believe that these novel mobility edges can be\nobserved experimentally.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This writeup is a review of current hot topics on solar neutrinos. It is\nbased on a talk at the conference \"Neutrinos: the quest for a new physics\nscale\", held at the CERN on March 2017, where the Organizers entrusted me with\na discussion of the provocative question \"whether solar neutrino physics is\nover\". Rather than providing a straight (negative) answer, in view of an\naudience consisting mostly of colleagues working in theoretical particle\nphysics, I deemed it more useful providing a description of what is the current\nactivity of the physicists working in solar neutrinos, leaving the listener\nfree of forming his/her own opinion apropos.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The goal of this paper is to investigate the stability of the Helmholtz\nequation in the high- frequency regime with non-smooth and rapidly oscillating\ncoefficients on bounded domains. Existence and uniqueness of the problem can be\nproved using the unique continuation principle in Fredholm's alternative.\nHowever, this approach does not give directly a coefficient-explicit energy\nestimate. We present a new theoretical approach for the one-dimensional problem\nand find that for a new class of coefficients, including coefficients with an\narbitrary number of discontinuities, the stability constant (i.e., the norm of\nthe solution operator) is bounded by a term independent of the number of jumps.\nWe emphasize that no periodicity of the coefficients is required. By selecting\nthe wave speed function in a certain \\resonant\" way, we construct a class of\noscillatory configurations, such that the stability constant grows\nexponentially in the frequency. This shows that our estimates are sharp.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This contribution to LCWS2016 presents recent developments within the CLICdp\ncollaboration. An updated scenario for the staged operation of CLIC has been\npublished; the accelerator will operate at 380 GeV, 1.5 TeV and 3 TeV. The\nlowest energy stage is optimised for precision Higgs and top physics, while the\nhigher energy stages offer extended Higgs and BSM physics sensitivity. The\ndetector models CLIC_SiD and CLIC_ILD have been replaced by a single optimised\ndetector; CLICdet. Performance studies and R&D in technologies to meet the\nrequirements for this detector design are ongoing.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The goal of this note is to give an introduction to locally conformally\nsymplectic and K\\\"ahler geometry. In particular, Sections 1 and 3 aim to\nprovide the reader with enough mathematical background to appreciate this kind\nof geometry. The reference book for locally conformally K\\\"ahler geometry is\n\"Locally conformal K\\\"ahler Geometry\" by Sorin Dragomir and Liviu Ornea. Many\nprogresses in this field, however, were accomplished after the publication of\nthis book, hence are not contained there. On the other hand, there is no book\non locally conformally symplectic geometry and many recent advances lie\nscattered in the literature. Sections 2 and 4 would like to demonstrate how\nthese geometries can be used to give precise mathematical formulations to ideas\ndeeply rooted in classical and modern Physics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  An identity of Chung, Graham and Knuth involving binomial coefficients and\nEulerian numbers motivates our study of a class of polynomials that we call\nbinomial-Eulerian polynomials. These polynomials share several properties with\nthe Eulerian polynomials. For one thing, they are $h$-polynomials of simplicial\npolytopes, which gives a geometric interpretation of the fact that they are\npalindromic and unimodal. A formula of Foata and Sch\\\"utzenberger shows that\nthe Eulerian polynomials have a stronger property, namely $\\gamma$-positivity,\nand a formula of Postnikov, Reiner and Williams does the same for the\nbinomial-Eulerian polynomials. We obtain $q$-analogs of both the\nFoata-Sch\\\"utzenberger formula and an alternative to the\nPostnikov-Reiner-Williams formula, and we show that these $q$-analogs are\nspecializations of analogous symmetric function identities. Algebro-geometric\ninterpretations of these symmetric function analogs are presented.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we consider the semilinear heat equations under Dirichlet\nboundary condition \\[ u_{t}\\left(x,t\\right)=\\Delta u\\left(x,t\\right)+f(u(x,t)),\n& \\left(x,t\\right)\\in \\Omega\\times\\left(0,+\\infty\\right), u\\left(x,t\\right)=0,\n& \\left(x,t\\right)\\in\\partial \\Omega\\times\\left[0,+\\infty\\right),\nu\\left(x,0\\right)=u_{0}\\geq0, & x\\in\\overline{\\Omega}, \\] where $\\Omega$ is a\nbounded domain of $\\mathbb{R}^{N}$ $(N\\geq1)$ with smooth boundary\n$\\partial\\Omega$. The main contribution of our work is to introduce a new\ncondition \\[ (C) \\alpha \\int_{0}^{u}f(s)ds \\leq uf(u)+\\beta\nu^{2}+\\gamma,\\,\\,u>0 \\] for some $\\alpha, \\beta, \\gamma>0$ with\n$0<\\beta\\leq\\frac{\\left(\\alpha-2\\right)\\lambda_{0}}{2}$, where $\\lambda_{0}$ is\nthe first eigenvalue of Laplacian $\\Delta$, and we use the concavity method to\nobtain the blow-up solutions to the semilinear heat equations. In fact, it will\nbe seen that the condition (C) improves the conditions known so far.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  ALICE (A Large Ion Collider Experiment) is the heavy-ion detector designed to\nstudy the strongly interacting state of matter realized in relativistic\nheavy-ion collisions at the CERN Large Hadron Collider (LHC). A major upgrade\nof the experiment is planned during the 2019-2020 long shutdown. In order to\ncope with a data rate 100 times higher than during LHC Run 1 and with the\ncontinuous read-out of the Time Projection Chamber (TPC), it is necessary to\nupgrade the Online and Offline Computing to a new common system called O2 . The\nO2 read- out chain will use commodity x86 Linux servers equipped with custom\nPCIe FPGA-based read- out cards. This paper discusses the driver architecture\nfor the cards that will be used in O2 : the PCIe v2 x8, Xilinx Virtex 6 based\nC-RORC (Common Readout Receiver Card) and the PCIe v3 x16, Intel Arria 10 based\nCRU (Common Readout Unit). Access to the PCIe cards is provided via three\nlayers of software. Firstly, the low-level PCIe (PCI Express) layer responsible\nfor the userspace interface for low-level operations such as memory mapping the\nPCIe BAR (Base Address Registers) and creating scatter-gather lists, which is\nprovided by the PDA (Portable Driver Architecture) library developed by the\nFrankfurt Institute for Advanced Studies (FIAS). Above that sits our userspace\ndriver which implements synchronization, controls the read-out card -- e.g.\nresetting and configuring the card, providing it with bus addresses to transfer\ndata to and checking for data arrival -- and presents a uniform, high-level C++\ninterface that abstracts over the differences between the C-RORC and CRU. This\ninterface -- of which direct usage is principally intended for high-performance\nread-out processes -- allows users to configure and use the various aspects of\nthe read-out cards, such as configuration, DMA transfers and commands to the\nfront-end. [...]\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Entanglement is a fundamental property of quantum mechanics, and is a primary\nresource in quantum information systems. Its manipulation remains a central\nchallenge in the development of quantum technology. In this work, we\ndemonstrate a device which can generate, manipulate, and analyse two-qubit\nentangled states, using miniature and mass-manufacturable silicon photonics. By\ncombining four photon-pair sources with a reconfigurable six-mode\ninterferometer, embedding a switchable entangling gate, we generate two-qubit\nentangled states, manipulate their entanglement, and analyse them, all in the\nsame silicon chip. Using quantum state tomography, we show how our source can\nproduce a range of entangled and separable states, and how our switchable\ncontrolled-Z gate operates on them, entangling them or making them separable\ndepending on its configuration.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  As we move towards an era of hundreds of cores, the research community has\nwitnessed the emergence of opto-electronic network on-chip designs based on\nnanophotonics, in order to achieve higher network throughput, lower latencies,\nand lower dynamic power. However, traditional nanophotonics options face\nlimitations such as large device footprints compared with electronics, higher\nstatic power due to continuous laser operation, and an upper limit on\nachievable data rates due to large device capacitances. Nanoplasmonics is an\nemerging technology that has the potential for providing transformative gains\non multiple metrics due to its potential to increase the light-matter\ninteraction. In this paper, we propose and analyze a hybrid opto-electric NoC\nthat incorporates Hybrid Plasmonics Photonics Interconnect (HyPPI), an optical\ninterconnect that combines photonics with plasmonics. We explore various\nopto-electronic network hybridization options by augmenting a mesh network with\nHyPPI links, and compare them with the equivalent options afforded by\nconventional nanophotonics as well as pure electronics. Our design space\nexploration indicates that augmenting an electronic NoC with HyPPI gives a\nperformance to cost ratio improvement of up to 1.8x. To further validate our\nestimates, we conduct trace based simulations using the NAS Parallel Benchmark\nsuite. These benchmarks show latency improvements up to 1.64x, with negligible\nenergy increase. We then further carry out performance and cost projections for\nfully optical NoCs, using HyPPI as well as conventional nanophotonics. These\nfuturistic projections indicate that all-HyPPI NoCs would be two orders more\nenergy efficient than electronics, and two orders more area efficient than\nall-photonic NoCs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present the discovery, classification, and radio-to-X-ray follow-up\nobservations of iPTF17cw, a broad-lined (BL) type Ic supernova (SN) discovered\nby the intermediate Palomar Transient Factory (iPTF). Although unrelated to the\ngravitational wave trigger, this SN was discovered as a happy by-product of the\nextensive observational campaign dedicated to the follow-up of Advanced LIGO\nevent GW170104. The spectroscopic properties and inferred peak bolometric\nluminosity of iPTF17cw are most similar to the gamma-ray burst (GRB) associated\nSN 1998bw, while the shape of the r-band light curve is most similar to that of\nthe relativistic SN 2009bb. Karl G. Jansky Very Large Array (VLA) observations\nof the iPTF17cw field reveal a radio counterpart about 10 times less luminous\nthan SN 1998bw, and with peak radio luminosity comparable to that of SN\n2006aj/GRB 060218 and SN 2010bh/GRB 100316D. Our radio observations of iPTF17cw\nimply a relativistically expanding outflow. However, further late-time\nobservations with the VLA in its most extended configuration are needed to\nconfirm fading of iPTF radio counterpart at all frequencies. X-ray observations\ncarried out with Chandra reveal the presence of an X-ray counterpart with\nluminosity similar to that of SN 2010bh/GRB 100316D. Searching the Fermi\ncatalog for possible gamma-rays reveals that GRB 161228B is spatially and\ntemporally compatible with iPTF17cw. The similarity to SN 1998bw and SN 2009bb,\nthe radio and X-ray detections, and the potential association with GRB 161228B,\nall point to iPTF17cw being a new candidate member of the rare sample of\noptically-discovered engine-driven BL-Ic SNe associated with relativistic\nejecta.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the energy density and pressure of a relativistic thermal gas of\nmassless fermions on four-dimensional Minkowski and anti-de Sitter space-times\nusing relativistic kinetic theory. The corresponding quantum field theory\nquantities are given by components of the renormalized expectation value of the\nstress-energy tensor operator acting on a thermal state. On Minkowski\nspace-time, the renormalized vacuum expectation value of the stress-energy\ntensor is by definition zero, while on anti-de Sitter space-time the vacuum\ncontribution to this expectation value is in general nonzero. We compare the\nproperties of the vacuum and thermal expectation values of the energy density\nand pressure for massless fermions and discuss the circumstances in which the\nthermal contribution dominates over the vacuum one.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Time crystals are quantum many-body systems which, due to interactions\nbetween particles, are able to spontaneously self-organize their motion in a\nperiodic way in time by analogy with the formation of crystalline structures in\nspace in condensed matter physics. In solid state physics properties of space\ncrystals are often investigated with the help of external potentials that are\nspatially periodic and reflect various crystalline structures. A similar\napproach can be applied for time crystals, as periodically driven systems\nconstitute counterparts of spatially periodic systems, but in the time domain.\nHere we show that condensed matter problems ranging from single particles in\npotentials of quasi-crystal structure to many-body systems with exotic\nlong-range interactions can be realized in the time domain with an appropriate\nperiodic driving. Moreover, it is possible to create molecules where atoms are\nbound together due to destructive interference if the atomic scattering length\nis modulated in time.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  With the first direct detection of merging black holes in 2015, the era of\ngravitational wave (GW) astrophysics began. A complete picture of compact\nobject mergers, however, requires the detection of an electromagnetic (EM)\ncounterpart. We report ultraviolet (UV) and X-ray observations by Swift and the\nNuclear Spectroscopic Telescope ARray (NuSTAR) of the EM counterpart of the\nbinary neutron star merger GW170817. The bright, rapidly fading ultraviolet\nemission indicates a high mass ($\\approx0.03$ solar masses) wind-driven outflow\nwith moderate electron fraction ($Y_{e}\\approx0.27$). Combined with the X-ray\nlimits, we favor an observer viewing angle of $\\approx 30^{\\circ}$ away from\nthe orbital rotation axis, which avoids both obscuration from the heaviest\nelements in the orbital plane and a direct view of any ultra-relativistic,\nhighly collimated ejecta (a gamma-ray burst afterglow).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We explore the formation of mass-transferring binary systems containing black\nholes within globular clusters. We show that it is possible to form\nmass-transferring black hole binaries with main sequence, giant, and white\ndwarf companions with a variety of orbital parameters in globular clusters\nspanning a large range in present-day properties. All mass-transferring black\nhole binaries found in our models at late times are dynamically created. The\nblack holes in these systems experienced a median of $\\sim 30$ dynamical\nencounters within the cluster before and after acquiring the donor.\nFurthermore, we show that the presence of mass-transferring black hole systems\nhas little correlation with the total number of black holes within the cluster\nat any time. This is because the net rate of formation of black hole-non-black\nhole binaries in a cluster is largely independent of the total number of\nretained black holes. Our results suggest that the detection of a\nmass-transferring black hole binary in a globular cluster does not necessarily\nindicate that the host cluster contains a large black hole population.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  User participation is considered an effective way to conduct requirements\nengineering, but user-developer perception gaps in requirements understanding\noccur frequently. Since user participation in practice is not as active as we\nexpect and the requirements perception gap has been recognized as a risk that\nnegatively affects projects, exploring whether user-developer perception gaps\nin requirements understanding will hinder user participation is worthwhile.\nThis will help develop a greater comprehension of the intertwined relationship\nbetween user participation and perception gap, a topic that has not yet been\nextensively examined. This study investigates the direct and mediating\ninfluences of user-developer requirements perception gaps on user participation\nby integrating requirements uncertainty and top management support. Survey data\ncollected from 140 subjects were examined and analyzed using structural\nequation modeling. The results indicate that perception gaps have a direct\nnegative effect on user participation and negate completely the positive effect\nof top management support on user participation. Additionally, perception gaps\ndo not have a mediating effect between requirements uncertainty and user\nparticipation because requirements uncertainty does not significantly and\ndirectly affect user participation, but requirements uncertainty indirectly\ninfluences user participation due to its significant direct effect on\nperception gaps. The theoretical and practical implications are discussed, and\nlimitations and possible future research areas are identified.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We implement imaging spectroscopy of the optical clock transition of\nlattice-trapped degenerate fermionic Sr in the Mott-insulating regime,\ncombining micron spatial resolution with submillihertz spectral precision. We\nuse these tools to demonstrate atomic coherence for up to 15 s on the clock\ntransition and reach a record frequency precision of $2.5\\times 10^{-19}$. We\nperform the most rapid evaluation of trapping light shifts and record a 150 mHz\nlinewidth, the narrowest Rabi line shape observed on a coherent optical\ntransition. The important emerging capability of combining high-resolution\nimaging and spectroscopy will improve the clock precision, and provide a path\ntowards measuring many-body interactions and testing fundamental physics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The liquid drop model of 2-flavored ($u$ and $d$) nucleus is well known and\nsuccessful, analogically, a similar drop model for 3-flavored ($u$, $d$ and\n$s$) nucleus is developed. A 3-flavored nucleus conjectured could be stable\nonly if its baryon number is lager than a critical one, $A_{\\rm c}$, in which\nstrangeons are the constituent as an analogy of nucleons for nucleus. We try to\nmodel strangeon matter in a sense of phenomenological liquid drop, with two\nfree parameters: the mass per bayron of a strangeon in vacuum, $M$, and\npotential deep between strangeons, $\\epsilon$. It is found that, for $M\\sim$\nGeV and $\\epsilon\\sim 100$ MeV, strangeon matter could be stable and its\ncritical number could be as low as $A_{\\rm c}=300$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A virtual network (VN) contains a collection of virtual nodes and links\nassigned to underlying physical resources in a network substrate. VN migration\nis the process of remapping a VN's logical topology to a new set of physical\nresources to provide failure recovery, energy savings, or defense against\nattack. Providing VN migration that is transparent to running applications is a\nsignificant challenge. Efficient migration mechanisms are highly dependent on\nthe technology deployed in the physical substrate. Prior work has considered\nmigration in data centers and in the PlanetLab infrastructure. However, there\nhas been little effort targeting an SDN-enabled wide-area networking\nenvironment - an important building block of future networking infrastructure.\nIn this work, we are interested in the design, implementation and evaluation of\nVN migration in GENI as a working example of such a future network. We identify\nand propose techniques to address key challenges: the dynamic allocation of\nresources during migration, managing hosts connected to the VN, and flow table\nmigration sequences to minimize packet loss. We find that GENI's virtualization\narchitecture makes transparent and efficient migration challenging. We suggest\nalternatives that might be adopted in GENI and are worthy of adoption by\nvirtual network providers to facilitate migration.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, I present an optimization problem which consists of assigning\nentries of a stellar catalog to multiple entries of another stellar catalog\nsuch that the probability of such assignment is maximum. I show a way of\nmodeling it as a Maximum Weighted Stable Set Problem which is further used to\nsolve a real astronomical instance and I partially characterize the forbidden\nsubgraphs of the resulting family of graphs given by that reduction. Finally, I\nprove that the problem is NP-Hard.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present a new topic model that generates documents by sampling a topic for\none whole sentence at a time, and generating the words in the sentence using an\nRNN decoder that is conditioned on the topic of the sentence. We argue that\nthis novel formalism will help us not only visualize and model the topical\ndiscourse structure in a document better, but also potentially lead to more\ninterpretable topics since we can now illustrate topics by sampling\nrepresentative sentences instead of bag of words or phrases. We present a\nvariational auto-encoder approach for learning in which we use a factorized\nvariational encoder that independently models the posterior over topical\nmixture vectors of documents using a feed-forward network, and the posterior\nover topic assignments to sentences using an RNN. Our preliminary experiments\non two different datasets indicate early promise, but also expose many\nchallenges that remain to be addressed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Materials with strongly-correlated electrons exhibit interesting phenomena\nsuch as metal-insulator transitions and high-temperature superconductivity. In\nstark contrast to ordinary metals, electron transport in these materials is\nthought to resemble the flow of viscous fluids. Despite their differences, it\nis predicted that transport in both, conventional and correlated materials, is\nfundamentally limited by the uncertainty principle applied to energy\ndissipation. Here we discover hydrodynamic electron flow in the Weyl-semimetal\ntungsten phosphide (WP2). Using thermal and magneto-electric transport\nexperiments, we observe the transition from a conventional metallic state, at\nhigher temperatures, to a hydrodynamic electron fluid below 20 K. The\nhydrodynamic regime is characterized by a viscosity-induced dependence of the\nelectrical resistivity on the square of the channel width, and by the\nobservation of a strong violation of the Wiedemann-Franz law. From\nmagneto-hydrodynamic experiments and complementary Hall measurements, the\nrelaxation times for momentum and thermal energy dissipating processes are\nextracted. Following the uncertainty principle, both are limited by the\nPlanckian bound of dissipation, independent of the underlying transport regime.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work, we revisit a criterion, originally proposed in [Nonlinearity\n{\\bf 17}, 207 (2004)], for the stability of solitary traveling waves in\nHamiltonian, infinite-dimensional lattice dynamical systems. We discuss the\nimplications of this criterion from the point of view of stability theory, both\nat the level of the spectral analysis of the advance-delay differential\nequations in the co-traveling frame, as well as at that of the Floquet problem\narising when considering the traveling wave as a periodic orbit modulo a shift.\nWe establish the correspondence of these perspectives for the pertinent\neigenvalue and Floquet multiplier and provide explicit expressions for their\ndependence on the velocity of the traveling wave in the vicinity of the\ncritical point. Numerical results are used to corroborate the relevant\npredictions in two different models, where the stability may change twice. Some\nextensions, generalizations and future directions of this investigation are\nalso discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given two relatively prime positive integers $\\alpha$ and $\\beta$, we\nconsider simple lattice paths (with unit East and unit North steps) from\n$(0,0)$ to $(\\alpha k,\\beta k)$, and enumerate them by their left and right\nbounces with respect to the line $y=\\frac{\\beta}{\\alpha} x$. We give the\ncorresponding multivariate generating functions for all such paths as well as\nfor subclasses of paths that start and end with a prescribed step. For\nillustration purposes, we discuss the case $\\beta=1$ and express some of our\nfunctions in terms of the Fuss-Catalan generating function $c_\\alpha(x)$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this work we consider a class of nonlocal non-autonomous evolution\nequations, which generalizes the model of neuronal activity that arises in\nAmari (1979).\n  Under suitable assumptions on the nonlinearity and on the parameters present\nin the equation, we study, in an appropriated Banach space, the assimptotic\nbehavior of the evolution process generated by this equation. We prove results\non existence, uniqueness and smoothness of the solutions and on the existence\nof pullback attracts for the evolution process associated to this equation. We\nalso prove a continuous dependence of the evolution process with respect to\nexternal stimulus function present in the model. Furthermore, using the result\nof continuous dependence of the evolution process, we also prove the upper\nsemicontinuity of pullback attracts with respect to stimulus function. We\nconclude with a small discussion about the model and about a biological\ninterpretation of the result of continuous dependence of neuronal activity with\nrespect to the external stimulus function.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In August 2015 the cryptographic world was shaken by a sudden and surprising\nannouncement by the US National Security Agency NSA concerning plans to\ntransition to post-quantum algorithms. Since this announcement post-quantum\ncryptography has become a topic of primary interest for several standardization\nbodies. The transition from the currently deployed public-key algorithms to\npost-quantum algorithms has been found to be challenging in many aspects. In\nparticular the problem of evaluating the quantum-bit security of such\npost-quantum cryptosystems remains vastly open. Of course this question is of\nprimarily concern in the process of standardizing the post-quantum\ncryptosystems. In this paper we consider the quantum security of the problem of\nsolving a system of {\\it $m$ Boolean multivariate quadratic equations in $n$\nvariables} (\\MQb); a central problem in post-quantum cryptography. When $n=m$,\nunder a natural algebraic assumption, we present a Las-Vegas quantum algorithm\nsolving \\MQb{} that requires the evaluation of, on average, $O(2^{0.462n})$\nquantum gates. To our knowledge this is the fastest algorithm for solving\n\\MQb{}.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this joint introduction to an Asterisque volume, we give a short\ndiscussion of the historical developments in the study of nonlinear covering\ngroups, touching on their structure theory, representation theory and the\ntheory of automorphic forms. This serves as a historical motivation and sets\nthe scene for the papers in the volume. Our discussion is necessarily\nsubjective and will undoubtedly leave out the contributions of many authors, to\nwhom we apologize in earnest.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In modern day society, the ability to code is a highly desirable skill. So\nmuch so that the current supply from third level institutes across the world\ndoes not meet the high demands of industry. One of the major issues is the low\nprogression rates from first to second year in third level Computer Science\ncourses with introductory programming courses proving to be a high contributing\nfactor. This is something that needs to be addressed. One such way to address\nthe issue is to get children involved and engaged with computing at young ages.\n  This paper describes a study undertaken that is the first step in a body of\nwork that aims to garner the interest of potential Computer Science students at\nan early age. The study involves a comparison of two short courses; one based\nin Java and one based in Snap. The goal is to determine whether either of these\nlanguages is a better first programming language for students than the other,\nor if both are viable. These languages were chosen to allow for a comparison\nbetween a Visual Programming Language and a Textual Programming Language.\n  Feedback in the form of a survey will be used to gather the opinions of the\nstudents. This will provide data on issues such as which language was easier to\nlearn and which language was preferred amongst others. Based on the outcomes of\nthis study, a full-scale curriculum will be developed in the coming year. The\noutcomes of this study will help to establish which is the best programming\nlanguage to suit the learning needs of students.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The aim of this paper is to generalize the Hermite--Hadamard inequality for\nfunctions convex on the coordinates. Our composite result generalizes the\nresult of Dragomir in \\cite{Drag}. Many other interesting inequalities can be\nderived from our results by choosing different values of $n\\in\\mathbb{N}.$\nFurthermore, we add to the literature a new result for positive functions\nconvex on the coordinates.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We use flux-transmission correlations in \\Lya forests to measure the imprint\nof baryon acoustic oscillations (BAO). The study uses spectra of 157,783\nquasars in the redshift range $2.1\\le z \\le 3.5$ from the Sloan Digital Sky\nSurvey (SDSS) Data Release 12 (DR12). Besides the statistical improvements on\nour previous studies using SDSS DR9 and DR11, we have implemented numerous\nimprovements in the analysis procedure, allowing us to construct a physical\nmodel of the correlation function and to investigate potential systematic\nerrors in the determination of the BAO peak position. The Hubble distance,\n$\\DHub=c/H(z)$, relative to the sound horizon is $\\DHub(z=2.33)/r_d=9.07 \\pm\n0.31$. The best-determined combination of comoving angular-diameter distance,\n$\\DM$, and the Hubble distance is found to be\n$\\DHub^{0.7}\\DM^{0.3}/r_d=13.94\\pm0.35$. This value is $1.028\\pm0.026$ times\nthe prediction of the flat-\\lcdm model consistent with the cosmic microwave\nbackground (CMB) anisotropy spectrum. The errors include marginalization over\nthe effects of unidentified high-density absorption systems and fluctuations in\nultraviolet ionizing radiation. Independently of the CMB measurements, the\ncombination of our results and other BAO observations determine the open-\\lcdm\ndensity parameters to be $\\om=0.296 \\pm 0.029$, $\\ol=0.699 \\pm 0.100$ and\n$\\Omega_k = -0.002 \\pm 0.119$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  This paper presents a new approach to study the effects of temperature on the\nporo- elastic and viscoelastic behavior of articular cartilage. Biphasic\nsolid-fluid mixture theory is applied to study the poro-mechancial behavior of\narticular cartilage in a fully saturated state. The balance of linear momentum,\nmass, and energy are considered to describe deformation of the solid skeleton,\npore fluid pressure, and temperature distribution in the mixture. The\nmechanical model assumes both linear elastic and viscoelastic isotropic\nmaterials, infinitesimal strain theory, and a time-dependent response. The\ninfluence of temperature on the mixture behavior is modeled through temperature\ndependent mass density and volumetric thermal strain. The fluid flow through\nthe porous medium is described by the Darcy's law. The stress-strain relation\nfor time-dependent viscoelastic deformation in the solid skeleton is described\nusing the generalized Maxwell model. A verification example is presented to\nillustrate accuracy and efficiency of the developed finite element model. The\ninfluence of temperature is studied through examining the behavior of articular\ncartilage for confined and unconfined boundary conditions. Furthermore,\narticular cartilage under partial loading condition is modeled to investigate\nthe deformation, pore fluid pressure, and temperature dissipation processes.\nThe results suggest significant impacts of temperature on both poro- elastic\nand viscoelastic behavior of articular cartilage.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Bishop-Phelps-Bollob\\'{a}s property deals with simultaneous approximation\nof an operator $T$ and a vector $x$ at which $T$ nearly attains its norm by an\noperator $T_0$ and a vector $x_0$, respectively, such that $T_0$ attains its\nnorm at $x_0$. In this note we extend the already known results about {the}\nBishop-Phelps-Bollob\\'{a}s property for Asplund operators to a wider class of\nBanach spaces and to a wider class of operators. Instead of proving a BPB-type\ntheorem for each space separately we isolate two main notions: $\\Gamma$-flat\noperators and Banach spaces with ACK$_\\rho$ structure. In particular, we prove\na general BPB-type theorem for $\\Gamma$-flat operators acting to a space with\nACK$_\\rho$ structure and show that uniform algebras and spaces with the\nproperty $\\beta$ have ACK$_\\rho$ structure. We also study the stability of the\nACK$_\\rho$ structure under some natural Banach space theory operations. As a\nconsequence, we discover many new examples of spaces $Y$ such that the\nBishop-Phelps-Bollob\\'{a}s property for Asplund operators is valid for all\npairs of the form ($X,Y$).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  These lectures discuss recent advances on syzygies on algebraic curves,\nespecially concerning the Green, the Prym-Green and the Green-Lazarsfeld Secant\nConjectures. The methods used are largely geometric and variational, with a\nspecial emphasis on examples and explicit calculations. The notes are based on\nseries of lectures given in Daejeon (March 2013), Rome (November-December 2015)\nand Guanajuato (February 2016).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We describe \\,$q$-hypergeometric solutions of the equivariant quantum\ndifferential equations and associated qKZ difference equations for the\ncotangent bundle $T^*F_\\lambda$ of a partial flag variety \\,$F_\\lambda$\\,.\nThese \\,$q$-hypergeometric solutions manifest a Landau-Ginzburg mirror symmetry\nfor the cotangent bundle. We formulate and prove Pieri rules for quantum\nequivariant cohomology of the cotangent bundle. Our Gamma theorem for\n\\,$T^*F_\\lambda$ \\,says that the leading term of the asymptotics of the\n\\,$q$-hypergeometric solutions can be written as the equivariant Gamma class of\nthe tangent bundle of $T^*F_\\lambda$ multiplied by the exponentials of the\nequivariant first Chern classes of the associated vector bundles. That\nstatement is analogous to the statement of the gamma conjecture by B.\\,Dubrovin\nand by S.\\,Galkin, V.\\,Golyshev, and H.\\,Iritani, see also the Gamma theorem\nfor \\,$F_\\lambda$ \\,in Appendix B.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Multi-frequency Very Long Baseline Array (VLBA) polarimetry observation of\nthe GHz-Peaked Spectrum (GPS) quasar OQ172 (J1445+0958) has been performed at\n1.6, 2.2, 4.8, 8.3 and 15.3 GHz in 2005. Core-jet structures are detected in\nall bands with the jet strongly bent at about 3 mas from the core. The radio\nemission of the source is polarised at all five bands. We study the Faraday\nRotation in the core and jet components at all five bands, and find good linear\nfits of Faraday Rotation in the core and jet components at 4.8 and 8.3 GHz. At\nthese two frequencies, the Rotation Measure (RM) is $\\sim 2000~\\rm rad~m^{-2}$\nin the core and $\\sim 700~\\rm rad~m^{-2}$ in the inner jet components and\ncontinues to decrease at the outer jet parts. We find that the depolarisation\nat 4.8 and 8.3 GHz might be caused by the internal medium in the source. We\ninvestigate consistency of the turnover spectra of VLBI components with the\nSynchrotron Self-Absorption (SSA) and Free-Free Absorption (FFA) models.\nAlthough these two models can not be easily distinguished due to the lack of\nlow-frequency data, the physical parameters can be constrained for each model.\nWe find that the large width of the $\\rm [OIII]_{5007}$ line is likely caused\nby a jet interaction with a Narrow Line Region (NLR) medium. The jet bending,\nsignificant RM variations, Faraday depolarisation, spectral turnover, and broad\nline width of $\\rm [OIII]_{5007}$ could be closely related, likely caused by\nthe same nucleus medium, presumably NLR.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Is it possible to recover the position of a source from the steady-state\nfluxes of Brownian particles to small absorbing windows located on the boundary\nof a domain? To address this question, we develop a numerical procedure to\navoid tracking Brownian trajectories in the entire infinite space. Instead, we\ngenerate particles near the absorbing windows, computed from the analytical\nexpression of the exit probability. When the Brownian particles are generated\nby a steady-state gradient at a single point, we compute asymptotically the\nfluxes to small absorbing holes distributed on the boundary of half-space and\non a disk in two dimensions, which agree with stochastic simulations. We also\nderive an expression for the splitting probability between small windows using\nthe matched asymptotic method. Finally, when there are more than two small\nabsorbing windows, we show how to reconstruct the position of the source from\nthe diffusion fluxes. The present approach provides a computational first\nprinciple for the mechanism of sensing a gradient of diffusing particles, a\nubiquitous problem in cell biology.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study classes of Borel subsets of the real line $\\mathbb{R}$ such as\nlevels of the Borel hierarchy and the class of sets that are reducible to the\nset $\\mathbb{Q}$ of rationals, endowed with the Wadge quasi-order of\nreducibility with respect to continuous functions on $\\mathbb{R}$. Notably, we\nexplore several structural properties of Borel subsets of $\\mathbb{R}$ that\ndiverge from those of Polish spaces with dimension zero. Our first main result\nis on the existence of embeddings of several posets into the restriction of\nthis quasi-order to any Borel class that is strictly above the classes of open\nand closed sets, for instance the linear order $\\omega_1$, its reverse\n$\\omega_1^\\star$ and the poset $\\mathcal{P}(\\omega)/\\mathsf{fin}$ of inclusion\nmodulo finite error. As a consequence of its proof, it is shown that there are\nno complete sets for these classes. We further extend the previous theorem to\ntargets that are reducible to $\\mathbb{Q}$. These non-structure results\nmotivate the study of further restrictions of the Wadge quasi-order. In our\nsecond main theorem, we introduce a combinatorial property that is shown to\ncharacterize those $F_\\sigma$ sets that are reducible to $\\mathbb{Q}$. This is\napplied to construct a minimal set below $\\mathbb{Q}$ and prove its uniqueness\nup to Wadge equivalence. We finally prove several results concerning gaps and\ncardinal characteristics of the Wadge quasi-order and thereby answer questions\nof Brendle and Geschke.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Interactive model analysis, the process of understanding, diagnosing, and\nrefining a machine learning model with the help of interactive visualization,\nis very important for users to efficiently solve real-world artificial\nintelligence and data mining problems. Dramatic advances in big data analytics\nhas led to a wide variety of interactive model analysis tasks. In this paper,\nwe present a comprehensive analysis and interpretation of this rapidly\ndeveloping area. Specifically, we classify the relevant work into three\ncategories: understanding, diagnosis, and refinement. Each category is\nexemplified by recent influential work. Possible future research opportunities\nare also explored and discussed.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper, we try to predict the winning team of a match in the\nmultiplayer eSports game Dota 2. To address the weaknesses of previous work, we\nconsider more aspects of prior (pre-match) features from individual players'\nmatch history, as well as real-time (during-match) features at each minute as\nthe match progresses. We use logistic regression, the proposed Attribute\nSequence Model, and their combinations as the prediction models. In a dataset\nof 78362 matches where 20631 matches contain replay data, our experiments show\nthat adding more aspects of prior features improves accuracy from 58.69% to\n71.49%, and introducing real-time features achieves up to 93.73% accuracy when\npredicting at the 40th minute.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Context. Convection is a candidate to explain the trigger of red supergiant\nstar mass loss. Owing to the small size of the convective cells on the\nphotosphere, few of their characteristics are known. Aims. Using near infrared\ninterferometry, we intend to resolve the photosphere of red supergiant stars\nand to bring new constraints on their modeling. Methods. We observed the nearby\nred supergiant Antares using the 4-telescope instrument VLTI/PIONIER. We\ncollected data on the three available configurations of the 1.8m telescopes in\nthe H band. Results. We obtained unprecedented angular resolution on the disk\nof a star (6% of the star angular diameter) that limits the mean size of\nconvective cells, brings new constraints on numerical simulations. Using an\nanalytical model with a distribution of bright spots we determine their effect\non the visibility signal. Conclusion. We determine that the interferometric\nsignal on Antares is compatible with convective cells with various sizes from\n45% to 5% of the angular diameter. We also conclude that convective cells can\nstrongly affect the angular diameter and limb-darkening measurements. In\nparticular, the apparent angular diameter becomes dependent on the sampled\nposition angles.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In our previous work we reported on a linked-courses learning community for\nunderrepresented groups in computer science, finding differences in attitudes\nand resource utilization between students in the community and other\nprogramming students. Here we present the first statistically significant\ndifferences in pre- to post-quarter student attitudes between those in the\nlearning community and others taking equivalent programming classes. We find\nthat students in the learning community are less likely to feel isolated\npost-quarter than other programming students. We also present results showing\ndifferences in resource utilization by learning-community participants.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We construct the Atiyah-Hirzebruch spectral sequence (AHSS) for twisted\ndifferential generalized cohomology theories. This generalizes to the twisted\nsetting the authors' corresponding earlier construction for differential\ncohomology theories, as well as to the differential setting the AHSS for\ntwisted generalized cohomology theories, including that of twisted K-theory by\nRosenberg and Atiyah-Segal. In describing twisted differential spectra we build\non the work of Bunke-Nikolaus, but we find it useful for our purposes to take\nan approach that highlights direct analogies with classical bundles and that is\nat the same time amenable for calculations. We will, in particular, establish\nthat twisted differential spectra are bundles of spectra equipped with a flat\nconnection. Our prominent case will be twisted differential K-theory, for which\nwe work out the differentials in detail. This involves differential refinements\nof primary and secondary cohomology operations the authors developed in earlier\npapers. We illustrate our constructions and computational tools with examples.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we tackle the problem of visually predicting surface friction\nfor environments with diverse surfaces, and integrating this knowledge into\nbiped robot locomotion planning. The problem is essential for autonomous robot\nlocomotion since diverse surfaces with varying friction abound in the real\nworld, from wood to ceramic tiles, grass or ice, which may cause difficulties\nor huge energy costs for robot locomotion if not considered. We propose to\nestimate friction and its uncertainty from visual estimation of material\nclasses using convolutional neural networks, together with probability\ndistribution functions of friction associated with each material. We then\nrobustly integrate the friction predictions into a hierarchical (footstep and\nfull-body) planning method using chance constraints, and optimize the same\ntrajectory costs at both levels of the planning method for consistency. Our\nsolution achieves fully autonomous perception and locomotion on slippery\nterrain, which considers not only friction and its uncertainty, but also\ncollision, stability and trajectory cost. We show promising friction prediction\nresults in real pictures of outdoor scenarios, and planning experiments on a\nreal robot facing surfaces with different friction.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Solar flares are generally believed to be powered by free magnetic energy\nstored in the corona, but the build up of coronal energy alone may be\ninsufficient for the imminent flare occurrence. The flare onset mechanism is a\ncritical but less understood problem, insights into which could be gained from\nsmall-scale energy releases known as precursors, which are observed as small\npre-flare brightenings in various wavelengths, and also from certain\nsmall-scale magnetic configurations such as the opposite polarity fluxes, where\nmagnetic orientation of small bipoles is opposite to that of the ambient main\npolarities. However, high-resolution observations of flare precursors together\nwith the associated photospheric magnetic field dynamics are lacking. Here we\nstudy precursors of a flare using unprecedented spatiotemporal resolution of\nthe 1.6 m New Solar Telescope, complemented by novel microwave data. Two\nepisodes of precursor brightenings are initiated at a small-scale magnetic\nchannel (a form of opposite polarity fluxes) with multiple polarity inversions\nand enhanced magnetic fluxes and currents, lying near the footpoints of sheared\nmagnetic loops. The low-atmospheric origin of these precursor emissions is\ncorroborated by microwave spectra. We propose that the emerging magnetic\nchannel field interacts with the sheared arcades to cause precursor\nbrightenings at the main flare core region. These high-resolution results\nprovide evidence of low-atmospheric small-scale energy release and possible\nrelationship to the onset of the main flare.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The stochastic gravitational wave (GW) background provides a fascinating\nwindow to the physics of the very early universe. Beyond the nearly\nscale-invariant primordial GW spectrum produced during inflation, a spectrum\nwith a much richer structure is typically generated during the preheating phase\nafter inflation (or after some other phase transition at lower energies). This\nraises the question of what one can learn from a future observation of the\nstochastic gravitational wave background spectrum about the underlying physics\nduring preheating. Recently, it has been shown that during preheating\nnon-perturbative quasi-stable objects like oscillons can act as strong sources\nfor GW, leading to characteristic features such as distinct peaks in the\nspectrum. In this paper, we study the GW production from oscillons using\nsemi-analytical techniques. In particular, we discuss how the GW spectrum is\naffected by the parameters that characterise a given oscillon system, e.g. by\nthe background cosmology, the asymmetry of the oscillons and the evolution of\nthe number density of the oscillons. We compare our semi-analytic results with\nnumerical lattice simulations for a hilltop inflation model and a KKLT\nscenario, which differ strongly in some of these characteristics, and find very\ngood agreement.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We present Atacama Large Millimeter/sub-millimeter Array (ALMA) observations\nof the star-forming environment surrounding V1647 Ori, an outbursting FUor/EXor\npre-MS star. Dust continuum and the (J = 2 - 1) $^{12}$CO, $^{13}$CO, C$^{18}$O\nmolecular emission lines were observed to characterize the V1647 Ori\ncircumstellar disc and any large scale molecular features present. We detect\ncontinuum emission from the circumstellar disc and determine a radius r = 40\nau, inclination i = 17$^{\\circ}$$^{+6}_{-9}$ and total disc mass of\nM$_{\\mathrm{disk}}$ of ~0.1 M$_{\\odot}$. We do not identify any disc structures\nassociated with nearby companions, massive planets or fragmentation. The\nmolecular cloud environment surrounding V1647 Ori is both structured and\ncomplex. We confirm the presence of an excavated cavity north of V1647 Ori and\nhave identified dense material at the base of the optical reflection nebula\n(McNeil's Nebula) that is actively shaping its surrounding environment. Two\ndistinct outflows have been detected with dynamical ages of ~11,700 and 17,200\nyears. These outflows are misaligned suggesting disc precession over ~5500\nyears as a result of anisotropic accretion events is responsible. The\ncollimated outflows exhibit velocities of ~2 km s$^{-1}$, similar in velocity\nto that of other FUor objects presented in this series but significantly slower\nthan previous observations and model predictions. The V1647 Ori system is\nseemingly connected by an \"arm\" of material to a large unresolved structure\nlocated ~20$\"$ to the west. The complex environment surrounding V1647 Ori\nsuggests it is in the early stages of star formation which may relate to its\nclassification as both an FUor and EXor type object.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In a recent paper we analyzed the space complexity of streaming algorithms\nwhose goal is to decide membership of a sliding window to a fixed language. For\nthe class of regular languages we proved a space trichotomy theorem: for every\nregular language the optimal space bound is either constant, logarithmic or\nlinear. In this paper we continue this line of research: We present natural\ncharacterizations for the constant and logarithmic space classes and establish\ntight relationships to the concept of language growth. We also analyze the\nspace complexity with respect to automata size and prove almost matching lower\nand upper bounds. Finally, we consider the decision problem whether a language\ngiven by a DFA/NFA admits a sliding window algorithm using logarithmic/constant\nspace.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Many asteroid databases with lightcurve brightness measurements (e.g. WISE,\nPan-STARRS1) contain enormous amounts of data for asteroid shape and spin\nmodelling. While lightcurve inversion is not plausible for individual targets\nwith scarce data, it is possible for large populations with thousands of\nasteroids, where the distributions of the shape and spin characteristics of the\npopulations are obtainable.\n  We aim to introduce a software implementation of a method that computes the\njoint shape elongation p and spin latitude beta distributions for a population,\nwith the brightness observations given in an asteroid database. Other main\ngoals are to include a method for performing validity checks of the algorithm,\nand a tool for a statistical comparison of populations.\n  The LEADER software package read the brightness measurement data for a\nuser-defined subpopulation from a given database. The observations were used to\ncompute estimates of the brightness variations of the population members. A\ncumulative distribution function (CDF) was constructed of these estimates. A\nsuperposition of known analytical basis functions yielded this CDF as a\nfunction of the (shape, spin) distribution. The joint distribution can be\nreconstructed by solving a linear constrained inverse problem. To test the\nvalidity of the method, the algorithm can be run with synthetic asteroid\nmodels, where the shape and spin characteristics are known, and by using the\ngeometries taken from the examined database.\n  LEADER is a fast and robust software package for solving shape and spin\ndistributions for large populations. There are major differences in the quality\nand coverage of measurements depending on the database used, so synthetic\nsimulations are always necessary before a database can be reliably used. We\nshow examples of differences in the results when switching to another database.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  A local existence and uniqueness theorem for ODEs in the special algebra of\ngeneralized functions is established, as well as versions including parameters\nand dependence on initial values in the generalized sense. Finally, a Frobenius\ntheorem is proved. In all these results, composition of generalized functions\nis based on the notion of c-boundedness.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The Dirac equation in curved space is used to study the optical transmittance\nof deformed graphene along a given direction. Our theoretical analysis of the\navailable experimental data for the light transmittance suggests that the\nperiodic ripple associated with the out-of-plane deformation observed in\nunstrained graphene explains the observations. Furthermore, the experimental\nuniaxial strained graphene for light transmittance show two features, namely\nthe modification of the $\\cos^2\\theta$ law and the decrease of the amplitude of\nthe oscillations with the polarization angle $\\theta$, which can be well\naccommodated within the theoretical analysis used here and provide further\nevidence of the validity of using QFT in curved space to understand two\ndimensional materials.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We prove two rigidity theorems for maps between Riemannian manifolds. First,\nwe prove that a Lipschitz map $f:M\\to N$ between two oriented Riemannian\nmanifolds, whose differential is almost everywhere an orientation-preserving\nisometry, is an isometric immersion. This theorem was previously proved using\nregularity theory for conformal maps; we give a new, simple proof, by\ngeneralizing the Piola identity for the cofactor operator. Second, we prove\nthat if there exists a sequence of mapping $f_n:M\\to N$, whose differentials\nconverge in $L^p$ to the set of orientation-preserving isometries, then there\nexists a subsequence converging to an isometric immersion. These results are\ngeneralizations of celebrated rigidity theorems by Liouville (1850) and\nReshetnyak (1967) from Euclidean to Riemannian settings. Finally, we describe\napplications of these theorems to non-Euclidean elasticity and to convergence\nnotions of manifolds.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  I give a pedagogical introduction into flavour-changing neutral current\ninteractions of kaons and their role to reveal or constrain physics beyond the\nStandard Model (SM). Then I discuss the measure $\\epsilon_K^\\prime$ of direct\nCP violation in $K\\to \\pi\\pi$ decays, which deviates from the SM prediction by\n$2.8\\sigma$. A supersymmetric scenario with flavour mixing among left-handed\nsquarks can accomodate the measured value of $\\epsilon_K^\\prime$ even for very\nheavy sparticles, outside the reach of the LHC. The considered scenario employs\nmass splittings among the right-handed up and down squarks (to enhance\n$\\epsilon_K^\\prime$) and a gluino which is heavier than the left-handed\nstrange-down mixed squarks by at least a factor of 1.5 (to suppress excessive\ncontribution to $\\epsilon_K$, the measure of indirect CP violation). The\nbranching ratios of the rare decays $K^+ \\to \\pi^+ \\nu \\bar\\nu$ and $K_L \\to\n\\pi^0 \\nu \\bar\\nu$, to be measured by the NA62 and KOTO-step2 experiments,\nrespectively, are only moderately affected. These measurements have the\ncapability to either falsify the model or to constrain the CP phase associated\nwith strange-down squark mixing accurately.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Recent experiments on Weyl semimetals reveal that charged impurities may play\nan important role. We use a screened Coulomb disorder to model the charged\nimpurities, and study the magneto-transport in a two-node Weyl semimetal. It is\nfound that when the external magnetic field is applied parallel to the electric\nfield, the calculated longitudinal magnetoconductivity shows positive in the\nmagnetic field, which is just the negative longitudinal magnetoresistivity\n(LMR) observed in experiments. When the two fields are perpendicular to each\nother, the transverse magnetoconductivities are measured. It is found that the\nlongitudinal (transverse) magnetoconductivity is suppressed (enhanced)\nsensitively with increasing the screening length. This feature makes it hardly\nto observe the negative LMR in Weyl semimetals experimentally owing to a small\nscreening length. Our findings gain insight into further understanding on\nrecently actively debated magneto-transport behaviors in Weyl semimetals.\nFurthermore we studied the relative weight of the inter-valley scattering and\nthe intra-valley scattering. It shows that the former is as important as the\nlatter and even dominates in the case of strong magnetic fields and small\nscreening length. We emphasize that the discussions on inter-valley scattering\nis out of the realm of one-node model which has been studied.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We report the first detection of sodium absorption in the atmosphere of the\nhot Jupiter WASP-52b. We observed one transit of WASP-52b with the\nlow-resolution Optical System for Imaging and low-Intermediate-Resolution\nIntegrated Spectroscopy (OSIRIS) at the 10.4 m Gran Telescopio Canarias (GTC).\nThe resulting transmission spectrum, covering the wavelength range from 522 nm\nto 903 nm, is flat and featureless, except for the significant narrow\nabsorption signature at the sodium doublet, which can be explained by an\natmosphere in solar composition with clouds at 1 mbar. A cloud-free atmosphere\nis stringently ruled out. By assessing the absorption depths of sodium in\nvarious bin widths, we find that temperature increases towards lower\natmospheric pressure levels, with a positive temperature gradient of 0.88 +/-\n0.65 K/km, possibly indicative of upper atmospheric heating and a temperature\ninversion.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Requirements engineering provides several practices to analyze how a user\nwants to interact with a future software. Mockups, prototypes, and scenarios\nare suitable to understand usability issues and user requirements early.\nNevertheless, users are often dissatisfied with the usability of a resulting\nsoftware. Apparently, previously explored information was lost or no longer\naccessible during the development phase. Scenarios are one effective practice\nto describe behavior. However, they are commonly notated in natural language\nwhich is often improper to capture and communicate interaction knowledge\ncomprehensible to developers and users. The dynamic aspect of interaction is\nlost if only static descriptions are used. Digital prototyping enables the\ncreation of interactive prototypes by adding responsive controls to hand- or\ndigitally drawn mockups. We propose to capture the events of these controls to\nobtain a representation of the interaction. From this data, we generate videos,\nwhich demonstrate interaction sequences, as additional support for textual\nscenarios. Variants of scenarios can be created by modifying the captured event\nsequences and mockups. Any change is unproblematic since videos only need to be\nregenerated. Thus, we achieve video as a by-product of digital prototyping.\nThis reduces the effort compared to video recording such as screencasts. A\nfirst evaluation showed that such a generated video supports a faster\nunderstanding of a textual scenario compared to static mockups.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In this paper we study the abelian sandpile model on the two-dimensional grid\nwith uniform neighborhood, and prove that any family of neighborhoods defined\nas scalings of a continuous non-flat shape can ultimately perform crossing.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the holonomy group of singular K\\\"ahler-Einstein metrics on\nklt varieties with numerically trivial canonical divisor. Finiteness of the\nnumber of connected components, a Bochner principle for holomorphic tensors,\nand a connection between irreducibility of holonomy representations and\nstability of the tangent sheaf are established. As a consequence, known\ndecompositions for tangent sheaves of varieties with trivial canonical divisor\nare refined. In particular, we show that up to finite quasi-\\'etale covers,\nvarieties with strongly stable tangent sheaf are either Calabi-Yau or\nirreducible holomorphic symplectic. These results form one building block for\nH\\\"oring-Peternell's recent proof of a singular version of the\nBeauville-Bogomolov Decomposition Theorem.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate scattering of the topological surface state of a\nthree-dimensional time-reversal invariant topological insulator when graphene\nis deposited on the topological-insulator surface. Specifically, we consider\nthe (111) surface of a Bi$_2$Se$_3$-like topological insulator. We present a\nlow-energy model for the bulk graphene-topological insulator heterostructure\nand we calculate the transmission probability at zigzag and armchair edges of\nthe deposited graphene, and the conductance through graphene nanoribbon\nbarriers and show that its features can be understood from antiresonances in\nthe transmission probability.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Although an increased availability of computational resources has enabled\nhigh-fidelity simulations of turbulent flows, the RANS models are still the\ndominant tools for industrial applications. However, the predictive\ncapabilities of RANS models are limited by potential inaccuracy driven by\nhypotheses in the Reynolds stress closure. Recently, a Physics-Informed Machine\nLearning (PIML) approach has been proposed to learn the functional form of\nReynolds stress discrepancy in RANS simulations based on available data. It has\nbeen demonstrated that the learned discrepancy function can be used to improve\nReynolds stresses in different flows where data are not available. However,\nowing to a number of challenges, the improvements have been demonstrated only\nin the Reynolds stress prediction but not in the corresponding propagated\nquantities of interest. In this work, we introduce the procedures toward a\ncomplete PIML framework for predictive turbulence modeling, including learning\nReynolds stress discrepancy function, predicting Reynolds stresses in different\nflows, and propagating to mean flow fields. The process of Reynolds stress\npropagation and predictive accuracy of the propagated velocity field are\ninvestigated. To improve the learning-prediction performance, the input\nfeatures are enriched based on an integrity basis of invariants. The fully\ndeveloped turbulent flow in a square duct is used as the test case. The\ndiscrepancy model is trained on flow fields obtained from several Reynolds\nnumbers and evaluated on a duct flow at a Reynolds number higher than any of\nthe training cases. The predicted Reynolds stresses are propagated to velocity\nfield through RANS equations. Numerical results show excellent predictive\nperformances in both Reynolds stresses and their propagated velocities,\ndemonstrating the merits of the PIML approach in predictive turbulence\nmodeling.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study mechanical behavior of soft rubber-like digital materials used in\nPolyjet multi-material 3D-printing to create deformable composite materials and\nflexible structures. These soft digital materials are frequently treated as\nlinear elastic materials in the literature. However, our experiments clearly\nshow that these materials exhibit significant non-linearities under large\nstrain regime. Moreover, the materials demonstrate pronounced rate-dependent\nbehavior. In particular, their instantaneous moduli as well as ultimate strain\nand stress significantly depend on the strain rate. To take into account both\nhyper- and viscoelasticity phenomena, we employ the Quasi-Linear Viscoelastic\n(QLV) model with instantaneous Yeoh strain-energy density function. We show\nthat the QLV-Yeoh model accurately describes the mechanical behavior of the\nmajority of the soft digital materials under uniaxial tension.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  To date, nearly all multi-wavelength modeling of long-duration gamma-ray\nbursts has ignored synchrotron radiation from the significant population of\nelectrons expected to pass the shock without acceleration into a power-law\ndistribution. We investigate the effect of including the contribution of\nthermal, non-accelerated electrons to synchrotron absorption and emission in\nthe standard afterglow model, and show that these thermal electrons provide an\nadditional source of opacity to synchrotron self-absorption, and yield an\nadditional emission component at higher energies. The extra opacity results in\nan increase in the synchrotron self-absorption frequency by factors of 10--100\nfor fiducial parameters. The nature of the additional emission depends on the\ndetails of the thermal population, but is generally observed to yield a\nspectral peak in the optical brighter than radiation from the nonthermal\npopulation by similar factors a few seconds after the burst, remaining\ndetectable at millimeter and radio frequencies several days later.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Magnetorotational instability (MRI) is one of the fundamental processes in\nastrophysics, driving angular momentum transport and mass accretion in a wide\nvariety of cosmic objects. Despite much theoretical/numerical and experimental\nefforts over the last decades, its saturation mechanism and amplitude, which\nsets the angular momentum transport rate, remains not well understood,\nespecially in the limit of high resistivity, or small magnetic Prandtl numbers\ntypical to interiors (dead zones) of protoplanetary disks, liquid cores of\nplanets and liquid metals in laboratory. Using direct numerical simulations, in\nthis paper we investigate the nonlinear development and saturation properties\nof the helical magnetorotational instability (HMRI) -- a relative of the\nstandard MRI -- in a magnetized Taylor-Couette flow at very low magnetic\nPrandtl number (correspondingly at low magnetic Reynolds number) relevant to\nliquid metals. For simplicity, the ratio of azimuthal field to axial field is\nkept fixed. From the linear theory of HMRI, it is known that the Elsasser\nnumber, or interaction parameter determines its growth rate and plays a special\nrole in the dynamics. We show that this parameter is also important in the\nnonlinear problem. By increasing its value, a sudden transition from weakly\nnonlinear, where the system is slightly above the linear stability threshold,\nto strongly nonlinear, or turbulent regime occurs. We calculate the azimuthal\nand axial energy spectra corresponding to these two regimes and show that they\ndiffer qualitatively. Remarkably, the nonlinear state remains in all cases\nnearly axisymmetric suggesting that HMRI turbulence is quasi two-dimensional in\nnature. Although the contribution of non-axisymmetric modes increases\nmoderately with the Elsasser number, their total energy remains much smaller\nthan that of the axisymmetric ones.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  PSR B1259-63/LS2883 is a binary system composed of a pulsar and a Be star.\nThe Be star has an equatorial circumstellar disk (CD). The {\\it Fermi}\nsatellite discovered unexpected gamma-ray flares around 30 days after the last\ntwo periastron passages. The origin of the flares remain puzzling. In this\nwork, we explore the possibility that, the GeV flares are consequences of\ninverse Compton-scattering of soft photons by the pulsar wind. The soft photons\nare from an accretion disk around the pulsar, which is composed by the matter\nfrom CD captured by the pulsar's gravity at disk-crossing before the\nperiastron. At the other disk-crossing after the periastron, the density of the\nCD is not high enough so that accretion is prevented by the pulsar wind shock.\nThis model can reproduce the observed SEDs and light curves satisfactorily.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Two finite-time consensus protocols are proposed for multi-dimensional\nmulti-agent systems, using direction-preserving and component-wise signum\ncontrols respectively. Filippov solutions and non-smooth analysis techniques\nare adopted to handle discontinuities. Sufficient and necessary conditions are\nprovided to guarantee finite-time convergence and boundedness of the solutions.\nIt turns out that the number of agents which have continuous control law plays\nan essential role for finite-time convergence. In addition it is shown that the\nunit balls introduced by $\\ell_p$ and $\\ell_{\\infty}$ norms are invariant for\nthese two protocols respectively.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Background: It is commonly assumed in neuronal coding that repeated\npresentations of a stimulus to a coding neuron elicit similar responses. One\ncommon way to assess similarity are spike train distances. These can be divided\ninto spike-resolved, such as the Victor-Purpura and the van Rossum distance,\nand time-resolved, e.g. the ISI-, the SPIKE- and the RI-SPIKE-distance.\n  New Method: We use independent steady-rate Poisson processes as surrogates\nfor spike trains with fixed rate and no timing information to address two basic\nquestions: How does the sensitivity of the different spike train distances to\ntemporal coding depend on the rates of the two processes and how do the\ndistances deal with very low rates?\n  Results: Spike-resolved distances always contain rate information even for\nparameters indicating time coding. This is an issue for reasonably high rates\nbut beneficial for very low rates. In contrast, the operational range for\ndetecting time coding of time-resolved distances is superior at normal rates,\nbut these measures produce artefacts at very low rates. The RI-SPIKE-distance\nis the only measure that is sensitive to timing information only.\n  Comparison with Existing Methods: While our results on rate-dependent\nexpectation values for the spike-resolved distances agree with\n\\citet{Chicharro11}, we here go one step further and specifically investigate\napplicability for very low rates.\n  Conclusions: The most appropriate measure depends on the rates of the data\nbeing analysed. Accordingly, we summarize our results in one table that allows\nan easy selection of the preferred measure for any kind of data.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We study the geometry of some moduli spaces of twisted sheaves on K3\nsurfaces. In particular we introduce induced automorphisms from a K3 surface on\nmoduli spaces of twisted sheaves on this K3 surface. As an application we prove\nthe unirationality of moduli spaces of irreducible holomorphic symplectic\nmanifolds of $K3^{[2]}$-type admitting non symplectic involutions with\ninvariant lattices $U(2)\\oplus D_4(-1)$ or $U(2)\\oplus E_8(-2)$. This\ncomplements the results obtained in [Mongardi and Wandel 2015], [Bossiere et al\n2016], and the results from [arXiv:1603.00403] about the geometry of IHS\nfourfolds constructed using the Hilbert scheme of $(1,1)$ conics on Verra\nfourfolds. As a byproduct we find that IHS fourfolds of $K3^{[2]}$-type with\nPicard lattice $U(2)\\oplus E_8(-2)$ naturally contain non-nodal Enriques\nsurfaces.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We investigate the effect of a degenerate optical parametric amplifier (OPA)\nplaced inside an optomechanical cavity on the steady-state entanglement of two\ncavity modes, which jointly interact with a mechanical resonator. Two cavity\nmodes are respectively driven at the red and blue sideband associated with the\nmechanical resonator, which generates entanglement between them in the limit of\nresolved sideband. The OPA gives rise to single-mode squeezing of the cavity\nfields, which results in significant improvement of the two-mode entanglement.\nIt is found that an optimal nonlinear gain of the OPA exists, depending on the\nsystem temperatures, which yields the maximum entanglement. The improvement is\nparticularly remarkable for the system at cryogenic temperatures.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  These proceedings review the two DUNE prototype detectors, namely Single- and\nDual-Phase ProtoDUNEs. The detectors, both employing liquid argon Time\nProjection Chambers (LAr TPCs), are currently being built at CERN as part of\nthe ProtoDUNE experimental programme. Such R&D programme aims at validating the\nprototypes design and technology, which will eventually be applied to the DUNE\nFar Detector at the Sanford Underground Research Facility (SURF).\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We provide mass-loss rate predictions for O stars from Large and Small\nMagellanic Clouds. We calculate global (unified, hydrodynamic) model\natmospheres of main sequence, giant, and supergiant stars for chemical\ncomposition corresponding to Magellanic Clouds. The models solve radiative\ntransfer equation in comoving frame, kinetic equilibrium equations (also known\nas NLTE equations), and hydrodynamical equations from (quasi-)hydrostatic\natmosphere to expanding stellar wind. The models allow us to predict wind\ndensity, velocity, and temperature (consequently also the terminal wind\nvelocity and the mass-loss rate) just from basic global stellar parameters. As\na result of their lower metallicity, the line radiative driving is weaker\nleading to lower wind mass-loss rates with respect to the Galactic stars. We\nprovide a formula that fits the mass-loss rate predicted by our models as a\nfunction of stellar luminosity and metallicity. On average, the mass-loss rate\nscales with metallicity as $ \\dot M\\sim Z^{0.59}$. The predicted mass-loss\nrates are lower than mass-loss rates derived from H$\\alpha$ diagnostics and can\nbe reconciled with observational results assuming clumping factor\n$C_\\text{c}=9$. On the other hand, the predicted mass-loss rates either agree\nor are slightly higher than the mass-loss rates derived from ultraviolet wind\nline profiles. The calculated \\ion{P}{v} ionization fractions also agree with\nvalues derived from observations for LMC stars with\n$T_\\text{eff}\\leq40\\,000\\,$K. Taken together, our theoretical predictions\nprovide reasonable models with consistent mass-loss rate determination, which\ncan be used for quantitative study of stars from Magellanic Clouds.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Hamilton's Ricci flow (RF) equations were recently expressed in terms of a\nsparsely-coupled system of autonomous first-order nonlinear differential\nequations for the edge lengths of a d-dimensional piecewise linear (PL)\nsimplicial geometry. More recently, this system of discrete Ricci flow (DRF)\nequations was further simplified by explicitly constructing the Forman-Ricci\ntensor associated to each edge, thereby diagonalizing the first-order\ndifferential operator and avoiding the need to invert large sparse matrices at\neach time step. We recently showed analytically and numerically that these\nequations converge for axisymmetric 3-geometries to the corresponding continuum\nRF equations. We demonstrate here that these DRF equations yield an explicit\nnumerical realization of Thurston's geometrization procedure for a discrete 3D\naxially-symmetric neckpinch geometry by using surgery to explicitly integrate\nthrough its Type-1 neck pinch singularity. A cubic-spline-based adaptive mesh\nwas required to complete the evolution. Our numerically efficient simulations\nyield the expected Thurston decomposition of the sufficiently pinched axially\nsymmetric geometry into its unique geometric structure -- a direct product of\ntwo lobes, each collapsing toward a 3-sphere geometry. The structure of our\ncurvature may be used to better inform one of the vertex and edge weighting\nfactors that appear in the Forman's expression of Ricci curvature on graphs.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We introduce Lipschitz functions on a finite partially ordered set $P$ and\nstudy the associated Lipschitz polytope $L(P)$. The geometry of $L(P)$ can be\ndescribed in terms of descent-compatible permutations and permutation\nstatistics that generalize descents and big ascents. For ranked posets,\nLipschitz polytopes are centrally-symmetric and Gorenstein, which implies\nsymmetry and unimodality of the statistics. Finally, we define\n$(P,k)$-hypersimplices as generalizations of classical hypersimplices and give\ncombinatorial interpretations of their volumes and $h^*$-vectors.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We consider the Ising model at its critical temperature with external\nmagnetic field $ha^{15/8}$ on the square lattice with lattice spacing $a$. We\nshow that the truncated two-point function in this model decays exponentially\nwith a rate independent of $a$. As a consequence, we show exponential decay in\nthe near-critical scaling limit Euclidean magnetization field. For the lattice\nmodel with $a=1$, the mass (inverse correlation length) is of order $h^{8/15}$\nas $h\\downarrow 0$; for the Euclidean field, it equals exactly $Ch^{8/15}$ for\nsome $C$. Although there has been much progress in the study of critical\nscaling limits, results on near-critical models are far fewer due to the lack\nof conformal invariance away from the critical point. Our arguments combine\nlattice and continuum FK representations, including coupled conformal loop and\nmeasure ensembles, showing that such ensembles can be useful even in the study\nof near-critical scaling limits. Thus we provide the first substantial\napplication of measure ensembles.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Automatic cell image segmentation methods in connectomics produce merge and\nsplit errors, which require correction through proofreading. Previous research\nhas identified the visual search for these errors as the bottleneck in\ninteractive proofreading. To aid error correction, we develop two classifiers\nthat automatically recommend candidate merges and splits to the user. These\nclassifiers use a convolutional neural network (CNN) that has been trained with\nerrors in automatic segmentations against expert-labeled ground truth. Our\nclassifiers detect potentially-erroneous regions by considering a large context\nregion around a segmentation boundary. Corrections can then be performed by a\nuser with yes/no decisions, which reduces variation of information 7.5x faster\nthan previous proofreading methods. We also present a fully-automatic mode that\nuses a probability threshold to make merge/split decisions. Extensive\nexperiments using the automatic approach and comparing performance of novice\nand expert users demonstrate that our method performs favorably against\nstate-of-the-art proofreading methods on different connectomics datasets.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Given a triangulated surface $M$, we use Ge-Xu's $\\alpha$-flow \\cite{Ge-Xu1}\nto deform any initial inversive distance circle packing metric to a metric with\nconstant $\\alpha$-curvature. More precisely, we prove that the inversive\ndistance circle packing with constant $\\alpha$-curvature is unique if\n$\\alpha\\chi(M)\\leq 0$, which generalize Andreev-Thurston's rigidity results for\ncircle packing with constant cone angles. We further prove that the solution to\nGe-Xu's $\\alpha$-flow can always be extended to a solution that exists for all\ntime and converges exponentially fast to constant $\\alpha$-curvature. Finally,\nwe give some combinatorial and topological obstacles for the existence of\nconstant $\\alpha$-curvature metrics.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We determine which faithful irreducible representations $V$ of a simple\nlinear algebraic group $G$ are generically free for Lie($G$), i.e., which $V$\nhave an open subset consisting of vectors whose stabilizer in Lie($G$) is zero.\nThis relies on bounds on $\\dim V$ obtained in prior work (part I), which reduce\nthe problem to a finite number of possibilities for $G$ and highest weights for\n$V$, but still infinitely many characteristics. The remaining cases are handled\nindividually, some by computer calculation. These results were previously known\nfor fields of characteristic zero, although new phenomena appear in prime\ncharacteristic; we provide a shorter proof that gives the result with very mild\nhypotheses on the characteristic. (The few characteristics not treated here are\nsettled in part III.) These results are related to questions about invariants\nand the existence of a stabilizer in general position.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We find a new example of an asymptotically $AdS_5 \\times S^5$ geometry which\nhas an entanglement shadow: that is, a region of spacetime which no\nRyu-Takayanagi minimal surface enters. Our example is a particular case of the\nsupersymmetric LLM geometries. Our results illustrate how minimal surfaces,\nwhich holographically geometrize entanglement entropy, can fail to probe the\nwhole of spacetime, posing a challenge for attempts to directly reconstruct\nholographic geometries from the entanglement entropies of the dual field\ntheory. We also comment on the relation to previous investigations of minimal\nsurfaces localised in the $S^5$ factor of AdS$_5 \\times S^5$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Failure rates in high performance computers rapidly increase due to the\ngrowth in system size and complexity. Hence, failures became the norm rather\nthan the exception. Different approaches on high performance computing (HPC)\nsystems have been introduced, to prevent failures (e. g., redundancy) or at\nleast minimize their impacts (e. g., checkpoint and restart). In most cases,\nwhen these approaches are employed to increase the resilience of certain parts\nof a system, energy consumption rapidly increases, or performance significantly\ndegrades. To address this challenge, we propose on-demand resilience as an\napproach to achieve adaptive resilience in HPC systems. In this work, the HPC\nsystem is considered in its entirety and resilience mechanisms such as\ncheckpointing, isolation, and migration, are activated on-demand. Using the\nproposed approach, the unavoidable increase in total energy consumption and\nsystem performance degradation is decreased compared to the typical\ncheckpoint/restart and redundant resilience mechanisms. Our work aims to\nmitigate a large number of failures occurring at various layers in the system,\nto prevent their propagation, and to minimize their impact, all of this in an\nenergy-saving manner. In the case of failures that are estimated to occur but\ncannot be mitigated using the proposed on-demand resilience approach, the\nsystem administrators will be notified in view of performing further\ninvestigations into the causes of these failures and their impacts.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Using the transfer-matrix approach and solving time-domain differential\nequations, we analyze the loss compensation mechanism in multilayer systems\ncomposed of an absorbing transparent conductive oxide and dielectric doped with\nan active material. We reveal also another regime with the possibility of\nenhanced transmission with suppressed reflection originating from the resonant\nproperties of the multilayers. For obliquely incident and evanescent waves,\nsuch enhanced transmission under suppressed reflection turns into the\nreflectionless regime, which is similar to that observed in the PT-symmetric\nstructures, but does not require PT symmetry. We infer that the reflectionless\ntransmission is due to the full loss compensation at the resonant wavelengths\nof the multilayers.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Stellar feedback created by radiation and winds from massive stars plays a\nsignificant role in both physical and chemical evolution of molecular clouds.\nThis energy and momentum leaves an identifiable signature (\"bubbles\") that\naffect the dynamics and structure of the cloud. Most bubble searches are\nperformed \"by-eye\", which are usually time-consuming, subjective and difficult\nto calibrate. Automatic classifications based on machine learning make it\npossible to perform systematic, quantifiable and repeatable searches for\nbubbles. We employ a previously developed machine learning algorithm, Brut, and\nquantitatively evaluate its performance in identifying bubbles using synthetic\ndust observations. We adopt magneto-hydrodynamics simulations, which model\nstellar winds launching within turbulent molecular clouds, as an input to\ngenerate synthetic images. We use a publicly available three-dimensional dust\ncontinuum Monte-Carlo radiative transfer code, hyperion, to generate synthetic\nimages of bubbles in three Spitzer bands (4.5 um, 8 um and 24 um). We designate\nhalf of our synthetic bubbles as a training set, which we use to train Brut\nalong with citizen-science data from the Milky Way Project. We then assess\nBrut's accuracy using the remaining synthetic observations. We find that after\nretraining Brut's performance increases significantly, and it is able to\nidentify yellow bubbles, which are likely associated with B-type stars. Brut\ncontinues to perform well on previously identified high-score bubbles, and over\n10% of the Milky Way Project bubbles are reclassified as high-confidence\nbubbles, which were previously marginal or ambiguous detections in the Milky\nWay Project data. We also investigate the size of the training set, dust model,\nevolution stage and background noise on bubble identification.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The classic arcsine law for the number\n$N_{n}^{>}:=n^{-1}\\sum_{k=1}^{n}\\mathbf{1}_{\\{S_{k}>0\\}}$ of positive terms, as\n$n\\to\\infty$, in an ordinary random walk $(S_{n})_{n\\ge 0}$ is extended to the\ncase when this random walk is governed by a positive recurrent Markov chain\n$(M_{n})_{n\\ge 0}$ on a countable state space $\\mathcal{S}$, that is, for a\nMarkov random walk $(M_{n},S_{n})_{n\\ge 0}$ with positive recurrent discrete\ndriving chain. More precisely, it is shown that $n^{-1}N_{n}^{>}$ converges in\ndistribution to a generalized arcsine law with parameter $\\rho\\in [0,1]$ (the\nclassic arcsine law if $\\rho=1/2$) iff the Spitzer condition $$\n\\lim_{n\\to\\infty}\\frac{1}{n}\\sum_{k=1}^{n}\\mathbb{P}_{i}(S_{n}>0)\\ =\\ \\rho $$\nholds true for some and then all $i\\in\\mathcal{S}$, where\n$\\mathbb{P}_{i}:=\\mathbb{P}(\\cdot|M_{0}=i)$ for $i\\in\\mathcal{S}$. It is also\nproved, under an extra assumption on the driving chain if $0<\\rho<1$, that this\ncondition is equivalent to the stronger variant $$\n\\lim_{n\\to\\infty}\\mathbb{P}_{i}(S_{n}>0)\\ =\\ \\rho. $$ For an ordinary random\nwalk, this was shown by Doney for $0<\\rho<1$ and by Bertoin and Doney for\n$\\rho\\in\\{0,1\\}$.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  We devise variants of classical nonconforming methods for symmetric elliptic\nproblems. These variants differ from the original ones only by transforming\ndiscrete test functions into conforming functions before applying the load\nfunctional. We derive and discuss conditions on these transformations implying\nthat the ensuing method is quasi-optimal and that its quasi-optimality constant\ncoincides with its stability constant. As applications, we consider the\napproximation of the Poisson problem with Crouzeix-Raviart elements and higher\norder counterparts and the approximation of the biharmonic problem with Morley\nelements. In each case, we construct a computationally feasible transformation\nand obtain a quasi-optimal method with respect to the piecewise energy norm on\na shape regular mesh.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  In the paper Dynkin construction for self-intersection local time of planar\nWiener process is extended on Hilbert-valued weights.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  The infimal prefix-closed, controllable and observable superlanguage plays an\nessential role in the relationship between controllability, observability and\nco-observability -- the central notions of supervisory control theory. Existing\nalgorithms for its computation are exponential and it is not known whether a\npolynomial algorithm exists. In this paper, we study the state complexity of\nthis language. State complexity of a language is the number of states of the\nminimal DFA for the language. For a language of state complexity $n$, we show\nthat the upper-bound state complexity on the infimal prefix-closed and\nobservable superlanguage is $2^n + 1$ and that this bound is asymptotically\ntight. It proves that there is no algorithm computing a DFA of the infimal\nprefix-closed and observable superlanguage in polynomial time. Our construction\nfurther shows that such a DFA can be computed in time $O(2^n)$. The\nconstruction involves NFAs and a computation of the supremal prefix-closed\nsublanguage. We study the computation of the supremal prefix-closed sublanguage\nand show that there is no polynomial-time algorithm that computes an NFA of the\nsupremal prefix-closed sublanguage of a language given as an NFA even if the\nlanguage is unary.\n\n\n###\n\n", "completion": " 17\n"}
{"prompt": "  Life evolved on our planet by means of a combination of Darwinian selection\nand innovations leading to higher levels of complexity. The emergence and\nselection of replicating entities is a central problem in prebiotic evolution.\nTheoretical models have shown how populations of different types of replicating\nentities exclude or coexist with other classes of replicators. Models are\ntypically kinetic, based on standard replicator equations. On the other hand,\nthe presence of thermodynamical constrains for these systems remain an open\nquestion. This is largely due to the lack of a general theory of out of\nstatistical methods for systems far from equilibrium. Nonetheless, a first\napproach to this problem has been put forward in a series of novel\ndevelopements in non-equilibrium physics, under the rubric of the extended\nsecond law of thermodynamics. The work presented here is twofold: firstly, we\nreview this theoretical framework and provide a brief description of the three\nfundamental replicator types in prebiotic evolution: parabolic, malthusian and\nhyperbolic. Finally, we employ these previously mentioned techinques to explore\nhow replicators are constrained by thermodynamics.\n\n\n###\n\n", "completion": " 17\n"}
