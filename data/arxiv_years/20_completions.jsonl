{"prompt": "  We study the problem of selling a divisible item to agents who have concave\nvaluation functions for fractions of the item. This is a fundamental problem\nwith apparent applications to pricing communication bandwidth or cloud\ncomputing services. We focus on simple sequential posted pricing mechanisms\nthat use linear pricing, i.e., a fixed price for the whole item and\nproportional prices for fractions of it. We present results of the following\nform that can be thought of as analogs of the well-known prophet inequality of\nSamuel-Cahn (1984). For $\\rho\\approx 32\\%$, if there is a linear pricing so\nthat sequential posted pricing sells a $\\rho$-fraction of the item, this\nresults in a $\\rho$-approximation of the optimal social welfare. The value of\n$\\rho$ can be improved to approximately $42\\%$ if sequential posted pricing\nconsiders the agents in random order. We also show that the best linear pricing\nyields an expected revenue that is at most $O(\\kappa^2)$ times smaller than the\noptimal one, where $\\kappa$ is a bound on the curvature of the valuation\nfunctions. The proof extends and exploits the approach of Alaei et al. (2019)\nand bounds the revenue gap by the objective value of a mathematical program.\nThe dependence of the revenue gap on $\\kappa$ is unavoidable as a lower bound\nof $\\Omega(\\ln{\\kappa})$ indicates.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Topology control, including topology construction and maintenance phases, is\na vital conception for wireless ad-hoc networks of any kind, expressly the\nwireless sensor networks (WSN). Topology maintenance, the latter phase,\nconcerns several problems, such as optimizing the energy consumption,\nincreasing the data rate, making clusters, and sustaining the connectivity. A\ndisconnected network, among other strategies, can efficiently be connected\nagain using a Movement-based Connectivity Restoration (MCR) method, where a\ncommensurate number of nodes move (or are moved) to the desired positions.\nHowever, finding an optimal route for the nodes to be moved can be a formidable\nproblem. As a matter of fact, this paper presents details regarding a direct\nproof of the NP-Completeness of the MCR Problem by a reduction of the\nwell-studied Steiner Tree Problem using the minimum number of Steiner points\nand the bounded edge length.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Graphics Processing Units (GPUs) employ large register files to accommodate\nall active threads and accelerate context switching. Unfortunately, register\nfiles are a scalability bottleneck for future GPUs due to long access latency,\nhigh power consumption, and large silicon area provisioning. Prior work\nproposes hierarchical register file to reduce the register file power\nconsumption by caching registers in a smaller register file cache.\nUnfortunately, this approach does not improve register access latency due to\nthe low hit rate in the register file cache.\n  In this paper, we propose the Latency-Tolerant Register File (LTRF)\narchitecture to achieve low latency in a two-level hierarchical structure while\nkeeping power consumption low. We observe that compile-time interval analysis\nenables us to divide GPU program execution into intervals with an accurate\nestimate of a warp's aggregate register working-set within each interval. The\nkey idea of LTRF is to prefetch the estimated register working-set from the\nmain register file to the register file cache under software control, at the\nbeginning of each interval, and overlap the prefetch latency with the execution\nof other warps. We observe that register bank conflicts while prefetching the\nregisters could greatly reduce the effectiveness of LTRF. Therefore, we devise\na compile-time register renumbering technique to reduce the likelihood of\nregister bank conflicts. Our experimental results show that LTRF enables\nhigh-capacity yet long-latency main GPU register files, paving the way for\nvarious optimizations. As an example optimization, we implement the main\nregister file with emerging high-density high-latency memory technologies,\nenabling 8X larger capacity and improving overall GPU performance by 34%.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  An analytical solution for a quantum wave impedance in a case of piesewise\nconstant potential was derived. It is in fact an analytical depiction of a\nwell-known iterative method of a quantum wave impedance determination. The\nexpression for a transmission probability as a function of a particle energy\nfor an arbitrary cascad of constant potentials was obtained. The application of\nobtained results was illustrated on a system of double-well/barrier structures.\n\n\n###\n\n", "completion": " 05"}
{"prompt": "  It is well known from the Butcher-Oemler effect that galaxies in dense\nenvironment are mostly red with little star formation and the fraction of blue\ngalaxies in galaxy groups/clusters also declines rapidly with redshifts. A\nrecent work by Hashimoto et al. reported a local 'blue cluster' with high\nfraction of blue galaxies ($\\sim 0.57$), higher than the model predictions.\nThey ascribed this blue cluster to the feeding of gas along a filamentary\nstructure around the cluster. In this work we use group catalog from the Sloan\nDigital Sky Survey Data Release 7 (SDSS DR7) and the state-of-art of\nsemi-analytic model (SAM) to investigate the formation of blue clusters in\nlocal Universe. In total, we find four blue clusters with halo mass $\\sim\n10^{14}M_{\\odot}$ at $0.02 < z < 0.082$, while only the one found by Hashimoto\net al. is in a filamentary structure. The SAM predicts that blue clusters have\nlater formation time and most blue satellite galaxies are recently accreted. We\nconclude that the formation of blue clusters is mainly governed by newly\naccreted blue satellites, rather than the effect of large-scale environment.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Searching for space-time variations of the constants of Nature is a promising\nway to search for new physics beyond General Relativity and the standard model\nmotivated by unification theories and models of dark matter and dark energy. We\npropose a new way to search for a variation of the fine-structure constant\nusing measurements of late-type evolved giant stars from the S-star cluster\norbiting the supermassive black hole in our Galactic Center. A measurement of\nthe difference between distinct absorption lines (with different sensitivity to\nthe fine structure constant) from a star leads to a direct estimate of a\nvariation of the fine structure constant between the star's location and Earth.\nUsing spectroscopic measurements of 5 stars, we obtain a constraint on the\nrelative variation of the fine structure constant below $10^{-5}$. This is the\nfirst time a varying constant of Nature is searched for around a black hole and\nin a high gravitational potential. This analysis shows new ways the monitoring\nof stars in the Galactic Center can be used to probe fundamental physics.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Many important robotics problems are partially observable in the sense that a\nsingle visual or force-feedback measurement is insufficient to reconstruct the\nstate. Standard approaches involve learning a policy over beliefs or\nobservation-action histories. However, both of these have drawbacks; it is\nexpensive to track the belief online, and it is hard to learn policies directly\nover histories. We propose a method for policy learning under partial\nobservability called the Belief-Grounded Network (BGN) in which an auxiliary\nbelief-reconstruction loss incentivizes a neural network to concisely summarize\nits input history. Since the resulting policy is a function of the history\nrather than the belief, it can be executed easily at runtime. We compare BGN\nagainst several baselines on classic benchmark tasks as well as three novel\nrobotic touch-sensing tasks. BGN outperforms all other tested methods and its\nlearned policies work well when transferred onto a physical robot.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We show that in the family of degree $d\\geq 2$ rational maps of the Riemann\nsphere, the closure of strictly postcritically finite maps contains a\n(relatively) Baire generic subset of maps displaying maximal non-statistical\nbehavior: for a map $f$ in this generic subset, the set of accumulation points\nof the sequence of empirical measures of almost every point in the phase space\nis the largest possible one that is, the set of all $f$-invariant measures. The\nproofs is based on a transversality argument which allows us to control the\nbehavior of the orbits of critical points for maps close to strictly\npostcritically finite rational maps and also a new concept developed in the\nauthor's PhD thesis, that we call statistical bifurcation.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We propose a cross-modality manifold alignment procedure that leverages\ntriplet loss to jointly learn consistent, multi-modal embeddings of\nlanguage-based concepts of real-world items. Our approach learns these\nembeddings by sampling triples of anchor, positive, and negative data points\nfrom RGB-depth images and their natural language descriptions. We show that our\napproach can benefit from, but does not require, post-processing steps such as\nProcrustes analysis, in contrast to some of our baselines which require it for\nreasonable performance. We demonstrate the effectiveness of our approach on two\ndatasets commonly used to develop robotic-based grounded language learning\nsystems, where our approach outperforms four baselines, including a\nstate-of-the-art approach, across five evaluation metrics.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Probabilistic word embeddings have shown effectiveness in capturing notions\nof generality and entailment, but there is very little work on doing the\nanalogous type of investigation for sentences. In this paper we define\nprobabilistic models that produce distributions for sentences. Our\nbest-performing model treats each word as a linear transformation operator\napplied to a multivariate Gaussian distribution. We train our models on\nparaphrases and demonstrate that they naturally capture sentence specificity.\nWhile our proposed model achieves the best performance overall, we also show\nthat specificity is represented by simpler architectures via the norm of the\nsentence vectors. Qualitative analysis shows that our probabilistic model\ncaptures sentential entailment and provides ways to analyze the specificity and\npreciseness of individual words.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Using data from the Large European Array for Pulsars (LEAP), and the\nEffelsberg telescope, we study the scintillation parameters of the millisecond\npulsar J0613-0200 over a 7 year timespan. The \"secondary spectrum\" -- the 2D\npower spectrum of scintillation -- presents the scattered power as a function\nof time delay, and contains the relative velocities of the pulsar, observer,\nand scattering material. We detect a persistent parabolic scintillation arc,\nsuggesting scattering is dominated by a thin, anisotropic region. The\nscattering is poorly described by a simple exponential tail, with excess power\nat high delays; we measure significant, detectable scattered power at times out\nto $\\sim 5 \\mu s$, and measure the bulk scattering delay to be between 50 to\n200\\,ns with particularly strong scattering throughout 2013. These delays are\ntoo small to detect a change of the pulse profile shape, yet they would change\nthe times-of-arrival as measured through pulsar timing. The arc curvature\nvaries annually, and is well fit by a one-dimensional scattering screen $\\sim\n40\\%$ of the way towards the pulsar, with a changing orientation during the\nincreased scattering in 2013. Effects of uncorrected scattering will introduce\ntime delays correlated over time in individual pulsars, and may need to be\nconsidered in gravitational wave analyses. Pulsar timing programs would benefit\nfrom simultaneously recording in a way that scintillation can be resolved, in\norder to monitor the variable time delays caused by multipath propagation.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We present NECI, a state-of-the-art implementation of the Full Configuration\nInteraction Quantum Monte Carlo algorithm, a method based on a stochastic\napplication of the Hamiltonian matrix on a sparse sampling of the wave\nfunction. The program utilizes a very powerful parallelization and scales\nefficiently to more than 24000 CPU cores. In this paper, we describe the core\nfunctionalities of NECI and recent developments. This includes the capabilities\nto calculate ground and excited state energies, properties via the one- and\ntwo-body reduced density matrices, as well as spectral and Green's functions\nfor ab initio and model systems. A number of enhancements of the bare FCIQMC\nalgorithm are available within NECI, allowing to use a partially deterministic\nformulation of the algorithm, working in a spin-adapted basis or supporting\ntranscorrelated Hamiltonians. NECI supports the FCIDUMP file format for\nintegrals, supplying a convenient interface to numerous quantum chemistry\nprograms and it is licensed under GPL-3.0.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Compared with laborious pixel-wise dense labeling, it is much easier to label\ndata by scribbles, which only costs 1$\\sim$2 seconds to label one image.\nHowever, using scribble labels to learn salient object detection has not been\nexplored. In this paper, we propose a weakly-supervised salient object\ndetection model to learn saliency from such annotations. In doing so, we first\nrelabel an existing large-scale salient object detection dataset with\nscribbles, namely S-DUTS dataset. Since object structure and detail information\nis not identified by scribbles, directly training with scribble labels will\nlead to saliency maps of poor boundary localization. To mitigate this problem,\nwe propose an auxiliary edge detection task to localize object edges\nexplicitly, and a gated structure-aware loss to place constraints on the scope\nof structure to be recovered. Moreover, we design a scribble boosting scheme to\niteratively consolidate our scribble annotations, which are then employed as\nsupervision to learn high-quality saliency maps. As existing saliency\nevaluation metrics neglect to measure structure alignment of the predictions,\nthe saliency map ranking metric may not comply with human perception. We\npresent a new metric, termed saliency structure measure, to measure the\nstructure alignment of the predicted saliency maps, which is more consistent\nwith human perception. Extensive experiments on six benchmark datasets\ndemonstrate that our method not only outperforms existing\nweakly-supervised/unsupervised methods, but also is on par with several\nfully-supervised state-of-the-art models. Our code and data is publicly\navailable at https://github.com/JingZhang617/Scribble_Saliency.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Alzheimer's Disease (AD) is nowadays the most common form of dementia, and\nits automatic detection can help to identify symptoms at early stages, so that\npreventive actions can be carried out. Moreover, non-intrusive techniques based\non spoken data are crucial for the development of AD automatic detection\nsystems. In this light, this paper is presented as a contribution to the ADReSS\nChallenge, aiming at improving AD automatic detection from spontaneous speech.\nTo this end, recordings from 108 participants, which are age-, gender-, and AD\ncondition-balanced, have been used as training set to perform two different\ntasks: classification into AD/non-AD conditions, and regression over the\nMini-Mental State Examination (MMSE) scores. Both tasks have been performed\nextracting 28 features from speech -- based on prosody and voice quality -- and\n51 features from the transcriptions -- based on lexical and turn-taking\ninformation. Our results achieved up to 87.5 % of classification accuracy using\na Random Forest classifier, and 4.54 of RMSE using a linear regression with\nstochastic gradient descent over the provided test set. This shows promising\nresults in the automatic detection of Alzheimer's Disease through speech and\nlexical features.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Let $E$ be a rearrangement invariant (r.i.) function space on $[0,1]$, and\nlet $Z_E$ consist of all measurable functions $f$ on $(0,\\infty)$ such that\n$f^*\\chi_{[0,1]}\\in E$ and $f^*\\chi_{[1,\\infty)}\\in L^2$. We reveal close\nconnections between properties of the generalized Rosenthal's space,\ncorresponding to the space $Z_E$, and the behaviour of independent\nsymmetrically distributed random variables in $E$. The results obtained are\napplied to consider the problem of the existence of isomorphisms between r.i.\\\nspaces on $[0,1]$ and $(0,\\infty)$. Exploiting particular properties of\ndisjoint sequences, we identify a rather wide new class of r.i.\\ spaces on\n$[0,1]$ ``close'' to $L^\\infty$, which fail to be isomorphic to r.i.\\ spaces on\n$(0,\\infty)$. In particular, this property is shared by the Lorentz spaces\n$\\Lambda_2(\\log^{-\\alpha}(e/u))$, with $0<\\alpha\\le 1$.\n\n\n###\n\n", "completion": " 00"}
{"prompt": "  In 2005 a new topological invariant defined in terms of the Brouwer degree of\na determinant map, was introduced by Musso, Pejsachowicz and the first name\nauthor for counting the conjugate points along a semi-Riemannian geodesic. This\ninvariant was defined in terms of a suspension of a complexified family of\nlinear second order Dirichlet boundary value problems.\n  In this paper, starting from this result, we generalize this invariant to a\ngeneral self-adjoint Morse-Sturm system and we prove a new spectral flow\nformula. Finally we discuss the relation between this spectral flow formula and\nthe Hill's determinant formula and we apply this invariant for detecting\ninstability of periodic orbits of a Hamiltonian system.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  We introduce the package \"GraphicalModelsMLE\" for computing the maximum\nlikelihood estimates (MLEs) of a Gaussian graphical model in the computer\nalgebra system Macaulay2. This package allows the computation of MLEs for the\nclass of loopless mixed graphs. Additional functionality allows the user to\nexplore the underlying algebraic structure of the model, such as its maximum\nlikelihood degree and the ideal of score equations.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  The heterogenous wireless services and exponentially growing traffic call for\nnovel spectrum- and energy-efficient wireless communication technologies. In\nthis paper, a new technique, called symbiotic radio (SR), is proposed to\nexploit the benefits and address the drawbacks of cognitive radio (CR) and\nambient backscattering communications(AmBC), leading to mutualism spectrum\nsharing and highly reliable backscattering communications. In particular, the\nsecondary transmitter (STx) in SR transmits messages to the secondary receiver\n(SRx) over the RF signals originating from the primary transmitter (PTx) based\non cognitive backscattering communications, thus the secondary system shares\nnot only the radio spectrum, but also the power, and infrastructure with the\nprimary system. In return, the secondary transmission provides beneficial\nmultipath diversity to the primary system, therefore the two systems form\nmutualism spectrum sharing. More importantly, joint decoding is exploited at\nSRx to achieve highly reliable backscattering communications. To exploit the\nfull potential of SR, in this paper, we address three fundamental tasks in SR:\n(1) enhancing the backscattering link via active load; (2) achieving highly\nreliable communications through joint decoding; and (3) capturing PTx's RF\nsignals using reconfigurable intelligent surfaces. Emerging applications,\ndesign challenges and open research problems will also be discussed.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We analyze relative abundances and ionization conditions in a strong\nabsorption system at z=6.84, seen in the spectrum of the z=7.54 background\nquasar ULAS J134208.10+092838.61. Singly ionized C, Si, Fe, Mg, and Al\nmeasurements are consistent with a warm neutral medium that is metal-poor but\nnot chemically pristine. Firm non-detections of C IV and Si IV imply that any\nwarm ionized phase of the IGM or CGM has not yet been enriched past the\nultra-metal-poor regime (<0.001Z_{solar}), unlike lower redshift DLAs where\nthese lines are nearly ubiquitous. Relative abundances of the heavy elements\n794 Myr after the Big Bang resemble those of metal-poor damped Lyman Alpha\nsystems at intermediate redshift and Milky Way halo stars, and show no evidence\nof enhanced [alpha/Fe], [C/Fe] or other signatures of yields dominated by\nmassive stars. A detection of the CII* fine structure line reveals local\nsources of excitation from heating, beyond the level of photo-excitation\nsupplied by the CMB. We estimate the total and [CII] cooling rates, balancing\nagainst ISM heating sources to develop an heuristic two-phase model of the\nneutral medium. The implied heating requires a surface density of star\nformation slightly exceeding that of the Milky Way but not at the level of a\nstrong starburst. For a typical (assumed) NHI=10^{20.6}, an abundance of\n[Fe/H]=-2.2 matches the columns of species in the neutral phase. To remain\nundetected in C IV, a warm ionized phase would either need much lower\n[C/H]<-4.2 over an absorption path of 1 kpc, or else a very small absorption\npath (a few pc). While still speculative, these results suggest a significant\nreduction in heavy element enrichment outside of neutral star forming regions\nof the ISM, as would be expected in early stages of galactic chemical\nevolution.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  The notion of age of information (AoI) has become an important performance\nmetric in network and control systems. Information freshness, represented by\nAoI, naturally arises in the context of caching. We address optimal scheduling\nof cache updates for a time-slotted system where the contents vary in size.\nThere is limited capacity for the cache and for making content updates. Each\ncontent is associated with a utility function that is monotonically decreasing\nin the AoI. For this combinatorial optimization problem, we present the\nfollowing contributions. First, we provide theoretical results settling the\nboundary of problem tractability. In particular, by a reformulation using\nnetwork flows, we prove the boundary is essentially determined by whether or\nnot the contents are of equal size. Second, we derive an integer linear\nformulation for the problem, of which the optimal solution can be obtained for\nsmall-scale scenarios. Next, via a mathematical reformulation, we derive a\nscalable optimization algorithm using repeated column generation. In addition,\nthe algorithm computes a bound of global optimum, that can be used to assess\nthe performance of any scheduling solution. Performance evaluation of\nlarge-scale scenarios demonstrates the strengths of the algorithm in comparison\nto a greedy schedule. Finally, we extend the applicability of our work to\ncyclic scheduling.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  A spectral mixture (SM) kernel is a flexible kernel used to model any\nstationary covariance function. Although it is useful in modeling data, the\nlearning of the SM kernel is generally difficult because optimizing a large\nnumber of parameters for the SM kernel typically induces an over-fitting,\nparticularly when a gradient-based optimization is used. Also, a longer\ntraining time is required. To improve the training, we propose an approximate\nBayesian inference for the SM kernel. Specifically, we employ the variational\ndistribution of the spectral points to approximate SM kernel with a random\nFourier feature. We optimize the variational parameters by applying a\nsampling-based variational inference to the derived evidence lower bound (ELBO)\nestimator constructed from the approximate kernel. To improve the inference, we\nfurther propose two additional strategies: (1) a sampling strategy of spectral\npoints to estimate the ELBO estimator reliably and thus its associated\ngradient, and (2) an approximate natural gradient to accelerate the convergence\nof the parameters. The proposed inference combined with two strategies\naccelerates the convergence of the parameters and leads to better optimal\nparameters.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We present a new application of deep learning to reconstruct the cosmic\nmicrowave background (CMB) temperature maps from the images of microwave sky,\nand to use these reconstructed maps to estimate the masses of galaxy clusters.\nWe use a feed-forward deep learning network, mResUNet, for both steps of the\nanalysis. The first deep learning model, mResUNet-I, is trained to reconstruct\nforeground and noise suppressed CMB maps from a set of simulated images of the\nmicrowave sky that include signals from the cosmic microwave background,\nastrophysical foregrounds like dusty and radio galaxies, instrumental noise as\nwell as the cluster's own thermal Sunyaev Zel'dovich signal. The second deep\nlearning model, mResUNet-II, is trained to estimate cluster masses from the\ngravitational lensing signature in the reconstructed foreground and noise\nsuppressed CMB maps. For SPTpol-like noise levels, the trained mResUNet-II\nmodel recovers the mass for $10^4$ galaxy cluster samples with a 1-$\\sigma$\nuncertainty $\\Delta M_{\\rm 200c}^{\\rm est}/M_{\\rm 200c}^{\\rm est} =$ 0.108 and\n0.016 for input cluster mass $M_{\\rm 200c}^{\\rm true}=10^{14}~\\rm M_{\\odot}$\nand $8\\times 10^{14}~\\rm M_{\\odot}$, respectively. We also test for potential\nbias on recovered masses, finding that for a set of $10^5$ clusters the\nestimator recovers $M_{\\rm 200c}^{\\rm est} = 2.02 \\times 10^{14}~\\rm\nM_{\\odot}$, consistent with the input at 1% level. The 2 $\\sigma$ upper limit\non potential bias is at 3.5% level.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  LiDAR-driven 3D sensing allows new generations of vehicles to achieve\nadvanced levels of situation awareness. However, recent works have demonstrated\nthat physical adversaries can spoof LiDAR return signals and deceive 3D object\ndetectors to erroneously detect \"ghost\" objects. Existing defenses are either\nimpractical or focus only on vehicles. Unfortunately, it is easier to spoof\nsmaller objects such as pedestrians and cyclists, but harder to defend against\nand can have worse safety implications. To address this gap, we introduce\nShadow-Catcher, a set of new techniques embodied in an end-to-end prototype to\ndetect both large and small ghost object attacks on 3D detectors. We\ncharacterize a new semantically meaningful physical invariant (3D shadows)\nwhich Shadow-Catcher leverages for validating objects. Our evaluation on the\nKITTI dataset shows that Shadow-Catcher consistently achieves more than 94%\naccuracy in identifying anomalous shadows for vehicles, pedestrians, and\ncyclists, while it remains robust to a novel class of strong \"invalidation\"\nattacks targeting the defense system. Shadow-Catcher can achieve real-time\ndetection, requiring only between 0.003s-0.021s on average to process an object\nin a 3D point cloud on commodity hardware and achieves a 2.17x speedup compared\nto prior work\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Whereas the original Boltzmann's $H$-theorem applies to elastic collisions,\nits rigorous generalization to the inelastic case is still lacking.\nNonetheless, it has been conjectured in the literature that the relative\nentropy of the velocity distribution function with respect to the homogeneous\ncooling state (HCS) represents an adequate nonequilibrium entropy-like\nfunctional for an isolated freely cooling granular gas. In this work, we\npresent molecular dynamics results reinforcing this conjecture and rejecting\nthe choice of the Maxwellian over the HCS as a reference distribution. These\nresults are qualitatively predicted by a simplified theoretical toy model.\nAdditionally, a Maxwell-demon-like velocity-inversion simulation experiment\nhighlights the microscopic irreversibility of the granular gas dynamics,\nmonitored by the relative entropy, where a short ``anti-kinetic'' transient\nregime appears for nearly elastic collisions only.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We investigate the potential of the channel {\\em mono-Higgs + MET} in\nyielding signals of dark mater at the high-luminosity Large Hadron Collider\n(LHC). As illustration, a scalar dark matter in a Higgs portal scenario has\nbeen chosen, whose phenomenological viability has been ensured by postulating\nthe existence of dimension-6 operators that enable cancellation in certain\namplitudes for elastic scattering of dark matter in direct search experiments.\nThese operators are found to have non-negligible contribution to the mono-Higgs\nsignal. Thereafter, we carry out a detailed analysis of this signal, with the\naccompanying MET providing a useful handle in suppressing backgrounds. Signals\nfor the Higgs decaying into both the diphoton and $b{\\bar b}$ channels have\nbeen studied. A cut-based simulation is presented first, followed by a\ndemonstration of how the statistical significance can be improved through\nanalyses based on Boosted Decision Trees and Artificial Neural Network. The\nimprovement is found to be especially noticeable for the $b{\\bar b}$ channel.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  In the current industrial practices, the exponential growth in terms of\navailability and affordability of sensors, data acquisition systems, and\ncomputer networks forces factories to move toward implementing high integrating\nCyber-Physical Systems (CPS) with production, logistics, and services. This\ntransforms today's factories into Industry 4.0 factories with significant\neconomic potential. Industry 4.0, also known as the fourth Industrial\nRevolution, levers on the integration of cyber technologies, the Internet of\nThings, and Services. This paper proposes an Augmented Reality (AR)-based\nsystem that creates a Cognition Level that integrates existent Manufacturing\nExecution Systems (MES) to CPS. The idea is to highlight the opportunities\noffered by AR technologies to CPS by describing an application scenario. The\nsystem, analyzed in a real factory, shows its capacity to integrate physical\nand digital worlds strongly. Furthermore, the conducted survey (based on the\nSituation Awareness Global Assessment Technique method) reveals significant\nadvantages in terms of production monitoring, progress, and workers' Situation\nAwareness in general.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Adopted by government agencies in Australia, New Zealand and the UK as policy\ninstrument or as embodied into legislation, the 'Five Safes' framework aims to\nmanage risks of releasing data derived from personal information. Despite its\npopularity, the Five Safes has undergone little legal or technical critical\nanalysis. We argue that the Fives Safes is fundamentally flawed: from being\ndisconnected from existing legal protections and appropriation of notions of\nsafety without providing any means to prefer strong technical measures, to\nviewing disclosure risk as static through time and not requiring repeat\nassessment. The Five Safes provides little confidence that resulting data\nsharing is performed using 'safety' best practice or for purposes in service of\npublic interest.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  In self-supervised spatio-temporal representation learning, the temporal\nresolution and long-short term characteristics are not yet fully explored,\nwhich limits representation capabilities of learned models. In this paper, we\npropose a novel self-supervised method, referred to as video Playback Rate\nPerception (PRP), to learn spatio-temporal representation in a\nsimple-yet-effective way. PRP roots in a dilated sampling strategy, which\nproduces self-supervision signals about video playback rates for representation\nmodel learning. PRP is implemented with a feature encoder, a classification\nmodule, and a reconstructing decoder, to achieve spatio-temporal semantic\nretention in a collaborative discrimination-generation manner. The\ndiscriminative perception model follows a feature encoder to prefer perceiving\nlow temporal resolution and long-term representation by classifying\nfast-forward rates. The generative perception model acts as a feature decoder\nto focus on comprehending high temporal resolution and short-term\nrepresentation by introducing a motion-attention mechanism. PRP is applied on\ntypical video target tasks including action recognition and video retrieval.\nExperiments show that PRP outperforms state-of-the-art self-supervised models\nwith significant margins. Code is available at github.com/yuanyao366/PRP\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  With optical spectroscopy we provide evidence that the insulator-metal\ntransition in Sr$_2$Ir$_{1-x}$Rh$_{x}$O$_{4}$ occurs close to a crossover from\nthe Mott- to the Slater-type. The Mott-gap at $x = 0$ persists to high\ntemperature and evolves without an anomaly across the N\\'{e}el temperature,\n$T_N$. Upon Rh-doping, it collapses rather rapidly and vanishes around $x =\n0.055$. Notably, just as the Mott-gap vanishes yet another gap appears that is\nof the Slater-type and develops right below $T_N$. This Slater-gap is only\npartial and is accompanied by a reduced scattering rate of the remaining free\ncarriers, similar as in the parent compounds of the iron arsenide\nsuperconductors.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In this paper, we show that the pair of classes of locally H\\\"{o}lder\ncontinuous functions (considered on $\\mathbb{R}$ and $\\mathbb{R}^{2}$,\nrespectively) has the double difference property.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Visual imagery is an intuitive brain-computer interface paradigm, referring\nto the emergence of the visual scene. Despite its convenience, analysis of its\nintrinsic characteristics is limited. In this study, we demonstrate the effect\nof time interval and channel selection that affects the decoding performance of\nthe multi-class visual imagery. We divided the epoch into time intervals of 0-1\ns and 1-2 s and performed six-class classification in three different brain\nregions: whole brain, visual cortex, and prefrontal cortex. In the time\ninterval, 0-1 s group showed 24.2 % of average classification accuracy, which\nwas significantly higher than the 1-2 s group in the prefrontal cortex. In the\nthree different regions, the classification accuracy of the prefrontal cortex\nshowed significantly higher performance than the visual cortex in 0-1 s\ninterval group, implying the cognitive arousal during the visual imagery. This\nfinding would provide crucial information in improving the decoding\nperformance.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  With the rise of natural user interfaces, immersive analytics applications\noften focus on novel forms of interaction modalities such as mid-air gestures,\ngaze or tangible interaction utilizing input devices such as depth-sensors,\ntouch screens and eye-trackers. At the same time, traditional input devices\nsuch as the physical keyboard and mouse are used to a lesser extent. We argue,\nthat for certain work scenarios, such as conducting analytic tasks at\nstationary desktop settings, it can be valuable to combine the benefits of\nnovel and established input devices as well as input modalities to create\nproductive immersive analytics environments.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Today's intelligent traffic light control system is based on the current road\ntraffic conditions for traffic regulation. However, these approaches cannot\nexploit the future traffic information in advance. In this paper, we propose\nGPlight, a deep reinforcement learning (DRL) algorithm integrated with graph\nneural network (GNN) , to relieve the traffic congestion for multi-intersection\nintelligent traffic control system. In GPlight, the graph neural network (GNN)\nis first used to predict the future short-term traffic flow at the\nintersections. Then, the results of traffic flow prediction are used in traffic\nlight control, and the agent combines the predicted results with the observed\ncurrent traffic conditions to dynamically control the phase and duration of the\ntraffic lights at the intersection. Experiments on both synthetic and two\nreal-world data-sets of Hangzhou and New-York verify the effectiveness and\nrationality of the GPlight algorithm.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  A graph $G$ is weakly $H$-saturated if the complete graph is obtained by\niteratively completing copies of $H$ minus an edge. We identify the threshold\n$p_c$ at which the Erd\\H{o}s-R\\'enyi graph ${\\mathcal G}_{n,p}$ is likely to be\nweakly $H$-saturated, for all $H$ such that $H\\setminus e$ is 2-balanced for\nevery edge $e\\in H$. The threshold is sharp if this holds strictly. We also\nestablish a general asymptotic lower bound for $p_c$, which holds for all\ngraphs $H$, and is sharp in many cases. Our results apply for instance when\n$H=K_r$, solving a problem of Balogh, Bollob\\'as and Morris.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Deep neural networks are vulnerable to adversarial examples -- minor\nperturbations added to a model's input which cause the model to output an\nincorrect prediction. We introduce a new method for improving the efficacy of\nadversarial attacks in a black-box setting by undertraining the surrogate model\nwhich the attacks are generated on. Using two datasets and five model\narchitectures, we show that this method transfers well across architectures and\noutperforms state-of-the-art methods by a wide margin. We interpret the\neffectiveness of our approach as a function of reduced surrogate model loss\nfunction curvature and increased universal gradient characteristics, and show\nthat our approach reduces the presence of local loss maxima which hinder\ntransferability. Our results suggest that finding strong single surrogate\nmodels is a highly effective and simple method for generating transferable\nadversarial attacks, and that this method represents a valuable route for\nfuture study in this field.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  A new semi-analytical solution to the advection-dispersion-reaction equation\nfor modelling solute transport in layered porous media is derived using the\nLaplace transform. Our solution approach involves introducing unknown functions\nrepresenting the dispersive flux at the interfaces between adjacent layers,\nallowing the multilayer problem to be solved separately on each layer in the\nLaplace domain before being numerically inverted back to the time domain. The\nderived solution is applicable to the most general form of linear\nadvection-dispersion-reaction equation, a finite medium comprising an arbitrary\nnumber of layers, continuity of concentration and dispersive flux at the\ninterfaces between adjacent layers and transient boundary conditions of\narbitrary type at the inlet and outlet. The derived semi-analytical solution\nextends and addresses deficiencies of existing analytical solutions in a\nlayered medium, which consider analogous processes such as diffusion or\nreaction-diffusion only and/or require the solution of complicated nonlinear\ntranscendental equations to evaluate the solution expressions. Code\nimplementing our semi-analytical solution is supplied and applied to a\nselection of test cases, with the reported results in excellent agreement with\na standard numerical solution and other analytical results available in the\nliterature.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Le Cam's method, Fano's inequality, and Assouad's lemma are three widely used\ntechniques to prove lower bounds for statistical estimation tasks. We propose\ntheir analogues under central differential privacy. Our results are simple,\neasy to apply and we use them to establish sample complexity bounds in several\nestimation tasks. We establish the optimal sample complexity of discrete\ndistribution estimation under total variation distance and $\\ell_2$ distance.\nWe also provide lower bounds for several other distribution classes, including\nproduct distributions and Gaussian mixtures that are tight up to logarithmic\nfactors. The technical component of our paper relates coupling between\ndistributions to the sample complexity of estimation under differential\nprivacy.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  In this paper, we present an experiment, designed to investigate and evaluate\nthe scalability and the robustness aspects of mobile manipulation. The\nexperiment involves performing variations of mobile pick and place actions and\nopening/closing environment containers in a human household. The robot is\nexpected to act completely autonomously for extended periods of time. We\ndiscuss the scientific challenges raised by the experiment as well as present\nour robotic system that can address these challenges and successfully perform\nall the tasks of the experiment. We present empirical results and the lessons\nlearned as well as discuss where we hit limitations.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Dedicated accelerometers have been developed for the MICROSCOPE mission\ntaking into account the specific range of acceleration to be measured on board\nthe satellite. Considering one micro-g and even less as the full range of the\ninstrument, leads to a customized concept and a high performance electronics\nfor the sensing and servo-actuations of the accelerometer test-masses. In\naddition to a very accurate geometrical sensor core, a high performance\nelectronics architecture provides the measurement of the weak electrostatic\nforces and torques applied to the test-masses. A set of capacitive sensors\ndelivers the position and the attitude of the test-mass with respect to a very\nsteady gold coated cage made in silica. The voltages applied on the electrodes\nsurrounding each test-mass are finely controlled to generate the adequate\nelectrical field and so the electrostatic pressures on the test-mass. This\nfield maintains the test-mass motionless with respect to the instrument\nstructure. Digital control laws are implemented in order to enable instrument\noperation flexibility and a weak position sensor noise. These electronics\nprovide both the scientific data for MICROSCOPE's test of General Relativity\nand the data for the satellite drag-free and attitude control system (DFACS).\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  In this paper, we establish pointwise estimates for supersolutions of\nquasilinear elliptic equations with structural conditions involving a\ngeneralized Orlicz growth in terms of a Wolff type potential. As a consequence,\nunder the extra assumption, we obtain that the supersolutions satisfy a Harnack\ninequality and local H\\\"older continuity.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  In 1924, Satyendra Nath Bose dispatched a manuscript introducing the concept\nnow known as Bose statistics to Albert Einstein. Bose could hardly have\nimagined that the exotic statistics of certain emergent particles of quantum\nmatter would one day suggest a route to fault-tolerant quantum computation.\nThis non-technical Commentary on \"anyons,\" namely particles whose statistics is\nintermediate between Bose and Fermi, aims to convey the underlying concept as\nwell as its experimental manifestations to the uninitiated.\n\n\n###\n\n", "completion": " 99"}
{"prompt": "  We investigate nef and movable cones of hypersurfaces in Mori dream spaces.\nThe first result is: Let $Z$ be a smooth Mori dream space of dimension at least\nfour whose extremal contractions are of fiber type of relative dimension at\nleast two and let $X$ be a smooth ample divisor in $Z$, then $X$ is a Mori\ndream space as well.\n  The second result is: Let $Z$ be a Fano manifold of dimension at least four\nwhose extremal contractions are of fiber type and let $X$ be a smooth\nanti-canonical hypersurface in $Z$, which is a smooth Calabi--Yau variety, then\nthe unique minimal model of $X$ up to isomorphism is $X$ itself, and moreover,\nthe movable cone conjecture holds for $X$, namely, there exists a rational\npolyhedral cone which is a fundamental domain for the action of birational\nautomorphisms on the effective movable cone of $X$.\n  The third result is: Let $P:= \\mathbb{P}^n \\times \\cdots \\times \\mathbb{P}^n$\nbe the $N$-fold self-product of the $n$-dimensional projective space. Let $X$\nbe a general complete intersection of $n+1$ hypersurfaces of multidegree $(1,\n\\dots, 1)$ in $P$ with $\\dim X \\geq 3$. Then $X$ has only finitely many minimal\nmodels up to isomorphism, and moreover, the movable cone conjecture holds for\n$X$.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  The giant $\\{ \\mathrm{Mn}_{70} \\}$ and $\\{ \\mathrm{Mn}_{84} \\}$ wheels are\nthe largest nuclearity single-molecule magnets synthesized to date and\nunderstanding their magnetic properties poses a challenge to theory. Starting\nfrom first principles calculations, we explore the magnetic properties and\nexcitations in these wheels using effective spin Hamiltonians. We find that the\nunusual geometry of the superexchange pathways leads to weakly coupled $\\{\n\\mathrm{Mn}_{7} \\}$ subunits carrying an effective $S=2$ spin. The spectrum\nexhibits a hierarchy of energy scales and massive degeneracies, with the lowest\nenergy excitations arising from Heisenberg-ring-like excitations of the $\\{\n\\mathrm{Mn}_{7} \\}$ subunits around the wheel, at energies consistent with the\nobserved temperature dependence of the magnetic susceptibility. We further\nsuggest an important role for weak longer-range couplings in selecting the\nprecise spin ground-state of the $\\mathrm{Mn}$ wheels out of the nearly\ndegenerate ground-state band.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We revisit perturbative RG analysis in the replicated Landau-Ginzburg\ndescription of the Random Field Ising Model near the upper critical dimension\n6. Working in a field basis with manifest vicinity to a weakly-coupled\nParisi-Sourlas supersymmetric fixed point (Cardy, 1985), we look for\ninteractions which may destabilize the SUSY RG flow and lead to the loss of\ndimensional reduction. This problem is reduced to studying the anomalous\ndimensions of \"leaders\" -- lowest dimension parts of $S_n$-invariant\nperturbations in the Cardy basis. Leader operators are classified as\nnon-susy-writable, susy-writable or susy-null depending on their symmetry.\nSusy-writable leaders are additionally classified as belonging to superprimary\nmultiplets transforming in particular $\\textrm{OSp}(d | 2)$ representations. We\nenumerate all leaders up to 6d dimension $\\Delta = 12$, and compute their\nperturbative anomalous dimensions (up to two loops). We thus identify two\nperturbations (with susy-null and non-susy-writable leaders) becoming relevant\nbelow a critical dimension $d_c \\approx 4.2$ - $4.7$. This supports the\nscenario that the SUSY fixed point exists for all $3 < d \\leq 6$, but becomes\nunstable for $d < d_c$.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  Software development is a very broad activity that captures the entire life\ncycle of a software, which includes designing, programming, maintenance and so\non. In this study, we focus on the maintenance-related concerns of the\npost-deployment of smart contracts. Smart contracts are self-executed programs\nthat run on a blockchain. They cannot be modified once deployed and hence they\nbring unique maintenance challenges compared to conventional software.\nAccording to the definition of ISO/IEC 14764, there are four kinds of software\nmaintenance, i.e., corrective, adaptive, perfective, and preventive\nmaintenance. This study aims to answer (i) What kinds of issues will smart\ncontract developers encounter for corrective, adaptive, perfective, and\npreventive maintenance after they are deployed to the Ethereum? (ii) What are\nthe current maintenance-related methods used for smart contracts? To obtain the\nanswers to these research questions, we first conducted a systematic literature\nreview to analyze 131 smart contract related research papers published from\n2014 to 2020. Since the Ethereum ecosystem is fast-growing, some results from\nprevious publications might be out-of-date and there may be a gap between\nacademia and industry. To address this, we performed an online survey of smart\ncontract developers on Github to validate our findings and received 165 useful\nresponses. Based on the survey feedback and literature review, we present the\nfirst empirical study on smart contract maintenance-related concerns. Our study\ncan help smart contract developers better maintain their smart contract-based\nprojects, and we highlight some key future research directions to improve the\nEthereum ecosystem.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We prove some contact analogs of smooth embedding theorems for closed\n$\\pi$-manifolds. We show that a closed, $k$-connected, $\\pi$-manifold of\ndimension (2n + 1) that bounds a $\\pi$-manifold, contact embeds in the\n$(4n-2k+3)$-dimensional Euclidean space with the standard contact structure. We\nalso prove some isocontact embedding results for $\\pi$-manifolds and\nparallelizable manifolds.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  A novel coronavirus disease (COVID-19) is sweeping the world and has taken\naway thousands of lives. As the current epicenter, the United States has the\nlargest number of confirmed and death cases of COVID-19. Meteorological factors\nhave been found associated with many respiratory diseases in the past studies.\nIn order to understand that how and during which period of time do the\nmeteorological factors have the strongest association with the transmission and\nfatality of COVID-19, we analyze the correlation between each meteorological\nfactor during different time periods within the incubation window and the\nconfirmation and fatality rate, and develop statistic models to quantify the\neffects at county level. Results show that meteorological variables except\nmaximum wind speed during the day 13 - 0 before current day shows the most\nsignificant correlation (P < 0.05) with the daily confirmed rate, while\ntemperature during the day 13 - 8 before are most significantly correlated (P <\n0.05) with the daily fatality rate. Temperature is the only meteorological\nfactor showing dramatic positive association nationally, particularly in the\nsoutheast US where the current outbreak most intensive. The influence of\ntemperature is remarkable on the confirmed rate with an increase of over 5 pmp\nin many counties, but not as much on the fatality rate (mostly within 0.01%).\nFindings in this study will help understanding the role of meteorological\nfactors in the spreading of COVID-19 and provide insights for public and\nindividual in fighting against this global epidemic.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Thermal Kinetic Inductance Detectors (TKIDs) combine the excellent noise\nperformance of traditional bolometers with a radio frequency multiplexing\narchitecture that enables the large detector counts needed for the next\ngeneration of millimeter-wave instruments. In this paper, we first discuss the\nexpected noise sources in TKIDs and derive the limits where the phonon noise\ncontribution dominates over the other detector noise terms:\ngeneration-recombination, amplifier, and two-level system (TLS) noise. Second,\nwe characterize aluminum TKIDs in a dark environment. We present measurements\nof TKID resonators with quality factors of about $10^5$ at 80 mK. We also\ndiscuss the bolometer thermal conductance, heat capacity, and time constants.\nThese were measured by the use of a resistor on the thermal island to excite\nthe bolometers. These dark aluminum TKIDs demonstrate a noise equivalent power\nNEP = $2 \\times 10^{-17} \\mathrm{W}/\\mathrm{\\sqrt{Hz}} $, with a $1/f$ knee at\n0.1 Hz, which provides background noise limited performance for ground-based\ntelescopes observing at 150 GHz.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  In this paper we derive the leading quantum gravitational corrections to the\ngeodesics and the equations of motion for a scalar field in the spacetime\ncontaining a constant density star. It is shown that these corrections can be\ncalculated in quantum gravity reliably and in a model independent way.\nFurthermore, we find that quantum gravity gives rise to an additional redshift\nthat results from the gradient instead of the amplitude of the density profile.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Studies show that neural networks, not unlike traditional programs, are\nsubject to bugs, e.g., adversarial samples that cause classification errors and\ndiscriminatory instances that demonstrate the lack of fairness. Given that\nneural networks are increasingly applied in critical applications (e.g.,\nself-driving cars, face recognition systems and personal credit rating\nsystems), it is desirable that systematic methods are developed to analyze\n(e.g., test or verify) neural networks against desirable properties. Recently,\na number of approaches have been developed for analyzing neural networks. These\nefforts are however scattered (i.e., each approach tackles some restricted\nclasses of neural networks against certain particular properties), incomparable\n(i.e., each approach has its own assumptions and input format) and thus hard to\napply, reuse or extend. In this project, we aim to build a unified framework\nfor developing techniques to analyze neural networks. Towards this goal, we\ndevelop a platform called SOCRATES which supports a standardized format for a\nvariety of neural network models, an assertion language for property\nspecification as well as multiple neural network analysis algorithms including\ntwo novel ones for falsifying and probabilistic verification of neural network\nmodels. SOCRATES is extensible and thus existing approaches can be easily\nintegrated. Experiment results show that our platform can handle a wide range\nof networks models and properties. More importantly, it provides a platform for\nsynergistic research on neural network analysis.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We introduce transfer learning for nonlinear dynamics, which enables\nefficient predictions of chaotic dynamics by utilizing a small amount of data.\nFor the Lorenz chaos, by optimizing the transfer rate, we accomplish more\naccurate inference than the conventional method by an order of magnitude.\nMoreover, a surprisingly small amount of learning is enough to infer the energy\ndissipation rate of the Navier-Stokes turbulence because we can, thanks to the\nsmall-scale universality of turbulence, transfer a large amount of the\nknowledge learned from turbulence data at lower Reynolds number.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Federated learning is a distributed learning technique where machine learning\nmodels are trained on client devices in which the local training data resides.\nThe training is coordinated via a central server which is, typically,\ncontrolled by the intended owner of the resulting model. By avoiding the need\nto transport the training data to the central server, federated learning\nimproves privacy and efficiency. But it raises the risk of model theft by\nclients because the resulting model is available on every client device. Even\nif the application software used for local training may attempt to prevent\ndirect access to the model, a malicious client may bypass any such restrictions\nby reverse engineering the application software. Watermarking is a well-known\ndeterrence method against model theft by providing the means for model owners\nto demonstrate ownership of their models. Several recent deep neural network\n(DNN) watermarking techniques use backdooring: training the models with\nadditional mislabeled data. Backdooring requires full access to the training\ndata and control of the training process. This is feasible when a single party\ntrains the model in a centralized manner, but not in a federated learning\nsetting where the training process and training data are distributed among\nseveral client devices. In this paper, we present WAFFLE, the first approach to\nwatermark DNN models trained using federated learning. It introduces a\nretraining step at the server after each aggregation of local models into the\nglobal model. We show that WAFFLE efficiently embeds a resilient watermark into\nmodels incurring only negligible degradation in test accuracy (-0.17%), and\ndoes not require access to training data. We also introduce a novel technique\nto generate the backdoor used as a watermark. It outperforms prior techniques,\nimposing no communication, and low computational (+3.2%) overhead.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  An elementary derivation of the Newton \"inverse square law\" from the three\nKepler laws is proposed. Our proof, thought essentially for first-year\nundergraduates, basically rests on Euclidean geometry. It could then be offered\neven to high-school students possessing only the first basics of Calculus.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  The rates of strong convergence for various approximation schemes are\ninvestigated for a class of stochastic differential equations (SDEs) which\ninvolve a random time change given by an inverse subordinator. SDEs to be\nconsidered are unique in two different aspects: i) they contain two drift\nterms, one driven by the random time change and the other driven by a regular,\nnon-random time variable; ii) the standard Lipschitz assumption is replaced by\nthat with a time-varying Lipschitz bound. The difficulty imposed by the first\naspect is overcome via an approach that is significantly different from a\nwell-known method based on the so-called duality principle. On the other hand,\nthe second aspect requires the establishment of a criterion for the existence\nof exponential moments of functions of the random time change.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  In this work we analyse five popular commercial password managers for\nsecurity vulnerabilities. Our analysis is twofold. First, we compile a list of\npreviously disclosed vulnerabilities through a comprehensive review of the\nacademic and non-academic sources and test each password manager against all\nthe previously disclosed vulnerabilities. We find a mixed picture of fixed and\npersisting vulnerabilities. Then we carry out systematic functionality tests on\nthe considered password managers and find four new vulnerabilities. Notably,\none of the new vulnerabilities we identified allows a malicious app to\nimpersonate a legitimate app to two out of five widely-used password managers\nwe tested and as a result steal the user's password for the targeted service.\nWe implement a proof-of-concept attack to show the feasibility of this\nvulnerability in a real-life scenario. Finally, we report and reflect on our\nexperience of responsible disclosure of the newly discovered vulnerabilities to\nthe corresponding password manager vendors.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Matrix acidization simulation is a challenging task in the study of flows in\nporous media, due to the changing porosity in the procedure. The improved DBF\nframework is one model to do this simulation, and its numerical scheme\ndiscretises the mass and momentum conservation equations together to form a\npressure-velocity linear system. However, this linear system can only be solved\nby direct solvers to solve for pressure and velocity simultaneously, since\nzeros appear in the diagonal of the coefficient matrix. Considering the\nlarge-scale attribute of matrix acidization simulation, the solving time of\ndirect solvers is not intolerant. Thus, a decoupled scheme is proposed in this\nwork to decouple the coupled pressure-velocity linear system into two\nindependent linear systems: one is to solve for pressure, and the other one is\nto solve for velocity. Both of the new linear systems can be solved by parallel\nand iterative solvers, which guarantees the large-scale simulation can be\nfinished in a reasonable time period. A numerical experiment is carried out to\ndemonstrate the correctness of the decoupled scheme and its higher computing\nefficiency.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  In $L_2({\\mathbb R}^d; {\\mathbb C}^n)$, we consider a matrix strongly\nelliptic differential operator ${A}_\\varepsilon$ of order $2p$, $p \\geqslant\n2$. The operator ${A}_\\varepsilon$ is given by ${A}_\\varepsilon =\nb(\\mathbf{D})^* g(\\mathbf{x}/\\varepsilon) b(\\mathbf{D})$, $\\varepsilon >0$,\nwhere $g(\\mathbf{x})$ is a periodic, bounded, and positive definite\nmatrix-valued function, and $b(\\mathbf{D})$ is a homogeneous differential\noperator of order $p$. We prove that, for fixed $\\tau \\in {\\mathbb R}$ and\n$\\varepsilon \\to 0$, the operator exponential $e^{-i \\tau {A}_\\varepsilon}$\nconverges to $e^{-i \\tau {A}^0}$ in the norm of operators acting from the\nSobolev space $H^s({\\mathbb R}^d; {\\mathbb C}^n)$ (with a suitable $s$) into\n$L_2({\\mathbb R}^d; {\\mathbb C}^n)$. Here $A^0$ is the effective operator.\nSharp-order error estimate is obtained. The results are applied to\nhomogenization of the Cauchy problem for the Schr\\\"odinger-type equation $i\n\\partial_\\tau {\\mathbf u}_\\varepsilon = {A}_\\varepsilon {\\mathbf u}_\\varepsilon\n+ {\\mathbf F}$, ${\\mathbf u}_\\varepsilon\\vert_{\\tau=0} = \\boldsymbol{\\phi}$.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We present a lattice QCD calculation of the $\\Delta I=1/2$, $K\\to\\pi\\pi$\ndecay amplitude $A_0$ and $\\varepsilon'$, the measure of direct CP-violation in\n$K\\to\\pi\\pi$ decay, improving our 2015 calculation of these quantities. Both\ncalculations were performed with physical kinematics on a $32^3\\times 64$\nlattice with an inverse lattice spacing of $a^{-1}=1.3784(68)$ GeV. However,\nthe current calculation includes nearly four times the statistics and numerous\ntechnical improvements allowing us to more reliably isolate the $\\pi\\pi$\nground-state and more accurately relate the lattice operators to those defined\nin the Standard Model. We find ${\\rm Re}(A_0)=2.99(0.32)(0.59)\\times 10^{-7}$\nGeV and ${\\rm Im}(A_0)=-6.98(0.62)(1.44)\\times 10^{-11}$ GeV, where the errors\nare statistical and systematic, respectively. The former agrees well with the\nexperimental result ${\\rm Re}(A_0)=3.3201(18)\\times 10^{-7}$ GeV. These results\nfor $A_0$ can be combined with our earlier lattice calculation of $A_2$ to\nobtain ${\\rm Re}(\\varepsilon'/\\varepsilon)=21.7(2.6)(6.2)(5.0) \\times 10^{-4}$,\nwhere the third error represents omitted isospin breaking effects, and\nRe$(A_0)$/Re$(A_2) = 19.9(2.3)(4.4)$. The first agrees well with the\nexperimental result of ${\\rm Re}(\\varepsilon'/\\varepsilon)=16.6(2.3)\\times\n10^{-4}$. A comparison of the second with the observed ratio Re$(A_0)/$Re$(A_2)\n= 22.45(6)$, demonstrates the Standard Model origin of this \"$\\Delta I = 1/2$\nrule\" enhancement.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Notable progress has been made in numerous fields of machine learning based\non neural network-driven mutual information (MI) bounds. However, utilizing the\nconventional MI-based losses is often challenging due to their practical and\nmathematical limitations. In this work, we first identify the symptoms behind\ntheir instability: (1) the neural network not converging even after the loss\nseemed to converge, and (2) saturating neural network outputs causing the loss\nto diverge. We mitigate both issues by adding a novel regularization term to\nthe existing losses. We theoretically and experimentally demonstrate that added\nregularization stabilizes training. Finally, we present a novel benchmark that\nevaluates MI-based losses on both the MI estimation power and its capability on\nthe downstream tasks, closely following the pre-existing supervised and\ncontrastive learning settings. We evaluate six different MI-based losses and\ntheir regularized counterparts on multiple benchmarks to show that our approach\nis simple yet effective.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Animals use stereo sampling of odor concentration to localize sources and\nfollow odor trails. We analyze the dynamics of a bilateral model that depends\non the simultaneous comparison between odor concentrations detected by left and\nright sensors. The general model consists of three differential equations for\nthe positions in the plane and the heading. When the odor landscape is an\ninfinite trail, then we reduce the dynamics to a planar system whose dynamics\nhave just two fixed points. Using an integrable approximation (for short\nsensors) we estimate the basin of attraction. In the case of a radially\nsymmetric landscape, we again can reduce the dynamics to a planar system, but\nthe behavior is considerably richer with multi-stability, isolas, and limit\ncycles. As in the linear trail case, there is also an underlying integrable\nsystem when the sensors are short. In odor landscapes that consist of multiple\nspots and trail segments, we find periodic and chaotic dynamics and\ncharacterize the behavior on trails with gaps and that turn corners.\n\n\n###\n\n", "completion": " 07"}
{"prompt": "  The metal diborides are a class of ceramic materials with crystal structures\nconsisting of hexagonal sheets of boron atoms alternating with planes of metal\natoms held together with mixed character ionic/covalent bonds. Many of the\nmetal diborides are ultrahigh temperature ceramics like HfB$_2$, TaB$_2$, and\nZrB$_2$, which have melting points above 3000$^\\circ$C, high mechanical\nhardness and strength at high temperatures, and high chemical resistance, while\nMgB$_2$ is a superconductor with a transition temperature of 39 K. Here we\ndemonstrate that this diverse family of non-van der Waals materials can be\nprocessed into stable dispersions of two-dimensional (2D) nanosheets using\nultrasonication-assisted exfoliation. We generate 2D nanosheets of the metal\ndiborides AlB$_2$, CrB$_2$, HfB$_2$, MgB$_2$, NbB$_2$, TaB$_2$, TiB$_2$, and\nZrB$_2$, and use electron and scanning probe microscopies to characterize their\nstructures, morphologies, and compositions. The exfoliated layers span up to\nmicrometers in lateral dimension and reach thicknesses down to 2-3 nm, while\nretaining their hexagonal atomic structure and chemical composition. We exploit\nthe convenient solution-phase dispersions of exfoliated CrB$_2$ nanosheets to\nincorporate them directly into polymer composites. In contrast to the hard and\nbrittle bulk CrB$_2$, we find that CrB$_2$ nanocomposites remain very flexible\nand simultaneously provide increases in the elastic modulus and the ultimate\ntensile strength of the polymer. The successful liquid-phase production of 2D\nmetal diborides enables their processing using scalable low-temperature\nsolution-phase methods, extending their use to previously unexplored\napplications, and reveals a new family of non-van der Waals materials that can\nbe efficiently exfoliated into 2D forms.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We report the first map of large-scale (10 pc in length) emission of\nmillimeter-wavelength hydrogen recombination lines (mm-RRLs) toward the giant H\nII region around the W43-Main young massive star cluster (YMC). Our mm-RRL data\ncome from the IRAM 30 m telescope and are analyzed together with radio\ncontinuum and cm-RRL data from the Karl G. Jansky Very Large Array and\nHCO$^{+}$ 1-0 line emission data from the IRAM 30 m. The mm-RRLs reveal an\nexpanding wind-blown ionized gas shell with an electron density ~70-1500\ncm$^{-3}$ driven by the WR/OB cluster, which produces a total Ly$\\alpha$ photon\nflux of 1.5 x 10$^{50}$ s$^{-1}$. This shell is interacting with the dense\nneutral molecular gas in the W43-Main dense cloud. Combining the high spectral\nand angular resolution mm-RRL and cm-RRL cubes, we derive the two-dimensional\nrelative distributions of dynamical and pressure broadening of the ionized gas\nemission and find that the RRL line shapes are dominated by pressure broadening\n(4-55 km s$^{-1}$) near the YMC and by dynamical broadening (8-36 km s$^{-1}$)\nnear the shell's edge. Ionized gas clumps hosting ultra-compact H II regions\nfound at the edge of the shell suggest that large-scale ionized gas motion\ntriggers the formation of new star generation near the periphery of the shell.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  The predict+optimize problem combines machine learning ofproblem coefficients\nwith a combinatorial optimization prob-lem that uses the predicted\ncoefficients. While this problemcan be solved in two separate stages, it is\nbetter to directlyminimize the optimization loss. However, this requires\ndif-ferentiating through a discrete, non-differentiable combina-torial\nfunction. Most existing approaches use some form ofsurrogate gradient.\nDemirovicet alshowed how to directlyexpress the loss of the optimization\nproblem in terms of thepredicted coefficients as a piece-wise linear function.\nHow-ever, their approach is restricted to optimization problemswith a dynamic\nprogramming formulation. In this work wepropose a novel divide and conquer\nalgorithm to tackle op-timization problems without this restriction and predict\nitscoefficients using the optimization loss. We also introduce agreedy version\nof this approach, which achieves similar re-sults with less computation. We\ncompare our approach withother approaches to the predict+optimize problem and\nshowwe can successfully tackle some hard combinatorial problemsbetter than\nother predict+optimize methods.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  In this paper we present new theoretical results on optimal estimation of\ncertain random quantities based on high frequency observations of a L\\'evy\nprocess. More specifically, we investigate the asymptotic theory for the\nconditional mean and conditional median estimators of the supremum/infimum of a\nlinear Brownian motion and a stable L\\'evy process. Another contribution of our\narticle is the conditional mean estimation of the local time and the occupation\ntime measure of a linear Brownian motion. We demonstrate that the new\nestimators are considerably more efficient compared to the classical\nestimators. Furthermore, we discuss pre-estimation of the parameters of the\nunderlying models, which is required for practical implementation of the\nproposed statistics.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Recently, a de-Sitter epoch has been found in the new model of loop quantum\ncosmology which is governed by the scalar constraint with both of Euclidean and\nLorentz terms. The singularity free bounce in the new LQC model and the\nemergent cosmology constant strongly suggest that the effective stress energy\ntensor induced by quantum corrections must violate the standard energy\nconditions. In this paper, we do an explicit calculation to analyze the\nbehaviours of specific representative energy conditions, i.e., average null,\nstrong and dominant energy conditions. It turns out that the averaging null\nenergy condition is violated while the dominant energy condition is violated\nonly at a period around the bounce point. More specifically, the strong energy\ncondition is violated not only at a period around the bounce point, but also\nthe whole period from the bounce point to the classical phase corresponding to\nthe de Sitter period. Our results is expected to shed some lights on\nconstruction of the wormhole and time machine which usually need exotic matters\nviolate energy conditions.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Spontaneous symmetry breaking constitutes a paradigmatic classification\nscheme of matter. However, broken symmetry also entails domain degeneracy that\noften impedes identification of novel low symmetry states. In quantum matter,\nthis is additionally complicated by competing intertwined symmetry breaking\norders. A prime example is that of unconventional superconductivity and\ndensity-wave orders in doped cuprates in which their respective symmetry\nrelation remains a key question. Using uniaxial pressure as a domain-selective\nstimulus in combination with x-ray diffraction, we unambiguously reveal that\nthe fundamental symmetry of the charge order in the prototypical cuprate\nLa$_{1.88}$Sr$_{0.12}$CuO$_4$ is characterized by uniaxial stripes. We further\ndemonstrate the direct competition of this stripe order with unconventional\nsuperconductivity via magnetic field tuning. The stripy nature of the\ncharge-density-wave state established by our study is a prerequisite for the\nexistence of a superconducting pair-density-wave -- a theoretical proposal that\nclarifies the interrelation of intertwined quantum phases in unconventional\nsuperconductors -- and paves the way for its high-temperature realization.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Vehicles crossing bridge structures respond dynamically to the bridge's\nvibrations. An acceleration signal collected within a moving vehicle contains a\ntrace of the bridge's structural response, but also includes other sources such\nas the vehicle suspension system and surface roughness-induced vibrations. This\npaper introduces two methods for the bridge system identification using data\ncollected by a network of moving vehicles. The contributions of the vehicle\nsuspension system are removed by deconvolving the vehicle response in frequency\ndomain. The first approach utilizes the vehicle transfer function, and the\nsecond uses EEMD method. Next, roughness-induced vibrations are extracted using\nsecond-order blind identification (SOBI) method. After these two processes the\nresulting signal is equivalent to the readings of mobile sensors that scan the\nbridge's dynamic response. Structural modal identification using mobile sensor\ndata has been recently introduced as STRIDEX algorithm. The processed mobile\nsensor data is analyzed using STRIDEX to identify the modal properties of the\nbridge. The performance of the methods is validated on numerical case studies\nof a long single-span bridge monitored via a network of moving vehicles. The\nanalyses consider three road surface roughness patterns. Results show that the\nproposed algorithms are successful in extracting pure bridge vibrations, and\nproduce accurate and comprehensive modal properties of the bridge. The study\nshows that the proposed transfer function method can efficiently deconvolve the\nlinear dynamics of a moving vehicle. EEMD method is able to extract vehicle\ndynamic response without a-priori information about the vehicle. This study is\nthe first proposed methodology for complete bridge modal identification,\nincluding operational natural frequencies, mode shapes and damping ratios using\n\\textit{moving vehicles sensor data}.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  A novel evaluation study of the most appropriate round function for\nnearest-neighbor (NN) image interpolation is presented. Evaluated rounding\nfunctions are selected among the five rounding rules defined by the Institute\nof Electrical and Electronics Engineers (IEEE) 754-2008 standard. Both full-\nand no-reference image quality assessment (IQA) metrics are used to study and\nevaluate the influence of rounding functions on NN interpolation image quality.\nThe concept of achieved occurrences over targeted occurrences is used to\ndetermine the percentage of achieved occurrences based on the number of test\nimages used. Inferential statistical analysis is applied to deduce from a small\nnumber of images and draw a conclusion of the behavior of each rounding\nfunction on a bigger number of images. Under the normal distribution and at the\nlevel of confidence equals to 95%, the maximum and minimum achievable\noccurrences by each evaluated rounding function are both provided based on the\ninferential analysis-based experiments.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We show a near optimal direct-sum theorem for the two-party randomized\ncommunication complexity. Let $f\\subseteq X \\times Y\\times Z$ be a relation,\n$\\varepsilon> 0$ and $k$ be an integer. We show,\n$$\\mathrm{R}^{\\mathrm{pub}}_\\varepsilon(f^k) \\cdot\n\\log(\\mathrm{R}^{\\mathrm{pub}}_\\varepsilon(f^k)) \\ge \\Omega(k \\cdot\n\\mathrm{R}^{\\mathrm{pub}}_\\varepsilon(f)) \\enspace,$$ where $f^k= f \\times\n\\ldots \\times f$ ($k$-times) and $\\mathrm{R}^{\\mathrm{pub}}_\\varepsilon(\\cdot)$\nrepresents the public-coin randomized communication complexity with worst-case\nerror $\\varepsilon$. Given a protocol $\\mathcal{P}$ for $f^k$ with\ncommunication cost $c \\cdot k$ and worst-case error $\\varepsilon$, we exhibit a\nprotocol $\\mathcal{Q}$ for $f$ with external-information-cost $O(c)$ and\nworst-error $\\varepsilon$. We then use a message compression protocol due to\nBarak, Braverman, Chen and Rao [2013] for simulating $\\mathcal{Q}$ with\ncommunication $O(c \\cdot \\log(c\\cdot k))$ to arrive at our result. To show this\nreduction we show some new chain-rules for capacity, the maximum information\nthat can be transmitted by a communication channel. We use the powerful concept\nof Nash-Equilibrium in game-theory, and its existence in suitably defined\ngames, to arrive at the chain-rules for capacity. These chain-rules are of\nindependent interest.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  One believed path to Interstellar Complexes Organic Molecules (iCOMs)\nformation inside the Interstellar Medium (ISM) is through chemical\nrecombination at the surface of amorphous solid water (ASW) mantle covering the\nsilicate-based core of the interstellar grains. The study of these iCOMs\nformation and their binding energy to the ASW, using computational chemistry,\ndepends strongly on the ASW models used, as different models may exhibit sites\nwith different adsorbing features. ASW extended models are rare in the\nliterature because large sizes require very large computational resources when\nquantum mechanical methods based on DFT are used. To circumvent this problem,\nwe propose to use the newly developed GFN-xTB Semi-empirical Quantum Mechanical\n(SQM) methods from the Grimme's group. These methods are, at least, two orders\nof magnitude faster than conventional DFT, only require modest central memory,\nand in this paper we aim to benchmark their accuracy against rigorous and\nresource hungry quantum mechanical methods. We focused on 38 water structures\nstudied by MP2 and CCSD(T) approaches comparing energetic and structures with\nthree levels of GFN-xTB parametrization (GFN0, GFN1, GFN2) methods. The\nextremely good results obtained at the very cheap GFN-xTB level for both water\ncluster structures and energetic paved the way towards the modeling of very\nlarge AWS models of astrochemical interest.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Many data mining and analytical tasks rely on the abstraction of networks\n(graphs) to summarize relational structures among individuals (nodes). Since\nrelational data are often sensitive, we aim to seek effective approaches to\ngenerate utility-preserved yet privacy-protected structured data. In this\npaper, we leverage the differential privacy (DP) framework to formulate and\nenforce rigorous privacy constraints on deep graph generation models, with a\nfocus on edge-DP to guarantee individual link privacy. In particular, we\nenforce edge-DP by injecting proper noise to the gradients of a link\nreconstruction-based graph generation model, while ensuring data utility by\nimproving structure learning with structure-oriented graph discrimination.\nExtensive experiments on two real-world network datasets show that our proposed\nDPGGAN model is able to generate graphs with effectively preserved global\nstructure and rigorously protected individual link privacy.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  The fractional calculus framework will be used to invert the potential energy\nfunction from the classical scattering angle, which will be related to\nRiemann-Liouville fractional integral. Numerical solution of this fractional\norder problem will be applied to the inverse Rutherford scattering and to the\ninverse scattering of Xe--Rn atoms, in which the potential is given by\nLennard-Jones function. Proofs of existence will be presented for more clarity\nand completness of the present work. In the two cases considered, the potential\nenergy function can be retrieved with a desired precision. The present method\ngives a clear understanding of the inverse fractional problem framework.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Robust optimization is a popular paradigm for modeling and solving two- and\nmulti-stage decision-making problems affected by uncertainty. In many\nreal-world applications, the time of information discovery is\ndecision-dependent and the uncertain parameters only become observable after an\noften costly investment. Yet, most of the literature assumes that uncertain\nparameters can be observed for free and that the sequence in which they are\nrevealed is independent of the decision-maker's actions. To fill this gap. we\nconsider two- and multi-stage robust optimization problems in which part of the\ndecision variables control the time of information discovery. Thus, information\ncan be discovered (at least in part) by making strategic exploratory\ninvestments in previous stages. We propose a novel dynamic formulation of the\nproblem and prove its correctness. We leverage our model to provide a solution\nmethod inspired from the K-adaptability approximation. We reformulate the\nproblem as a finite mixed-integer (resp. bilinear) program if none (resp. some\nof the) decision variables are real-valued. This finite program is solvable\nwith off-the-shelf solvers. We generalize our approach to the minimization of\npiecewise linear convex functions. We demonstrate the effectiveness of our\nmethod in terms of interpretability, optimality, and speed on synthetic\ninstances of the Pandora box problem, the preference elicitation problem, the\nbest box problem, and the R&D project portfolio optimization problem. Finally,\nwe evaluate it on an instance of the active preference elicitation problem used\nto recommend kidney allocation policies to policy-makers at the United Network\nfor Organ Sharing.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We describe and characterize an experimental apparatus that has been used to\nstudy interactions between ultracold lithium atoms and ytterbium ions. The\npreparation of ultracold clouds of Li atoms is described as well as their\nsubsequent transport and overlap with Yb$^+$ ions trapped in a Paul trap. We\nshow how the kinetic energy of the ion after interacting with the atoms can be\nobtained by laser spectroscopy. From analyzing the dynamics of the ion in the\nabsence of atoms, we conclude that background heating, due to electric field\nnoise, limits attainable buffer gas cooling temperatures. We suspect that this\neffect can be mitigated by noise reduction and by increasing the density of the\nLi gas, in order to improve its cooling power. Imperfections in the Paul trap\nlead to so-called excess micromotion, which poses another limitation to the\nbuffer gas cooling. We describe in detail how we measure and subsequently\nminimize excess micromotion in our setup. We measure the effect of excess\nmicromotion on attainable ion temperatures after buffer gas cooling and compare\nthis to molecular dynamics simulations which describe the observed data very\nwell.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Observations are studied in toy-models constituting exact cosmological\nsolutions to the Einstein equation which are statistically homogeneous but\nlocally inhomogeneous, without an a priori introduced FLRW background and with\n\"structures\" evolving fairly slowly. The mean redshift-distance relation and\nredshift drift along 500 light rays in each of two models are compared to\nrelations based on spatial averages. The relations based on spatial averages\ngive a good reproduction of the mean redshift-distance relation, although most\nconvincingly in the model where the kinematical backreaction is subpercent. In\nboth models, the mean redshift drift clearly differs from the drift of the mean\nredshift. This indicates that redshift drift could be an important tool for\ntesting the backreaction conjecture as redshift drift appears to distinguish\nbetween local and global effects. The method presented for computing the\nredshift drift is straightforward to generalize and can thus be utilized to\nfairly easily compute this quantity in a general spacetime.\n\n\n###\n\n", "completion": " 00"}
{"prompt": "  Subclassification and matching are often used in empirical studies to adjust\nfor observed covariates; however, they are largely restricted to relatively\nsimple study designs with a binary treatment and less developed for designs\nwith a continuous exposure. Matching with exposure doses is particularly useful\nin instrumental variable designs and in understanding the dose-response\nrelationships. In this article, we propose two criteria for optimal\nsubclassification based on subclass homogeneity in the context of having a\ncontinuous exposure dose, and propose an efficient polynomial-time algorithm\nthat is guaranteed to find an optimal subclassification with respect to one\ncriterion and serves as a 2-approximation algorithm for the other criterion. We\ndiscuss how to incorporate dose and use appropriate penalties to control the\nnumber of subclasses in the design. Via extensive simulations, we\nsystematically compare our proposed design to optimal non-bipartite pair\nmatching, and demonstrate that combining our proposed subclassification scheme\nwith regression adjustment helps reduce model dependence for parametric causal\ninference with a continuous dose. We apply the new design and associated\nrandomization-based inferential procedure to study the effect of\ntransesophageal echocardiography (TEE) monitoring during coronary artery bypass\ngraft (CABG) surgery on patients' post-surgery clinical outcomes using Medicare\nand Medicaid claims data, and find evidence that TEE monitoring lowers\npatients' all-cause $30$-day mortality rate.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We consider the zero-energy deformations of periodic origami sheets with\ngeneric crease patterns. Using a mapping from the linear folding motions of\nsuch sheets to force-bearing modes in conjunction with the Maxwell-Calladine\nindex theorem we derive a relation between the number of linear folding motions\nand the number of rigid body modes that depends only on the average\ncoordination number of the origami's vertices. This supports the recent result\nby Tachi which shows periodic origami sheets with triangular faces exhibit\ntwo-dimensional spaces of rigidly foldable cylindrical configurations. We also\nfind, through analytical calculation and numerical simulation, branching of\nthis configuration space from the flat state due to geometric compatibility\nconstraints that prohibit finite Gaussian curvature. The same counting argument\nleads to pairing of spatially varying modes at opposite wavenumber in\ntriangulated origami, preventing topological polarization but permitting a\nfamily of zero energy deformations in the bulk that may be used to reconfigure\nthe origami sheet.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  We investigate the global dynamics of a renewal-type epidemic model with\nvariable susceptibility. We show that in this extended model there exists a\nunique endemic equilibrium and prove that it is globally asymptotically stable\nwhen $R_0 > 1$, i.e. when it exists. We also show that the infection-free\nequilibrium, which exists always, is globally asymptotically stable for $R_0\n\\leq 1$.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  The problem of objectivity, i.e. how to explain on quantum grounds the\nobjective character of the macroscopic world, is one of the aspects of the\ncelebrated quantum-to-classical transition. Initiated by W. H. Zurek and\ncollaborators, this problem gained some attention recently with several\napproaches being developed. The aim of this work is to compare three of them:\nquantum Darwinism, Spectrum Broadcast Structures, and strong quantum Darwinism.\nThe paper is concentrated on foundations, providing a synthetic analysis of how\nthe three approaches realize the idea of objectivity and how they are related\nto each other. As a byproduct of this analysis, a proof of a generalized\nSpectrum Broadcast Structure theorem is presented. Recent quantum Darwinism\nexperiments are also briefly discussed.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  This paper introduces VESR-Net, a method for video enhancement and\nsuper-resolution (VESR). We design a separate non-local module to explore the\nrelations among video frames and fuse video frames efficiently, and a channel\nattention residual block to capture the relations among feature maps for video\nframe reconstruction in VESR-Net. We conduct experiments to analyze the\neffectiveness of these designs in VESR-Net, which demonstrates the advantages\nof VESR-Net over previous state-of-the-art VESR methods. It is worth to mention\nthat among more than thousands of participants for Youku video enhancement and\nsuper-resolution (Youku-VESR) challenge, our proposed VESR-Net beat other\ncompetitive methods and ranked the first place.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  It is well known that a Weinberg dimension-5 operator for small neutrino\nmasses can be realized at tree level in three types of renormalizable models:\n(i) the type-I seesaw mediated by fermion singlets, (ii) the type-II seesaw\nmediated by Higgs triplets, (iii) the type-III seesaw mediated by fermion\ntriplets. We here point out such operator can be also induced at tree level by\nvector-like lepton doublets in association with unusual fermion singlets, Higgs\ntriplets or fermion triplets. If these unusual fermion singlets, Higgs triplets\nor fermion triplets are heavy enough, their decays can generate a lepton\nasymmetry to explain the cosmic baryon asymmetry, meanwhile, the vector-like\nlepton doublets can lead to a novel inverse or linear seesaw with rich\nobservable phenomena. We further specify our scenario can be naturally embedded\ninto a grand unification theory without the conventional type-I, type-II or\ntype-III seesaw.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  This survey is devoted to the classical and modern problems related to the\nentire function ${\\sigma({\\bf u};\\lambda)}$, defined by a family of nonsingular\nalgebraic curves of genus $2$, where ${\\bf u} = (u_1,u_3)$ and $\\lambda =\n(\\lambda_4, \\lambda_6,\\lambda_8,\\lambda_{10})$. It is an analogue of the\nWeierstrass sigma function $\\sigma(u;g_2,g_3)$ of a family of elliptic curves.\nLogarithmic derivatives of order 2 and higher of the function ${\\sigma({\\bf\nu};\\lambda)}$ generate fields of hyperelliptic functions of ${\\bf u} =\n(u_1,u_3)$ on the Jacobians of curves with a fixed parameter vector $\\lambda$.\nWe consider three Hurwitz series $\\sigma({\\bf u};\\lambda)=\\sum_{m,n\\ge\n0}a_{m,n}(\\lambda)\\frac{u_1^mu_3^n}{m!n!}$, $\\sigma({\\bf u};\\lambda) =\n\\sum_{k\\ge 0}\\xi_k(u_1;\\lambda)\\frac{u_3^k}{k!}$ and $\\sigma({\\bf u};\\lambda) =\n\\sum_{k\\ge 0}\\mu_k(u_3;\\lambda)\\frac{u_1^k}{k!}$. The survey is devoted to the\nnumber-theoretic properties of the functions $a_{m,n}(\\lambda)$,\n$\\xi_k(u_1;\\lambda)$ and $\\mu_k(u_3;\\lambda)$. It includes the latest results,\nwhich proofs use the fundamental fact that the function ${\\sigma ({\\bf\nu};\\lambda)}$ is determined by the system of four heat equations in a\nnonholonomic frame of six-dimensional space.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  The paper deals with conditional linear information inequalities valid for\nentropy functions induced by discrete random variables. Specifically, the\nso-called conditional Ingleton inequalities are in the center of interest:\nthese are valid under conditional independence assumptions on the inducing\nrandom variables. We discuss five inequalities of this particular type, four of\nwhich has appeared earlier in the literature. Besides the proof of the new\nfifth inequality, simpler proofs of (some of) former inequalities are\npresented. These five information inequalities are used to characterize all\nconditional independence structures induced by four discrete random variables.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Language model based pre-trained models such as BERT have provided\nsignificant gains across different NLP tasks. In this paper, we study different\ntypes of transformer based pre-trained models such as auto-regressive models\n(GPT-2), auto-encoder models (BERT), and seq2seq models (BART) for conditional\ndata augmentation. We show that prepending the class labels to text sequences\nprovides a simple yet effective way to condition the pre-trained models for\ndata augmentation. Additionally, on three classification benchmarks,\npre-trained Seq2Seq model outperforms other data augmentation methods in a\nlow-resource setting. Further, we explore how different pre-trained model based\ndata augmentation differs in-terms of data diversity, and how well such methods\npreserve the class-label information.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  In this paper we study connections between Besov spaces of functions on a\ncompact metric space $Z$, equipped with a doubling measure, and the\nNewton--Sobolev space of functions on a uniform domain $X_\\varepsilon$. This\nuniform domain is obtained as a uniformization of a (Gromov) hyperbolic filling\nof $Z$. To do so, we construct a family of hyperbolic fillings in the style of\nthe work of Bonk and Kleiner and the work of Bourdon and Pajot. Then for each\nparameter $\\beta>0$ we construct a lift $\\mu_\\beta$ of the doubling measure\n$\\nu$ on $Z$ to $X_\\varepsilon$, and show that $\\mu_\\beta$ is doubling and\nsupports a $1$-Poincar\\'e inequality. We then show that for each $\\theta$ with\n$0<\\theta<1$ and $p\\ge 1$ there is a choice of $\\beta=p(1-\\theta)\\log\\alpha$\nsuch that the Besov space $B^\\theta_{p,p}(Z)$ is the trace space of the\nNewton--Sobolev space $N^{1,p}(X_\\varepsilon,\\mu_\\beta)$ when\n$\\varepsilon=\\log\\alpha$. Finally, we exploit the tools of potential theory on\n$X_\\varepsilon$ to obtain fine properties of functions in $B^\\theta_{p,p}(Z)$,\nsuch as their quasicontinuity and quasieverywhere existence of $L^q$-Lebesgue\npoints with $q=s_\\nu p/(s_\\nu-p\\theta)$, where $s_\\nu$ is a doubling dimension\nassociated with the measure $\\nu$ on $Z$. Applying this to compact subsets of\nEuclidean spaces improves upon a result of Netrusov in $\\mathbb{R}^n$.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We propose a standardized methodology for developing and evaluating use cases\nfor quantum computers and quantum inspired methods. This methodology consists\nof a standardized set of questions which should be asked to determine how and\nindeed if, near term quantum computing can play a role in a given application.\nDeveloping such a set of questions is important because it allows different use\ncases to be evaluated in a fair and objective way, rather than considering each\ncase on an ad hoc basis which could lead to an evaluation which focuses on\npositives of a use case, while ignoring weaknesses. To demonstrate our\nmethodology we apply it to a concrete use case, ambulance dispatch, and find\nthat there are some ways in which near term quantum computing could be deployed\nsensibly, but also demonstrate some cases ways in which its use would not be\nadvised. The purpose of this paper is to initiate a dialogue within the\ncommunity of quantum computing scientists and potential end users on what\nquestions should be asked when developing real world use cases.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Recent advancements in Neural Architecture Search(NAS) resulted in finding\nnew state-of-the-art Artificial Neural Network (ANN) solutions for tasks like\nimage classification, object detection, or semantic segmentation without\nsubstantial human supervision. In this paper, we focus on exploring NAS for a\ndense prediction task that is image denoising. Due to a costly training\nprocedure, most NAS solutions for image enhancement rely on reinforcement\nlearning or evolutionary algorithm exploration, which usually take weeks (or\neven months) to train. Therefore, we introduce a new efficient implementation\nof various superkernel techniques that enable fast (6-8 RTX2080 GPU hours)\nsingle-shot training of models for dense predictions. We demonstrate the\neffectiveness of our method on the SIDD+ benchmark for image denoising.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Quantum heat transfer through a generic superconducting set-up consisting of\na tunable transmon qubit placed between resonators that are termined by thermal\nreservoirs is explored. Two types of architectures are considered, a sequential\nand a beam splitter setting. Applying the numerical exact hierarchical equation\nof motion (HEOM) approach, steady state properties are revealed, and\nexperimentally relevant parameter sets are identified. Benchmark results are\ncompared with predictions based on approximate treatments to demonstrate their\nfailure in broad ranges of parameter space. These findings may allow to improve\nfuture designs for heat control in superconducting devices.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  There is an increased demand for task automation in robots. Contact-rich\ntasks, wherein multiple contact transitions occur in a series of operations,\nare extensively being studied to realize high accuracy. In this study, we\npropose a methodology that uses reinforcement learning (RL) to achieve high\nperformance in robots for the execution of assembly tasks that require precise\ncontact with objects without causing damage. The proposed method ensures the\nonline generation of stiffness matrices that help improve the performance of\nlocal trajectory optimization. The method has an advantage of rapid response\nowing to short sampling time of the trajectory planning. The effectiveness of\nthe method was verified via experiments involving two contact-rich tasks. The\nresults indicate that the proposed method can be implemented in various\ncontact-rich manipulations. A demonstration video shows the performance.\n(https://youtu.be/gxSCl7Tp4-0)\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  The collapse of a gas or vapour bubble near a solid boundary produces a jet\ndirected towards the boundary. High surface pressure and shear stress induced\nby this jet can damage, or clean, the surface. More complex geometries will\nresult in changes in collapse behaviour, in particular the direction of the\njet. The majority of prior research has focused on simple flat boundaries or\nlimited cases with analytic solutions. We numerically and experimentally\ninvestigate how a slot in a flat boundary affects the jet direction for a\nsingle bubble. We use a boundary element model to predict how the jet direction\ndepends on key geometric parameters and show that the results collapse to a\nsingle curve when the parameters are normalised appropriately. We then\nexperimentally validate the predictions using laser-induced cavitation and\ncompare the experimental results to the predicted dependencies. This research\nreveals a tendency for the jet to be directed away from a slot and shows that\nthe jet direction is independent of slot height for slots of sufficient height.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In this paper, we propose a neural machine translation system for Wolof, a\nlow-resource Niger-Congo language. First we gathered a parallel corpus of 70000\naligned French-Wolof sentences. Then we developped a baseline LSTM based\nencoder-decoder architecture which was further extended to bidirectional LSTMs\nwith attention mechanisms. Our models are trained on a limited amount of\nparallel French-Wolof data of approximately 35000 parallel sentences.\nExperimental results on French-Wolof translation tasks show that our approach\nproduces promising translations in extremely low-resource conditions. The best\nmodel was able to achieve a good performance of 47% BLEU score.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Collisional ionization between two Rydberg atoms in relative motion is\nexamined. A classical trajectory Monte Carlo method is used to determine the\ncross sections associated with Penning ionization. The dependence of the\nionization cross section on the magnitude and the direction of orbital angular\nmomentum of the electrons and the direction of the Laplace-Runge-Lenz vector of\nthe electrons is studied. For a given magnitude of angular momentum, there can\nexist a difference of a factor of up to $\\sim2.5$ in the ionization cross\nsection between the orientation with the highest and the lowest ionization\ncross section. The case of exchange ionization is examined and its dependence\non the magnitude of angular momentum is studied.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  We recast the soft $S$-matrices on the celestial sphere as correlation\nfunctions of certain $2$-dimensional models of topological defects. In pointing\nout the double copy structure between the soft photon and soft graviton cases,\nwe arrive at a putative classical double copy between the corresponding\ntopological models and a rederivation of gauge invariance and the equivalence\nprinciple as Ward identities of the $2$-dimensional theories.\n\n\n###\n\n", "completion": " 98"}
{"prompt": "  The overall cosmological parameter tension between the Atacama Cosmology\nTelescope 2020 (ACT) and Planck 2018 data within the concordance cosmological\nmodel is quantified using the suspiciousness statistic to be 2.6$\\sigma$.\nBetween ACT and the South Pole Telescope (SPT) we find a tension of\n2.4$\\sigma$, and 2.8$\\sigma$ between ACT and Planck+SPT combined. While it is\nunclear whether the tension is caused by statistical fluctuations, systematic\neffects or new physics, caution should be exercised in combining these cosmic\nmicrowave background datasets in the context of the $\\Lambda$CDM standard model\nof the universe.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  This paper develops an easily-implementable version of Page's CUSUM\nquickest-detection test, designed to work in certain composite hypothesis\nscenarios with time-varying data statistics. The decision statistic can be cast\nin a recursive form and is particularly suited for on-line analysis. By\nback-testing our approach on publicly-available COVID-19 data we find reliable\nearly warning of infection flare-ups, in fact sufficiently early that the tool\nmay be of use to decision-makers on the timing of restrictive measures that may\nin the future need to be taken.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Invisible decays of neutral hadrons are evaluated as ordinary-mirror particle\noscillations using the newly developed mirror matter model. Assuming\nequivalence of the $CP$ violation and mirror symmetry breaking scales for\nneutral kaon oscillations, rather precise values of the mirror matter model\nparameters are predicted for such ordinary-mirror particle oscillations. Not\nonly do these parameter values satisfy the cosmological constraints, but they\ncan also be used to precisely determine the oscillation or invisible decay\nrates of neutral hadrons. In particular, invisible decay branching fractions\nfor relatively long-lived hadrons such as $K^0_L$, $K^0_S$, $\\Lambda^0$, and\n$\\Xi^0$ due to such oscillations are calculated to be $9.9\\times 10^{-6}$,\n$1.8\\times 10^{-6}$, $4.4\\times 10^{-7}$, and $3.6\\times 10^{-8}$,\nrespectively. These significant invisible decays are readily detectable at\nexisting accelerator facilities.\n\n\n###\n\n", "completion": " 02"}
{"prompt": "  This survey describes probabilistic algorithms for linear algebra\ncomputations, such as factorizing matrices and solving linear systems. It\nfocuses on techniques that have a proven track record for real-world problem\ninstances. The paper treats both the theoretical foundations of the subject and\nthe practical computational issues.\n  Topics covered include norm estimation; matrix approximation by sampling;\nstructured and unstructured random embeddings; linear regression problems;\nlow-rank approximation; subspace iteration and Krylov methods; error estimation\nand adaptivity; interpolatory and CUR factorizations; Nystr\\\"om approximation\nof positive-semidefinite matrices; single view (\"streaming\") algorithms; full\nrank-revealing factorizations; solvers for linear systems; and approximation of\nkernel matrices that arise in machine learning and in scientific computing.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  This paper is an attempt to extend the recent understanding of the Page curve\nfor evaporating black holes to more general systems coupled to a heat bath.\nAlthough calculating the von Neumann entropy by the replica trick is usually a\nchallenge, we have identified two solvable cases. For the initial section of\nthe Page curve, we sum up the perturbation series in the system-bath coupling\n$\\kappa$; the most interesting contribution is of order $2s$, where $s$ is the\nnumber of replicas. For the saturated regime, we consider the effect of an\nexternal impulse on the entropy at a later time and relate it to OTOCs. A\nsignificant simplification occurs in the maximal chaos case such that the\neffect may be interpreted in terms of an intermediate object, analogous to the\nbranching surface of a replica wormhole.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  In this paper, we consider various graphs, namely: power graph, cyclic graph,\nenhanced power graph and commuting graph, on a finite semigroup $S$. For an\narbitrary pair of these four graphs, we classify finite semigroups such that\nthe graphs in this pair are equal. In this connection, for each of the graph we\nalso give a necessary and sufficient condition on $S$ such that it is complete.\nThe work of this paper generalize the corresponding results obtained for\ngroups.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Air quality has major impact on a country's socio-economic position and\nidentifying major air pollution sources is at the heart of tackling the issue.\nSpatially and temporally distributed air quality data acquisition across a\ncountry as varied as India has been a challenge to such analysis. The launch of\nthe Sentinel-5P satellite has helped in the observation of a wider variety of\nair pollutants than measured before at a global scale on a daily basis. In this\nchapter, spatio-temporal multi pollutant data retrieved from Sentinel-5P\nsatellite is used to cluster states as well as districts in India and\nassociated average monthly pollution signature and trends depicted by each of\nthe clusters are derived and presented.The clustering signatures can be used to\nidentify states and districts based on the types of pollutants emitted by\nvarious pollution sources.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  The thermophotovoltaic cells which convert the low temperature radiation into\nelectricity are of significance due to their potential applications in many\nfields. In this work, Bi2Te3/Si thermophotovoltaic cells which work under the\nradiation from the blackbody with the temperature of 300 K-480 K are presented.\nThe experimental results show that the cells can output electricity even under\nthe radiation temperature of 300 K. The band structure of Bi2Te3/Si\nheterojunctions and the defects in Bi2Te3 thin films lower the conversion\nefficiency of the cells. It is also demonstrated that the resistivity of Si and\nthe thickness of Bi2Te3 thin films have important effects on Bi2Te3/Si\nthermophotovoltaic cells. Although the cells' output power is small, this work\nprovides a possible way to utilize the low temperature radiation.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We propose a notion of iterating functions $f:X^{k}\\rightarrow X$ in a way\nthat represents recurrence relations of the form\n$a_{n+k}=f(a_{n},a_{n+1},...,a_{n+k-1})$. We define a function as\n$n$-involutory when its $n$th iterate is the identity map, and discuss\nelementary group-theoretic properties of such functions along with their\nrelation to cycles of their corresponding recurrence relations. Further, it is\nshown that a function $f:X^{k}\\rightarrow X$ that is 2-involutory in each of\nits $k$ arguments (holding others fixed) is $(k+1)$-involutory.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  Fossil groups (FGs) have been discovered twenty-five years ago, and are now\ndefined as galaxy groups with an X-ray luminosity higher than $10^{42}\\\nh_{50}^{-2}$ erg s$^{-1}$ and a brightest group galaxy brighter than the other\ngroup members by at least 2 magnitudes. However, the scenario of their\nformation remains controversial. We propose here a probabilistic analysis of\nFGs, extracted from the large catalogue of candidate groups and clusters\ndetected by Sarron et al. (2018) in the CFHTLS survey, based on photometric\nredshifts, to investigate their position in the cosmic web and probe their\nenvironment. Based on spectroscopic and photometric redshifts, we estimate the\nprobability of galaxies to belong to a galaxy structure, and by imposing the\ncondition that the brightest group galaxy is at least brighter than the others\nby 2 magnitudes, we compute the probability for a given galaxy structure to be\na FG. We analyse the mass distribution of these candidate FGs, and estimate\ntheir distance to the filaments and nodes of the cosmic web in which they are\nembedded. We find that the structures with masses lower than $2.4\\times\n10^{14}$ M$_\\odot$ have the highest probabilities of being fossil groups (PFG).\nOverall, structures with PFG$\\geq$50% are located close to the cosmic web\nfilaments (87% are located at less than 1 Mpc from their nearest filament).\nThey are preferentially four times more distant from their nearest node than\nfrom their nearest filament. We confirm that FGs have small masses and are\nrare. They seem to reside closeby cosmic filaments and do not survive in nodes.\nBeing in a poor environment could therefore be the driver of FG formation, the\nnumber of nearby galaxies not being sufficient to compensate for the\ncannibalism of the central group galaxy.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Many ultra-diffuse galaxies (UDGs) have been discovered in the Coma cluster,\nand there is evidence that some, notably Dragonfly 44, have Milky Way-like\ndynamical masses despite dwarf-like stellar masses. We used X-ray, UV, and\noptical data to investigate the star formation and nuclear activity in the Coma\nUDGs, and we obtained deep UV and X-ray data (Swift and XMM-Newton) for\nDragonfly 44 to search for low-level star formation, hot circumgalactic gas,\nand the integrated emission from X-ray binaries. Among the Coma UDGs, we find\nUV luminosities consistent with quiescence but NUV$-r$ colors indicating star\nformation in the past Gyr. This indicates that the UDGs were recently quenched.\nThe $r$-band luminosity declines with projected distance from the Coma core.\nThe Dragonfly 44 UV luminosity is also consistent with quiescence, with\nSFR$<6\\times 10^{-4} M_{\\odot}$ yr$^{-1}$, and no X-rays are detected down to a\nsensitivity of $10^{38}$ erg s$^{-1}$. This rules out a hot corona with a $M >\n10^8 M_{\\odot}$ within the virial radius, which would normally be expected for\na dynamically massive galaxy. The absence of bright, low mass X-ray binaries is\nconsistent with the expectation from the galaxy total stellar mass, but it is\nunlikely if most low-mass X-ray binaries form in globular clusters, as\nDragonfly 44 has a very large population. Based on the UV and X-ray analysis,\nthe Coma UDGs are consistent with quenched dwarf galaxies, although we cannot\nrule out a dynamically massive population.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Segmentation of handwritten document images into text lines and words is one\nof the most significant and challenging tasks in the development of a complete\nOptical Character Recognition (OCR) system. This paper addresses the automatic\nsegmentation of text words directly from unconstrained Bangla handwritten\ndocument images. The popular Distance transform (DT) algorithm is applied for\nlocating the outer boundary of the word images. This technique is free from\ngenerating the over-segmented words. A simple post-processing procedure is\napplied to isolate the under-segmented word images, if any. The proposed\ntechnique is tested on 50 random images taken from CMATERdb1.1.1 database.\nSatisfactory result is achieved with a segmentation accuracy of 91.88% which\nconfirms the robustness of the proposed methodology.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Aims. We investigate the physical and chemical conditions of molecular gas in\nthe circumnuclear disk (CND) region of NGC 1068. Methods. We carried out a\nspectral line survey with the IRAM 30m telescope toward the center of NGC 1068\nand mainly focused on the 2 mm band with a frequency coverage of 160.7-168.6\nGHz and 176.5-184.3 GHz. Results. Fifteen lines are detected in NGC 1068, eight\nof which are new detections for this galaxy. We derive the rotation\ntemperatures and column densities of fourteen molecular species. Conclusions.\nBased on the [HCO+ (2 - 1)]/[HOC+ (2 - 1)] ratio, we obtain a high ionization\ndegree in the CND of NGC 1068. It is found that HC3N is concentrated in the\neast knot, while 13CCH, CH3CN, SO, HOC+, CS, CH3CCH, and H2CO are concentrated\nin the west knot. Compared to the star-forming galaxies M 82 and NGC 253, the\nchemistry of NGC 1068 might be less strongly affected by the UV radiation\nfield, and its kinetic temperature might be lower.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  Structural engineering of van der Waals heterostructures via stacking and\ntwisting has recently been used to create moir\\'e superlattices, enabling the\nrealization of new optical and electronic properties in solid-state systems. In\nparticular, moir\\'e lattices in twisted bilayers of transition metal\ndichalcogenides (TMDs) have been shown to lead to exciton trapping, host Mott\ninsulating and superconducting states, and act as unique Hubbard systems whose\ncorrelated electronic states can be detected and manipulated optically.\nStructurally, these twisted heterostructures also feature atomic reconstruction\nand domain formation. Unfortunately, due to the nanoscale sizes (~10 nm) of\ntypical moir\\'e domains, the effects of atomic reconstruction on the electronic\nand excitonic properties of these heterostructures could not be investigated\nsystematically and have often been ignored. Here, we use near-0$^o$ twist angle\nMoSe$_2$/MoSe$_2$ bilayers with large rhombohedral AB/BA domains to directly\nprobe excitonic properties of individual domains with far-field optics. We show\nthat this system features broken mirror/inversion symmetry, with the AB and BA\ndomains supporting interlayer excitons with out-of-plane (z) electric dipole\nmoments in opposite directions. The dipole orientation of ground-state\n$\\Gamma$-K interlayer excitons (X$_{I,1}$) can be flipped with electric fields,\nwhile higher-energy K-K interlayer excitons (X$_{I,2}$) undergo\nfield-asymmetric hybridization with intralayer K-K excitons (X$_0$). Our study\nreveals the profound impacts of crystal symmetry on TMD excitons and points to\nnew avenues for realizing topologically nontrivial systems, exotic\nmetasurfaces, collective excitonic phases, and quantum emitter arrays via\ndomain-pattern engineering.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We investigate the possibility of completing financial markets in a model\nwith no exogenous probability measure and market imperfections. A necessary and\nsufficient condition is obtained for such extension to be possible.\n\n\n###\n\n", "completion": " 06"}
{"prompt": "  We study a noisy oscillator with pulse delayed feedback, theoretically and in\nan electronic experimental implementation. Without noise, this system has\nmultiple stable periodic regimes. We consider two types of noise: i) phase\nnoise acting on the oscillator state variable and ii) stochastic fluctuations\nof the coupling delay. For both types of stochastic perturbations the system\nhops between the deterministic regimes, but it shows dramatically different\nscaling properties for different types of noise. The robustness to conventional\nphase noise increases with coupling strength. However for stochastic variations\nin the coupling delay, the lifetimes decrease exponentially with the coupling\nstrength. We provide an analytic explanation for these scaling properties in a\nlinearised model. Our findings thus indicate that the robustness of a system to\nstochastic perturbations strongly depends on the nature of these perturbations.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  This paper develops a mechanical tool as well as its manipulation policies\nfor 2-finger parallel robotic grippers. It primarily focuses on a mechanism\nthat converts the gripping motion of 2-finger parallel grippers into a\ncontinuous rotation to realize tasks like fastening screws. The essential\nstructure of the tool comprises a Scissor-Like Element (SLE) mechanism and a\ndouble-ratchet mechanism. They together convert repeated linear motion into\ncontinuous rotating motion. At the joints of the SLE mechanism, elastic\nelements are attached to provide resisting force for holding the tool as well\nas for producing torque output when a gripper releases the tool. The tool is\nentirely mechanical, allowing robots to use the tool without any peripherals\nand power supply. The paper presents the details of the tool design, optimizes\nits dimensions and effective stroke lengths, and studies the contacts and\nforces to achieve stable grasping and screwing. Besides the design, the paper\ndevelops manipulation policies for the tool. The policies include visual\nrecognition, picking-up and manipulation, and exchanging tooltips. The\ndeveloped tool produces clockwise rotation at the front end and\ncounter-clockwise rotation at the back end. Various tooltips can be installed\nat both two ends. Robots may employ the developed manipulation policies to\nexchange the tooltips and rotating directions following the needs of specific\nfastening or loosening tasks. Robots can also reorient the tool using\npick-and-place or handover, and move the tool to work poses using the policies.\nThe designed tool, together with the developed manipulation policies, are\nanalyzed and verified in several real-world applications. The tool is small,\ncordless, convenient, and has good robustness and adaptability.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  The use of photo-activated fluorescent molecules to create long sequences of\nlow emitter-density diffraction-limited images enables high-precision emitter\nlocalization, but at the cost of low temporal resolution. We suggest combining\nSPARCOM, a recent high-performing classical method, with model-based deep\nlearning, using the algorithm unfolding approach, to design a compact neural\nnetwork incorporating domain knowledge. Our results show that we can obtain\nsuper-resolution imaging from a small number of high emitter density frames\nwithout knowledge of the optical system and across different test sets using\nthe proposed learned SPARCOM (LSPARCOM) network. We believe LSPARCOM can pave\nthe way to interpretable, efficient live-cell imaging in many settings, and\nfind broad use in single-molecule localization microscopy of biological\nstructures.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  This paper proposes a new reactive temporal logic planning algorithm for\nmultiple robots that operate in environments with unknown geometry modeled\nusing occupancy grid maps. The robots are equipped with individual sensors that\nallow them to continuously learn a grid map of the unknown environment using\nexisting Simultaneous Localization and Mapping (SLAM) methods. The goal of the\nrobots is to accomplish complex collaborative tasks, captured by global Linear\nTemporal Logic (LTL) formulas. The majority of existing LTL planning approaches\nrely on discrete abstractions of the robot dynamics operating in known\nenvironments and, as a result, they cannot be applied to the more realistic\nscenarios where the environment is initially unknown. In this paper, we address\nthis novel challenge by proposing the first reactive, abstraction-free, and\ndistributed LTL planning algorithm that can be applied for complex mission\nplanning of multiple robots operating in unknown environments. The proposed\nalgorithm is reactive, i.e., planning is adapting to the updated environmental\nmap and abstraction-free as it does not rely on designing abstractions of the\nrobot dynamics. Also, our algorithm is distributed in the sense that the global\nLTL task is decomposed into single-agent reachability problems constructed\nonline based on the continuously learned map. The proposed algorithm is\ncomplete under mild assumptions on the structure of the environment and the\nsensor models. We provide extensive numerical simulations and hardware\nexperiments that illustrate the theoretical analysis and show that the proposed\nalgorithm can address complex planning tasks for large-scale multi-robot\nsystems in unknown environments.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Autofocus (AF) methods are extensively used in biomicroscopy, for example to\nacquire timelapses, where the imaged objects tend to drift out of focus. AD\nalgorithms determine an optimal distance by which to move the sample back into\nthe focal plane. Current hardware-based methods require modifying the\nmicroscope and image-based algorithms either rely on many images to converge to\nthe sharpest position or need training data and models specific to each\ninstrument and imaging configuration. Here we propose DeepFocus, an AF method\nwe implemented as a Micro-Manager plugin, and characterize its Convolutional\nneural network-based sharpness function, which we observed to be depth\nco-variant and sample-invariant. Sample invariance allows our AF algorithm to\nconverge to an optimal axial position within as few as three iterations using a\nmodel trained once for use with a wide range of optical microscopes and a\nsingle instrument-dependent calibration stack acquisition of a flat (but\narbitrary) textured object. From experiments carried out both on synthetic and\nexperimental data, we observed an average precision, given 3 measured images,\nof 0.30 +- 0.16 micrometers with a 10x, NA 0.3 objective. We foresee that this\nperformance and low image number will help limit photodamage during\nacquisitions with light-sensitive samples.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Gate-induced modulation of the spin-orbit interaction (SOI) in a 1.5 nm-thick\nPd thin film grown on a ferrimagnetic insulator was investigated. Efficient\ncharge accumulation by ionic gating enables a substantial upshift in the Fermi\nlevel of the Pd film, which was corroborated by suppression of the resistivity\nin the Pd. Electromotive forces arising from the inverse spin Hall effect in Pd\nunder spin pumping were substantially modulated by the gating, in consequence\nof the modulation of the spin Hall conductivity of Pd as in an ultrathin Pt\nfilm. The same experiment using a thin Cu film, for which the band structure is\nlargely different from Pd and Pt and its SOI is quite small, provides further\nresults supporting our claim. The results obtained help in developing a\nholistic understanding of the gate-tunable SOI in solids and confirm a previous\nexplanation of the significant modulation of the spin Hall conductivity in an\nultrathin Pt film by gating.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  The Ehrhart quasipolynomial of a rational polytope $P$ encodes the number of\ninteger lattice points in dilates of $P$, and the $h^*$-polynomial of $P$ is\nthe numerator of the accompanying generating function. We provide two\ndecomposition formulas for the $h^*$-polynomial of a rational polytope. The\nfirst decomposition generalizes a theorem of Betke and McMullen for lattice\npolytopes. We use our rational Betke--McMullen formula to provide a novel proof\nof Stanley's Monotonicity Theorem for the $h^*$-polynomial of a rational\npolytope. The second decomposition generalizes a result of Stapledon, which we\nuse to provide rational extensions of the Stanley and Hibi inequalities\nsatisfied by the coefficients of the $h^*$-polynomial for lattice polytopes.\nLastly, we apply our results to rational polytopes containing the origin whose\nduals are lattice polytopes.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  This work has two main purposes. On the one side we investigate in this work\na question of H. Esnault on congruence formula in a construction of H. Esnault\nand C. Xu for the number of rational points on the closed fiber of a singular\nmodel of the projective plane over a local field. From the viewpoint of\nasymptotic analysis, the question is quite familiar with a question of N.\nKoblitz, which in turn has some meaningful applications in cryptography. We\ndon't try to solve those questions in this work, but rather concentrate on\nstudying asymptotic behaviours with very elementary techniques of generating\nfunctions. On the other side we extend the discussion on generating functions\nto the global situation, which inherit hybrid-properties from the Riemann zeta\nfunction and the $L$-function of elliptic curves. At the end we will look at an\nexample of modular forms, where we are able to prove an analytic result, which\nis similar to a result of P\\'olya for the Riemann $\\xi$-function.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We show that correlations between the phases of the galaxy density field in\nredshift space provide additional information about the growth rate of\nlarge-scale structure that is complementary to the power spectrum multipoles.\nIn particular, we consider the multipoles of the line correlation function\n(LCF), which correlates phases between three collinear points, and use the\nFisher forecasting method to show that the LCF multipoles can break the\ndegeneracy between the measurement of the growth rate of structure $f$ and the\namplitude of perturbations $\\sigma_8$ that is present in the power spectrum\nmultipoles at large scales. This leads to an improvement in the measurement of\n$f$ and $\\sigma_8$ by up to 220 per cent for $k_{\\rm max} = 0.15 \\,\nh\\mathrm{Mpc}^{-1}$ and up to 50 per cent for $k_{\\rm max} = 0.30 \\,\nh\\mathrm{Mpc}^{-1}$ at redshift $z=0.25$, with respect to power spectrum\nmeasurements alone for the upcoming generation of galaxy surveys like DESI and\nEuclid. The average improvements in the constraints on $f$ and $\\sigma_8$ for\n$k_{\\rm max} = 0.15 \\, h\\mathrm{Mpc}^{-1}$ are $\\sim 90$ per cent for the DESI\nBGS sample with mean redshift $\\overline{z}=0.25$, $\\sim 40$ per cent for the\nDESI ELG sample with $\\overline{z}=1.25$, and $\\sim 40$ per cent for the Euclid\nH$\\alpha$ galaxies with $\\overline{z}=1.3$. For $k_{\\rm max} = 0.30 \\,\nh\\mathrm{Mpc}^{-1}$, the average improvements are $\\sim 40$ per cent for the\nDESI BGS sample and $\\sim 20$ per cent for both the DESI ELG and Euclid\nH$\\alpha$ galaxies.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  The contact process with diffusion (PCPD) defined by the binary reactions 2 B\n-> 3 B, 2 B -> 0 and diffusive particle spreading exhibits an unusual active to\nabsorbing phase transition whose universality class has long been disputed.\nMultiple studies have indicated that an explicit account of particle pair\ndegrees of freedom may be required to properly capture this system's effective\nlong-time, large-scale behavior. We introduce a two-species representation in\nwhich single particles B and pairs A are coupled according to the stochastic\nreactions B + B -> A, A -> A + B, A -> 0, and A -> B + B. Mean-field analysis\nreveals that the phase transition is driven by competition and balance between\nboth species. We employ Monte Carlo simulations to demonstrate that this model\ncaptures the pertinent PCPD features. In the inactive phase, A particles\nrapidly go extinct, leaving the B species to undergo pure pair annihilation\nkinetics. At criticality, both A and B densities decay with the same exponents\nas the PCPD order parameters, and display mean-field scaling above the critical\ndimension 2. In one dimension, the critical exponents for the B species\nobtained from seed simulations agree well with previously reported exponent\nvalues. We demonstrate that the scaling properties of consecutive particle\npairs in the PCPD are identical with that of the A species in the coupled\nmodel. This two-species picture resolves the conceptual difficulty for seed\nsimulations in the original PCPD and naturally introduces multiple length and\ntime scales, which cause strong corrections to scaling. The extracted moment\nratios from our simulations indicate that our model displays the same temporal\ncrossover behavior as the PCPD, which further corroborates its full dynamical\nequivalence with our coupled model.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  We theoretically investigate the piezo-optic effect of high-harmonic\ngeneration (HHG) in shear-strained semiconductors. By focusing on a typical\nsemiconductor, GaAs, we show that there is optical activity, meaning different\nresponses to right-handed and left-handed elliptically polarized electric\nfields. We also show that this optical activity is more pronounced for higher\nharmonics whose perturbative order exceeds the band-gap energy. These findings\npoint to a useful pathway for strain engineering of nonlinear optics to control\nthe reciprocity of HHG.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  We prove new results on upper and lower limits of real-valued functions by\nmeans of $\\psi$-densities introduced by P. D. Barry in 1962. This allows us to\nimprove several existing results on the growth of non-decreasing and unbounded\nreal-valued functions in sets of positive density. The $\\psi$-densities are\nalso used to introduce a new concept of a limit for real-valued functions. The\nresults in this paper are of interest in real analysis as well as in the theory\nof meromorphic functions.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We formulate a statistical wave-mechanical approach to describe dissipation\nand instabilities in two-dimensional turbulent flows of magnetized plasmas and\natmospheric fluids, such as drift and Rossby waves. This is made possible by\nthe existence of Hilbert space, associated with the electric potential of\nplasma or stream function of atmospheric fluid. We therefore regard such\nturbulent flows as macroscopic wave-mechanical phenomena, driven by the\nnon-Hermitian Hamiltonian operator we derive, whose anti-Hermitian component is\nattributed to an effect of the environment. Introducing a wave-mechanical\ndensity operator for the statistical ensembles of waves, we formulate master\nequations and define observables: such as the enstrophy and energy of both the\nwaves and zonal flow as statistical averages. We establish that our open system\ncan generally follow two types of time evolution, depending on whether the\nenvironment hinders or assists the system's stability and integrity. We also\nconsider a phase-space formulation of the theory, including the\ngeometrical-optic limit and beyond, and study the conservation laws of physical\nobservables. It is thus shown that the approach predicts various mechanisms of\nenergy and enstrophy exchange between drift waves and zonal flow, which were\nhitherto overlooked in models based on wave kinetic equations.\n\n\n###\n\n", "completion": " 06"}
{"prompt": "  Underwater wireless optical communication is one of the critical technologies\nfor buoy-based high-speed cross-sea surface communication, where the\ncommunication nodes are vertically deployed. Due to the vertically\ninhomogeneous nature of the underwater environment, seawater is usually\nvertically divided into multiple layers with different parameters that reflect\nthe real environment. In this work, we consider a generalized UWOC channel\nmodel that contains$N$ layers. To capture the effects of air bubbles and\ntemperature gradients on channel statistics, we model each layer by a mixture\nExponential-Generalized Gamma(EGG) distribution. We derive the PDF and CDF of\nthe end-to-end SNR in exact closed-form. Then, unified BER and outage\nexpressions using OOK and BPSK are also derived. The performance and behavior\nof common vertical underwater optical communication scenarios are thoroughly\nanalyzed through the appropriate selection of parameters. All the derived\nexpressions are verified via Monte Carlo simulations.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Let $m\\ge 1$ be an integer and $G$ be a graph with $m$ edges. We say that $G$\nhas an antimagic orientation if $G$ has an orientation $D$ and a bijection\n$\\tau:A(D)\\rightarrow \\{1,2,\\cdots,m\\}$ such that no two vertices in $D$ have\nthe same vertex-sum under $\\tau$, where the vertex-sum of a vertex $u$ in $D$\nunder $\\tau$ is the sum of labels of all arcs entering $u$ minus the sum of\nlabels of all arcs leaving $u$. Hefetz, M\\\"{u}tze and Schwartz [J. Graph\nTheory, 64: 219-232, 2010] conjectured that every connected graph admits an\nantimagic orientation. The conjecture was confirmed for certain classes of\ngraphs such as dense graphs, regular graphs, and trees including caterpillars\nand $k$-ary trees. In this note, we prove that every lobster admits an\nantimagic orientation.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  40 days after the start of the international monitoring of COVID-19, we\nsearch for the effect of official announcements regarding new cases of\ninfection and death ratio on the financial markets volatility index (VIX).\nWhereas the new cases reported in China and outside China have a mixed effect\non financial volatility, the death ratio positively influences VIX, that\noutside China triggering a more important impact. In addition, the higher the\nnumber of affected countries, the higher the financial volatility is.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  An experimental procedure for studying soliton gases in shallow water is\ndevised. Nonlinear waves propagate at constant depth in a 34\\,m-long wave\nflume. At one end of the flume, the waves are generated by a piston-type\nwave-maker. The opposite end is a vertical wall. Wave interactions are recorded\nwith a video system using seven side-looking cameras with a pixel resolution of\n1\\,mm, covering 14\\,m of the flume. The accuracy in the detection of the water\nsurface elevation is shown to be better than 0.1 mm. A continuous monochromatic\nforcing can lead to a random state such as a soliton gas. The measured wave\nfield is separated into right- and left-propagating waves in the Radon space\nand solitary pulses are identified as solitons of KdV or Rayleigh types. Both\nweak and strong interactions of solitons are detected. These interactions\ninduce phase shifts that constitute the seminal mechanism for disorganization\nand soliton gas formation.\n\n\n###\n\n", "completion": " 07"}
{"prompt": "  In this work, we present a quantum secret sharing scheme based on Bell state\nentanglement and sequential projection measurements. The protocol verifies the\n$n$ out of $n$ scheme and supports the aborting of the protocol in case all the\nparties do not divulge in their valid measurement outcomes. The operator-qubit\npair forms an integral part of the scheme determining the classical secret to\nbe shared. The protocol is robust enough to neutralize any eavesdropping on a\nparticular qubit of the dealer. The experimental demonstration of the scheme is\ndone on IBM-QE cloud platform with backends \\texttt{IBMQ\\_16\\_Melbourne} and\n\\texttt{IBMQ\\_QASM\\_SIMULATOR\\_V0.1.547} simulator. The security analysis\nperformed on the scheme and the comparative analysis supports our claim of a\nstringent and an efficient scheme as compared to some recent quantum and\nsemi-quantum techniques of secret sharing.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  The availability of shared software models provides opportunities for\nreusing, adapting and learning from them. Public models are typically stored in\na variety of locations, including model repositories, regular source code\nrepositories, web pages, etc. To profit from them developers need effective\nsearch mechanisms to locate the models relevant for their tasks. However, to\ndate, there has been little success in creating a generic and efficient search\nengine specially tailored to the modelling domain.\n  In this paper we present MAR, a search engine for models. MAR is generic in\nthe sense that it can index any type of model if its meta-model is known. MAR\nuses a query-by-example approach, that is, it uses example models as queries.\nThe search takes the model structure into account using the notion of bag of\npaths, which encodes the structure of a model using paths between model\nelements and is a representation amenable for indexing. MAR is built over HBase\nusing a specific design to deal with large repositories. Our benchmarks show\nthat the engine is efficient and has fast response times in most cases. We have\nalso evaluated the precision of the search engine by creating model mutants\nwhich simulate user queries. A REST API is available to perform queries and an\nEclipse plug-in allows end users to connect to the search engine from model\neditors. We have currently indexed more than 50.000 models of different kinds,\nincluding Ecore meta-models, BPMN diagrams and UML models. MAR is available at\nhttp://mar-search.org.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We study online learning in repeated first-price auctions with censored\nfeedback, where a bidder, only observing the winning bid at the end of each\nauction, learns to adaptively bid in order to maximize her cumulative payoff.\nTo achieve this goal, the bidder faces a challenging dilemma: if she wins the\nbid--the only way to achieve positive payoffs--then she is not able to observe\nthe highest bid of the other bidders, which we assume is iid drawn from an\nunknown distribution. This dilemma, despite being reminiscent of the\nexploration-exploitation trade-off in contextual bandits, cannot directly be\naddressed by the existing UCB or Thompson sampling algorithms.\n  In this paper, by exploiting the structural properties of first-price\nauctions, we develop the first learning algorithm that achieves\n$O(\\sqrt{T}\\log^{2.5} T)$ regret bound, which is minimax optimal up to $\\log$\nfactors, when the bidder's private values are stochastically generated. We do\nso by providing an algorithm on a general class of problems, called the\npartially ordered contextual bandits, which combine the graph feedback across\nactions, the cross learning across contexts, and a partial order over the\ncontexts. We establish both strengths and weaknesses of this framework, by\nshowing a curious separation that a regret nearly independent of the\naction/context sizes is possible under stochastic contexts, but is impossible\nunder adversarial contexts. Despite the limitation of this general framework,\nwe further exploit the structure of first-price auctions and develop a learning\nalgorithm that operates sample-efficiently (and computationally efficiently) in\nthe presence of adversarially generated private values. We establish an\n$O(\\sqrt{T}\\log^3 T)$ regret bound for this algorithm, hence providing a\ncomplete characterization of optimal learning guarantees for first-price\nauctions.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  In 2010, Olson \\& Robinson [Transactions of the American Mathematical\nSociety, 362(1), 145-168] introduced the notion of an almost homogeneous metric\nspace and showed that if $X$ is a subset of a Hilbert space such that $X-X$ is\nalmost homogeneous, then $X$ admits almost bi--Lipschitz embeddings into\nEuclidean spaces. In this paper, we extend this result and we show that if $X$\nis a subset of a Banach space such that $X-X$ is almost homogeneous at the\norigin, then $X$ can be embedded in a Euclidean space in an almost\nbi--Lipschitz way.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We propose a string theory construction which allows us to study properties\nof the potential of two heavy quarks coupled to a light quark. In such a case,\nthe potential is a function of separation between the heavy quarks. The results\nshow the universality of the string tension and factorization at small\nseparations expected from heavy quark-diquark symmetry. In addition, we make an\nestimate of the string breaking distance. With the parameter values we use,\nthis distance is found to be almost the same as that for the heavy\nquark-antiquark potential. We also discuss the heavy quark-quark potential and\nits relation to Lipkin rule.\n\n\n###\n\n", "completion": " 00"}
{"prompt": "  In a level-5 autonomous driving system, the autonomous driving vehicles (AVs)\nare expected to sense the surroundings via analyzing a large amount of data\ncaptured by a variety of onboard sensors in near-real-time. As a result,\nenormous computing costs will be introduced to the AVs for processing the tasks\nwith the deployed machine learning (ML) model, while the inference accuracy may\nnot be guaranteed. In this context, the advent of edge intelligence (EI) and\nsixth-generation (6G) wireless networking are expected to pave the way to more\nreliable and safer autonomous driving by providing multi-access edge computing\n(MEC) together with ML to AVs in close proximity. To realize this goal, we\npropose a two-tier EI-empowered autonomous driving framework. In the\nautonomous-vehicles tier, the autonomous vehicles are deployed with the shallow\nlayers by splitting the trained deep neural network model. In the\nedge-intelligence tier, an edge server is implemented with the remaining layers\n(also deep layers) and an appropriately trained multi-task learning (MTL)\nmodel. In particular, obtaining the optimal offloading strategy (including the\nbinary offloading decision and the computational resources allocation) can be\nformulated as a mixed-integer nonlinear programming (MINLP) problem, which is\nsolved via MTL in near-real-time with high accuracy. On another note, an\nedge-vehicle joint inference is proposed through neural network segmentation to\nachieve efficient online inference with data privacy-preserving and less\ncommunication delay. Experiments demonstrate the effectiveness of the proposed\nframework, and open research topics are finally listed.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  A new collaborative learning, called split learning, was recently introduced,\naiming to protect user data privacy without revealing raw input data to a\nserver. It collaboratively runs a deep neural network model where the model is\nsplit into two parts, one for the client and the other for the server.\nTherefore, the server has no direct access to raw data processed at the client.\nUntil now, the split learning is believed to be a promising approach to protect\nthe client's raw data; for example, the client's data was protected in\nhealthcare image applications using 2D convolutional neural network (CNN)\nmodels. However, it is still unclear whether the split learning can be applied\nto other deep learning models, in particular, 1D CNN.\n  In this paper, we examine whether split learning can be used to perform\nprivacy-preserving training for 1D CNN models. To answer this, we first design\nand implement an 1D CNN model under split learning and validate its efficacy in\ndetecting heart abnormalities using medical ECG data. We observed that the 1D\nCNN model under split learning can achieve the same accuracy of 98.9\\% like the\noriginal (non-split) model. However, our evaluation demonstrates that split\nlearning may fail to protect the raw data privacy on 1D CNN models. To address\nthe observed privacy leakage in split learning, we adopt two privacy leakage\nmitigation techniques: 1) adding more hidden layers to the client side and 2)\napplying differential privacy. Although those mitigation techniques are helpful\nin reducing privacy leakage, they have a significant impact on model accuracy.\nHence, based on those results, we conclude that split learning alone would not\nbe sufficient to maintain the confidentiality of raw sequential data in 1D CNN\nmodels.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  In this paper, we investigate the performance of a mixed\nradio-frequency-underwater wireless optical communication (RF-UWOC) system\nwhere an unmanned aerial vehicle (UAV), as a low-altitude mobile aerial base\nstation, transmits information to an autonomous underwater vehicle (AUV)\nthrough a fixed-gain amplify-and-forward (AF) or decode-and-forward (DF) relay.\nOur analysis accounts for the main factors that affect the system performance,\nsuch as the UAV height, air bubbles, temperature gradient, water salinity\nvariations, and detection techniques. Employing fixed-gain AF relaying and DF\nrelaying, we derive closed-form expressions for some key performance metrics,\ne.g., outage probability (OP), average bit error rate (ABER), and average\nchannel capacity (ACC). In addition, in order to get further insights,\nasymptotic analyses for the OP and ABER are also carried out. Furthermore,\nassuming DF relaying, we derive analytical expressions for the optimal UAV\naltitude that minimizes the OP. Simulation results show that the UAV altitude\ninfluences the system performance and there is an optimal altitude which\nensures a minimum OP. Moreover, based on the asymptotic results, it is\ndemonstrated that the diversity order of fixed-gain AF relaying and DF relaying\nare respectively determined by the RF link and by the detection techniques of\nthe UWOC link.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Given pointed $CW$-complexes $X$ and $Y$, $\\rmph(X, Y)$ denotes the set of\nhomotopy classes of phantom maps from $X$ to $Y$ and $\\rmsph(X, Y)$ denotes the\nsubset of $\\rmph(X, Y)$ consisting of homotopy classes of special phantom maps.\nIn a preceding paper, we gave a sufficient condition such that $\\rmph(X, Y)$\nand $\\rmsph(X, Y)$ have natural group structures and established a formula for\ncalculating the groups $\\rmph(X, Y)$ and $\\rmsph(X, Y)$ in many cases where the\ngroups $[X,\\Omega \\widehat{Y}]$ are nontrivial. In this paper, we establish a\ndual version of the formula, in which the target is the total space of a\nfibration, to calculate the groups $\\rmph(X, Y)$ and $\\rmsph(X, Y)$ for pairs\n$(X,Y)$ to which the formula or existing methods do not apply. In particular,\nwe calculate the groups $\\rmph(X,Y)$ and $\\rmsph(X,Y)$ for pairs $(X,Y)$ such\nthat $X$ is the classifying space $BG$ of a compact Lie group $G$ and $Y$ is a\nhighly connected cover $Y' \\langle n \\rangle$ of a nilpotent finite complex\n$Y'$ or the quotient $\\gbb / H$ of $\\gbb = U, O$ by a compact Lie group $H$.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  The effects of resonant magnetic perturbations on the turbulent transport of\nfast ions in tokamak devices are investigated using a theoretical transport\nmodel of test-particle type. The direct numerical simulation method is used to\ncompute, via the transport model, the diffusion coefficients. The numerical\nresults are in good agreement with other, analytically derived, estimations. It\nis found that finite Larmor radius effects decrease algebraically the\ntransport, while the amplitude of magnetic perturbations has an opposite\neffect. In the presence of stochastic dynamics, the asymmetric toroidal\nmagnetic field induces a small, radial, outward pinch. A synergistic mechanism\nof non-linear coupling between turbulence and magnetic perturbations enhances\nthe radial diffusion. General scaling laws are proposed for the transport\ncoefficients.\n\n\n###\n\n", "completion": " 05"}
{"prompt": "  A search for direct pair production of scalar partners of the top quark (top\nsquarks or scalar third-generation up-type leptoquarks) in the all-hadronic\n$t\\bar{t}$ plus missing transverse momentum final state is presented. The\nanalysis of 139 fb$^{-1}$ of ${\\sqrt{s}=13}$ TeV proton-proton collision data\ncollected using the ATLAS detector at the LHC yields no significant excess over\nthe Standard Model background expectation. To interpret the results, a\nsupersymmetric model is used where the top squark decays via $\\tilde{t} \\to\nt^{(*)} \\tilde{\\chi}^0_1$, with $t^{(*)}$ denoting an on-shell (off-shell) top\nquark and $\\tilde{\\chi}^0_1$ the lightest neutralino. Three specific event\nselections are optimised for the following scenarios. In the scenario where\n$m_{\\tilde{t}}> m_t+m_{\\tilde{\\chi}^0_1}$, top squark masses are excluded in\nthe range 400-1250 GeV for $\\tilde{\\chi}^0_1$ masses below $200$ GeV at 95 %\nconfidence level. In the situation where $m_{\\tilde{t}}\\sim\nm_t+m_{\\tilde{\\chi}^0_1}$, top squark masses in the range 300-630 GeV are\nexcluded, while in the case where $m_{\\tilde{t}}< m_W+m_b+m_{\\tilde{\\chi}^0_1}$\n(with $m_{\\tilde{t}}-m_{\\tilde{\\chi}^0_1}\\ge 5$ GeV), considered for the first\ntime in an ATLAS all-hadronic search, top squark masses in the range 300-660\nGeV are excluded. Limits are also set for scalar third-generation up-type\nleptoquarks, excluding leptoquarks with masses below $1240$ GeV when\nconsidering only leptoquark decays into a top quark and a neutrino.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Systems using 5G are expected to be used in various cases of Society 5.0 and\nIndustrie 4.0 such as smart cities, smart factories, and also critical\ninfrastructures. These systems are essential for our life, thus cyberattacks\nagainst the system must be prevented. In this paper, we tackle two problems\nposed by 5G features: system construction using multi-vendor devices and\nsoftwarized functions. Specifically, there are supply-chain risks that\nmalicious devices are used in the construction phase. Moreover, the softwarized\nnetwork functions are easy to be attacked compared to hardware. To cope with\nthese problems, we propose a concept of architecture comprising a blockchain to\nrecord security events including supply-chain information and a tamper\ndetection engine to ensure the integrity of software components in 5G system.\nWe implement the initial prototype of the architecture and show its\nfeasibility.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Identifying similar protein sequences is a core step in many computational\nbiology pipelines such as detection of homologous protein sequences, generation\nof similarity protein graphs for downstream analysis, functional annotation and\ngene location. Performance and scalability of protein similarity searches have\nproven to be a bottleneck in many bioinformatics pipelines due to increases in\ncheap and abundant sequencing data. This work presents a new distributed-memory\nsoftware, PASTIS. PASTIS relies on sparse matrix computations for efficient\nidentification of possibly similar proteins. We use distributed sparse matrices\nfor scalability and show that the sparse matrix infrastructure is a great fit\nfor protein similarity searches when coupled with a fully-distributed\ndictionary of sequences that allows remote sequence requests to be fulfilled.\nOur algorithm incorporates the unique bias in amino acid sequence substitution\nin searches without altering the basic sparse matrix model, and in turn,\nachieves ideal scaling up to millions of protein sequences.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  With the widespread adoption of the quantified self movement, an increasing\nnumber of users rely on mobile applications to monitor their physical activity\nthrough their smartphones. Granting to applications a direct access to sensor\ndata expose users to privacy risks. Indeed, usually these motion sensor data\nare transmitted to analytics applications hosted on the cloud leveraging\nmachine learning models to provide feedback on their health to users. However,\nnothing prevents the service provider to infer private and sensitive\ninformation about a user such as health or demographic attributes.In this\npaper, we present DySan, a privacy-preserving framework to sanitize motion\nsensor data against unwanted sensitive inferences (i.e., improving privacy)\nwhile limiting the loss of accuracy on the physical activity monitoring (i.e.,\nmaintaining data utility). To ensure a good trade-off between utility and\nprivacy, DySan leverages on the framework of Generative Adversarial Network\n(GAN) to sanitize the sensor data. More precisely, by learning in a competitive\nmanner several networks, DySan is able to build models that sanitize motion\ndata against inferences on a specified sensitive attribute (e.g., gender) while\nmaintaining a high accuracy on activity recognition. In addition, DySan\ndynamically selects the sanitizing model which maximize the privacy according\nto the incoming data. Experiments conducted on real datasets demonstrate that\nDySan can drasticallylimit the gender inference to 47% while only reducing the\naccuracy of activity recognition by 3%.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  While low-luminosity galaxies dominate number counts at all redshifts, their\ncontribution to cosmic Reionization is poorly understood due to a lack of\nknowledge of their physical properties. We isolate a sample of 35 z~4-5\ncontinuum-faint Lyman-alpha emitters from deep VLT/MUSE spectroscopy and\ndirectly measure their Halpha emission using stacked Spitzer/IRAC Ch. 1\nphotometry. Based on Hubble Space Telescope imaging, we determine that the\naverage UV continuum magnitude is fainter than -16 (~0.01 L_star), implying a\nmedian Lyman-alpha equivalent width of 249 Angstroms. By combining the Halpha\nmeasurement with the UV magnitude we determine the ionizing photon production\nefficiency, xi_ion, a first for such faint galaxies. The measurement of log\n(xi_ion [Hz/erg]) = 26.28 (+0.28; -0.40) is in excess of literature\nmeasurements of both continuum- and emission line-selected samples, implying a\nmore efficient production of ionizing photons in these lower-luminosity,\nLyman-alpha-selected systems. We conclude that this elevated efficiency can be\nexplained by stellar populations with metallicities between 4e-4 and 0.008,\nwith light-weighted ages less than 3 Myr.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  We perform a complete study of the low-energy phenomenology of $S_1$ and\n$S_3$ lepto-quarks, aimed at addressing the observed deviations in $B$-meson\ndecays and the muon magnetic dipole moment. Leptoquark contributions to\nobservables are computed at one-loop accuracy in an effective field theory\napproach, using the recently published complete one-loop matching of these\nleptoquarks to the Standard Model effective field theory. We present several\nscenarios, discussing in each case the preferred parameter space and the most\nrelevant observables.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Field-induced excitation gaps in quantum spin chains are an interesting\nphenomenon related to confinements of topological excitations. In this paper, I\npresent a novel type of this phenomenon. I show that an effective magnetic\nfield with a fourfold screw symmetry induces the excitation gap accompanied by\ndimer orders. The gap and dimer orders induced so exhibit characteristic\npower-law dependence on the fourfold screw-symmetric field. Moreover, the\nfield-induced dimer order and the field-induced N\\'eel order coexist when the\nexternal uniform magnetic field, the fourfold screw-symmetric field, and the\ntwofold staggered field are applied. This situation is in close connection with\na compound [Cu(pym)(H$_2$O)$_4$]SiF$_6$ [J. Liu et al., Phys. Rev. Lett. 122,\n057207 (2019)]. In this paper, I discuss a mechanism of field-induced dimer\norders by using a density-matrix renormalization group method, a perturbation\ntheory, and quantum field theories.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Global Positioning System (GPS) and inertial measurement unit (IMU) sensors\nare commonly integrated using the extended Kalman filter (EKF), for achieving\nbetter navigation performance. However, because of nonlinearity, the\nperformance of the EKF is affected by the initial state estimation errors, and\nthe navigation solutions, including the attitude, diverge rapidly as the\ninitial errors increase. This paper analyzes the data obtained from an outdoor\nexperiment, and investigates the effect of the initial errors on the attitude\nestimation performance using EKF, which is used in loosely coupled low-cost\nsmartphone GPS/IMU sensors.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Byte-pair encoding (BPE) is a ubiquitous algorithm in the subword\ntokenization process of language models as it provides multiple benefits.\nHowever, this process is solely based on pre-training data statistics, making\nit hard for the tokenizer to handle infrequent spellings. On the other hand,\nthough robust to misspellings, pure character-level models often lead to\nunreasonably long sequences and make it harder for the model to learn\nmeaningful words. To alleviate these challenges, we propose a character-based\nsubword module (char2subword) that learns the subword embedding table in\npre-trained models like BERT. Our char2subword module builds representations\nfrom characters out of the subword vocabulary, and it can be used as a drop-in\nreplacement of the subword embedding table. The module is robust to\ncharacter-level alterations such as misspellings, word inflection, casing, and\npunctuation. We integrate it further with BERT through pre-training while\nkeeping BERT transformer parameters fixed--and thus, providing a practical\nmethod. Finally, we show that incorporating our module to mBERT significantly\nimproves the performance on the social media linguistic code-switching\nevaluation (LinCE) benchmark.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Recently, the search for an axion insulator state in the ferromagnet-3D\ntopological insulator (TI) heterostructure and $\\mathrm{MnBi_2Te_4}$ has\nattracted intensive interest. However, its detection remains difficult in\nexperiments. We systematically investigate the disorder-induced phase\ntransition of the axion insulator state in a 3D TI with antiparallel\nmagnetization alignment surfaces. It is found that there exists a 2D\ndisorder-induced phase transition which shares the same universality class with\nthe quantum Hall plateau to plateau transition. Then, we provide a\nphenomenological theory which maps the random mass Dirac Hamiltonian of the\naxion insulator state into the Chalker-Coddington network model. Therefore, we\npropose to probe the axion insulator state by investigating the universal\nsignature of such a phase transition in the ferromagnet-3D TI heterostructure\nand $\\mathrm{MnBi_2Te_4}$. Our findings not only show a global phase diagram of\nthe axion insulator state, but also provide a new experimental routine to probe\nit.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Gas and vapour explosions have been involved in industrial accidents since\nthe beginnings of industry. A century ago, at 11:55 am on Friday 24th September\n1920, the petroleum barge Warwick exploded in London's docklands and seven men\nwere killed. Understanding what happened when it blew up as it was being\nrefurbished, and how to prevent similar explosions, involves fluid mechanics\nand thermodynamics plus chemistry. I recount the 1920 accident as an example,\ntogether with the history of thermo-kinetic explosions prior to 1920 and up to\nthe present day, and I review the history and the actual state of the science\nof explosion and the roles of fluid mechanics, thermodynamics, and chemistry in\nthat science. The science of explosions has been aware of its societal\nimplications from the beginning, but, despite advances in health and safety\nover the past century, is there still work to do?\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We prove through Monte Carlo analysis that the covariant euclidean scalar\nfield theory, $\\varphi^r_n$, where $r$ denotes the power of the interaction\nterm and $n = s + 1$ where $s$ is the spatial dimension and $1$ adds imaginary\ntime, such that $r = 12, n = 3$ can be acceptably quantized using scaled affine\nquantization and the resulting theory is nontrivial, unlike what happens using\ncanonical quantization when the system is plagued by asymptotic freedom.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  Antibodies recognizing complexes of the chemokine platelet factor 4\n(PF4-CXCL4) and polyanions (P) opsonize PF4-coated bacteria hereby mediating\nbacterial host defense. A subset of these antibodies may activate platelets\nafter binding to PF4-heparin complexes, causing the prothrombotic adverse drug\nreaction heparin-induced thrombocytopenia (HIT). In autoimmune-HIT,\nanti-PF4-P-antibodies activate platelets in the absence of heparin. Here we\nshow that antibodies with binding forces of approximately 60-100 pN activate\nplatelets in the presence of polyanions, while a subset of antibodies from\nautoimmune-HIT patients with binding forces greater than 100 pN binds to PF4\nalone in the absence of polyanions. These antibodies with high binding forces\ncluster PF4-molecules forming antigenic complexes which allow binding of\npolyanion-dependent anti-PF4-P-antibodies. The resulting immunocomplexes induce\nmassive platelet activation in the absence of heparin. Antibody-mediated\nchanges in endogenous proteins that trigger binding of otherwise non-pathogenic\n(or cofactor-dependent) antibodies may also be relevant in other\nantibody-mediated autoimmune disorders.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We present TDNet, a temporally distributed network designed for fast and\naccurate video semantic segmentation. We observe that features extracted from a\ncertain high-level layer of a deep CNN can be approximated by composing\nfeatures extracted from several shallower sub-networks. Leveraging the inherent\ntemporal continuity in videos, we distribute these sub-networks over sequential\nframes. Therefore, at each time step, we only need to perform a lightweight\ncomputation to extract a sub-features group from a single sub-network. The full\nfeatures used for segmentation are then recomposed by application of a novel\nattention propagation module that compensates for geometry deformation between\nframes. A grouped knowledge distillation loss is also introduced to further\nimprove the representation power at both full and sub-feature levels.\nExperiments on Cityscapes, CamVid, and NYUD-v2 demonstrate that our method\nachieves state-of-the-art accuracy with significantly faster speed and lower\nlatency.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  It is commonly believed that networks cannot be both accurate and robust,\nthat gaining robustness means losing accuracy. It is also generally believed\nthat, unless making networks larger, network architectural elements would\notherwise matter little in improving adversarial robustness. Here we present\nevidence to challenge these common beliefs by a careful study about adversarial\ntraining. Our key observation is that the widely-used ReLU activation function\nsignificantly weakens adversarial training due to its non-smooth nature. Hence\nwe propose smooth adversarial training (SAT), in which we replace ReLU with its\nsmooth approximations to strengthen adversarial training. The purpose of smooth\nactivation functions in SAT is to allow it to find harder adversarial examples\nand compute better gradient updates during adversarial training.\n  Compared to standard adversarial training, SAT improves adversarial\nrobustness for \"free\", i.e., no drop in accuracy and no increase in\ncomputational cost. For example, without introducing additional computations,\nSAT significantly enhances ResNet-50's robustness from 33.0% to 42.3%, while\nalso improving accuracy by 0.9% on ImageNet. SAT also works well with larger\nnetworks: it helps EfficientNet-L1 to achieve 82.2% accuracy and 58.6%\nrobustness on ImageNet, outperforming the previous state-of-the-art defense by\n9.5% for accuracy and 11.6% for robustness. Models are available at\nhttps://github.com/cihangxie/SmoothAdversarialTraining.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  This paper presents a proposal of a faster Wasserstein $k$-means algorithm\nfor histogram data by reducing Wasserstein distance computations and exploiting\nsparse simplex projection. We shrink data samples, centroids, and the ground\ncost matrix, which leads to considerable reduction of the computations used to\nsolve optimal transport problems without loss of clustering quality.\nFurthermore, we dynamically reduced the computational complexity by removing\nlower-valued data samples and harnessing sparse simplex projection while\nkeeping the degradation of clustering quality lower. We designate this proposed\nalgorithm as sparse simplex projection based Wasserstein $k$-means, or SSPW\n$k$-means. Numerical evaluations conducted with comparison to results obtained\nusing Wasserstein $k$-means algorithm demonstrate the effectiveness of the\nproposed SSPW $k$-means for real-world datasets\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  In this paper, we provide a guideline for using the Neural Network\nDependability Kit (NNDK) during the development process of NN models, and show\nhow the algorithm is applied in two image classification use cases. The case\nstudies demonstrate the usage of the dependability kit to obtain insights about\nthe NN model and how they informed the development process of the neural\nnetwork model. After interpreting neural networks via the different metrics\navailable in the NNDK, the developers were able to increase the NNs' accuracy,\ntrust the developed networks, and make them more robust. In addition, we\nobtained a novel application-oriented technique to provide supporting evidence\nfor an NN's classification result to the user. In the medical image\nclassification use case, it was used to retrieve case images from the training\ndataset that were similar to the current patient's image and could therefore\nact as a support for the NN model's decision and aid doctors in interpreting\nthe results.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Charge transport processes at interfaces which are governed by complex\ninterfacial electronic structure play a crucial role in catalytic reactions,\nenergy storage, photovoltaics, and many biological processes. Here, the first\nsoft X-ray second harmonic generation (SXR-SHG) interfacial spectrum of a\nburied interface (boron/Parylene-N) is reported. SXR-SHG shows distinct\nspectral features that are not observed in X-ray absorption spectra,\ndemonstrating its extraordinary interfacial sensitivity. Comparison to\nelectronic structure calculations indicates a boron-organic separation distance\nof 1.9 {\\AA}, wherein changes as small as 0.1 {\\AA} result in easily detectable\nSXR-SHG spectral shifts (ca. 100s of meV). As SXR-SHG is inherently ultrafast\nand sensitive to individual atomic layers, it creates the possibility to study\na variety of interfacial processes, e.g. catalysis, with ultrafast time\nresolution and bond specificity.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We investigate partial functions and computability theory from within a\nconstructive, univalent type theory. The focus is on placing computability into\na larger mathematical context, rather than on a complete development of\ncomputability theory. We begin with a treatment of partial functions, using the\nnotion of dominance, which is used in synthetic domain theory to discuss\nclasses of partial maps. We relate this and other ideas from synthetic domain\ntheory to other approaches to partiality in type theory. We show that the\nnotion of dominance is difficult to apply in our setting: the set of\n$\\Sigma_0^1$ propositions investigated by Rosolini form a dominance precisely\nif a weak, but nevertheless unprovable, choice principle holds. To get around\nthis problem, we suggest an alternative notion of partial function we call\ndisciplined maps. In the presence of countable choice, this notion coincides\nwith Rosolini's.\n  Using a general notion of partial function, we take the first steps in\nconstructive computability theory. We do this both with computability as\nstructure, where we have direct access to programs; and with computability as\nproperty, where we must work in a program-invariant way. We demonstrate the\ndifference between these two approaches by showing how these approaches relate\nto facts about computability theory arising from topos-theoretic and\ntype-theoretic concerns. Finally, we tie the two threads together: assuming\ncountable choice and that all total functions $\\mathbb{N}\\to\\mathbb{N}$ are\ncomputable (both of which hold in the effective topos), the Rosolini partial\nfunctions, the disciplined maps, and the computable partial functions all\ncoincide. We observe, however, that the class of all partial functions includes\nnon-computable partial functions.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  One of the most challenging problems in solid state systems is the\nmicroscopic analysis of electronic correlations. A paramount minimal model that\nencodes correlation effects is the Hubbard Hamiltonian, which -- albeit its\nsimplicity -- is exactly solvable only in a few limiting cases and approximate\nmany-body methods are required for its solution. In this review we present an\noverview on the non-perturbative Two-Particle Self-Consistent method (TPSC)\nwhich was originally introduced to describe the electronic properties of the\nsingle-band Hubbard model. We introduce here a detailed derivation of the\nmulti-orbital generalization of TPSC and discuss particular features of the\nmethod on exemplary interacting models in comparison to dynamical mean-field\ntheory results.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Animals exhibit an innate ability to learn regularities of the world through\ninteraction. By performing experiments in their environment, they are able to\ndiscern the causal factors of variation and infer how they affect the world's\ndynamics. Inspired by this, we attempt to equip reinforcement learning agents\nwith the ability to perform experiments that facilitate a categorization of the\nrolled-out trajectories, and to subsequently infer the causal factors of the\nenvironment in a hierarchical manner. We introduce {\\em causal curiosity}, a\nnovel intrinsic reward, and show that it allows our agents to learn optimal\nsequences of actions and discover causal factors in the dynamics of the\nenvironment. The learned behavior allows the agents to infer a binary quantized\nrepresentation for the ground-truth causal factors in every environment.\nAdditionally, we find that these experimental behaviors are semantically\nmeaningful (e.g., our agents learn to lift blocks to categorize them by\nweight), and are learnt in a self-supervised manner with approximately 2.5\ntimes less data than conventional supervised planners. We show that these\nbehaviors can be re-purposed and fine-tuned (e.g., from lifting to pushing or\nother downstream tasks). Finally, we show that the knowledge of causal factor\nrepresentations aids zero-shot learning for more complex tasks. Visit\nhttps://sites.google.com/usc.edu/causal-curiosity/home for website.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We prove convergence of multiple interfaces in the critical planar q = 2\nrandom cluster model, and provide an explicit description of the scaling limit.\nRemarkably, the expression for the partition function of the resulting multiple\nSLE(16/3) coincides with the bulk spin correlation in the critical Ising model\nin the half-plane, after formally replacing a position of each spin and its\ncomplex conjugate with a pair of points on the real line. As a corollary, we\nrecover Belavin-Polyakov-Zamolodchikov equations for the spin correlations.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  An important experimental design problem in early-stage drug discovery is how\nto prioritize available compounds for testing when very little is known about\nthe target protein. Informer based ranking (IBR) methods address the\nprioritization problem when the compounds have provided bioactivity data on\nother potentially relevant targets. An IBR method selects an informer set of\ncompounds, and then prioritizes the remaining compounds on the basis of new\nbioactivity experiments performed with the informer set on the target. We\nformalize the problem as a two-stage decision problem and introduce the Bayes\nOptimal Informer SEt (BOISE) method for its solution. BOISE leverages a\nflexible model of the initial bioactivity data, a relevant loss function, and\neffective computational schemes to resolve the two-step design problem. We\nevaluate BOISE and compare it to other IBR strategies in two retrospective\nstudies, one on protein-kinase inhibition and the other on anti-cancer drug\nsensitivity. In both empirical settings BOISE exhibits better predictive\nperformance than available methods. It also behaves well with missing data,\nwhere methods that use matrix completion show worse predictive performance. We\nprovide an R implementation of BOISE at\nhttps://github.com/wiscstatman/esdd/BOISE\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  In crowd counting, each training image contains multiple people, where each\nperson is annotated by a dot. Existing crowd counting methods need to use a\nGaussian to smooth each annotated dot or to estimate the likelihood of every\npixel given the annotated point. In this paper, we show that imposing Gaussians\nto annotations hurts generalization performance. Instead, we propose to use\nDistribution Matching for crowd COUNTing (DM-Count). In DM-Count, we use\nOptimal Transport (OT) to measure the similarity between the normalized\npredicted density map and the normalized ground truth density map. To stabilize\nOT computation, we include a Total Variation loss in our model. We show that\nthe generalization error bound of DM-Count is tighter than that of the Gaussian\nsmoothed methods. In terms of Mean Absolute Error, DM-Count outperforms the\nprevious state-of-the-art methods by a large margin on two large-scale counting\ndatasets, UCF-QNRF and NWPU, and achieves the state-of-the-art results on the\nShanghaiTech and UCF-CC50 datasets. DM-Count reduced the error of the\nstate-of-the-art published result by approximately 16%. Code is available at\nhttps://github.com/cvlab-stonybrook/DM-Count.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  The use of multiple drugs accounts for almost 30% of all hospital admission\nand is the 5th leading cause of death in America. Since over 30% of all adverse\ndrug events (ADEs) are thought to be caused by drug-drug interactions (DDI),\nbetter identification and prediction of administration of known DDIs in primary\nand secondary care could reduce the number of patients seeking urgent care in\nhospitals, resulting in substantial savings for health systems worldwide along\nwith better public health. However, current DDI prediction models are prone to\nconfounding biases along with either inaccurate or a lack of access to\nlongitudinal data from Electronic Health Records (EHR) and other drug\ninformation such as FDA Adverse Event Reporting System (FAERS) which continue\nto be the main barriers in measuring the prevalence of DDI and characterizing\nthe phenomenon in medical care. In this review, analytical models including\nLabel Propagation using drug side effect data and Supervised Learning DDI\nPrediction model using Drug-Gene interactions (DGIs) data are discussed.\nImproved identification of DDIs in both of these models compared to previous\nversions are highlighted while limitations that include bias, inaccuracy, and\ninsufficient data are also assessed. A case study of Psoriasis DDI prediction\nby DGI data using Random Forest Classifier was studied. Transfer Matrix\nRecurrent Neural Networks (TM-RNN) that address the above limitations are\ndiscussed in future works.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  In this paper, we investigate the existence of an elementary abelian closure\nin characteristic not $2$ for biquadratic extensions. We discover that it\nexists for any non-cyclic extension. We make use of it to obtain a\nclassification for this class of extensions up to isomorphism via descent. This\npermits us to describe the geometry of this moduli space in group theoretic\nterms. We also provide two families of polynomials with two parameters that can\ndescribe any quartic extensions.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Acoustic shadow moir\\'e has unique properties to be used for many potential\napplications in medical diagnostics, manufacturing, and material\ncharacterization. In this paper, numerical analysis, using Comsol, is used to\ninvestigate the principles of acoustic moir\\'e interference phenomenon. The\nstudy confirmed that the expected fringe images of shadow interference can be\ncreated at Talbot distances. The study confirms the experimental results\nreported by this group [1] and proves without any doubt that acoustic moir\\'e\ninterference phenomenon exists.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  The locally modified finite element method, which is introduced in [Frei,\nRichter: SINUM 52(2014), p. 2315-2334] is a simple fitted finite element method\nthat is able to resolve weak discontinuities in interface problems. The method\nis based on a fixed structured coarse mesh, which is then refined into\nsub-elements to resolve an interior interface. In this work, we extend the\nlocally modified finite element method to second order using an isoparametric\napproach in the interface elements. Thereby we need to take care that the\nresulting curved edges do not lead to degenerate sub-elements. We prove optimal\na priori error estimates in the $L^2$-norm and in a modified energy norm, as\nwell as a reduced convergence order of ${\\cal O}(h^{3/2})$ in the standard\n$H^1$-norm. Finally, we present numerical examples to substantiate the\ntheoretical findings.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We analyze the convergence properties of operator product expansions (OPE)\nfor Lorentzian CFT four-point functions of scalar operators. We give a complete\nclassification of Lorentzian four-point configurations. All configurations in\neach class have the same OPE convergence properties in s-, t- and u-channels.\nWe give tables including the information of OPE convergence for all classes.\nOur work justifies that in a subset of the configuration space, Lorentzian CFT\nfour-point functions are genuine analytic functions. Our results are valid for\nunitary CFTs in $d\\geq2$. Our work also provides some Lorentzian regions where\none can do bootstrap analysis in the sense of functions.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  The nonlinear convection terms in the governing equations of compressible\nfluid flows are hyperbolic in nature and are nontrivial for modelling and\nnumerical simulation. Many numerical methods have been developed in the last\nfew decades for this purpose and are typically based on Riemann solvers, which\nare strongly dependent on the underlying eigen-structure of the governing\nequations. Objective of the present work is to develop simple algorithms which\nare not dependent on the eigen-structure and yet can tackle easily the\nhyperbolic parts. Central schemes with smart diffusion mechanisms are apt for\nthis purpose. For fixing the numerical diffusion, the basic ideas of satisfying\nthe Rankine-Hugoniot (RH) conditions along with generalized Riemann invariants\nare proposed. Two such interesting algorithms are presented, which capture\ngrid-aligned steady contact discontinuities exactly and yet have sufficient\nnumerical diffusion to avoid numerical shock instabilities. Both the algorithms\npresented are robust in avoiding shock instabilities, apart from being accurate\nin capturing contact discontinuities, do not need wave speed corrections and\nare independent of eigen-strutures of the underlying hyperbolic parts of the\nsystems.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Behavior Trees (BTs) got the robotics society attention not least thanks to\ntheir modularity and reusability. The subtrees of BTs could be treated as\nseparate behaviors and therefore reused. We address the following research\nquestion: do we exploit the full power of BT on these properties? We suggest to\ngeneralise the idea of subtree reuse to \"node templates\" concept, which allows\nto represent an arbitrary nodes collection. In addition, previously hardcoded\nbehaviors such as Node* and many Decorator nodes could be implemented in a\nmemory-based BT by node templates.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Multi-messenger astronomy has experienced an explosive development in the\npast few years. While not being a particularly young field, it has recently\nattracted a lot of attention by several major discoveries and unprecedented\nobservation campaigns covering the entity of the electromagnetic spectrum as\nwell as observations of cosmic rays, neutrinos, and gravitational waves. The\nexploration of synergies is in full steam and requires close cooperation\nbetween different instruments. Here I give an overview over the subject of\nmulti-messenger astronomy and its virtues compared to classical \"single\nmessenger\" observations, present the recent break throughs of the field, and\ndiscuss some of its organisational and technical challenges.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Several works in the past decade have used the ratio between total (rest\n8-1000$\\mu$m) infrared and radio (rest 1.4~GHz) luminosity in star-forming\ngalaxies (q$_{IR}$), often referred to as the \"infrared-radio correlation\"\n(IRRC), to calibrate radio emission as a star formation rate (SFR) indicator.\nPrevious studies constrained the evolution of q$_{IR}$ with redshift, finding a\nmild but significant decline, that is yet to be understood. For the first time,\nwe calibrate q$_{IR}$ as a function of \\textit{both} stellar mass (M$_{\\star}$)\nand redshift, starting from an M$_{\\star}$-selected sample of $>$400,000\nstar-forming galaxies in the COSMOS field, identified via (NUV-r)/(r-J)\ncolours, at redshifts 0.1$<$z$<$4.5. Within each (M$_{\\star}$,z) bin, we stack\nthe deepest available infrared/sub-mm and radio images. We fit the stacked IR\nspectral energy distributions with typical star-forming galaxy and IR-AGN\ntemplates, and carefully remove radio AGN candidates via a recursive approach.\nWe find that the IRRC evolves primarily with M$_{\\star}$, with more massive\ngalaxies displaying systematically lower q$_{IR}$. A secondary, weaker\ndependence on redshift is also observed. The best-fit analytical expression is\nthe following:\nq$_{IR}$(M$_{\\star}$,z)=(2.646$\\pm$0.024)$\\times$(1+z)$^{(-0.023\\pm0.008)}$-(0.148$\\pm$0.013)$\\times$($\\log~M_{\\star}$/M$_{\\odot}$-10).\nThe lower IR/radio ratios seen in more massive galaxies are well described by\ntheir higher observed SFR surface densities. Our findings highlight that using\nradio-synchrotron emission as a proxy for SFR requires novel\nM$_{\\star}$-dependent recipes, that will enable us to convert detections from\nfuture ultra deep radio surveys into accurate SFR measurements down to low-SFR,\nlow-M$_{\\star}$ galaxies.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Amenable category is a variant of the Lusternik-Schnirelman category, based\non covers by amenable open subsets. We study the monotonicity problem for\ndegree-one maps and amenable category and the relation between amenable\ncategory and topological complexity.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  The recently observed diversity of Type Ia supernovae (SNe Ia) has motivated\nus to conduct the theoretical modeling of SNe Ia for a wide parameter range. In\nparticular, the origin of Type Iax supernovae (SNe Iax) has been obscure.\nFollowing our earlier work on the parameter dependence of SN Ia models, we\nfocus on SNe Iax in the present study. For a model of SNe Iax, we adopt the\ncurrently leading model of pure turbulent deflagration (PTD) of\nnear-Chandrasekhar mass C+O white dwarfs (WDs). We carry out 2-dimensional\nhydrodynamical simulations of the propagation of deflagration wave, which\nleaves a small WD remnant behind and eject nucleosynthesis materials. We show\nhow the explosion properties, such as nucleosynthesis and explosion energy,\ndepend on the model parameters such as central densities and compositions of\nthe WDs (including the hybrid WDs), and turbulent flame prescription and\ninitial flame geometry. We extract the associated observables in our models,\nand compare with the recently discovered low-mass WDs with unusual surface\nabundance patterns and the abundance patterns of some SN remnants. We provide\nthe nucleosynthesis yield tables for applications to stellar archaeology and\ngalactic chemical evolution. Our results are compared with the representative\nmodels in the literature.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  The anisotropy in resonant tunneling transport through an electrostatic\nbarrier in mono layer black phosphorus either in presence or in absence of an\noscillating potential is studied. Non-perturbative Floquet theory is applied to\nsolve the time dependent problem and the results obtained are discussed\nthoroughly. The resonance spectra in field free transmission are Lorentzian in\nnature although the width of the resonance for the barrier along the zigzag\ndirection is too thinner than that for the armchair one. Resonant transmission\nis suppressed for both the cases by the application of oscillating potential\nthat produces small oscillations in the transmission around the resonant energy\nparticularly at low frequency range. Sharp asymmetric Fano resonances are noted\nin the transmission spectrum along the armchair direction while a distinct line\nshape resonance is noted for the zigzag direction at higher frequency of the\noscillating potential. Even after the angular average, the conductance along\nthe armchair direction retains the characteristic Fano features that could be\nobserved experimentally. The present results are supposed to suggest that the\nphosphorene electrostatic barrier could be used successfully as switching\ndevices and nano detectors.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Every philosophy has holes, and it is the responsibility of proponents of a\nphilosophy to point out these problems. Here are a few holes in Bayesian data\nanalysis: (1) the usual rules of conditional probability fail in the quantum\nrealm, (2) flat or weak priors lead to terrible inferences about things we care\nabout, (3) subjective priors are incoherent, (4) Bayesian decision picks the\nwrong model, (5) Bayes factors fail in the presence of flat or weak priors, (6)\nfor Cantorian reasons we need to check our models, but this destroys the\ncoherence of Bayesian inference. Some of the problems of Bayesian statistics\narise from people trying to do things they shouldn't be trying to do, but other\nholes are not so easily patched. In particular, it may be a good idea to avoid\nflat, weak, or conventional priors, but such advice, if followed, would go\nagainst the vast majority of Bayesian practice and requires us to confront the\nfundamental incoherence of Bayesian inference. This does not mean that we think\nBayesian inference is a bad idea, but it does mean that there is a tension\nbetween Bayesian logic and Bayesian workflow which we believe can only be\nresolved by considering Bayesian logic as a tool, a way of revealing inevitable\nmisfits and incoherences in our model assumptions, rather than as an end in\nitself.\n\n\n###\n\n", "completion": " 05"}
{"prompt": "  The manipulation of neutral atoms by light is at the heart of countless\nscientific discoveries in the field of quantum physics in the last three\ndecades. The level of control that has been achieved at the single particle\nlevel within arrays of optical traps, while preserving the fundamental\nproperties of quantum matter (coherence, entanglement, superposition), makes\nthese technologies prime candidates to implement disruptive computation\nparadigms. In this paper, we review the main characteristics of these devices\nfrom atoms / qubits to application interfaces, and propose a classification of\na wide variety of tasks that can already be addressed in a computationally\nefficient manner in the Noisy Intermediate Scale Quantum era we are in. We\nillustrate how applications ranging from optimization challenges to simulation\nof quantum systems can be explored either at the digital level (programming\ngate-based circuits) or at the analog level (programming Hamiltonian\nsequences). We give evidence of the intrinsic scalability of neutral atom\nquantum processors in the 100-1,000 qubits range and introduce prospects for\nuniversal fault tolerant quantum computing and applications beyond quantum\ncomputing.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  The Internet has been weaponized to carry out cybercriminal activities at an\nunprecedented pace. The rising concerns for preserving the privacy of personal\ndata while availing modern tools and technologies is alarming. End-to-end\nencrypted solutions are in demand for almost all commercial platforms. On one\nside, it seems imperative to provide such solutions and give people trust to\nreliably use these platforms. On the other side, this creates a huge\nopportunity to carry out unchecked cybercrimes. This paper proposes a robust\nvideo hashing technique, scalable and efficient in chalking out matches from an\nenormous bulk of videos floating on these commercial platforms. The video hash\nis validated to be robust to common manipulations like scaling, corruptions by\nnoise, compression, and contrast changes that are most probable to happen\nduring transmission. It can also be transformed into the encrypted domain and\nwork on top of encrypted videos without deciphering. Thus, it can serve as a\npotential forensic tool that can trace the illegal sharing of videos without\nknowing the underlying content. Hence, it can help preserve privacy and combat\ncybercrimes such as revenge porn, hateful content, child abuse, or illegal\nmaterial propagated in a video.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Data of long-lived and high profile projects is valuable for research on\nsuccessful software engineering in the wild. Having a dataset with different\nlinked software repositories of such projects, enables deeper diving\ninvestigations. This paper presents 20-MAD, a dataset linking the commit and\nissue data of Mozilla and Apache projects. It includes over 20 years of\ninformation about 765 projects, 3.4M commits, 2.3M issues, and 17.3M issue\ncomments, and its compressed size is over 6 GB. The data contains all the\ntypical information about source code commits (e.g., lines added and removed,\nmessage and commit time) and issues (status, severity, votes, and summary). The\nissue comments have been pre-processed for natural language processing and\nsentiment analysis. This includes emoticons and valence and arousal scores.\nLinking code repository and issue tracker information, allows studying\nindividuals in two types of repositories and provide more accurate time zone\ninformation for issue trackers as well. To our knowledge, this the largest\nlinked dataset in size and in project lifetime that is not based on GitHub.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  The kernel relation $K$ on the lattice $\\mathcal{L}(\\mathcal{CR})$ of\nvarieties of completely regular semigroups has been a central component in many\ninvestigations into the structure of $\\mathcal{L}(\\mathcal{CR})$. However,\napart from the $K$-class of the trivial variety, which is just the lattice of\nvarieties of bands, the detailed structure of kernel classes has remained a\nmystery until recently. Kad'ourek [RK2] has shown that for two large classes of\nsubvarieties of $\\mathcal{CR}$ their kernel classes are singletons. Elsewhere\n(see [RK1], [RK2], [RK3]) we have provided a detailed analysis of the kernel\nclasses of varieties of abelian groups. Here we study more general kernel\nclasses. We begin with a careful development of the concept of duality in the\nlattice of varieties of completely regular semigroups and then show that the\nkernel classes of many varieties, including many self-dual varieties, of\ncompletely regular semigroups contain multiple copies of the lattice of\nvarieties of bands as sublattices.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  It has been shown that the $\\alpha-z$ R{\\'e}nyi relative entropy satisfies\nthe Data Processing Inequality (DPI) for a certain range of $\\alpha$'s and\n$z$'s. Moreover, the range is completely characterized by Zhang in `20. We\nprove necessary and algebraically sufficient conditions to saturate the DPI for\nthe $\\alpha-z$ R{\\'e}nyi relative entropy whenever $1<\\alpha\\leq 2$ and\n$\\frac{\\alpha}{2}\\leq z\\leq\\alpha$. Moreover, these conditions coincide\nwhenever $\\alpha=z$.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Terrestrial communication networks mainly focus on users in urban areas but\nhave poor coverage performance in harsh environments, such as mountains,\ndeserts, and oceans. Satellites can be exploited to extend the coverage of\nterrestrial fifth-generation (5G) networks. However, satellites are restricted\nby their high latency and relatively low data rate. Consequently, the\nintegration of terrestrial and satellite components has been widely studied, to\ntake advantage of both sides and enable seamless broadband coverage. Due to the\nsignificant differences between satellite communications (SatComs) and\nterrestrial communications (TerComs) in terms of channel fading, transmission\ndelay, mobility, and coverage performance, the establishment of an efficient\nhybrid satellite-terrestrial network (HSTN) still faces many challenges. In\ngeneral, it is difficult to decompose a HSTN into a sum of separate satellite\nand terrestrial links due to the complicated coupling relationships therein. To\nuncover the complete picture of HSTNs, we regard the HSTN as a combination of\nbasic cooperative models that contain the main traits of satellite-terrestrial\nintegration but are much simpler and thus more tractable than the large-scale\nheterogeneous HSTNs. In particular, we present three basic cooperative models,\ni.e., model X, model L, and model V, and provide a survey of the\nstate-of-the-art technologies for each of them. We discuss future research\ndirections towards establishing a cell-free, hierarchical, decoupled HSTN. We\nalso outline open issues to envision an agile, smart, and secure HSTN for the\nsixth-generation (6G) ubiquitous Internet of Things (IoT).\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  State estimation aims at approximately reconstructing the solution $u$ to a\nparametrized partial differential equation from $m$ linear measurements, when\nthe parameter vector $y$ is unknown. Fast numerical recovery methods have been\nproposed based on reduced models which are linear spaces of moderate dimension\n$n$ which are tailored to approximate the solution manifold $\\mathcal{M}$ where\nthe solution sits. These methods can be viewed as deterministic counterparts to\nBayesian estimation approaches, and are proved to be optimal when the prior is\nexpressed by approximability of the solution with respect to the reduced model.\nHowever, they are inherently limited by their linear nature, which bounds from\nbelow their best possible performance by the Kolmogorov width\n$d_m(\\mathcal{M})$ of the solution manifold. In this paper we propose to break\nthis barrier by using simple nonlinear reduced models that consist of a finite\nunion of linear spaces $V_k$, each having dimension at most $m$ and leading to\ndifferent estimators $u_k^*$. A model selection mechanism based on minimizing\nthe PDE residual over the parameter space is used to select from this\ncollection the final estimator $u^*$. Our analysis shows that $u^*$ meets\noptimal recovery benchmarks that are inherent to the solution manifold and not\ntied to its Kolmogorov width. The residual minimization procedure is\ncomputationally simple in the relevant case of affine parameter dependence in\nthe PDE. In addition, it results in an estimator $y^*$ for the unknown\nparameter vector. In this setting, we also discuss an alternating minimization\n(coordinate descent) algorithm for joint state and parameter estimation, that\npotentially improves the quality of both estimators.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Recent theoretical studies have suggested that the suddenly recoiled atom\nstruck by dark matter (DM) particle is much more likely to excite or lose its\nelectrons than expected. Such Migdal effect provides a new avenue for exploring\nthe sub-GeV DM particles. There have been various attempts to describe the\nMigdal effect in liquids and semiconductor targets. In this paper we\nincorporate the treatment of the bremsstrahlung process and the electronic\nmany-body effects to give a full description of the Migdal effect in bulk\nsemiconductor targets diamond and silicon. Compared with the results obtained\nwith the atom-centered localized Wannier functions (WFs) under the framework of\nthe tight-binding (TB) approximation, the method proposed in this study yields\nmuch larger event rates in the low energy regime, due to a $\\omega^{-4}$\nscaling. We also find that the effect of the bremsstrahlung photon mediating\nthe Coulomb interaction between recoiled ion and the electron-hole pair is\nequivalent to that of the exchange of a single phonon.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Quantum thermodynamics has emerged as a separate sub-discipline, revising the\nconcepts and laws of thermodynamics, at the quantum scale. In particular, there\nhas been a disruptive shift in the way thermometry, and thermometers are\nperceived and designed. Currently, we face two major challenges in quantum\nthermometry. First, all of the existing optimally precise temperature probes\nare local, meaning their operation is optimal only for a narrow range of\ntemperatures. Second, aforesaid optimal local probes mandate complex energy\nspectrum with immense degeneracy, rendering them impractical. Here, we address\nthese challenges by formalizing the notion of global thermometry leading to the\ndevelopment of optimal temperature sensors over a wide range of temperatures.\nWe observe the emergence of different phases for such optimal probes as the\ntemperature interval is increased. In addition, we show how the best\napproximation of optimal global probes can be realized in spin chains,\nimplementable in ion traps and quantum dots.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  In a binary black hole merger, it is known that the inspiral portion of the\nwaveform corresponds to two distinct horizons orbiting each other, and the\nmerger and ringdown signals correspond to the final horizon being formed and\nsettling down to equilibrium. However, we still lack a detailed understanding\nof the relation between the horizon geometry in these three regimes and the\nobserved waveform. Here we show that the well known inspiral chirp waveform has\na clear counterpart on black hole horizons, namely, the shear of the outgoing\nnull rays at the horizon. We demonstrate that the shear behaves very much like\na compact binary coalescence waveform with increasing frequency and amplitude.\nFurthermore, the parameters of the system estimated from the horizon agree with\nthose estimated from the waveform. This implies that even though black hole\nhorizons are causally disconnected from us, assuming general relativity to be\ntrue, we can potentially infer some of their detailed properties from\ngravitational wave observations.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  One very common type of fake news is satire which comes in a form of a news\nwebsite or an online platform that parodies reputable real news agencies to\ncreate a sarcastic version of reality. This type of fake news is often\ndisseminated by individuals on their online platforms as it has a much stronger\neffect in delivering criticism than through a straightforward message. However,\nwhen the satirical text is disseminated via social media without mention of its\nsource, it can be mistaken for real news. This study conducts several\nexploratory analyses to identify the linguistic properties of Arabic fake news\nwith satirical content. We exploit these features to build a number of machine\nlearning models capable of identifying satirical fake news with an accuracy of\nup to 98.6%.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Satisfying the high computation demand of modern deep learning architectures\nis challenging for achieving low inference latency. The current approaches in\ndecreasing latency only increase parallelism within a layer. This is because\narchitectures typically capture a single-chain dependency pattern that prevents\nefficient distribution with a higher concurrency (i.e., simultaneous execution\nof one inference among devices). Such single-chain dependencies are so\nwidespread that even implicitly biases recent neural architecture search (NAS)\nstudies. In this visionary paper, we draw attention to an entirely new space of\nNAS that relaxes the single-chain dependency to provide higher concurrency and\ndistribution opportunities. To quantitatively compare these architectures, we\npropose a score that encapsulates crucial metrics such as communication,\nconcurrency, and load balancing. Additionally, we propose a new generator and\ntransformation block that consistently deliver superior architectures compared\nto current state-of-the-art methods. Finally, our preliminary results show that\nthese new architectures reduce the inference latency and deserve more\nattention.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  The magnetotelluric (MT) responses of the Earth are biased by spatially\nheterogeneous source fields. Recently, such biases have been reported even in\nmid-latitude areas, where localized source currents rarely flow. This study\nfocuses on shifts in the MT responses arising from variations in the focus\nlatitude of the solar quiet (Sq) current. The MT responses at 60 s were\ncalculated by changing the center of the Sq current. Slight variations in the\nfocus latitude cause large shifts in the apparent resistivity and phase. During\nperiods of quiet geomagnetic activity, the center varies within a wide range of\n20-45 N, whereas this range narrows when there are disruptions. Even though\nthis study considers only a limited case, the results demonstrate the\ninstability of the impedances in periods of quiet geomagnetic activity and a\ncorrelation of the MT responses with the magnitude of the geomagnetic activity.\nAs a consequence, even when a station is located at mid-latitudes, the\nimpedances need to be treated carefully for time-lapse MT soundings, for\nexample, by checking the ionospheric current conditions and their dependence on\nthe geomagnetic activity.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We fabricate large-area atomically thin MoS$_2$ layers through the direct\ntransformation of crystalline molybdenum MoS$_2$ (MoO$_3$) by sulfurization at\nrelatively low temperatures. The obtained MoS2 sheets are polycrystalline\n(~10-20 nm single-crystal domain size) with areas of up to 300x300 um$^2$ with\n2-4 layers in thickness and show a marked p-type behaviour. The synthesized\nfilms are characterized by a combination of complementary techniques: Raman\nspectroscopy, X-ray diffraction, transmission electron microscopy and\nelectronic transport measurements.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Treating the cosmological constant as a dynamical variable, we investigate\nthe thermodynamics and weak cosmic censorship conjecture (WCCC) of a charged\nAdS black hole (BH) in the Rastall gravity. We determine the energy momentum\nrelation of charged fermion at the horizon of the BH by using the Dirac\nequation. Based on this relation, we show that the first law of thermodynamics\n(FLT) still holds as a fermion is absorbed by the BH. However, the entropy of\nboth the extremal and near-extremal BH decreases in the irreversible process,\nwhich means that the second law of thermodynamics (SLT) is violated.\nFurthermore, we verify the validity of the WCCC by the minimum values of the\nmetric function h(r) at its final state. For the extremal charged AdS BH in the\nRastall gravity, we find that the WCCC is valid always since the BH is extreme.\nWhile for the case of near-extremal BH, we find the WCCC could be violable in\nthe extended phase space (EPS), depending on the value of the parameters of the\nBH and their variations.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Recently, a growing interest has been seen in deep learning-based semantic\nsegmentation. UNet, which is one of deep learning networks with an\nencoder-decoder architecture, is widely used in medical image segmentation.\nCombining multi-scale features is one of important factors for accurate\nsegmentation. UNet++ was developed as a modified Unet by designing an\narchitecture with nested and dense skip connections. However, it does not\nexplore sufficient information from full scales and there is still a large room\nfor improvement. In this paper, we propose a novel UNet 3+, which takes\nadvantage of full-scale skip connections and deep supervisions. The full-scale\nskip connections incorporate low-level details with high-level semantics from\nfeature maps in different scales; while the deep supervision learns\nhierarchical representations from the full-scale aggregated feature maps. The\nproposed method is especially benefiting for organs that appear at varying\nscales. In addition to accuracy improvements, the proposed UNet 3+ can reduce\nthe network parameters to improve the computation efficiency. We further\npropose a hybrid loss function and devise a classification-guided module to\nenhance the organ boundary and reduce the over-segmentation in a non-organ\nimage, yielding more accurate segmentation results. The effectiveness of the\nproposed method is demonstrated on two datasets. The code is available at:\ngithub.com/ZJUGiveLab/UNet-Version\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  In this paper we introduce a new type of exponential map in semi-simple\ncompact Lie groups, which is related to the sub-Riemannian geometry generated\nby the orthogonal complement of a Cartan subalgebra in a similar way to how the\ngroup exponential map is related to the Riemannian geometry.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  A human-swarm cooperative system, which mixes multiple robots and a human\nsupervisor to form a heterogeneous team, is widely used for emergent scenarios\nsuch as criminal tracking in social security and victim assistance in a natural\ndisaster. These emergent scenarios require a cooperative team to quickly\nterminate the current task and transit the system to a new task, bringing\ndifficulty in motion planning. Moreover, due to the immediate task transitions,\nuncertainty from both physical systems and prior tasks is accumulated to\ndecrease swarm performance, causing robot failures and influencing the\ncooperation effectiveness between the human and the robot swarm. Therefore,\ngiven the quick-transition requirements and the introduced uncertainty, it is\nchallenging for a human-swarm system to respond to emergent tasks, compared\nwith executing normal tasks where a gradual transition between tasks is\nallowed. Human trust reveals the behavior expectations of others and is used to\nadjust unsatisfactory behaviors for better cooperation. Inspired by human\ntrust, in this paper, a trust-aware reflective control (Trust-R) is developed\nto dynamically calibrate human-swarm cooperation. Trust-R, based on a weighted\nmean subsequence reduced algorithm (WMSR) and human trust modeling, helps a\nswarm to self-reflect its performance from the perspective of human trust; then\nproactively correct its faulty behaviors in an early stage before a human\nintervenes. One typical task scenario {emergency response} was designed in the\nreal-gravity simulation environment, and a human user study with 145 volunteers\nwas conducted. Trust-R's effectiveness in correcting faulty behaviors in\nemergency response was validated by the improved swarm performance and\nincreased trust scores.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Model-based reinforcement learning (RL) has emerged as a promising tool for\ndeveloping controllers for real world systems (e.g., robotics, autonomous\ndriving, etc.). However, real systems often have constraints imposed on their\nstate space which must be satisfied to ensure the safety of the system and its\nenvironment. Developing a verification tool for RL algorithms is challenging\nbecause the non-linear structure of neural networks impedes analytical\nverification of such models or controllers. To this end, we present a novel\nsafety verification framework for model-based RL controllers using reachable\nset analysis. The proposed frame-work can efficiently handle models and\ncontrollers which are represented using neural networks. Additionally, if a\ncontroller fails to satisfy the safety constraints in general, the proposed\nframework can also be used to identify the subset of initial states from which\nthe controller can be safely executed.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  In this paper we study the smooth convex-concave saddle point problem.\nSpecifically, we analyze the last iterate convergence properties of the\nExtragradient (EG) algorithm. It is well known that the ergodic (averaged)\niterates of EG converge at a rate of $O(1/T)$ (Nemirovski, 2004). In this\npaper, we show that the last iterate of EG converges at a rate of\n$O(1/\\sqrt{T})$. To the best of our knowledge, this is the first paper to\nprovide a convergence rate guarantee for the last iterate of EG for the smooth\nconvex-concave saddle point problem. Moreover, we show that this rate is tight\nby proving a lower bound of $\\Omega(1/\\sqrt{T})$ for the last iterate. This\nlower bound therefore shows a quadratic separation of the convergence rates of\nergodic and last iterates in smooth convex-concave saddle point problems.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Universal quantum computation requires the implementation of a logical\nnon-Clifford gate. In this paper, we characterize all stabilizer codes whose\ncode subspaces are preserved under physical $T$ and $T^{-1}$ gates. For\nexample, this could enable magic state distillation with non-CSS codes and,\nthus, provide better parameters than CSS-based protocols. However, among\nnon-degenerate stabilizer codes that support transversal $T$, we prove that CSS\ncodes are optimal. We also show that triorthogonal codes are, essentially, the\nonly family of CSS codes that realize logical transversal $T$ via physical\ntransversal $T$. Using our algebraic approach, we reveal new purely-classical\ncoding problems that are intimately related to the realization of logical\noperations via transversal $T$. Decreasing monomial codes are also used to\nconstruct a code that realizes logical CCZ. Finally, we use Ax's theorem to\ncharacterize the logical operation realized on a family of quantum Reed-Muller\ncodes. This result is generalized to finer angle $Z$-rotations in\narXiv:1910.09333.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  The miniaturization of infrared gas sensors is largely hindered by expensive\nand bulky laser sources as well as the use of optical filters. In this work, we\npropose a dual-band, directional thermal emitter based on compact W-Si-Cu\nmetasurfaces to address this issue. This metasurface emitter is designed to\nsupport two nondispersive magnetic polariton modes that exhibit distinct\ndirectional thermal emission profiles, thus enabling dual-band detection\nwithout the need of optical filters. Specifically, we evaluate the feasibility\nof such dual-band filterless detection by adapting the metasurface emitter to\nCO2 sensing. The model of sensing system shows a selective relative sensitivity\nof CO2 which is 3.2 times higher than that using a blackbody emitter, and a\nrelative sensitivity of temperature of emitter about 1.32%/K.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We present a novel technique for solving the problem of safe control for a\ngeneral class of nonlinear, control-affine systems subject to parametric model\nuncertainty. Invoking Lyapunov analysis and the notion of fixed-time stability\n(FxTS), we introduce a parameter adaptation law which guarantees convergence of\nthe estimates of unknown parameters in the system dynamics to their true values\nwithin a fixed-time independent of the initial parameter estimation error. We\nthen synthesize the adaptation law with a robust, adaptive control barrier\nfunction (RaCBF) based quadratic program to compute safe control inputs despite\nthe considered model uncertainty. To corroborate our results, we undertake a\ncomparative case study on the efficacy of this result versus other recent\napproaches in the literature to safe control under uncertainty, and close by\nhighlighting the value of our method in the context of an automobile overtake\nscenario.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Robotic manipulation of deformable 1D objects such as ropes, cables, and\nhoses is challenging due to the lack of high-fidelity analytic models and large\nconfiguration spaces. Furthermore, learning end-to-end manipulation policies\ndirectly from images and physical interaction requires significant time on a\nrobot and can fail to generalize across tasks. We address these challenges\nusing interpretable deep visual representations for rope, extending recent work\non dense object descriptors for robot manipulation. This facilitates the design\nof interpretable and transferable geometric policies built on top of the\nlearned representations, decoupling visual reasoning and control. We present an\napproach that learns point-pair correspondences between initial and goal rope\nconfigurations, which implicitly encodes geometric structure, entirely in\nsimulation from synthetic depth images. We demonstrate that the learned\nrepresentation -- dense depth object descriptors (DDODs) -- can be used to\nmanipulate a real rope into a variety of different arrangements either by\nlearning from demonstrations or using interpretable geometric policies. In 50\ntrials of a knot-tying task with the ABB YuMi Robot, the system achieves a 66%\nknot-tying success rate from previously unseen configurations. See\nhttps://tinyurl.com/rope-learning for supplementary material and videos.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  GPU accelerators have become an important backbone for scientific high\nperformance computing, and the performance advances obtained from adopting new\nGPU hardware are significant. In this paper we take a first look at NVIDIA's\nnewest server line GPU, the A100 architecture part of the Ampere generation.\nSpecifically, we assess its performance for sparse linear algebra operations\nthat form the backbone of many scientific applications and assess the\nperformance improvements over its predecessor.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  We provide the proof of a previously announced result that resolves the\nfollowing problem posed by A.~A.~Kirillov. Let $T$ be a presentation of a group\n$\\mathcal{G}$ by bounded linear operators in a Banach space $G$ and $E\\subset\nG$ be a closed invariant subspace. Then $T$ generates in the natural way\npresentations $T_1$ in $E$ and $T_2$ in $F:=G/E$. What additional information\nis required besides $T_1, T_2$ to recover the presentation $T$? In\nfinite-dimensional (and even in infinite dimensional Hilbert) case the solution\nis well known: one needs to supply a group cohomology class $h\\in\nH^1(\\mathcal{G},Hom(F,E))$. The same holds in the Banach case, if the subspace\n$E$ is complemented in $G$. However, every Banach space that is not isomorphic\nto a Hilbert one has non-complemented subspaces, which aggravates the problem\nsignificantly and makes it non-trivial even in the case of a trivial group\naction, where it boils down to what is known as the three-space problem. This\nexplains the title we have chosen. A solution of the problem stated above has\nbeen announced by the author in 1976, but the complete proof, for\nnon-mathematical reasons, has not been made available. This article contains\nthe proof, as well as some related considerations of the functor $Ext^1$ in the\ncategory \\textbf{Ban} of Banach spaces.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  With entanglement-assisted (EA) formalism, arbitrary classical linear codes\nare allowed to transform into EAQECCs by using pre-shared entanglement between\nthe sender and the receiver. In this paper, based on classical cyclic MDS codes\nby exploiting pre-shared maximally entangled states, we construct two families\nof $q$-ary entanglement-assisted quantum MDS codes\n$[[\\frac{q^{2}+1}{a},\\frac{q^{2}+1}{a}-2(d-1)+c,d;c]]$, where q is a prime\npower in the form of $am+l$, and $a=(l^2+1)$ or $a=\\frac{(l^2+1)}{5}$. We show\nthat all of $q$-ary EAQMDS have minimum distance upper limit much larger than\nthe known quantum MDS (QMDS) codes of the same length. Most of these $q$-ary\nEAQMDS codes are new in the sense that their parameters are not covered by the\ncodes available in the literature.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  The self-learning Metropolis-Hastings algorithm is a powerful Monte Carlo\nmethod that, with the help of machine learning, adaptively generates an\neasy-to-sample probability distribution for approximating a given\nhard-to-sample distribution. This paper provides a new self-learning Monte\nCarlo method that utilizes a quantum computer to output a proposal\ndistribution. In particular, we show a novel subclass of this general scheme\nbased on the quantum Fourier transform circuit; this sampler is classically\nsimulable while having a certain advantage over conventional methods. The\nperformance of this \"quantum inspired\" algorithm is demonstrated by some\nnumerical simulations.\n\n\n###\n\n", "completion": " 18"}
