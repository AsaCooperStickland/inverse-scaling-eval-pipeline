{"prompt": "  Dots are ideal systems to study fundamentals on heat transfer at the\nnanoscale and promising nanoscale heat-engines and thermal devices. Here, we\nreport on the validation of our theoretical model on the thermal conductance of\na metallic dot single-electron transistor (md-SET) by a recent experiment on\nthe low-T thermal conductance. We compare with the experiment, we emphasize the\nphysics interpretation and characteristic values and we apply the model to\nevaluate the operation the md-SET as heat-switch. Perfect agreement is shown\nbetween the calculated and the measured charge conductance G, heat conductance\n\\k{appa} and the ratio \\k{appa}/GT. The experimental findings confirm the\ntheoretical predictions on the periodicity of the Coulomb oscillations in the\nclassical regime, the low-T extreme values and the high-T limits of G and\n\\k{appa}. The calculated conductances of the md-SET are presented in universal\ncurves from low-T to high-T. It is shown that the md-SET can efficiently\noperate as a heat switch at temperatures , Ec being the charging energy of the\ndot.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The phenomenon of subpulse drifting offers unique insights into the emission\ngeometry of pulsars, and is commonly interpreted in terms of a rotating\ncarousel of \"spark\" events near the stellar surface. We develop a detailed\ngeometric model for the emission columns above a carousel of sparks that is\nentirely calculated in the observer's inertial frame, and which is consistent\nwith the well-understood rotational effects of aberration and retardation. We\nexplore the observational consequences of the model, including (1) the\nappearance of the reconstructed beam pattern via the cartographic transform and\n(2) the morphology of drift bands and how they might evolve as a function of\nfrequency. The model, which is implemented in the software package PSRGEOM, is\napplicable to a wide range of viewing geometries, and we illustrate its\nimplications using PSRs B0809+74 and B2034+19 as examples. Some specific\npredictions are made with respect to the difference between subpulse evolution\nand microstructure evolution, which provides a way to further test our model.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show that a small cover of dimension $3$ is atorodal if and only if there\nis no $4$-belt in the corresponding simple polytope.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We develop a family of techniques to align word embeddings which are derived\nfrom different source datasets or created using different mechanisms (e.g.,\nGloVe or word2vec). Our methods are simple and have a closed form to optimally\nrotate, translate, and scale to minimize root mean squared errors or maximize\nthe average cosine similarity between two embeddings of the same vocabulary\ninto the same dimensional space. Our methods extend approaches known as\nAbsolute Orientation, which are popular for aligning objects in\nthree-dimensions, and generalize an approach by Smith etal (ICLR 2017). We\nprove new results for optimal scaling and for maximizing cosine similarity.\nThen we demonstrate how to evaluate the similarity of embeddings from different\nsources or mechanisms, and that certain properties like synonyms and analogies\nare preserved across the embeddings and can be enhanced by simply aligning and\naveraging ensembles of embeddings.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A package for the Sage computer algebra system is developed for checking\nfeasibility of a given intersection array for a distance-regular graph. We use\nthis tool to show that there is no distance-regular graph with intersection\narray $\\{(2r+1)(4r+1)(4t-1), 8r(4rt-r+2t), (r+t)(4r+1); 1, (r+t)(4r+1),\n4r(2r+1)(4t-1)\\}$ ($r, t \\ge 1$), $\\{135, 128, 16; 1, 16, 120\\}$, $\\{234, 165,\n12; 1, 30, 198\\}$ or $\\{55, 54, 50, 35, 10; 1, 5, 20, 45, 55\\}$. In all cases,\nthe proofs rely on equality in the Krein condition, from which triple\nintersection numbers are determined. Further combinatorial arguments are then\nused to derive nonexistence.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The magneto-Rayleigh-Taylor (MRT) instability has been investigated in great\ndetail in previous work using magnetohydrodynamic and kinetic models for\nlow-beta plasmas. The work presented here extends previous studies of this\ninstability to regimes where finite-Larmor-Radius (FLR) effects may be\nimportant. Comparisons of the MRT instability are made using a 5-moment and a\n10-moment two-fluid model, the two fluids being ions and electrons. The\n5-moment model includes Hall stabilization whereas the 10-moment model includes\nHall and FLR stabilization. Results are presented for these two models using\ndifferent electron mass to understand the role of electron inertia in the\nlate-time nonlinear evolution of the MRT instability. For the 5-moment model,\nthe late-time nonlinear MRT evolution does not significantly depend on the\nelectron inertia. However, when FLR stabilization is important, the 10-moment\nresults show that a lower ion-to-electron mass ratio (i.e. larger electron\ninertia) under-predicts the energy in high-wavenumber modes due to larger FLR\nstabilization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The experimentally observed swelling and collapse response of weakly charged\npolymers to the addition of specific salts displays quite convoluted behavior\nthat is not easy to categorize. Here we use a minimalistic implicit solvent /\nexplicit salt simulation model with a focus on ion-specific interactions\nbetween ions and a single weakly charged polyelectrolyte to qualitatively\nexplain the observed effects. In particular, we demonstrate ion-specific\nscreening and bridging effects cause collapse at low salt concentrations\nwhereas the same strong ion-specific direct interactions drive re-entrant\nswelling at high concentrations. Consistently with experiments, a distinct salt\nconcentration at which the salting-out power of anions inverts from the reverse\nto direct Hofmeister series is observed. At this, so called 'isospheric point',\nthe ion-specific effects vanish. Furthermore, with additional simplifying\nassumptions, an ion-specific mean-field model is developed for the collapse\ntransition which quantitatively agrees with the simulations. Our work\ndemonstrates the sensitivity of the structural behavior of charged polymers to\nthe addition of specific salt and shall be useful for further guidance of\nexperiments.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the problem of writing Gaussian primes as the sum of two squares,\nboth of which are interesting arithmetically, in particular, when one is the\nsquare of a prime and the other the square of an almost-prime.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We discuss the Standard Model Effective Field Theory (SM-EFT) contributions\nto neutral- and charge-current Drell-Yan production, associated production of\nthe Higgs and a vector boson, and Higgs boson production via vector boson\nfusion. We consider all the dimension-six SM-EFT operators that contribute to\nthese processes at leading order, include next-to-leading order QCD\ncorrections, and interface them with parton showering and hadronization in\nPythia8 according to the POWHEG method. We discuss existing constraints on the\ncoefficients of dimension-six operators and identify differential and angular\ndistributions that can differentiate between different effective operators,\npointing to specific features of Beyond-the-Standard-Model physics.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  As of today, abuse is a pressing issue to participants and administrators of\nOnline Social Networks (OSN). Abuse in Twitter can spawn from arguments\ngenerated for influencing outcomes of a political election, the use of bots to\nautomatically spread misinformation, and generally speaking, activities that\ndeny, disrupt, degrade or deceive other participants and, or the network. Given\nthe difficulty in finding and accessing a large enough sample of abuse ground\ntruth from the Twitter platform, we built and deployed a custom crawler that we\nuse to judiciously collect a new dataset from the Twitter platform with the aim\nof characterizing the nature of abusive users, a.k.a abusive birds, in the\nwild. We provide a comprehensive set of features based on users' attributes, as\nwell as social-graph metadata. The former includes metadata about the account\nitself, while the latter is computed from the social graph among the sender and\nthe receiver of each message. Attribute-based features are useful to\ncharacterize user's accounts in OSN, while graph-based features can reveal the\ndynamics of information dissemination across the network. In particular, we\nderive the Jaccard index as a key feature to reveal the benign or malicious\nnature of directed messages in Twitter. To the best of our knowledge, we are\nthe first to propose such a similarity metric to characterize abuse in Twitter.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  While many recent advances in deep reinforcement learning (RL) rely on\nmodel-free methods, model-based approaches remain an alluring prospect for\ntheir potential to exploit unsupervised data to learn environment model. In\nthis work, we provide an extensive study on the design of deep generative\nmodels for RL environments and propose a sample efficient and robust method to\nlearn the model of Atari environments. We deploy this model and propose\ngenerative adversarial tree search (GATS) a deep RL algorithm that learns the\nenvironment model and implements Monte Carlo tree search (MCTS) on the learned\nmodel for planning. While MCTS on the learned model is computationally\nexpensive, similar to AlphaGo, GATS follows depth limited MCTS. GATS employs\ndeep Q network (DQN) and learns a Q-function to assign values to the leaves of\nthe tree in MCTS. We theoretical analyze GATS vis-a-vis the bias-variance\ntrade-off and show GATS is able to mitigate the worst-case error in the\nQ-estimate. While we were expecting GATS to enjoy a better sample complexity\nand faster converges to better policies, surprisingly, GATS fails to outperform\nDQN. We provide a study on which we show why depth limited MCTS fails to\nperform desirably.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper considers links between the original risk-sensitive performance\ncriterion for quantum control systems and its recent quadratic-exponential\ncounterpart. We discuss a connection between the minimization of these cost\nfunctionals and robustness with respect to uncertainty in system-environment\nquantum states whose deviation from a nominal state is described in terms of\nthe quantum relative entropy. These relations are similar to those in minimax\nLQG control for classical systems. The results of the paper can be of use in\nproviding a rational choice of the risk-sensitivity parameter in the context of\nrobust quantum control with entropy theoretic quantification of statistical\nuncertainty in the system-field state.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Entangled photon sources with simultaneously near-unity heralding efficiency\nand indistinguishability are the fundamental elements for scalable photonic\nquantum technologies. We design and realize a degenerate entangled-photon\nsource from an ultrafast pulsed laser pumped spontaneous parametric\ndown-conversion (SPDC), which show simultaneously ~97% heralding efficiency and\n~96% indistinguishability between independent single photons. Such a\nhigh-efficiency and frequency-uncorrelated SPDC source allows generation of the\nfirst 12-photon genuine entanglement with a state fidelity of 0.572(24). We\nfurther demonstrate a blueprint of scalable scattershot boson sampling using 12\nSPDC sources and a 12*12-modes interferometer for three-, four-, and five-boson\nsampling, which yields count rates more than four orders of magnitudes higher\nthan all previous SPDC experiments. Our work immediately enables\nhigh-efficiency implementations of multiplexing, scattershot boson sampling,\nand heralded creation of remotely entangled photons, opening up a promising\npathway to scalable photonic quantum technologies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We demonstrate the existence of an exactly marginal deformation, with\nderivative coupling, about the free theory of a $(2+1)$-dimensional charged,\nLifshitz scalar with dynamic critical exponent $z=4$ and particle-hole\nasymmetry. We show that the other classically scale invariant interactions\n(consistent with translational and rotational invariance) break the scale\nsymmetry at the quantum level and find a trace identity for the\nstress-energy-momentum tensor complex. We conjecture the existence of bound\nstates of $(N+1)$-particles, as a manifestation of broken scale invariance,\nwhen we turn on an attractive, classically scale invariant, polynomial\ninteraction in charged, scalar Lifshitz field theories with dynamic critical\nexponent $z=2N$, $n \\in \\mathbb{N}$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  By inverting the distributions of galaxies' apparent ellipticities and\nmisalignment angles (measured around the projected half-light radius $R_{\\rm\ne}$) between their photometric and kinematic axes, we study the intrinsic shape\ndistribution of 189 slow rotator early-type galaxies with stellar masses\n$2\\times 10^{11} M_{\\odot}<M_\\ast<2\\times 10^{12} M_{\\odot}$, extracted from a\nsample of about 2200 galaxies with integral-field stellar kinematics from the\nDR14 of the SDSS-IV MaNGA IFU survey. Thanks to the large sample of slow\nrotators, Graham+18 showed that there is clear structure in the misalignment\nangle distribution, with two peaks at both $0^{\\circ}$ and $90^{\\circ}$\nmisalignment (characteristic of oblate and prolate rotation respectively). Here\nwe invert the observed distribution from Graham+18. The large sample allows us\nto go beyond the known fact that slow rotators are weakly triaxial and to place\nuseful constraints on their intrinsic triaxiality distribution (around $1R_{\\rm\ne}$) for the first time. The shape inversion is generally non-unique. However,\nwe find that, for a wide set of model assumptions, the observed distribution\nclearly requires a dominant triaxial-oblate population. For some of our models,\nthe data suggest a hint for a minor triaxial-prolate population, but a dominant\nprolate population is ruled out.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The $\\Xi\\Xi$ interaction in the $^1$S$_0$ channel is studied to examine the\nconvergence of the derivative expansion of the non-local HAL QCD potential at\nthe next-to-next-to-leading order (N$^2$LO). We find that (i) the leading order\npotential from the N$^2$LO analysis gives the scattering phase shifts\naccurately at low energies, (ii) the full N$^2$LO potential gives only small\ncorrection to the phase shifts even at higher energies below the inelastic\nthreshold, and (iii) the potential determined from the wall quark source at the\nleading order analysis agrees with the one at the N$^2$LO analysis except at\nshort distances, and thus, it gives correct phase shifts at low energies. We\nalso study the possible systematic uncertainties in the HAL QCD potential such\nas the inelastic state contaminations and the finite volume artifact for the\npotential and find that they are well under control for this particular system.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we present error-correcting codes which are the results of our\nresearch on the sub-exceeding functions. For a short and medium distance data\ntransmission (wifi network, bluetooth, cable, ...), we see that these codes\nmentioned above present many advantages compared with the Hamming code which is\na 1 correcting code.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Sobol' indices are a recognized tool in global sensitivity analysis. When\nthe uncertain variables in a model are statistically independent, the Sobol'\nindices may be easily interpreted and utilized. However, their interpretation\nand utility is more challenging with statistically dependent variables. This\narticle develops an approximation theoretic perspective to interpret Sobol'\nindices in the presence of variable dependencies. The value of this perspective\nis demonstrated in the context of dimension reduction, a common application of\nthe Sobol' indices. Theoretical analysis and illustrative examples are\nprovided.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Using a kinetic model for the ions and adiabatic electrons, we solve a steady\nstate, electron-repelling magnetic presheath in which a uniform magnetic field\nmakes a small angle $\\alpha \\ll 1$ (in radians) with the wall. The presheath\ncharacteristic thickness is the typical ion gyroradius $\\rho_{\\text{i}}$. The\nDebye length $\\lambda_{\\text{D}}$ and the collisional mean free path of an ion\n$\\lambda_{\\text{mfp}}$ satisfy the ordering $\\lambda_{\\text{D}} \\ll\n\\rho_{\\text{i}} \\ll \\alpha \\lambda_{\\text{mfp}}$, so a quasineutral and\ncollisionless model is used. We assume that the electrostatic potential is a\nfunction only of distance from the wall, and it varies over the scale\n$\\rho_{\\text{i}}$. Using the expansion in $\\alpha \\ll 1$, we derive an\nanalytical expression for the ion density that only depends on the ion\ndistribution function at the entrance of the magnetic presheath and the\nelectrostatic potential profile. Importantly, we have added the crucial\ncontribution of the orbits in the region near the wall. By imposing the\nquasineutrality equation, we derive a condition that the ion distribution\nfunction must satisfy at the magnetic presheath entrance --- the kinetic\nequivalent of the Chodura condition. Using an ion distribution function at the\nentrance of the magnetic presheath that satisfies the kinetic Chodura\ncondition, we find numerical solutions for the self-consistent electrostatic\npotential, ion density and flow across the magnetic presheath for several\nvalues of $\\alpha$. Our numerical results also include the distribution of ion\nvelocities at the Debye sheath entrance. We find that at small values of\n$\\alpha$ there are substantially fewer ions travelling with a large normal\ncomponent of the velocity into the wall.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper describes a data reduction technique in case of a markov chain of\nspecified order. Instead of observing all the transitions in a markov chain we\nrecord only a few of them and treat the remaining part as missing. The decision\nabout which transitions to be filtered is taken before the observation process\nstarts. Based on the filtered chain we try to estimate the parameters of the\nmarkov model using EM algorithm. In the first half of the paper we characterize\na class of filtering mechanism for which all the parameters remain\nidentifiable. In the later half we explain methods of estimation and testing\nabout the transition probabilities of the markov chain based on the filtered\ndata. The methods are first developed assuming a simple markov model with each\nprobability of transition positive, but then generalized for models with\nstructural zeroes in the transition probability matrix. Further extension is\nalso done for multiple markov chains. The performance of the developed method\nof estimation is studied using simulated data along with a real life data.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It has been proposed that topological insulators can be best characterized\nnot as surface conductors, but as bulk magnetoelectrics that -- under the right\nconditions-- have a universal quantized magnetoelectric response coefficient\n$e^2/2h$. However, it is not clear to what extent these conditions are\nachievable in real materials that can have disorder, finite chemical potential,\nresidual dissipation, and even inversion symmetry. This has led to some\nconfusion and misconceptions. The primary goal of this work is to illustrate\nexactly under what real life scenarios and in what context topological\ninsulators can be described as magnetoelectrics. We explore analogies of the 3D\nmagnetoelectric response to electric polarization in 1D in detail, the formal\nvs. effective polarization and magnetoelectric susceptibility, the 1/2\nquantized surface quantum Hall effect, the multivalued nature of the\nmagnetoelectric susceptibility, the role of inversion symmetry, the effects of\ndissipation, and the necessity for finite frequency measurements. We present\nthese issues from the perspective of experimentalists who have struggled to\ntake the beautiful theoretical ideas and to try to measure their (sometimes\nsubtle) physical consequences in messy real material systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Medical research suggests that the anterior-posterior (AP)-diameter of the\ninferior vena cava (IVC) and its associated temporal variation as imaged by\nbedside ultrasound is useful in guiding fluid resuscitation of the\ncritically-ill patient. Unfortunately, indistinct edges and gaps in vessel\nwalls are frequently present which impede accurate estimation of the IVC\nAP-diameter for both human operators and segmentation algorithms. The majority\nof research involving use of the IVC to guide fluid resuscitation involves\nmanual measurement of the maximum and minimum AP-diameter as it varies over\ntime. This effort proposes using a time-varying circle fitted inside the\ntypically ellipsoid IVC as an efficient, consistent and novel approach to\ntracking and approximating the AP-diameter even in the context of poor image\nquality. In this active-circle algorithm, a novel evolution functional is\nproposed and shown to be a useful tool for ultrasound image processing. The\nproposed algorithm is compared with an expert manual measurement, and\nstate-of-the-art relevant algorithms. It is shown that the algorithm\noutperforms other techniques and performs very close to manual measurement.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Hipparcos catalog contains stars suspected to be {\\delta} Scuti variables\nfor which extensive ground-based observations and characterization of\nvariability are necessary. Our aim was to characterize variability of 13\ncandidates to {\\delta} Scuti type stars. We obtained 24 215 CCD images and\nanalyzed stellar light curves using the Period04 program. Twelve {\\delta} Scuti\ncandidate stars have been characterized as pulsating with frequencies intrinsic\nto {\\delta} Scuti stars: HIP 2923, HIP 5526, HIP 5659, HIP 11090, HIP 17585,\nHIP 74155, HIP 101473, HIP 106219, HIP 107786, HIP 113487, HIP 115093, HIP\n115856. Five of them (HIP 2923, HIP 5526, HIP 11090, HIP 115856 and HIP 106219)\nmay be hybrid {\\delta} Scuti-{\\gamma} Doradus pulsators. One more candidate,\nHIP 106223, is a variable star with longer periods of pulsations which are\nintrinsic to {\\gamma} Doradus.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We discuss herein the emergence of a large entropy change in metallic\nLi0.33VS2 derived from the orbitally assisted loose {\\sigma} bond formation.\nComprehensive structural studies based on synchrotron x-ray and neutron\ndiffraction analyses clarify the fabrication of ribbon chains at 375 K,\nconsisting of multiple three-centered two-electron {\\sigma} bonds based on the\nviewpoint of local chemical bonding. Although the metallic conductivity\npersists down to the lowest temperature measured, exceptionally large entropy\nchange as a metal, as much as {\\Delta}S = 6.6 J/mol K, appears at the\ntransition. Emergence of a large entropy change in a metallic state expects us\nthe possible novel functional materials, such as a heat-storage material with\nrapid thermal response.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In these mini-proceedings we review the results of the workshop `Impact of\n$B\\to\\mu^+\\mu^-$ on New Physics Searches' that took place at the Paul Scherrer\nInstitute (PSI) on the 18th-19th December 2017.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  With the development of feature extraction technique, one sample always can\nbe represented by multiple features which locate in high-dimensional space.\nMultiple features can re ect various perspectives of one same sample, so there\nmust be compatible and complementary information among the multiple views.\nTherefore, it's natural to integrate multiple features together to obtain\nbetter performance. However, most multi-view dimension reduction methods cannot\nhandle multiple features from nonlinear space with high dimensions. To address\nthis problem, we propose a novel multi-view dimension reduction method named\nMulti-view Reconstructive Preserving Embedding (MRPE) in this paper. MRPE\nreconstructs each sample by utilizing its k nearest neighbors. The similarities\nbetween each sample and its neighbors are primely mapped into lower-dimensional\nspace in order to preserve the underlying neighborhood structure of the\noriginal manifold. MRPE fully exploits correlations between each sample and its\nneighbors from multiple views by linear reconstruction. Furthermore, MRPE\nconstructs an optimization problem and derives an iterative procedure to obtain\nthe low-dimensional embedding. Various evaluations based on the applications of\ndocument classification, face recognition and image retrieval demonstrate the\neffectiveness of our proposed approach on multi-view dimension reduction.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Solar Energetic Particles (SEPs) are an important aspect of space weather.\nSEP events posses a high destructive potential, since they may cause\ndisruptions of communication systems on Earth and be fatal to crew members\nonboard spacecrafts and, in extreme cases, harmful to people onboard high\naltitude flights. However, currently the research community lacks efficient\ntools to predict such hazardous threat and its potential impacts. Such a tool\nis a first step for mankind to improve its preparedness for SEP events and\nultimately to be able to mitigate their effects. The main goal of the presented\nresearch effort is to develop a computational tool that will have the\nforecasting capability and can be serve in operational system that will provide\nlive information on the current potential threats posed by SEP based on the\nobservations of the Sun. In the present paper the fundamentals of\nmagneto-hydrodynamical (MHD) simulations are discussed to be employed as a\ncritical part of the desired forecasting system.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, a new spectrum sharing model referred to as riding on the\nprimary (ROP) is proposed for wireless-powered IoT devices with ambient\nbackscatter communication capabilities. The key idea of ROP is that the\nsecondary transmitter harvests energy from the primary signal, then modulates\nits information bits to the primary signal, and reflects the modulated signal\nto the secondary receiver without violating the primary system's interference\nrequirement. Compared with the conventional spectrum sharing model, the\nsecondary system in the proposed ROP not only utilizes the spectrum of the\nprimary system but also takes advantage of the primary signal to harvest energy\nand to carry its information. In this paper, we investigate the performance of\nsuch a spectrum sharing system under fading channels. To be specific, we\nmaximize the ergodic capacity of the secondary system by jointly optimizing the\ntransmit power of the primary signal and the reflection coefficient of the\nsecondary ambient backscatter. Different (ideal/practical) energy consumption\nmodels, different (peak/average) transmit power constraints, different types\n(fixed/dynamically adjustable) reflection coefficient, different primary\nsystem's interference requirements (rate/outage) are considered. Optimal power\nallocation and reflection coefficient are obtained for each scenario.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The absence of large-angle correlations in the map of cosmic microwave\nbackground temperature fluctuations is among the well-established anomalies\nidentified in full-sky and cut-sky maps over the past three decades. Suppressed\nlarge-angle correlations are rare statistical flukes in standard inflationary\ncosmological models. One natural explanation could be that the underlying\nprimordial density perturbations lack correlations on large distance scales. To\ntest this idea, we replace Fourier modes by a wavelet basis with compact\nspatial support. While the angular correlation function of perturbations can\nreadily be suppressed, the observed monopole and dipole-subtracted correlation\nfunction is not generally suppressed. This suggests that suppression of\nlarge-angle temperature correlations requires a mechanism that has both\nreal-space and harmonic-space effects.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present an open access grid of 3930 calculations of externally evaporating\nprotoplanetary discs. This spans a range of disc sizes (1-400AU), disc masses,\nUV field strengths (10-10$^4$G$_0$) and stellar masses (0.05-1.9M$_\\odot$). The\ngrid is publicly available for download, and offers a means of cheaply\nincluding external photoevaporation in disc evolutionary calculations. It can\nalso be queried using an online tool for quick estimates of instantaneous mass\nloss rates (e.g for convenient evaluation of real observed systems). The\n`FRIED' grid itself illustrates that for discs around stars $\\leq0.3$M$_\\odot$\nexternal photoevaporation is effective down to small radii ($<50$AU) down to UV\nfields at least as weak as 10G$_0$. At the other end of the scale, in a\n$10^4$G$_0$ environment photoevaporation is effective down to 1AU even for\nstellar masses at least as high as 1.9M$_\\odot$. We also illustrate in which\nregimes CO survives in the photoevaporative outflow for significant mass loss\nrates; marking a system a good candidate to detect external photoevaporation in\nweak-intermediate UV environments through sub-Keplerian rotation. Finally we\nmake illustrative mass loss rate estimates for discs in Taurus based on the\nGuilloteau et al. (2011) star-disc parameters, finding that around half are\nexpected to have both significant mass loss and retain CO in the\nphotoevaporative outflow.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report a systematic study of thickness-dependent superconductivity and\ncarrier transport properties in exfoliated layered 2H-NbS2. Hall-effect\nmeasurements reveal 2H-NbS2 in its normal state to be a p-type metal with hole\nmobility of 1-3 cm2/Vs. The superconducting transition temperature is found to\ndecrease with thickness. We find that the suppression of superconductivity is\ndue to disorder resulting from the incorporation of atmospheric oxygen and a\nreduced hole density. Cross-section transmission electron microscope (TEM)\nimaging reveals a chemical change of NbS2 in ambient conditions, resulting in\nthe formation of amorphous oxide layers sandwiching crystalline layered NbS2.\nThough few-nm-thick 2H-NbS2 completely converts to amorphous oxide in ambient\nconditions, PMMA encapsulation prevents further chemical change and preserves\nsuperconductivity.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the homotopy category $\\mathrm{hef}(R,W)$ (and its\n$\\mathbb{Z}_2$-graded version $\\mathrm{HEF}(R,W)$) of elementary\nfactorizations, where $R$ is a B\\'ezout domain which has prime elements and\n$W=W_0 W_c$, where $W_0\\in R^\\times$ is a square-free element of $R$ and\n$W_c\\in R^\\times$ is a finite product of primes with order at least two. In\nthis situation, we give criteria for detecting isomorphisms in\n$\\mathrm{hef}(R,W)$ and $\\mathrm{HEF}(R,W)$ and formulas for the number of\nisomorphism classes of objects. We also study the full subcategory\n$\\mathbf{hef}(R,W)$ of the homotopy category $\\mathrm{hmf}(R,W)$ of finite rank\nmatrix factorizations of $W$ which is additively generated by elementary\nfactorizations. We show that $\\mathbf{hef}(R,W)$ is Krull-Schmidt and we\nconjecture that it coincides with $\\mathrm{hmf}(R,W)$. Finally, we discuss a\nfew classes of examples.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Time-evolving stream datasets exist ubiquitously in many real-world\napplications where their inherent hot keys often evolve over times.\nNevertheless, few existing solutions can provide efficient load balance on\nthese time-evolving datasets while preserving low memory overhead. In this\npaper, we present a novel grouping approach (named FISH), which can provide the\nefficient time-evolving stream processing at scale. The key insight of this\nwork is that the keys of time-evolving stream data can have a skewed\ndistribution within any bounded distance of time interval. This enables to\naccurately identify the recent hot keys for the real-time load balance within a\nbounded scope. We therefore propose an epoch-based recent hot key\nidentification with specialized intra-epoch frequency counting (for maintaining\nlow memory overhead) and inter-epoch hotness decaying (for suppressing\nsuperfluous computation). We also propose to heuristically infer the accurate\ninformation of remote workers through computation rather than communication for\ncost-efficient worker assignment. We have integrated our approach into Apache\nStorm. Our results on a cluster of 128 nodes for both synthetic and real-world\nstream datasets show that FISH significantly outperforms state-of-the-art with\nthe average and the 99th percentile latency reduction by 87.12% and 76.34% (vs.\nW-Choices), and memory overhead reduction by 99.96% (vs. Shuffle Grouping).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Learning to follow human instructions is a long-pursued goal in artificial\nintelligence. The task becomes particularly challenging if no prior knowledge\nof the employed language is assumed while relying only on a handful of examples\nto learn from. Work in the past has relied on hand-coded components or manually\nengineered features to provide strong inductive biases that make learning in\nsuch situations possible. In contrast, here we seek to establish whether this\nknowledge can be acquired automatically by a neural network system through a\ntwo phase training procedure: A (slow) offline learning stage where the network\nlearns about the general structure of the task and a (fast) online adaptation\nphase where the network learns the language of a new given speaker. Controlled\nexperiments show that when the network is exposed to familiar instructions but\ncontaining novel words, the model adapts very efficiently to the new\nvocabulary. Moreover, even for human speakers whose language usage can depart\nsignificantly from our artificial training language, our network can still make\nuse of its automatically acquired inductive bias to learn to follow\ninstructions more effectively.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study by Monte Carlo methods the thermodynamics of a spin polarized gas of\nnon-relativistic fermions in 1+1 dimensions. The main result of this work is\nthat our action suffers no significant sign problem for any spin polarization\nin the region relevant for dilute degenerate fermi gases. This lack of sign\nproblem allows us to study attractive spin polarized fermions\nnon-perturbatively at spin polarizations not previously explored. For some\nparameters values we verify results previously obtained by methods which\ninclude an uncontrolled step like complex Langevin and/or analytical\ncontinuation from imaginary chemical potential. For others, larger values of\nthe polarization, we deviate from these previous results.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This work presents a depleted monolithic active pixel sensor (DMAPS)\nprototype manufactured in the LFoundry 150\\,nm CMOS process. DMAPS exploit high\nvoltage and/or high resistivity inclusion of modern CMOS technologies to\nachieve substantial depletion in the sensing volume. The described device,\nnamed LF-Monopix, was designed as a proof of concept of a fully monolithic\nsensor capable of operating in the environment of outer layers of the ATLAS\nInner Tracker upgrade in 2025 for the High Luminosity Large Hadron Collider\n(HL-LHC). This type of devices has a lower production cost and lower material\nbudget compared to presently used hybrid designs. In this work, the chip\narchitecture will be described followed by the characterization of the\ndifferent pre-amplifier and discriminator flavors with an external injection\nsignal and an iron source (5.9\\,keV x-rays).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Several diseases of parkinsonian syndromes present similar symptoms at early\nstage and no objective widely used diagnostic methods have been approved until\nnow. Positron emission tomography (PET) with $^{18}$F-FDG was shown to be able\nto assess early neuronal dysfunction of synucleinopathies and tauopathies.\nTensor factorization (TF) based approaches have been applied to identify\ncharacteristic metabolic patterns for differential diagnosis. However, these\nconventional dimension-reduction strategies assume linear or multi-linear\nrelationships inside data, and are therefore insufficient to distinguish\nnonlinear metabolic differences between various parkinsonian syndromes. In this\npaper, we propose a Deep Projection Neural Network (DPNN) to identify\ncharacteristic metabolic pattern for early differential diagnosis of\nparkinsonian syndromes. We draw our inspiration from the existing TF methods.\nThe network consists of a (i) compression part: which uses a deep network to\nlearn optimal 2D projections of 3D scans, and a (ii) classification part: which\nmaps the 2D projections to labels. The compression part can be pre-trained\nusing surplus unlabelled datasets. Also, as the classification part operates on\nthese 2D projections, it can be trained end-to-end effectively with limited\nlabelled data, in contrast to 3D approaches. We show that DPNN is more\neffective in comparison to existing state-of-the-art and plausible baselines.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigated the elongational flows of the weakly entangled linear polymer\nmelt using a coarse-grained molecular dynamics simulation. We extended the\nuniform extensional flow (UEF) method developed by Nicholson and Rutledge (D.\nA. Nicholson and G. C. Rutledge, J. Chem. Phys., 145, 244903 (2016)) for\napplication to Langevin dynamics. We succeeded in observing the elongational\nviscosity of the weakly entangled linear polymer melt from the equilibrium\nstate to the steady state using the extended UEF method, whereas the\nconventional rectangular parallelepiped shape technique for extensional flows\nhas failed to do so for over 20 years.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Although reinforcement learning methods can achieve impressive results in\nsimulation, the real world presents two major challenges: generating samples is\nexceedingly expensive, and unexpected perturbations or unseen situations cause\nproficient but specialized policies to fail at test time. Given that it is\nimpractical to train separate policies to accommodate all situations the agent\nmay see in the real world, this work proposes to learn how to quickly and\neffectively adapt online to new tasks. To enable sample-efficient learning, we\nconsider learning online adaptation in the context of model-based reinforcement\nlearning. Our approach uses meta-learning to train a dynamics model prior such\nthat, when combined with recent data, this prior can be rapidly adapted to the\nlocal context. Our experiments demonstrate online adaptation for continuous\ncontrol tasks on both simulated and real-world agents. We first show simulated\nagents adapting their behavior online to novel terrains, crippled body parts,\nand highly-dynamic environments. We also illustrate the importance of\nincorporating online adaptation into autonomous agents that operate in the real\nworld by applying our method to a real dynamic legged millirobot. We\ndemonstrate the agent's learned ability to quickly adapt online to a missing\nleg, adjust to novel terrains and slopes, account for miscalibration or errors\nin pose estimation, and compensate for pulling payloads.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Selected configuration interaction (sCI) methods including second-order\nperturbative corrections provide near full CI (FCI) quality energies with only\na small fraction of the determinants of the FCI space. Here, we introduce both\na state-specific and a multi-state sCI method based on the CIPSI (Configuration\nInteraction using a Perturbative Selection made Iteratively) algorithm. The\npresent method revises the reference (internal) space under the effect of its\ninteraction with the outer space via the construction of an effective\nHamiltonian, following the shifted-Bk philosophy of Davidson and coworkers. In\nparticular, the multi-state algorithm removes the storage bottleneck of the\neffective Hamiltonian via a low-rank factorization of the dressing matrix.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Large-scale quantum technologies require exquisite control over many\nindividual quantum systems. Typically, such systems are very sensitive to\nenvironmental fluctuations, and diagnosing errors via measurements causes\nunavoidable perturbations. In this work we present an in situ frequency locking\ntechnique that monitors and corrects frequency variations in single photon\nsources based on microring resonators. By using the same classical laser fields\nrequired for photon generation as a probe to diagnose variations in the\nresonator frequency, our protocol applies feedback control to correct photon\nfrequency errors in parallel to the optical quantum computation without\ndisturbing the physical qubit. We implement our technique on a silicon photonic\ndevice and demonstrate sub 1 pm frequency stabilization in the presence of\napplied environmental noise, corresponding to a fractional frequency drift of\n<1 % of a photon linewidth. Using these methods we demonstrate feedback\ncontrolled quantum state engineering. By distributing a single local oscillator\nacross a single chip or network of chips, our approach enables frequency\nlocking of many single photon sources for large-scale photonic quantum\ntechnologies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Adam is shown not being able to converge to the optimal solution in certain\ncases. Researchers recently propose several algorithms to avoid the issue of\nnon-convergence of Adam, but their efficiency turns out to be unsatisfactory in\npractice. In this paper, we provide new insight into the non-convergence issue\nof Adam as well as other adaptive learning rate methods. We argue that there\nexists an inappropriate correlation between gradient $g_t$ and the\nsecond-moment term $v_t$ in Adam ($t$ is the timestep), which results in that a\nlarge gradient is likely to have small step size while a small gradient may\nhave a large step size. We demonstrate that such biased step sizes are the\nfundamental cause of non-convergence of Adam, and we further prove that\ndecorrelating $v_t$ and $g_t$ will lead to unbiased step size for each\ngradient, thus solving the non-convergence problem of Adam. Finally, we propose\nAdaShift, a novel adaptive learning rate method that decorrelates $v_t$ and\n$g_t$ by temporal shifting, i.e., using temporally shifted gradient $g_{t-n}$\nto calculate $v_t$. The experiment results demonstrate that AdaShift is able to\naddress the non-convergence issue of Adam, while still maintaining a\ncompetitive performance with Adam in terms of both training speed and\ngeneralization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We derive and study the effective spin model that explains the anomalous spin\ndynamics in the one-dimensional Hubbard model with strong potential disorder.\nAssuming that charges are localized, we show that spins are delocalized and\ntheir subdiffusive transport originates from a singular random distribution of\nspin exchange interactions. The exponent relevant for the subdiffusion is\ndetermined by the Anderson localization length and the density of electrons.\nWhile the analytical derivations are valid for low particle density, numerical\nresults for the full model reveal a qualitative agreement up to half-filling.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study diffusion on a multilayer network where the contact dynamics between\nthe nodes is governed by a random process and where the waiting time\ndistribution differs for edges from different layers. We study the impact on a\nrandom walk of the competition that naturally emerges between the edges of the\ndifferent layers. In opposition to previous studies which have imposed a priori\ninter-layer competition, the competition is here induced by the heterogeneity\nof the activity on the different layers. We first study the precedence relation\nbetween different edges and by extension between different layers, and show\nthat it determines biased paths for the walker. We also discuss the emergence\nof cyclic, rock-paper-scissors random walks, when the precedence between layers\nis non-transitive. Finally, we numerically show the slowing-down effect due to\nthe competition on a heterogeneous multilayer as the walker is likely to be\ntrapped for a longer time either on a single layer, or on an oriented cycle .\n  Keywords: random walks; multilayer networks; dynamical systems on networks;\nmodels of networks; simulations of networks; competition between layers.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We experimentally investigate a strongly driven GaAs double quantum dot\ncharge qubit weakly coupled to a superconducting microwave resonator. The\nFloquet states emerging from strong driving are probed by tracing the qubit -\nresonator resonance condition. This way we probe the resonance of a qubit that\nis driven in an adiabatic, a non-adiabatic, or an intermediate rate showing\ndistinct quantum features of multi-photon processes and\nLandau-Zener-St\\\"uckelberg interference pattern. Our resonant detection scheme\nenables the investigation of novel features when the drive frequency is\ncomparable to the resonator frequency. Models based on adiabatic approximation,\nrotating wave approximation, and Floquet theory explain our experimental\nobservations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A fundamental challenge in neuroscience is to understand what structure in\nthe world is represented in spatially distributed patterns of neural activity\nfrom multiple single-trial measurements. This is often accomplished by learning\na simple, linear transformations between neural features and features of the\nsensory stimuli or motor task. While successful in some early sensory\nprocessing areas, linear mappings are unlikely to be ideal tools for\nelucidating nonlinear, hierarchical representations of higher-order brain areas\nduring complex tasks, such as the production of speech by humans. Here, we\napply deep networks to predict produced speech syllables from cortical surface\nelectric potentials recorded from human sensorimotor cortex. We found that deep\nnetworks had higher decoding prediction accuracy compared to baseline models,\nand also exhibited greater improvements in accuracy with increasing dataset\nsize. We further demonstrate that deep network's confusions revealed\nhierarchical latent structure in the neural data, which recapitulated the\nunderlying articulatory nature of speech motor control. Finally, we used deep\nnetworks to compare task-relevant information in different neural frequency\nbands, and found that the high-gamma band contains the vast majority of\ninformation relevant for the speech prediction task, with little-to-no\nadditional contribution from lower-frequencies. Together, these results\ndemonstrate the utility of deep networks as a data analysis tool for\nneuroscience.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Underwater optical wireless links have limited range and intermittent\nconnectivity due to the hostile aquatic channel impairments and misalignment\nbetween the optical transceivers. Therefore, multi-hop communication can expand\nthe communication range, enhance network connectivity, and provide a more\nprecise network localization scheme. In this regard, this paper investigates\nthe connectivity of underwater optical wireless sensor networks (UOWSNs) and\nits impacts on the network localization performance. Firstly, we model UOWSNs\nas randomly scaled sector graphs where the connection between sensors is\nestablished by point-to-point directed links. Thereafter, the probability of\nnetwork connectivity is analytically derived as a function of network density,\ncommunication range, and optical transmitters' divergence angle. Secondly, the\nnetwork localization problem is formulated as an unconstrained optimization\nproblem and solved using the conjugate gradient technique. Numerical results\nshow that different network parameters such as the number of nodes, divergence\nangle, and transmission range significantly influence the probability of a\nconnected network. Furthermore, the performance of the proposed localization\ntechnique is compared to well-known network localization schemes and the\nresults show that the localization accuracy of the proposed technique\noutperforms the literature in terms of network connectivity, ranging error, and\nnumber of anchors.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper by making use of the \"Complexity=Action\" proposal, we study the\ncomplexity growth after shock waves in holographic field theories. We consider\nboth double black hole-Vaidya and AdS-Vaidya with multiple shocks geometries.\nWe find that the Lloyd's bound is respected during the thermalization process\nin each of these geometries and at the late time, the complexity growth\nsaturates to the value which is proportional to the energy of the final state.\nWe conclude that the saturation value of complexity growth rate is independent\nof the initial temperature and in the case of thermal initial state, the rate\nof complexity is always less than the value for the vacuum initial state such\nthat considering multiple shocks it gets more smaller. Our results indicate\nthat by increasing the temperature of the initial state, the corresponding rate\nof complexity growth starts far from final saturation rate value.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Laplace equation in the two-dimensional Euclidean plane is considered in\nthe context of the inverse stereographic projection. The Lie algebra of the\nconformal group as the symmetry group of the Laplace equation can be\nrepresented solely in terms of the solutions and derivatives of the solutions\nof the Laplace equation. It is then possible to put contents from differential\ngeometry and quantum systems, like the Hopf bundle, relativistic spin,\nbicomplex numbers, and the Fock space into a common context. The basis elements\nof the complex numbers, considered as a Clifford paravector algebra, are\nreinterpreted as differential tangent vectors referring to dilations and\nrotations. In relation to this a homogeneous space is defined with the Lie\nalgebra of the conformal group, where dilations and rotations are the coset\nrepresentatives. Potential applications in physics are discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $f(x)$ be a nonconstant polynomial with integer coefficients and nonzero\ndiscriminant. We study the distribution modulo primes of the set of squarefree\nintegers $d$ such that the curve $dy^2=f(x)$ has a nontrivial rational or\nintegral point.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Topological quantum computation employs two-dimensional quasiparticles called\nanyons. The generally accepted mathematical basis for the theory of anyons is\nthe framework of modular tensor categories. That framework involves a\nsubstantial amount of category theory and is, as a result, considered rather\ndifficult to understand. Is the complexity of the present framework necessary?\nThe computations of associativity and braiding matrices can be based on a much\nsimpler framework, which looks less like category theory and more like familiar\nalgebra. We introduce that framework here.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we define an interesting family of perfect ideals of\ncodimension three, with five generators, of Cohen-Macaulay type two with\ntrivial multiplication on the Tor algebra. This family is likely to play a key\nrole in classifying perfect ideals with five generators of type two.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we apply different NMT models to the problem of historical\nspelling normalization for five languages: English, German, Hungarian,\nIcelandic, and Swedish. The NMT models are at different levels, have different\nattention mechanisms, and different neural network architectures. Our results\nshow that NMT models are much better than SMT models in terms of character\nerror rate. The vanilla RNNs are competitive to GRUs/LSTMs in historical\nspelling normalization. Transformer models perform better only when provided\nwith more training data. We also find that subword-level models with a small\nsubword vocabulary are better than character-level models for low-resource\nlanguages. In addition, we propose a hybrid method which further improves the\nperformance of historical spelling normalization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In the mentioned paper we presented results of the estimation of Kolmogorov\ncomplexity of sequences of random numbers generated in a famous Bell's\nexperiment, aimed to study the security of QKD. We focused on series of time\ndifferences between successive detections of coincidences, and found that\nrandomness cannot be taken for granted. It was then criticized that the\ntheorems that demonstrate the randomness of series produced in Bell's\nexperiments involve series of measurement outcomes, not of measurement times.\nHere we reply to this objection and present data of series of outcomes, showing\nthat the conclusions in the mentioned paper are valid also in this case.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Models that accurately predict the output voltage ripple magnitude are\nessential for applications with stringent performance target for it. Impact of\ndc input ripple on the output ripple for a Series Resonant Converter (SRC)\nusing discrete domain exact discretization modelling method is analysed in this\npaper. A novel discrete state space model along with a small signal model for\nSRC considering 3 state variables is presented. The audiosusceptibility (AS)\ntransfer function which relates the input to output ripple is derived from the\nsmall signal model. Analysis of the AS transfer function indicates a resonance\npeak and an expression is derived connecting the AS resonance frequency for\ninput ripple with different SRC component values. Further analysis is done to\nshow that a set of values for SRC parameter exists, which forms a design\nregion, for which the normalized gain offered by the SRC for input ripple is\nless than unity at any input ripple frequency. A test setup to introduce the\nvariable frequency ripple at the input of SRC for the experimental evaluation\nof AS transfer function is also proposed. Influence of stray parameters on AS\ngain, AS resonance frequency and on SRC tank resonance frequency is addressed.\nAn SRC is designed at a power level of 10kW. The analysis using the derived\nmodel, simulations, and experimental results are found to be closely matching.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the problem of maximizing the sum of a monotone submodular\nfunction and a linear function subject to a general solvable polytope\nconstraint. Recently, Sviridenko et al. (2017) described an algorithm for this\nproblem whose approximation guarantee is optimal in some intuitive and formal\nsenses. Unfortunately, this algorithm involves a guessing step which makes it\nless clean and significantly affects its time complexity. In this work we\ndescribe a clean alternative algorithm that uses a novel weighting technique in\norder to avoid the problematic guessing step while keeping the same\napproximation guarantee as the algorithm of Sviridenko et al.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  If the extremely low surface brightness galaxy Coma P lies at $5.5\\pm0.3$ Mpc\nas recently proposed then it would have an extraordinarily deviant peculiar\nvelocity of $\\sim900$ km $\\mathrm{s^{-1}}$ at a location where differential\nvelocities between galaxies are low. We have accessed the images from the HST\narchives used to derive the literature distance from the magnitude of the tip\nof the red giant branch. Our analysis gives the distance to be $10.9\\pm1.0$\nMpc. At this location the galaxy lies within the infall region of the Virgo\nCluster, such that its still considerable peculiar velocity of $\\sim500$ km\n$\\mathrm{s^{-1}}$ is consistent with an established model. Coma P has an\nunusually pronounced asymptotic giant branch relative to its red giant branch.\nThe dominant stellar population is just a few Gyr old.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The presence of massive neutrinos affects structure formation, leaving\nimprints on large-scale structure observables such as the weak lensing field.\nThe common lensing analyses with two-point statistics are insensitive to the\nlarge amount of non-Gaussian information in the density field. We investigate\nnon-Gaussian tools, in particular the Minkowski Functionals\n(MFs)---morphological descriptors including area, perimeter, and genus---in an\nattempt to recover the higher-order information. We use convergence maps from\nthe Cosmological Massive Neutrino Simulations (\\texttt{MassiveNus}) and assume\ngalaxy noise, density, and redshift distribution for an LSST-like survey. We\nshow that MFs are sensitive to the neutrino mass sum, and the sensitivity is\nredshift dependent and is non-Gaussian. We find that redshift tomography\nsignificantly improves the constraints on neutrino mass for MFs, compared to\nthe improvements for the power spectrum. We attribute this to the stronger\nredshift dependence of neutrino effects on small scales. We then build an\nemulator to model the power spectrum and MFs, and study the constraints on\n$[M_{\\nu}$, $\\Omega_{m}$, $A_{s}]$ from the power spectrum, MFs, and their\ncombination. We show that MFs significantly outperform the power spectrum in\nconstraining neutrino mass, by more than a factor of four. However, a thorough\nstudy of the impact from systematics such as baryon physics and galaxy shape\nand redshift biases will be important to realize the full potential of MFs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In arXiv:1807.09038 we formulated a conjecture describing the derived\ncategory D-mod(Gr$_{GL(n)}$) of (all) D-modules on the affine Grassmannian of\nthe group $GL(n)$ as the category of quasi-coherent sheaves on a certain stack\n(it is explained in loc. cit. that this conjecture \"follows\" naturally from\nsome heuristic arguments involving 3-dimensional quantum field theory). In this\npaper we prove a weaker version of this conjecture for the case $n=2$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Within the context of an extended Nambu - Jona-Lasinio model, we analyze the\nrole of the axial-vector $a_1(1260)$ and $a_1(1640)$ mesons in the decay\n$\\tau\\to\\nu_\\tau \\rho^0\\pi^-$. The contributions of pseudoscalar $\\pi$ and $\\pi\n(1300)$ states are also considered. The form factors for the decay amplitude\nare determined in terms of the masses and widths of these states. To describe\nthe radial excited states $\\pi (1300)$ and $a_1(1640)$ we introduce two\nadditional parameters which can be estimated theoretically, or fixed from\nexperiment. The decay rate and $\\rho\\pi$ mass spectrum are calculated.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Despite decades of efforts, achieving $p$-type conductivity in the wide band\ngap ZnO in its ground-state wurtzite structure continues to be a challenge.\nHere we detail how $p$-type ZnO can be realized in the metastable,\nhigh-pressure rocksalt phase (also wide-gap) with Li as an external dopant.\nUsing modern first-principles defect theory, we predict Li to dope the rocksalt\nphase $p$-type by preferentially substituting for Zn and introducing shallow\nacceptor levels. Formation of compensating donors like interstitial Li and/or\nhydrogen, ubiqutous in the wurtzite phase, is inhibited by the close-packed\nnature of the rocksalt structure, which also exhibits relatively high absolute\nvalence band edge that promotes low hole effective mass and hole\ndelocalization. Resulting concentrations of free holes are predicted to exceed\n$\\sim10^{19}$ cm$^{-3}$ under O-rich synthesis conditions while under O-poor\nconditions the system remains $n$-type dopable. In addition to revealing\ncompelling opportunities offered by the metastable rocksalt structure in\nrealizing a long-sought $p$-type ZnO our results present polymorphism as a\npromising route to overcoming strong doping asymmetry of wide-band gap oxides.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Standard evaluations of deep learning models for semantics using naturalistic\ncorpora are limited in what they can tell us about the fidelity of the learned\nrepresentations, because the corpora rarely come with good measures of semantic\ncomplexity. To overcome this limitation, we present a method for generating\ndata sets of multiply-quantified natural language inference (NLI) examples in\nwhich semantic complexity can be precisely characterized, and we use this\nmethod to show that a variety of common architectures for NLI inevitably fail\nto encode crucial information; only a model with forced lexical alignments\navoids this damaging information loss.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Collecting flow records is a common practice of network operators and\nresearchers for monitoring, diagnosing and understanding a network. Traditional\ntools like NetFlow face great challenges when both the speed and the complexity\nof the network traffic increase. To keep pace up, we propose HashFlow, a tool\nfor more efficient and accurate collection and analysis of flow records. The\ncentral idea of HashFlow is to maintain accurate records for elephant flows,\nbut summarized records for mice flows, by applying a novel collision resolution\nand record promotion strategy to hash tables. The performance bound can be\nanalyzed with a probabilistic model, and with this strategy, HashFlow achieves\na better utilization of space, and also more accurate flow records, without\nbringing extra complexity. We have implemented HashFlow, as well as several\nlatest flow measurement algorithms such as FlowRadar, HashPipe and\nElasticSketch, in a P4 software switch. Then we use traces from different\noperational networks to evaluate them. In these experiments, for various types\nof traffic analysis applications, HashFlow consistently demonstrates a clearly\nbetter performance against its state-of-the-art competitors. For example, using\na small memory of 1 MB, HashFlow can accurately record around 55K flows, which\nis often 12.5% higher than the others. For estimating the sizes of 50K flows,\nHashFlow achieves a relative error of around 11.6%, while the estimation error\nof the best competitor is 42.9% higher. It detects 96.1% of the heavy hitters\nout of 250K flows with a size estimation error of 5.6%, which is 11.3% and\n73.7% better than the best competitor respectively. At last, we show these\nmerits of HashFlow come with almost no degradation of throughput.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The aim of this note is to point out an interesting fact related to the\nelliptic genus of complex algebraic surfaces in the context of Mathieu\nmoonshine. We also discuss the case of 4-folds.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Neutrinos emitted from a supernova may undergo flavor conversions almost\nimmediately above the core, with possible consequences for supernova dynamics\nand nucleosynthesis. However, the precise conditions for such fast conversions\ncan be difficult to compute and require knowledge of the full angular\ndistribution of the flavor-dependent neutrino fluxes, that is not available in\ntypical supernova simulations. In this paper, we show that the overall flavor\nevolution is qualitatively similar to the growth of a so-called `zero mode',\ndetermined by the background matter and neutrino densities, which can be\nreliably predicted using only the second angular moments of the electron lepton\nnumber distribution, i.e., the difference in the angular distributions of\n$\\nu_e$ and $\\bar{\\nu}_e$ fluxes. We propose that this zero mode, which neither\nrequires computing the full Green's function nor a detailed knowledge of the\nangular distributions, may be useful for a preliminary diagnosis of possible\nfast flavor conversions in supernova simulations with modestly resolved angular\ndistributions\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Nonclassicality of temporal correlations pertaining to noncommutative\nsequential measurements is defined through the violation of macrorealistic\ninequalities, known as Leggett-Garg inequalities (LGI). We investigate the\nenergy cost of the process associated with the Leggett-Garg test in the context\nof noiseless and Markovian noise for arbitrary initial states. We prove that in\nnoiseless and in certain noisy scenarios, the maximal violations of LGI under\nthe energy constraint occurs when the average energy of the process is equal to\nthe negative of the energy of the initial state. Such a dependence of LGI on\nthe choice of the initial state is not seen in the unconstrained case.\nMoreover, we find that in the presence of a moderate amount of Markovian noise,\nthe amount of violation of LGI remains almost unaltered with a suitable choice\nof the evolution and dephasing operators in the neighborhood of the maximal\nviolation line, thereby showing the robustness of temporal correlations under\nenvironmental effects.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study heat transfer mediated by near-field fluctuations of the\nelectromagnetic field. In case of metals the latter are dominated by Coulomb\ninteractions between thermal fluctuations of electronic density. We show that\nan elastic scattering of electrons, leading to diffusive propagation of density\nfluctuations, results in a qualitative change of the radiation law. While the\nheat flux between clean metals follows the Stefan-Boltzmann-like $T^4$\ndependence, the heat exchange between disordered conductors is significantly\nenhanced and scales as $T^3$ at low temperatures.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce forest straight-line programs (FSLPs) as a compressed\nrepresentation of unranked ordered node-labelled trees. FSLPs are based on the\noperations of forest algebra and generalize tree straight-line programs. We\ncompare the succinctness of FSLPs with two other compression schemes for\nunranked trees: top dags and tree straight-line programs of first-child/next\nsibling encodings. Efficient translations between these formalisms are\nprovided. Finally, we show that equality of unranked trees in the setting where\ncertain symbols are associative or commutative can be tested in polynomial\ntime. This generalizes previous results for testing isomorphism of compressed\nunordered ranked trees.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It has been recently suggested that oscillons produced in the early universe\nfrom certain asymmetric potentials continue to emit gravitational waves for a\nnumber of $e$-folds of expansion after their formation, leading to potentially\ndetectable gravitational wave signals. We revisit this claim by conducting a\nconvergence study using graphics processing unit (GPU)-accelerated lattice\nsimulations and show that numerical errors accumulated with time are\nsignificant in low-resolution scenarios, or in scenarios where the run-time\ncauses the resolution to drop below the relevant scales in the problem. Our\nstudy determines that the dominant, growing high frequency peak of the\ngravitational wave signals in the fiducial \"hill-top model\" in\n[arXiv:1607.01314] is a numerical artifact. This finding prompts the need for a\nmore careful analysis of the numerical validity of other similar results\nrelated to gravitational waves from oscillon dynamics.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this second paper of the series we specify general theory developed in the\nfirst paper. Here we study the structure of Jacobi fields in the case of an\nanalytic system and piece-wise analytic control. Moreover, we consider only\n1-dimensional control variations. Jacobi fields are piece-wise analytic in this\ncase but may have much more singularities than the control. We derive ODEs that\nthese fields satisfy on the intervals of regularity and study behavior of the\nfields in a neighborhood of a singularity where the ODE becomes singular and\nthe Jacobi fields may have jumps.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The evolution of surface gravity waves is driven by nonlinear interactions\nthat trigger an energy cascade similarly to the one observed in hydrodynamic\nturbulence. This process, known as wave turbulence, has been found to display\nanomalous scaling with deviation from classical turbulent predictions due to\nthe emergence of coherent and intermittent structures on the water surface. In\nrealistic oceanic sea states, waves are spread over a wide range of directions,\nwith a consequent attenuation of the nonlinear properties. A laboratory\nexperiment in a large wave facility is presented to discuss the effect of wave\ndirectionality on wave turbulence. Results show that the occurrence of coherent\nand intermitted structures become less likely with the broadening of the wave\ndirectional spreading. There is no evidence, however, that intermittency\ncompletely vanishes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Unconventional superconductivity typically emerges in the presence of\nquasi-degenerate ground states, and the associated intense fluctuations are\nlikely responsible for generating the superconducting state. Here we use\npolarized neutron scattering to study the spin space anisotropy of spin\nexcitations in Fe$_{1.07}$Te exhibiting bicollinear antiferromagnetic (AF)\norder, the parent compound of FeTe$_{1-x}$Se$_x$ superconductors. We confirm\nthat the low energy spin excitations are transverse spin waves, consistent with\na local-moment origin of the bicollinear AF order. While the ordered moments\nlie in the $ab$-plane in Fe$_{1.07}$Te, it takes less energy for them to\nfluctuate out-of-plane, similar to BaFe$_2$As$_2$ and NaFeAs. At energies above\n$E\\gtrsim20$ meV, we find magnetic scattering to be dominated by an isotropic\ncontinuum that persists up to at least 50 meV. Although the isotropic spin\nexcitations cannot be ascribed to spin waves from a long-range ordered local\nmoment antiferromagnet, the continuum can result from the bicollinear magnetic\norder ground state of Fe$_{1.07}$Te being quasi-degenerate with plaquette\nmagnetic order.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Several theoretical motivations point to ultralight QCD axions with large\ndecay constants $f_a \\simeq \\mathcal{O}(10^{16}-10^{17})$ GeV, to which\nexperimental proposals are dedicated. This regime is known to face the problem\nof overproduction of axion dark matter from the misalignment mechanism unless\nthe misalignment angle $\\theta_{\\rm mis}$ is as small as\n$\\mathcal{O}(10^{-3}-10^{-4})$, which is generally considered a fine-tuning\nproblem. We investigate a dynamical explanation for a small $\\theta_{\\rm mis}$.\nThe axion mass arises from strong dynamics and may be sufficiently enhanced by\nearly dynamics so as to overcome Hubble friction and drive the field value to\nthe bottom of the potential long before the QCD phase transition. Together with\nan approximate CP symmetry in the theory, this minimum is very closely related\nto today's value and thus $\\theta_{\\rm mis}$ can automatically be well under\nunity. Owing to such efficient relaxation, the isocurvature perturbations are\nessentially damped. As an existence proof, using supersymmetric theories we\nillustrate that the Higgs coupling with the inflaton energy can successfully\nachieve this axion damping in a consistent inflationary cosmology.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The tabu and restart are two fundamental strategies for local search. In this\npaper, we improve the local search algorithms for solving the Maximum Weight\nClique (MWC) problem by introducing new tabu and restart strategies. Both the\ntabu and restart strategies proposed are based on the notion of a local search\nscenario, which involves not only a candidate solution but also the tabu status\nand unlocking relationship. Compared to the strategy of configuration checking,\nour tabu mechanism discourages forming a cycle of unlocking operations. Our new\nrestart strategy is based on the re-occurrence of a local search scenario\ninstead of that of a candidate solution. Experimental results show that the\nresulting MWC solver outperforms several state-of-the-art solvers on the\nDIMACS, BHOSLIB, and two benchmarks from practical applications.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We experimentally investigate charge transport through the interface between\na niobium superconductor and a three-dimensional WTe$_2$ Weyl semimetal. In\naddition to classical Andreev reflection, we observe sharp non-periodic subgap\nresistance resonances. From an analysis of their positions, magnetic field and\ntemperature dependencies, we can interpret them as an analog of Tomasch\noscillations for transport along the topological surface state across the\nregion of proximity-induced superconductivity at the Nb-WTe$_2$ interface.\nObservation of distinct geometrical resonances implies a specific transmission\ndirection for carriers, which is a hallmark of the Fermi arc surface states.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper presents a study on detecting cyberattacks on industrial control\nsystems (ICS) using unsupervised deep neural networks, specifically,\nconvolutional neural networks. The study was performed on a SecureWater\nTreatment testbed (SWaT) dataset, which represents a scaled-down version of a\nreal-world industrial water treatment plant. e suggest a method for anomaly\ndetection based on measuring the statistical deviation of the predicted value\nfrom the observed value.We applied the proposed method by using a variety of\ndeep neural networks architectures including different variants of\nconvolutional and recurrent networks. The test dataset from SWaT included 36\ndifferent cyberattacks. The proposed method successfully detects the vast\nmajority of the attacks with a low false positive rate thus improving on\nprevious works based on this data set. The results of the study show that 1D\nconvolutional networks can be successfully applied to anomaly detection in\nindustrial control systems and outperform more complex recurrent networks while\nbeing much smaller and faster to train.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Edge detection has made significant progress with the help of deep\nConvolutional Networks (ConvNet). These ConvNet based edge detectors have\napproached human level performance on standard benchmarks. We provide a\nsystematical study of these detectors' outputs. We show that the detection\nresults did not accurately localize edge pixels, which can be adversarial for\ntasks that require crisp edge inputs. As a remedy, we propose a novel\nrefinement architecture to address the challenging problem of learning a crisp\nedge detector using ConvNet. Our method leverages a top-down backward\nrefinement pathway, and progressively increases the resolution of feature maps\nto generate crisp edges. Our results achieve superior performance, surpassing\nhuman accuracy when using standard criteria on BSDS500, and largely\noutperforming state-of-the-art methods when using more strict criteria. More\nimportantly, we demonstrate the benefit of crisp edge maps for several\nimportant applications in computer vision, including optical flow estimation,\nobject proposal generation and semantic segmentation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present Atacama Large Millimeter/Submillimeter Array observations of the\nrest-frame far-infrared (FIR) dust continuum emission of six bright Lyman-break\ngalaxies (LBGs) at $z \\simeq 7$. One LBG is detected ($5.2\\sigma$ at peak\nemission), while the others remain individually undetected at the $3\\sigma$\nlevel. The average FIR luminosity of the sample is found to be $L_{\\rm FIR}\n\\simeq 2 \\times 10^{11}\\,{\\rm L}_{\\odot}$, corresponding to an obscured\nstar-formation rate (SFR) that is comparable to that inferred from the\nunobscured UV emission. In comparison to the infrared excess (IRX$\\,=L_{\\rm\nFIR}/L_{\\rm UV}$)-$\\beta$ relation, our results are consistent with a\nCalzetti-like attenuation law (assuming a dust temperature of T = 40-50 K). We\nfind a physical offset of 3 kpc between the dust continuum emission and the\nrest-frame UV light probed by Hubble Space Telescope imaging for galaxy ID65666\nat $z = 7.17^{+0.09}_{-0.06}$. The offset is suggestive of an inhomogeneous\ndust distribution, where 75% of the total star formation activity (SFR$\n\\,\\simeq 70\\,{\\rm M}_{\\odot}/{\\rm yr}$) of the galaxy is completely obscured.\nOur results provide direct evidence that dust obscuration plays a key role in\nshaping the bright-end of the observed rest-frame UV luminosity function at $z\n\\simeq 7$, in agreement with cosmological galaxy formation simulations. The\nexistence of a heavily-obscured component of galaxy ID65666 indicates that\ndusty star-forming regions, or even entire galaxies, that are \"UV-dark\" are\nsignificant even in the $z \\simeq 7$ galaxy population.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Optimal transport (OT) and maximum mean discrepancies (MMD) are now routinely\nused in machine learning to compare probability measures. We focus in this\npaper on \\emph{Sinkhorn divergences} (SDs), a regularized variant of OT\ndistances which can interpolate, depending on the regularization strength\n$\\varepsilon$, between OT ($\\varepsilon=0$) and MMD ($\\varepsilon=\\infty$).\nAlthough the tradeoff induced by that regularization is now well understood\ncomputationally (OT, SDs and MMD require respectively $O(n^3\\log n)$, $O(n^2)$\nand $n^2$ operations given a sample size $n$), much less is known in terms of\ntheir \\emph{sample complexity}, namely the gap between these quantities, when\nevaluated using finite samples \\emph{vs.} their respective densities. Indeed,\nwhile the sample complexity of OT and MMD stand at two extremes, $1/n^{1/d}$\nfor OT in dimension $d$ and $1/\\sqrt{n}$ for MMD, that for SDs has only been\nstudied empirically. In this paper, we \\emph{(i)} derive a bound on the\napproximation error made with SDs when approximating OT as a function of the\nregularizer $\\varepsilon$, \\emph{(ii)} prove that the optimizers of regularized\nOT are bounded in a Sobolev (RKHS) ball independent of the two measures and\n\\emph{(iii)} provide the first sample complexity bound for SDs, obtained,by\nreformulating SDs as a maximization problem in a RKHS. We thus obtain a scaling\nin $1/\\sqrt{n}$ (as in MMD), with a constant that depends however on\n$\\varepsilon$, making the bridge between OT and MMD complete.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Construction of capacity achieving deletion correcting codes has been a\nbaffling challenge for decades. A recent breakthrough by Brakensiek $et~al$.,\nalongside novel applications in DNA storage, have reignited the interest in\nthis longstanding open problem. In spite of recent advances, the amount of\nredundancy in existing codes is still orders of magnitude away from being\noptimal. In this paper, a novel approach for constructing binary two-deletion\ncorrecting codes is proposed. By this approach, parity symbols are computed\nfrom indicator vectors (i.e., vectors that indicate the positions of certain\npatterns) of the encoded message, rather than from the message itself. Most\ninterestingly, the parity symbols and the proof of correctness are a direct\ngeneralization of their counterparts in the Varshamov-Tenengolts construction.\nOur techniques require $7\\log(n)+o(\\log(n)$ redundant bits to encode an~$n$-bit\nmessage, which is near-optimal.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  When generating adversarial examples to attack deep neural networks (DNNs),\nLp norm of the added perturbation is usually used to measure the similarity\nbetween original image and adversarial example. However, such adversarial\nattacks perturbing the raw input spaces may fail to capture structural\ninformation hidden in the input. This work develops a more general attack\nmodel, i.e., the structured attack (StrAttack), which explores group sparsity\nin adversarial perturbations by sliding a mask through images aiming for\nextracting key spatial structures. An ADMM (alternating direction method of\nmultipliers)-based framework is proposed that can split the original problem\ninto a sequence of analytically solvable subproblems and can be generalized to\nimplement other attacking methods. Strong group sparsity is achieved in\nadversarial perturbations even with the same level of Lp norm distortion as the\nstate-of-the-art attacks. We demonstrate the effectiveness of StrAttack by\nextensive experimental results onMNIST, CIFAR-10, and ImageNet. We also show\nthat StrAttack provides better interpretability (i.e., better correspondence\nwith discriminative image regions)through adversarial saliency map (Papernot et\nal., 2016b) and class activation map(Zhou et al., 2016).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  On-demand video accounts for the majority of wireless data traffic. Video\ndistribution schemes based on caching combined with device-to-device (D2D)\ncommunications promise order-of-magnitude greater spectral efficiency for video\ndelivery, but hinge on the principle of `concentrated demand distributions.'\nThis paper presents, for the first time, the analysis and evaluations of the\nthroughput--outage tradeoff of such schemes based on measured cellular demand\ndistributions. In particular, we use a dataset with more than 100 million\nrequests from the BBC iPlayer, a popular video streaming service in the U.K.,\nas the foundation of the analysis and evaluations. We present an achievable\nscaling law based on the practical popularity distribution, and show that such\nscaling law is identical to those reported in the literature. We find that also\nfor the numerical evaluations based on a realistic setup, order-of-magnitude\nimprovements can be achieved. Our results indicate that the benefits promised\nby the caching-based D2D in the literature could be retained for cellular\nnetworks in practice.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove that any finite system of interacted automata can not leave some\nfinite arrear of Calley graph of periodic group. If group has non-periodic\nelement, then its Calley graph can be explored by some finite automata with 3\npebbles. If group is finitelly generated and aperiodic then it can not be\nexplored by any system of finite automata.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Consider $L$ groups of point sources or spike trains, with the\n$l^{\\text{th}}$ group represented by $x_l(t)$. For a function $g:\\mathbb{R}\n\\rightarrow \\mathbb{R}$, let $g_l(t) = g(t/\\mu_l)$ denote a point spread\nfunction with scale $\\mu_l > 0$, and with $\\mu_1 < \\cdots < \\mu_L$. With $y(t)\n= \\sum_{l=1}^{L} (g_l \\star x_l)(t)$, our goal is to recover the source\nparameters given samples of $y$, or given the Fourier samples of $y$. This\nproblem is a generalization of the usual super-resolution setup wherein $L =\n1$; we call this the multi-kernel unmixing super-resolution problem. Assuming\naccess to Fourier samples of $y$, we derive an algorithm for this problem for\nestimating the source parameters of each group, along with precise\nnon-asymptotic guarantees. Our approach involves estimating the group\nparameters sequentially in the order of increasing scale parameters, i.e., from\ngroup $1$ to $L$. In particular, the estimation process at stage $1 \\leq l \\leq\nL$ involves (i) carefully sampling the tail of the Fourier transform of $y$,\n(ii) a \\emph{deflation} step wherein we subtract the contribution of the groups\nprocessed thus far from the obtained Fourier samples, and (iii) applying\nMoitra's modified Matrix Pencil method on a deconvolved version of the samples\nin (ii).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we present the results of the spectral studies of erosive\ndischarge with tin alloy electrodes and of the generated JFs, and\nexperimentally determine internal energy of JFs using the calorimetric\ntechnique.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Current face recognition systems robustly recognize identities across a wide\nvariety of imaging conditions. In these systems recognition is performed via\nclassification into known identities obtained from supervised identity\nannotations. There are two problems with this current paradigm: (1) current\nsystems are unable to benefit from unlabelled data which may be available in\nlarge quantities; and (2) current systems equate successful recognition with\nlabelling a given input image. Humans, on the other hand, regularly perform\nidentification of individuals completely unsupervised, recognising the identity\nof someone they have seen before even without being able to name that\nindividual. How can we go beyond the current classification paradigm towards a\nmore human understanding of identities? We propose an integrated Bayesian model\nthat coherently reasons about the observed images, identities, partial\nknowledge about names, and the situational context of each observation. While\nour model achieves good recognition performance against known identities, it\ncan also discover new identities from unsupervised data and learns to associate\nidentities with different contexts depending on which identities tend to be\nobserved together. In addition, the proposed semi-supervised component is able\nto handle not only acquaintances, whose names are known, but also unlabelled\nfamiliar faces and complete strangers in a unified framework.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Exact recovery of tensor decomposition (TD) methods is a desirable property\nin both unsupervised learning and scientific data analysis. The numerical\ndefects of TD methods, however, limit their practical applications on\nreal-world data. As an alternative, convex tensor decomposition (CTD) was\nproposed to alleviate these problems, but its exact-recovery property is not\nproperly addressed so far. To this end, we focus on latent convex tensor\ndecomposition (LCTD), a practically widely-used CTD model, and rigorously prove\na sufficient condition for its exact-recovery property. Furthermore, we show\nthat such property can be also achieved by a more general model than LCTD. In\nthe new model, we generalize the classic tensor (un-)folding into reshuffling\noperation, a more flexible mapping to relocate the entries of the matrix into a\ntensor. Armed with the reshuffling operations and exact-recovery property, we\nexplore a totally novel application for (generalized) LCTD, i.e., image\nsteganography. Experimental results on synthetic data validate our theory, and\nresults on image steganography show that our method outperforms the\nstate-of-the-art methods.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a class of numerical schemes for nonlocal HJB variational\ninequalities (HJBVIs) with monotone drivers. The solution and free boundary of\nthe HJBVI are constructed from a sequence of penalized equations, for which a\ncontinuous dependence result is derived and the penalization error is\nestimated. The penalized equation is then discretized by a class of\nsemi-implicit monotone approximations. We present a novel analysis technique\nfor the well-posedness of the discrete equation, and demonstrate the\nconvergence of the scheme, which subsequently gives a constructive proof for\nthe existence of a solution to the penalized equation and variational\ninequality. We further propose an efficient iterative algorithm with local\nsuperlinear convergence for solving the discrete equation. Numerical\nexperiments are presented for an optimal investment problem under ambiguity and\na recursive consumption-portfolio allocation problem.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We analyze hydrodynamic simulations of turbulent, star-forming molecular\nclouds that are post-processed with the photo-dissociation region\nastrochemistry code 3D-PDR. We investigate the sensitivity of 15 commonly\napplied turbulence statistics to post-processing assumptions, namely variations\nin gas temperature, abundance and external radiation field. We produce\nsynthetic $^{12}$CO(1-0) and CI($^{3}$P$_{1}$-$^{3}$P$_{0}$) observations and\nexamine how the variations influence the resulting emission distributions. To\ncharacterize differences between the datasets, we perform statistical\nmeasurements, identify diagnostics sensitive to our chemistry parameters, and\nquantify the statistic responses by using a variety of distance metrics. We\nfind that multiple turbulent statistics are sensitive not only to the chemical\ncomplexity but also to the strength of the background radiation field. The\nstatistics with meaningful responses include principal component analysis,\nspatial power spectrum and bicoherence. A few of the statistics, such as the\nvelocity coordinate spectrum, are primarily sensitive to the type of tracer\nbeing utilized, while others, like the delta-variance, strongly respond to the\nbackground radiation field. Collectively, these findings indicate that more\nrealistic chemistry impacts the responses of turbulent statistics and is\nnecessary for accurate statistical comparisons between models and observed\nmolecular clouds.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The present paper is a continuation of our recent paper \\cite{DaoReissig}. We\nwill consider the following Cauchy problems for semi-linear structurally damped\n$\\sigma$-evolution models: \\begin{equation*} u_{tt}+ (-\\Delta)^\\sigma u+ \\mu\n(-\\Delta)^\\delta u_t = f(u,u_t),\\, u(0,x)= u_0(x),\\, u_t(0,x)=u_1(x)\n\\end{equation*} with $\\sigma \\ge 1$, $\\mu>0$ and $\\delta \\in\n(\\frac{\\sigma}{2},\\sigma]$. Our aim is to study two main models including\n$\\sigma$-evolution models with structural damping $\\delta \\in\n(\\frac{\\sigma}{2},\\sigma)$ and those with visco-elastic damping\n$\\delta=\\sigma$. Here the function $f(u,u_t)$ stands for power nonlinearities\n$|u|^{p}$ and $|u_t|^{p}$ with a given number $p>1$. We are interested in\ninvestigating the global (in time) existence of small data solutions to the\nabove semi-linear models from suitable spaces basing on $L^q$ space by assuming\nadditional $L^{m}$ regularity on the initial data, with $q\\in (1,\\infty)$ and\n$m\\in [1,q)$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  By local measurements on party $A$ of a system $AB$ and classical\ncommunication between its two parties, one can achieve a nonlocal advantage of\nquantum coherence (NAQC) on party $B$. For the $l_1$ norm of coherence and the\nrelative entropy of coherence, we generalized the framework of NAQC for two\nqubits and derived the criteria which capture NAQC in the $(d\\times\nd)$-dimensional states when $d$ is a power of a prime. We also presented a new\nframework for formulating NAQC, and showed through explicit examples its\ncapacity on capturing the NAQC states. Moreover, we proved that any bipartite\nstate with NAQC is quantum entangled, thus the obtained criteria can also be\nused as an entanglement witness.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Maximum likelihood estimation is an important statistical technique for\nestimating missing data, for example in climate and environmental applications,\nwhich are usually large and feature data points that are irregularly spaced. In\nparticular, the Gaussian log-likelihood function is the \\emph{de facto} model,\nwhich operates on the resulting sizable dense covariance matrix. The advent of\nhigh performance systems with advanced computing power and memory capacity have\nenabled full simulations only for rather small dimensional climate problems,\nsolved at the machine precision accuracy. The challenge for high dimensional\nproblems lies in the computation requirements of the log-likelihood function,\nwhich necessitates ${\\mathcal O}(n^2)$ storage and ${\\mathcal O}(n^3)$\noperations, where $n$ represents the number of given spatial locations. This\nprohibitive computational cost may be reduced by using approximation techniques\nthat not only enable large-scale simulations otherwise intractable but also\nmaintain the accuracy and the fidelity of the spatial statistics model. In this\npaper, we extend the Exascale GeoStatistics software framework (i.e.,\nExaGeoStat) to support the Tile Low-Rank (TLR) approximation technique, which\nexploits the data sparsity of the dense covariance matrix by compressing the\noff-diagonal tiles up to a user-defined accuracy threshold. The underlying\nlinear algebra operations may then be carried out on this data compression\nformat, which may ultimately reduce the arithmetic complexity of the maximum\nlikelihood estimation and the corresponding memory footprint. Performance\nresults of TLR-based computations on shared and distributed-memory systems\nattain up to 13X and 5X speedups, respectively, compared to full accuracy\nsimulations using synthetic and real datasets (up to 2M), while ensuring\nadequate prediction accuracy.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We describe an exact simulation algorithm for the increments of Brownian\nmotion on a sphere of arbitrary dimension, based on the skew-product\ndecomposition of the process with respect to the standard geodesic distance.\nThe radial process is closely related to a Wright-Fisher diffusion, increments\nof which can be simulated exactly using the recent work of Jenkins & Span\\`{o}\n(2017) [JS17]. The rapid spinning phenomenon of the skew-product decomposition\nthen yields the algorithm for the increments of the process on the sphere.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Dynamical sampling, as introduced by Aldroubi et al., deals with frame\nproperties of sequences of the form $\\{T^i f_1\\}_{i\\in \\mathbb{N}}$, where\n$f_1$ belongs to Hilbert space $\\h$ and $T:\\h\\rightarrow\\h$ belongs to certain\nclasses of the bounded operators. Christensen et al., study frames for $\\h$\nwith index set $\\mathbb{N}$ (or $\\mathbb{Z}$), that have representations in the\nform $\\{T^{i-1}f_1\\}_{i\\in \\mathbb{N}}$ (or $\\{T^if_0\\}_{i\\in \\mathbb{Z}}$). As\nframes of subspaces, fusion frames and generalized translation invariant\nsystems are the spacial cases of $g$-frames, the purpose of this paper is to\nstudy $g$-frames $\\Lambda=\\{\\Lambda_i\\in B(\\h,\\K): i\\in I\\}$ $(I=\\mathbb{N}$ or\n$\\mathbb{Z}$) having the form $\\Lambda_{i+1}=\\Lambda_1 T^{i},$ for $T\\in\nB(\\h).$\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We discuss our recent results regarding chiral and $U(1)_A$ restoration, both\nfrom the formal point of view of QCD Ward Identities (WI) and from an Effective\nTheory analysis provided by $U(3)$ Chiral Perturbation Theory (ChPT) at finite\ntemperature. Our results lead to relevant conclusions regarding the behavior of\nchiral partners (in terms of susceptibilities) in the limit of exact\nrestoration and provide useful results for lattice analysis. In addition, it\nhelps to understand the temperature dependence of lattice screening masses in\nterms of quark condensate combinations. The U(3) ChPT calculation supports the\nconclusions obtained within the WI analysis. Finally, the role of the thermal\n$f_0(500)$ state in chiral symmetry restoration, regarding the scalar\nsusceptibility, is also discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Photon operators with the proper $J^{PC}$ quantum numbers are constructed,\nincluding one made of elementary plaquettes. In compact U(1) lattice gauge\ntheory, these explicit photon operators are shown to permit direct confirmation\nof the massive and massless states on each side of the phase transition. In the\nabelian Higgs model, these explicit photon operators avoid some excited state\ncontamination seen with the traditional composite operator, and allow more\ndetailed future studies of the Higgs mechanism.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A basic result is that the sample variance for i.i.d. observations is an\nunbiased estimator of the variance of the underlying distribution (see for\ninstance Casella and Berger (2002)). But what happens if the observations are\nneither independent nor identically distributed. What can we say? Can we in\nparticular compute explicitly the first two moments of the sample mean and\nhence generalize formulae provided in Tukey (1957a), Tukey (1957b) for the\nfirst two moments of the sample variance? We also know that the sample mean and\nvariance are independent if they are computed on an i.i.d. normal distribution.\nThis is one of the underlying assumption to derive the Student distribution\nStudent alias W. S. Gosset (1908). But does this result hold for any other\nunderlying distribution? Can we still have independent sample mean and variance\nif the distribution is not normal? This paper precisely answers these questions\nand extends previous work of Cho, Cho, and Eltinge (2004). We are able to\nderive a general formula for the first two moments and variance of the sample\nvariance under no specific assumption. We also provide a faster proof of a\nseminal result of Lukacs (1942) by using the log characteristic function of the\nunbiased sample variance estimator.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate an ultracold and dilute Bose gas by taking into account a\nfinite-range two-body interaction. The coupling constants of the resulting\nLagrangian density are related to measurable scattering parameters by following\nthe effective-field-theory approach. A perturbative scheme is then developed up\nto the Gaussian level, where both quantum and thermal fluctuations are\ncrucially affected by finite-range corrections. In particular, the relation\nbetween spontaneous symmetry breaking and the onset of superfluidity is\nemphasized by recovering the renowned Landau's equation for the superfluid\ndensity in terms of the condensate one.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The magnetoresistance of a three-dimensional Rashba material placed on top of\na ferromagnetic insulator is theoretically investigated. In addition to the\nintrinsic Rashba spin-orbit interaction, we also consider extrinsic spin-orbit\ncoupling via side-jump and skew scattering, and the Elliott-Yafet spin\nrelaxation mechanism. The latter is anisotropic due to the mass anisotropy\nwhich reflects the noncentrosymmetric crystal structure of three-dimensional\nRashba metals. A quasiclassical approach is employed to derive a set of coupled\nspin-diffusion equations, which are supplemented by boundary conditions that\naccount for the spin-transfer torque at the interface of the bilayer. The\nmagnetoresistance is fully determined by the current-induced spin polarization,\ni.e., it cannot in general be ascribed to a single (bulk) spin Hall angle. Our\ntheoretical results reproduce several features of the experiments, at least\nqualitatively, and contain established phenomenological results in the relevant\nlimiting cases. In particular, the anisotropy of the Elliott-Yafet spin\nrelaxation mechanism plays a major role for the interpretation of the observed\nmagnetoresistance.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Low-Power Wide-Area Networks (LPWANs) are being successfully used for the\nmonitoring of large-scale systems that are delay-tolerant and which have\nlow-bandwidth requirements. The next step would be instrumenting these for the\ncontrol of Cyber-Physical Systems (CPSs) distributed over large areas which\nrequire more bandwidth, bounded delays and higher reliability or at least more\nrigorous guarantees therein. This paper presents LPWA-MAC, a novel Low Power\nWide-Area network MAC protocol, that ensures bounded end-to-end delays, high\nchannel utility and supports many of the different traffic patterns and\ndata-rates typical of CPS.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This application of renormalization techniques offers a modern take on the\nclassical Arbelos geometry problem. Keeping within the context of the original\nproblem, two semicircles, meeting at chord T, are together circumscribed by a\nthird semicircle. Separate from the original Arbelos result, both circumscribed\nsemicircle areas are found in terms of chord T and the third circumscribing\nsemicircle radius R. This approach eliminates the additional variables of the\ncircumscribed semicircle radii.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Magnitude homology was introduced by Hepworth and Willerton in the case of\ngraphs, and was later extended by Leinster and Shulman to metric spaces and\nenriched categories. Here we introduce the dual theory, magnitude cohomology,\nwhich we equip with the structure of an associative unital graded ring. Our\nfirst main result is a 'recovery theorem' showing that the magnitude cohomology\nring of a finite metric space completely determines the space itself. The\nmagnitude cohomology ring is non-commutative in general, for example when\napplied to finite metric spaces, but in some settings it is commutative, for\nexample when applied to ordinary categories. Our second main result explains\nthis situation by proving that the magnitude cohomology ring of an enriched\ncategory is graded-commutative whenever the enriching category is cartesian. We\nend the paper by giving complete computations of magnitude cohomology rings for\nseveral large classes of graphs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study geometric aspects of the Laughlin fractional quantum Hall (FQH)\nstates using a description of these states in terms of a matrix quantum\nmechanics model known as the Chern-Simons matrix model (CSMM). This model was\nproposed by Polychronakos as a regularization of the noncommutative\nChern-Simons theory description of the Laughlin states proposed earlier by\nSusskind. Both models can be understood as describing the electrons in a FQH\nstate as forming a noncommutative fluid, i.e., a fluid occupying a\nnoncommutative space. Here we revisit the CSMM in light of recent work on\ngeometric response in the FQH effect, with the goal of determining whether the\nCSMM captures this aspect of the physics of the Laughlin states. For this model\nwe compute the Hall viscosity, Hall conductance in a non-uniform electric\nfield, and the Hall viscosity in the presence of anisotropy (or intrinsic\ngeometry). Our calculations show that the CSMM captures the guiding center\ncontribution to the known values of these quantities in the Laughlin states,\nbut lacks the Landau orbit contribution. The interesting correlations in a\nLaughlin state are contained entirely in the guiding center part of the\nstate/wave function, and so we conclude that the CSMM accurately describes the\nmost important aspects of the physics of the Laughlin FQH states, including the\nHall viscosity and other geometric properties of these states which are of\ncurrent interest.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we implement an optical fiber communication system as an\nend-to-end deep neural network, including the complete chain of transmitter,\nchannel model, and receiver. This approach enables the optimization of the\ntransceiver in a single end-to-end process. We illustrate the benefits of this\nmethod by applying it to intensity modulation/direct detection (IM/DD) systems\nand show that we can achieve bit error rates below the 6.7\\% hard-decision\nforward error correction (HD-FEC) threshold. We model all componentry of the\ntransmitter and receiver, as well as the fiber channel, and apply deep learning\nto find transmitter and receiver configurations minimizing the symbol error\nrate. We propose and verify in simulations a training method that yields robust\nand flexible transceivers that allow---without reconfiguration---reliable\ntransmission over a large range of link dispersions. The results from\nend-to-end deep learning are successfully verified for the first time in an\nexperiment. In particular, we achieve information rates of 42\\,Gb/s below the\nHD-FEC threshold at distances beyond 40\\,km. We find that our results\noutperform conventional IM/DD solutions based on 2 and 4 level pulse amplitude\nmodulation (PAM2/PAM4) with feedforward equalization (FFE) at the receiver. Our\nstudy is the first step towards end-to-end deep learning-based optimization of\noptical fiber communication systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Dirac fermion is an important fundamental particle appearing in\nhigh-energy physics and topological insulator physics. In particular, a Dirac\nfermion in a one-dimensional lattice system exhibits the essential properties\nof topological physics. However, the system has not been quantum simulated in\nexperiments yet. Herein, we propose a one-dimensional generalized lattice\nWilson-Dirac fermion model and study its topological phase structure. We show\nthe experimental setups of an atomic quantum simulator for the model, in which\ntwo parallel optical lattices with the same tilt for trapping cold fermion\natoms and a laser-assisted hopping scheme are used. Interestingly, we find that\nthe model exhibits nontrivial topological phases characterized by gapless edge\nmodes and a finite winding number in the broad regime of the parameter space.\nSome of the phase diagrams closely resemble those of the Haldane model. We also\ndiscuss topological charge pumping and a lattice Gross-Neveu model in the\nsystem of generalized Wilson-Dirac fermions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The key issue in Dynamic Ensemble Selection (DES) is defining a suitable\ncriterion for calculating the classifiers' competence. There are several\ncriteria available to measure the level of competence of base classifiers, such\nas local accuracy estimates and ranking. However, using only one criterion may\nlead to a poor estimation of the classifier's competence. In order to deal with\nthis issue, we have proposed a novel dynamic ensemble selection framework using\nmeta-learning, called META-DES. An important aspect of the META-DES framework\nis that multiple criteria can be embedded in the system encoded as different\nsets of meta-features. However, some DES criteria are not suitable for every\nclassification problem. For instance, local accuracy estimates may produce poor\nresults when there is a high degree of overlap between the classes. Moreover, a\nhigher classification accuracy can be obtained if the performance of the\nmeta-classifier is optimized for the corresponding data. In this paper, we\npropose a novel version of the META-DES framework based on the formal\ndefinition of the Oracle, called META-DES.Oracle. The Oracle is an abstract\nmethod that represents an ideal classifier selection scheme. A meta-feature\nselection scheme using an overfitting cautious Binary Particle Swarm\nOptimization (BPSO) is proposed for improving the performance of the\nmeta-classifier. The difference between the outputs obtained by the\nmeta-classifier and those presented by the Oracle is minimized. Thus, the\nmeta-classifier is expected to obtain results that are similar to the Oracle.\nExperiments carried out using 30 classification problems demonstrate that the\noptimization procedure based on the Oracle definition leads to a significant\nimprovement in classification accuracy when compared to previous versions of\nthe META-DES framework and other state-of-the-art DES techniques.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The seminal work \\cite{bm} by Brezis and Merle has been pioneering in\nstudying the bubbling phenomena of the mean field equation with singular\nsources. When the vortex points are not collapsing, the mean field equation\npossesses the property of the so-called \"bubbling implies mass concentration\".\nRecently, Lin and Tarantello in \\cite{lt} pointed out that the \"bubbling\nimplies mass concentration\" phenomena might not hold in general if the collapse\nof singularities occurs. In this paper, we shall construct the first concrete\nexample of non-concentrated bubbling solution of the mean field equation with\ncollapsing singularities.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we propose an improved version of the power index related to\nthe Banzhaf power index for weighted voting systems. This index now takes into\naccount the mutual persuasion power matrix(PPM) existing among the voters. This\nimproved index is calculated for European Union voting by basing the PPM on\nimmigration data among the EU countries. We also provide better approximation\nbounds for the Monte Carlo approximation method for computing power indices.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Accurate and efficient eye gaze estimation is important for emerging consumer\nelectronic systems such as driver monitoring systems and novel user interfaces.\nSuch systems are required to operate reliably in difficult, unconstrained\nenvironments with low power consumption and at minimal cost. In this paper a\nnew hardware friendly, convolutional neural network model with minimal\ncomputational requirements is introduced and assessed for efficient\nappearance-based gaze estimation. The model is tested and compared against\nexisting appearance based CNN approaches, achieving better eye gaze accuracy\nwith significantly fewer computational requirements. A brief updated literature\nreview is also provided.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The paper is devoted to dynamic games. We consider a general enough\nframework, which is not limited to e.g. differential games and could\naccommodate both discrete and continuous time. Assuming common dynamics, we\nstudy two game families with total payoffs that are defined either as the\nCes\\`{a}ro average (long run average game family) or Abel average (discounting\ngame family) of the running costs. We study a robust strategy that would\nprovide a near-optimal total payoff for all sufficiently small discounts and\nfor all sufficiently large planning horizons. Assuming merely the Dynamic\nProgramming Principle, we prove the following Tauberian theorem: if a strategy\nis uniformly optimal for one of the families (when discount goes to zero for\ndiscounting games, when planning horizon goes to infinity in long run average\ngames) and its value functions converge uniformly, then, for the other family,\nthis strategy is also uniformly optimal and its value functions converge\nuniformly to the same limit.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Microscopic particles suspended in liquids are the prime example of an\noverdamped system because viscous forces dominate over inertial effects. Apart\nfrom their use as model systems, they receive considerable attention as\nsensitive probes from which forces on molecular scales can be inferred. The\ninterpretation of such experiments rests on the assumption, that, even if the\nparticles are driven, the liquid remains in equilibrium, and all modes are\noverdamped. Here, we experimentally demonstrate that this is no longer valid\nwhen a particle is forced through a viscoelastic fluid. Even at small driving\nvelocities where Stokes law remains valid, we observe particle oscillations\nwith periods up to several tens of seconds. We attribute these to\nnon-equilibrium fluctuations of the fluid, which are excited by the particle's\nmotion. The observed oscillatory dynamics is in quantitative agreement with an\noverdamped Langevin equation with negative friction-memory term and which is\nequivalent to the motion of a stochastically driven underdamped oscillator.\nThis fundamentally new oscillatory mode will largely expand the variety of\nmodel systems but has also considerable implications on how molecular forces\nare determined by colloidal probe particles under natural viscoelastic\nconditions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study several aspects of the $k$-th Cheeger constant of a complex X, a\nparameter that quantifies the distance of $X$ from a complex $Y$ with\nnontrivial $k$-th cohomology over $\\mathbb{Z}_2$. Our results include general\nmethods for bounding the cosystolic norm of a cochain and for bounding the\nCheeger constant of a complex, a discussion of expansion of pseudomanifolds and\ngeometric lattices, probabilistic upper bounds on Cheeger constants, and\napplication of non-Abelian expansion to random complexes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Given a graph $G=(V,E)$, two vertices $s,t\\in V$, and two integers $k,\\ell$,\nthe Short Secluded Path problem is to find a simple $s$-$t$-path with at most\n$k$ vertices and $\\ell$ neighbors. We study the parameterized complexity of the\nproblem with respect to four structural graph parameters: the vertex cover\nnumber, treewidth, feedback vertex number, and feedback edge number. In\nparticular, we completely settle the question of the existence of problem\nkernels with size polynomial in these parameters and their combinations with\n$k$ and $\\ell$. We also obtain a $2^{O(w)}\\cdot \\ell^2\\cdot n$-time algorithm\nfor graphs of treewidth $w$, which yields subexponential-time algorithms in\nseveral graph classes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Polydisperse linear polymer melts can be microscopically described by the\ntube model and fractal reptation dynamics, while on the macroscopic side the\ngeneralized Maxwell model is capable of correctly displaying most of the\nrheological behavior. In this paper, a Laplace transform method is derived and\ndifferent macroscopic starting points for molecular mass distribution\ncalculation are compared to a classical light scattering evaluation. The\nunderlying assumptions comprise the modern understanding on polymer dynamics in\nentangled systems but can be stated in a mathematically generalized way. The\nresulting method is very easy to use due to its mathematical structure and it\nis capable of calculating multimodal molecular mass distributions of linear\npolymer melts.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The dust sub-millimetre polarisation of star-forming clouds carries\ninformation on dust and the role of magnetic fields in cloud evolution. With\nobservations of a dense filamentary cloud G035.39-00.33, we aim to characterise\nthe dust emission properties and the variations of the polarisation fraction.\nJCMT SCUBA-2/POL-2 data at 850um are combined with Planck 850um (353GHz) data\nto map polarisation fractions. With previous SCUBA-2 observations (450um and\n850um) and Herschel data, the column densities are determined via modified\nblackbody fits and via radiative transfer modelling. Models are constructed to\nexamine how the polarisation angles and fractions depend on potential magnetic\nfield geometries and grain alignment. POL-2 data show clear changes in the\nmagnetic field orientation. The filament has a peak column density of N(H2)~7\n10^22 cm-2, a minimum dust temperature of T~12 K, and a mass of some 4300Msun\nfor the area N(H2)> 5 10^21 cm-2. The estimated average value of the dust\nopacity spectral index is beta ~ 1.9. The ratio of sub-millimetre and J band\noptical depths is tau(250 um)/tau(J) ~ 2.5 10^-3, more than four times the\ntypical values for diffuse medium. The polarisation fraction decreases as a\nfunction of column density to p ~ 1% in the central filament. Because of noise,\nthe observed decrease of p(N) is significant only at N(H2)>2 10^22 cm-2. The\nobservations suggest that the grain alignment is not constant. Although the\ndata can be explained with a complete loss of alignment at densities above ~\n10^4 cm-3 or using the predictions of radiative torques alignment, the\nuncertainty of the field geometry and the spatial filtering of the SCUBA-2 data\nprevent strong conclusions. G035.39-00.33 shows strong signs of dust evolution\nand the low polarisation fraction is suggestive of a loss of polarised emission\nfrom its densest parts.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Typically, AI researchers and roboticists try to realize intelligent behavior\nin machines by tuning parameters of a predefined structure (body plan and/or\nneural network architecture) using evolutionary or learning algorithms. Another\nbut not unrelated longstanding property of these systems is their brittleness\nto slight aberrations, as highlighted by the growing deep learning literature\non adversarial examples. Here we show robustness can be achieved by evolving\nthe geometry of soft robots, their control systems, and how their material\nproperties develop in response to one particular interoceptive stimulus\n(engineering stress) during their lifetimes. By doing so we realized robots\nthat were equally fit but more robust to extreme material defects (such as\nmight occur during fabrication or by damage thereafter) than robots that did\nnot develop during their lifetimes, or developed in response to a different\ninteroceptive stimulus (pressure). This suggests that the interplay between\nchanges in the containing systems of agents (body plan and/or neural\narchitecture) at different temporal scales (evolutionary and developmental)\nalong different modalities (geometry, material properties, synaptic weights)\nand in response to different signals (interoceptive and external perception)\nall dictate those agents' abilities to evolve or learn capable and robust\nstrategies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Hyperbolic transport-reaction equations are abundant in the description of\nmovement of motile organisms. Here, we focus on system of four coupled\ntransport-reaction equations that arises from an age-structuring of a species\nof turning individuals. The highlight consists of the explicit construction and\ncharacterization of counter-propagating traveling waves, patterns which have\nbeen observed in bacterial colonies. Stability analysis reveals conditions for\nthe wave formation as well as pulsating-in-time spatially constant solutions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study boundary properties of plurisubharmonic functions near real\nsubmanifolds of almost complex manifolds.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We provide several extensions of the modular method which were motivated by\nthe problem of completing previous work to prove that, for any integer $n \\geq\n2$, the equation \\[ x^{13} + y^{13} = 3 z^n \\] has no non-trivial solutions. In\nparticular, we present four elimination techniques which are based on: (1)\nestablishing reducibility of certain residual Galois representations over a\ntotally real field; (2) generalizing image of inertia arguments to the setting\nof abelian surfaces; (3) establishing congruences of Hilbert modular forms\nwithout the use of often impractical Sturm bounds; and (4) a unit sieve\nargument which combines information from classical descent and the modular\nmethod.\n  The extensions are of broader applicability and provide further evidence that\nit is possible to obtain a complete resolution of a family of generalized\nFermat equations by remaining within the framework of the modular method. As a\nfurther illustration of this, we complete a theorem of Anni-Siksek to show\nthat, for $\\ell, m\\ge 5$, the only solutions to the equation $x^{2\\ell} +\ny^{2m} = z^{13}$ are the trivial ones.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Inner Oort Cloud objects (IOCs) are Trans-Plutonian for their entire orbits.\nThey are beyond the strong gravitational influences of the known planets yet\nclose enough to the Sun that outside forces are minimal. Here we report the\ndiscovery of the third known IOC after Sedna and 2012 VP113, called 2015 TG387.\n2015 TG387 has a perihelion of $65 \\pm 1$ au and semi-major axis of $1170 \\pm\n70$ au. The longitude of perihelion angle, $\\bar{\\omega}$, for 2015 TG387 is\nbetween that of Sedna and 2012 VP113, and thus similar to the main group of\nclustered extreme trans-Neptunian objects (ETNOs), which may be shepherded into\nsimilar orbital angles by an unknown massive distant planet, called Planet X or\nPlanet Nine. 2015 TG387's orbit is stable over the age of the solar system from\nthe known planets and Galactic tide. When including outside stellar encounters\nover 4 Gyrs, 2015 TG387's orbit is usually stable, but its dynamical evolution\ndepends on the stellar encounter scenarios used. Surprisingly, when including a\nmassive Planet X beyond a few hundred au on an eccentric orbit that is\nanti-aligned in longitude of perihelion with most of the known ETNOs, we find\n2015 TG387 is typically stable for Planet X orbits that render the other ETNOs\nstable as well. Notably, 2015 TG387's argument of perihelion is constrained and\nits longitude of perihelion librates about 180 degs from Planet X's longitude\nof perihelion, keeping 2015 TG387 anti-aligned with Planet X over the age of\nthe solar system. We find a power law slope near 3 for the semi-major axis\ndistribution of IOCs, meaning there are many more high than low semi-major axis\nIOCs. There are about 2 million IOCs larger than 40 km, giving a mass of\n$10^{22}$ kg. The IOCs inclination distribution is similar to the scattered\ndisk, with an average inclination of 19 degs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study in detail the recently proposed mechanism of generating superheavy\nDark Matter with the mass larger than the Hubble rate at the end of inflation.\nA real scalar field constituting Dark Matter linearly couples to the inflaton.\nAs a result of this interaction, the scalar gets displaced from its zero\nexpectation value. This offset feeds into the energy density of Dark Matter.\nThis mechanism is universal and can be implemented in a generic inflationary\nscenario. Phenomenology of the model is comprised of Dark Matter decay into\ninflatons, which in turn decay into Standard Model species triggering cascades\nof high energy particles contributing to the cosmic ray flux. We evaluate the\nlifetime of Dark Matter and obtain limits on the inflationary scenarios, where\nthis mechanism does not lead to the conflict with the Dark Matter stability\nconsiderations/studies of cosmic ray propagation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Privacy is a major concern in sharing human subject data to researchers for\nsecondary analyses. A simple binary consent (opt-in or not) may significantly\nreduce the amount of sharable data, since many patients might only be concerned\nabout a few sensitive medical conditions rather than the entire medical\nrecords. We propose event-level privacy protection, and develop a feature\nablation method to protect event-level privacy in electronic medical records.\nUsing a list of 13 sensitive diagnoses, we evaluate the feasibility and the\nefficacy of the proposed method. As feature ablation progresses, the\nidentifiability of a sensitive medical condition decreases with varying speeds\non different diseases. We find that these sensitive diagnoses can be divided\ninto 3 categories: (1) 5 diseases have fast declining identifiability (AUC\nbelow 0.6 with less than 400 features excluded); (2) 7 diseases with\nprogressively declining identifiability (AUC below 0.7 with between 200 and 700\nfeatures excluded); and (3) 1 disease with slowly declining identifiability\n(AUC above 0.7 with 1000 features excluded). The fact that the majority (12 out\nof 13) of the sensitive diseases fall into the first two categories suggests\nthe potential of the proposed feature ablation method as a solution for\nevent-level record privacy protection.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We resolved the hydrogen bond transition from the mode of ordinary water to\nits hydration in terms of its phonon stiffness (vibration frequency shift),\norder of fluctuation (line width), and number fraction (phonon abundance) upon\nchage injection by solvation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It is now well established that a Josephson junction made from conventional\nspin-singlet superconductors containing ferromagnetic layers can carry\nspin-triplet supercurrent under certain conditions. The first experimental\nsignature of that fact is the propagation of such supercurrent over long\ndistances through strong ferromagnetic materials. Surprisingly, one of the most\nsalient predictions of the theory has yet to be verified experimentally --\nnamely that a Josephson junction containing three magnetic layers with coplanar\nmagnetizations should exhibit a ground-state phase shift of either zero or pi\ndepending on the relative orientations of those magnetizations. Here we\ndemonstrate this property using Josephson junctions containing three different\ntypes of magnetic layers, chosen so that the magnetization of one layer can be\nswitched by 180 degrees without disturbing the other two. Phase-sensitive\ndetection is accomplished using a superconducting quantum interference device,\nor SQUID. Such a phase-controllable junction could be used as the memory\nelement in a fully-superconducting computer.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Thermal Radiative Transfer (TRT) is the dominant energy transfer mechanism in\nhigh-energy density physics with applications in inertial confinement fusion\nand astrophysics. The stiff interactions between the material and radiation\nfields make TRT problems challenging to model. In this study, we propose a\nmulti-dimensional extension of the deterministic particle (DP) method. The DP\nmethod combines aspects from both particle and deterministic methods. If the\nemission source is known \\apriori, and no physical scattering is present, the\nintensity of a particle can be integrated analytically. This introduces no\nstatistical noise compared to Monte-Carlo methods, while maintaining the\nflexibility of particle methods. The method is closely related to the popular\nmethod of long characteristics. The combination of the DP-method with a\ndiscretely-consistent, nonlinear, gray low-order system enables an efficient\nsolution algorithm for multi-frequency TRT problems. We demonstrate with\nnumerical examples that the use of a linear-source approximation based on\nspatial moments improves the behavior of our method in the thick diffusion\nlimit significantly.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider a controlled evolution problem for a set\n$\\Omega(t)\\in\\mathbb{R}^d$, originally motivated by a model where a dog\ncontrols a flock of sheep. Necessary conditions and sufficient conditions are\ngiven, in order that the evolution be completely controllable. Similar\ntechniques are then applied to the approximation of a sweeping process. Under\nsuitable assumptions, we prove that there exists a control function such that\nthe corresponding evolution of the set $\\Omega(t)$ is arbitrarily close to the\none determined by the sweeping process.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Emerging reinforcement learning techniques using deep neural networks have\nshown great promise in control optimization. They harness non-local\nregularities of noisy control trajectories and facilitate transfer learning\nbetween tasks. To leverage these powerful capabilities for quantum control\noptimization, we propose a new control framework to simultaneously optimize the\nspeed and fidelity of quantum computation against both leakage and stochastic\ncontrol errors. For a broad family of two-qubit unitary gates that are\nimportant for quantum simulation of many-electron systems, we improve the\ncontrol robustness by adding control noise into training environments for\nreinforcement learning agents trained with trusted-region-policy-optimization.\nThe agent control solutions demonstrate a two-order-of-magnitude reduction in\naverage-gate-error over baseline stochastic-gradient-descent solutions and up\nto a one-order-of-magnitude reduction in gate time from optimal gate synthesis\ncounterparts.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study ascending HNN-extensions $G$ of finitely generated free abelian\ngroups: examples of such $G$ include soluble Baumslag-Solitar groups and\nfundamental groups of orientable prime $3$-manifolds modelled on Sol geometry.\nIn particular, we study the elliptic subgroup $A \\leq G$, consisting of all\nelements that stabilise a point in the Bass-Serre tree of $G$. We consider the\ndensity of $A$ with respect to ball counting measures corresponding to finite\ngenerating sets of $G$, and we show that $A$ is exponentially negligible in $G$\nwith respect to such sequences of measures. As a consequence, we show that the\nset of tuples $(x_0,\\ldots,x_r) \\in G^{r+1}$, such that the $(r+1)$-fold simple\ncommutator $[x_0,\\ldots,x_r]$ vanishes, is exponentially negligible in\n$G^{r+1}$ with respect to sequences of ball counting measures.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this note we show that the cosmological domain wall and the de Sitter\nquantum breaking problems complement each other in theories with discrete\nsymmetries that are spontaneously broken at low energies. Either the symmetry\nis exact and there is a domain wall problem, or it is approximate and there\nexists an inconsistent de Sitter minimum. This leaves no room for many\nextension of the Standard Model based on such discrete symmetries. We give some\nexamples that include NMSSM, spontaneous CP violation at the weak scale and\nsome versions of the Peccei-Quinn scenario with discrete symmetries.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A star edge coloring of a graph $G$ is a proper edge coloring of $G$ such\nthat every path and cycle of length four in $G$ uses at least three different\ncolors. The star chromatic index of a graph $G$, is the smallest integer $k$\nfor which $G$ admits a star edge coloring with $k$ colors. In this paper, we\nfirst obtain some upper bounds for the star chromatic index of the Cartesian\nproduct of two graphs. We then determine the exact value of the star chromatic\nindex of $2$-dimensional grids. We also obtain some upper bounds on the star\nchromatic index of the Cartesian product of a path with a cycle,\n$d$-dimensional grids, $d$-dimensional hypercubes and $d$-dimensional toroidal\ngrids, for every positive integer $d$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Dealing with Commercial off-the-shelf (COTS) com- ponents is a daily business\nfor avionic system manufacturers. They are necessary ingredients for hardware\ndesigns, but are not built in accordance with the avionics consensus standard\nDO- 254 for Airborne Electronic Hardware (AEH) design. Especially for complex\nCOTS hardware components used in safety critical AEH, like Microcontroller\nUnits (MCUs), additional assurance activities have to be performed. All of them\ntogether shall form a convincing confident, that the hardware is safe in its\nintended operation environment. The focus of DO-254 is one approach called\nDesign Assurance (DA). Its aim is to reduce design errors by adherence of\nprescribed process objectives for the entire design life cycle. The effort for\ncertain COTS assurance activities could be reduced if it is possible to\ndemonstrate, that the COTS design process is based on similar effective design\nprocess guide- lines to minimize desgin errors. In the last years,\nsemiconductor manufacturers released safety MCUs in compliance to the ISO 26262\nstandard, dedicated for the development of functional safe automotive systems.\nThese products are COTS components in the sense of avionics, but they are also\ndeveloped according to a process that focuses on reduction of design errors. In\nthis paper an evaluation is performed to figure out if the ISO 26262 prescribes\na similar DA approach as the DO-254, in order to reduce the COTS assurance\neffort for coming avionic systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Any germ of a complex analytic space is equipped with two natural metrics:\nthe outer metric induced by the hermitian metric of the ambient space and the\ninner metric, which is the associated riemannian metric on the germ. These two\nmetrics are in general nonequivalent up to bilipschitz homeomorphism. We give a\nnecessary and sufficient condition for a normal surface singularity to be\nLipschitz normally embedded (LNE), i.e., to have bilipschitz equivalent outer\nand inner metrics. In a partner paper [15] we apply it to prove that rational\nsurface singularities are LNE if and only if they are minimal.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Graph Drawing Beyond Planarity is a rapidly growing research area that\nclassifies and studies geometric representations of non-planar graphs in terms\nof forbidden crossing configurations. Aim of this survey is to describe the\nmain research directions in this area, the most prominent known results, and\nsome of the most challenging open problems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper presents the sparsifying preconditioner for the time-harmonic\nMaxwell's equations in the integral formulation. Following the work on\nsparsifying preconditioner for the Lippmann-Schwinger equation, this paper\ngeneralizes that approach from the scalar wave case to the vector case. The key\nidea is to construct a sparse approximation to the dense system by minimizing\nthe non-local interactions in the integral equation, which allows for applying\nsparse linear solvers to reduce the computational cost. When combined with the\nstandard GMRES solver, the number of preconditioned iterations remains small\nand essentially independent of the frequency. This suggests that, when the\nsparsifying preconditioner is adopted, solving the dense integral system can be\ndone as efficiently as solving the sparse system from PDE discretization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper presents a novel approach for indoor acoustic source localization\nusing microphone arrays and based on a Convolutional Neural Network (CNN). The\nproposed solution is, to the best of our knowledge, the first published work in\nwhich the CNN is designed to directly estimate the three dimensional position\nof an acoustic source, using the raw audio signal as the input information\navoiding the use of hand crafted audio features. Given the limited amount of\navailable localization data, we propose in this paper a training strategy based\non two steps. We first train our network using semi-synthetic data, generated\nfrom close talk speech recordings, and where we simulate the time delays and\ndistortion suffered in the signal that propagates from the source to the array\nof microphones. We then fine tune this network using a small amount of real\ndata. Our experimental results show that this strategy is able to produce\nnetworks that significantly improve existing localization methods based on\n\\textit{SRP-PHAT} strategies. In addition, our experiments show that our CNN\nmethod exhibits better resistance against varying gender of the speaker and\ndifferent window sizes compared with the other methods.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A deep convolutional fuzzy system (DCFS) on a high-dimensional input space is\na multi-layer connection of many low-dimensional fuzzy systems, where the input\nvariables to the low-dimensional fuzzy systems are selected through a moving\nwindow across the input spaces of the layers. To design the DCFS based on\ninput-output data pairs, we propose a bottom-up layer-by-layer scheme.\nSpecifically, by viewing each of the first-layer fuzzy systems as a weak\nestimator of the output based only on a very small portion of the input\nvariables, we design these fuzzy systems using the WM Method. After the\nfirst-layer fuzzy systems are designed, we pass the data through the first\nlayer to form a new data set and design the second-layer fuzzy systems based on\nthis new data set in the same way as designing the first-layer fuzzy systems.\nRepeating this process layer-by-layer we design the whole DCFS. We also propose\na DCFS with parameter sharing to save memory and computation. We apply the DCFS\nmodels to predict a synthetic chaotic plus random time-series and the real Hang\nSeng Index of the Hong Kong stock market.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a novel mechanism for the production of gravitational waves in the\nearly Universe that originates from the relaxation processes induced by the QCD\nphase transition. While the energy density of the quark-gluon mean-field is\nmonotonously decaying in real time, its pressure undergoes a series of violent\noscillations at the characteristic QCD time scales that generates a primordial\nmulti-peaked gravitational waves' signal in the radio frequencies' domain. The\nsignal as an echo of the QCD phase transition, and is accessible by the FAST\nand SKA telescopes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the nonlocal dynamics of a single particle placed in an\ninfinite well with moving walls. It is shown that in this situation, the\nSchr\\\"odinger equation (SE) violates local causality by causing instantaneous\nchanges in the probability current everywhere inside the well. This violation\nis formalized by designing a gedanken faster-than-light communication device\nwhich uses an ensemble of long narrow cavities and weak measurements to resolve\nthe weak value of the momentum far away from the movable wall. Our system is\nfree from the usual features causing nonphysical violations of local causality\nwhen using the (nonrelativistic) SE, such as instantaneous changes in\npotentials or states involving arbitrarily high energies or velocities. We\nexplore in detail several possible artifacts that could account for the failure\nof the SE to respect local causality for systems involving time-dependent\nboundary conditions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a new recurrent generative model for generating images from text\ncaptions while attending on specific parts of text captions. Our model creates\nimages by incrementally adding patches on a \"canvas\" while attending on words\nfrom text caption at each timestep. Finally, the canvas is passed through an\nupscaling network to generate images. We also introduce a new method for\ngenerating visual-semantic sentence embeddings based on self-attention over\ntext. We compare our model's generated images with those generated Reed et.\nal.'s model and show that our model is a stronger baseline for text to image\ngeneration tasks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A recent laboratory experiment of ideal magnetohydrodynamic (MHD)\ninstabilities reveals four distinct eruption regimes readily distinguished by\nthe torus instability (TI) and helical kink instability (KI) parameters\n\\citep{Myers2015}. To establish its observational counterpart, we collect 38\nsolar flares (stronger than GOES class M5 in general) that took place within\n45$^{\\circ}$ of disk center during 2011$-$2017, 26 of which are associated with\na halo or partial halo coronal mass ejection (CME) (i.e., ejective events),\nwhile the others are CMEless (i.e., confined events). This is a complete sample\nof solar events satisfying our selection criteria detailed in the paper. For\neach event, we calculate decay index $n$ of the potential strapping field above\nthe magnetic flux rope (MFR) in and around the flaring magnetic polarity\ninversion line (a TI parameter), and the unsigned twist number $T_w$ of the\nnon-linear force-free (NLFF) field lines forming the same MFR (a KI parameter).\nWe then construct a $n-T_w$ diagram to investigate how the eruptiveness depends\non these parameters. We find: (1) $T_w$ appears to play little role in\ndiscriminating between confined and ejective events; (2) the events with\n$n\\gtrsim0.8$ are all ejective and all confined events have $n\\lesssim0.8$.\nHowever, $n\\gtrsim0.8$ is not a necessary condition for eruption, because some\nevents with $n\\lesssim0.8$ also erupted. In addition, we investigate the MFR's\ngeometrical parameters, apex height and distance between footpoints, as a\npossible factor for the eruptiveness. We briefly discuss the difference of the\npresent result for solar eruptions with that of the laboratory result in terms\nof the role played by magnetic reconnection.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the spin transport phenomena in two-dimensional graphene-like\nmaterials with arbitrary tilted Dirac cones. The tilt arises due to\nnext-nearest hopping when the bottom of the conduction band and top of the\nvalence band does not simultaneously coincide at Dirac point. We consider\nnormal-ferromagnetic-normal (N-F-N) junction of the materials and using the\ngeneralized scattering approach calculate the spin current. Here, we show that\ntilting the Dirac cones can strongly change the transport properties by\nmodifying the period of oscillation of the spin current. The spin conductance\ncan be effectively tuned by the tilt with taking advantage of the modified\ninterference condition. A pure spin current reversal also possible with a\nsmooth variation of the tilting. We further study the spin current by the\nadiabatic precession of a doped ferromagnet on top of the material. It is shown\nthat the spin-mixing conductance and hence the spin current can become zero by\nturning the tilt of the Dirac cone. Our findings provide an efficient way\ntowards high controllability of spin transport by tuning the tilt of the\nferromagnetic junction and can be very useful in the field of spintronics. The\nmodel also presents a simplified way to measure the tilt of Dirac cone of those\nmaterials.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove q-analogues of two Ramanujan-type series for $1/\\pi$ from\n$q$-analogues of ordinary WZ pairs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present an efficient quantum algorithm for some independent set problems\nin graph theory, based on non-abelian adiabatic mixing. We illustrate the\nperformance of our algorithm with analysis and numerical calculations for two\ndifferent types of graphs, with the number of edges proportional to the number\nof vertices or its square. The theoretical advantages of our quantum algorithm\nover classical algorithms are discussed. Non-abelian adiabatic mixing can be a\ngeneral technique to aid exploration in a landscape of near-degenerate ground\nstates.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Convolutional neural networks(CNN) have been shown to perform better than the\nconventional stereo algorithms for stereo estimation. Numerous efforts focus on\nthe pixel-wise matching cost computation, which is the important building block\nfor many start-of-the-art algorithms. However, those architectures are limited\nto small and single scale receptive fields and use traditional methods for cost\naggregation or even ignore cost aggregation. Differently we take them both into\nconsideration. Firstly, we propose a new multi-scale matching cost computation\nsub-network, in which two different sizes of receptive fields are implemented\nparallelly. In this way, the network can make the best use of both variants and\nbalance the trade-off between the increase of receptive field and the loss of\ndetail. Furthermore, we show that our multi-dimension aggregation sub-network\nwhich containing 2D convolution and 3D convolution operations can provide rich\ncontext and semantic information for estimating an accurate initial disparity.\nFinally, experiments on challenging stereo benchmark KITTI demonstrate that the\nproposed method can achieve competitive results even without any additional\npost-processing.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We describe how the extension of a solver for linear differential equations\nby Kovacic's algorithm helps to improve a method to compute the inverse Mellin\ntransform of holonomic sequences. The method is implemented in the computer\nalgebra package HarmonicSums.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  One of the major goals of the NEXT-White (NEW) detector is to demonstrate the\nenergy resolution that an electroluminescent high pressure xenon TPC can\nachieve for high energy tracks. For this purpose, energy calibrations with\n137Cs and 232Th sources have been carried out as a part of the long run taken\nwith the detector during most of 2017. This paper describes the initial results\nobtained with those calibrations, showing excellent linearity and an energy\nresolution that extrapolates to approximately 1% FWHM at Q$_{\\beta\\beta}$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Understanding phonon transport mechanisms in nanostructures is of great\nimportance for delicately tailoring thermal properties. Combining phonon\nparticle and wave effects through different strategies, previous studies have\nobtained ultra-low thermal conductivity in nanostructures. However, phonon\nparticle and wave effects are coupled together, that is their individual\ncontributions to phonon transport cannot be figured out. Here, we present how\nto quantify the particle and wave effects on phonon transport by combining\nMonte Carlo and atomic green function methods. We apply it to 1D silicon\nnanophononic metamaterial with cross-junctions, where it has been thought that\nthe wave effect was the main modulator to block phonon transport and the\nparticle effect was negligibly weak. Surprisingly, we find that the particle\neffect is quite significant as well and can contribute as much as 39% to the\ntotal thermal conductivity reduction. Moreover, the particle effect does not\ndecrease much as the cross section area (CSA) of the structure decreases and\nstill keeps quite strong even for CSA as small as 2.23 nm2. Further phonon\ntransmission analysis by reducing the junction leg length also qualitatively\ndemonstrates the strong particle effect. The results highlight the importance\nof mutually controlling particle and wave characteristics, and the\nmethodologies for quantifying phonon particle and wave effect are important for\nphonon engineering by nanostructuring.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Given a finite generating set $T=\\{g_0,\\dots, g_n\\}$ of a group $G$, and a\nrepresentation $\\rho$ of $G$ on a Hilbert space $V$, we investigate how the\ngeometry of the set $D(T,\\rho)=\\{ [x_0 : \\dots : x_n] \\in\\mathbb C\\mathbb P^n\n\\mid \\sum x_i\\rho(g_i) \\text{ not invertible} \\}$ reflects the properties of\n$\\rho$. When $V$ is finite-dimensional this is an algebraic hypersurface in\n$\\mathbb C\\mathbb P^n$. In the special case $T=G$ and $\\rho=$ the left regular\nrepresentation of $G$, this hypersurface is defined by the \\emph{group\ndeterminant}, an object studied extensively in the founding work of Frobenius\nthat lead to the creation of representation theory. We focus on the classic\ncase when $G$ is a finite Coxeter group, and make $T$ by adding the identity\nelement $1_G$ to a Coxeter generating set for $G$. Under these assumptions we\nshow in our first main result that if $\\rho$ is the left regular\nrepresentation, then $D(T,\\rho)$ determines the isomorphism class of $G$. Our\nsecond main result is that if $G$ is not of exceptional type, and $\\rho$ is any\nfinite dimensional representation, then $D(T,\\rho)$ determines $\\rho$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In the high-scale (split) MSSM, the measured Higgs mass sets an upper bound\non the supersymmetric scalar mass scale MSUSY around $10^{11}$ ($10^{8}$) GeV,\nfor $\\tan\\beta$ in the standard range and the central value of the top quark\nmass $m_t$. This article discusses how maximal MSUSY is affected by negative\nthreshold corrections to the quartic Higgs coupling arising from the sbottom\nand stop trilinear couplings. In the high-scale MSSM with very high\n$\\tan\\beta$, the electroweak vacuum decay due to the large bottom Yukawa\ncoupling rules out the possibility of raising MSUSY beyond the above limit. In\ncases with large $A_b$ or $A_t$, MSUSY as a common mass of the extra fermions\nand scalars can be as high as $10^{17}$ GeV remaining consistent with $m_h$ and\nthe vacuum longevity if $m_t$ is smaller than the central value by $2\\sigma$.\nFor the central value of $m_t$, the upper limit on MSUSY does not change very\nmuch owing to the metastability, which is the case also in the split MSSM even\nwith $\\pm 2\\sigma$ variations in $m_t$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We extend the injectivity theorem of Esnault and Viehweg to a class of\nnon-normal log varieties, which contains normal crossings log varieties, and is\nclosed under the operation of taking the $\\LCS$ locus.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  CO is commonly used as a tracer of the total gas mass in both the\ninterstellar medium and in protoplanetary disks. Recently there has been much\ndebate about the utility of CO as a mass tracer in disks. Observations of CO in\nprotoplanetary disks reveal a range of CO abundances, with measurements of low\nCO to dust mass ratios in numerous systems. One possibility is that carbon is\nremoved from CO via chemistry. However, the full range of physical conditions\nconducive to this chemical reprocessing is not well understood. We perform a\nsystematic survey of the time dependent chemistry in protoplanetary disks for\n198 models with a range of physical conditions. We varying dust grain size\ndistribution, temperature, comic ray and X-ray ionization rate, disk mass, and\ninitial water abundance, detailing what physical conditions are necessary to\nactivate the various CO depletion mechanisms in the warm molecular layer. We\nfocus our analysis on the warm molecular layer in two regions: the outer disk\n(100 au) well outside the CO snowline and the inner disk (19 au) just inside\nthe midplane CO snow line. After 1 Myr, we find that the majority of models\nhave a CO abundance relative to H$_2$ less than $10^{-4}$ in the outer disk,\nwhile an abundance less than $10^{-5}$ requires the presence of cosmic rays.\nInside the CO snow line, significant depletion of CO only occurs in models with\na high cosmic ray rate. If cosmic rays are not present in young disks it is\ndifficult to chemically remove carbon from CO. Additionally, removing water\nprior to CO depletion impedes the chemical processing of CO. Chemical\nprocessing alone cannot explain current observations of low CO abundances.\nOther mechanisms must also be involved.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Event Horizon Telescope is a millimeter VLBI array that aims to take the\nfirst pictures of the black holes in the center of the Milky Way and of the M87\ngalaxy, with horizon scale resolution. Measurements of the shape and size of\nthe shadows cast by the black holes on the surrounding emission can test the\ncosmic censorship conjecture and the no-hair theorem and may find evidence for\nclassical effects of the quantum structure of black holes. Observations of\ncoherent structures in the accretion flows may lead to accurate measurements of\nthe spins of the black holes and of other properties of their spacetimes. For\nSgr A*, the black hole in the center of the Milky Way, measurements of the\nprecession of stellar orbits and timing monitoring of orbiting pulsars offer\ncomplementary avenues to the gravitational tests with the Event Horizon\nTelescope.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Given a compact set $K$ one may define a transfinite diameter for $K$ via a\nlimiting process involving maximising a Vandermonde determinant over $K$ with\nrespect to a monomial basis. Different transfinite diameters may be obtained by\nusing different polynomial bases in the Vandermonde determinant calculation. We\nshow that if these bases are sufficiently similar that the transfinite diameter\nof $K$ is unchanged. Utilising this result we show that the transfinite\ndiameters defined by Cox-Ma`u and Berman-Boucksom for algebraic varieties are\nequal.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Madelung transform is known to relate Schr\\\"odinger-type equations in\nquantum mechanics and the Euler equations for barotropic-type fluids. We prove\nthat, more generally, the Madelung transform is a K\\\"ahler map (i.e. a\nsymplectomorphism and an isometry) between the space of wave functions and the\ncotangent bundle to the density space equipped with the Fubini-Study metric and\nthe Fisher-Rao information metric, respectively. We also show that Fusca's\nmomentum map property of the Madelung transform is a manifestation of the\ngeneral approach via reduction for semi-direct product groups. Furthermore, the\nHasimoto transform for the binormal equation turns out to be the 1D case of the\nMadelung transform, while its higher-dimensional version is related to the\nproblem of conservation of the Willmore energy in binormal flows.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  User demand for blocking advertising and tracking online is large and\ngrowing. Existing tools, both deployed and described in research, have proven\nuseful, but lack either the completeness or robustness needed for a general\nsolution. Existing detection approaches generally focus on only one aspect of\nadvertising or tracking (e.g. URL patterns, code structure), making existing\napproaches susceptible to evasion.\n  In this work we present AdGraph, a novel graph-based machine learning\napproach for detecting advertising and tracking resources on the web. AdGraph\ndiffers from existing approaches by building a graph representation of the HTML\nstructure, network requests, and JavaScript behavior of a webpage, and using\nthis unique representation to train a classifier for identifying advertising\nand tracking resources. Because AdGraph considers many aspects of the context a\nnetwork request takes place in, it is less susceptible to the single-factor\nevasion techniques that flummox existing approaches.\n  We evaluate AdGraph on the Alexa top-10K websites, and find that it is highly\naccurate, able to replicate the labels of human-generated filter lists with\n95.33% accuracy, and can even identify many mistakes in filter lists. We\nimplement AdGraph as a modification to Chromium. AdGraph adds only minor\noverhead to page loading and execution, and is actually faster than stock\nChromium on 42% of websites and AdBlock Plus on 78% of websites. Overall, we\nconclude that AdGraph is both accurate enough and performant enough for online\nuse, breaking comparable or fewer websites than popular filter list based\napproaches.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the production and decays of doubly-charged Higgs bosons for\nthe Type-II seesaw mechanism at an $e^{+} e^{-}$ collider with two center of\nmass energies, $\\sqrt{s}=380$ GeV and 3 TeV, and analyze the fully hadronic\nfinal states in detail. Lower mass ranges can be probed during the 380 GeV run\nof the collider, while high mass ranges, which are beyond the 13 TeV Large\nHadron Collider discovery reach, can be probed with $\\sqrt{s}=3$ TeV. For such\na heavy Higgs boson, the final decay products are collimated, resulting in\nfat-jets. We perform a substructure analysis to reduce the background and find\nthat a doubly-charged Higgs boson in the mass range 800-1120 GeV can be\ndiscovered during the 3 TeV run, with integrated luminosity $\\mathcal{L} \\sim\n95\\, \\rm{fb}^{-1}$ of data. For 380 GeV center of mass energy, we find that for\nthe doubly-charged Higgs boson in the range 160-172 GeV, a $5\\sigma$\nsignificance can be achieved with only integrated luminosity $\\mathcal{L} \\sim\n24 \\, \\rm{fb}^{-1}$. Therefore, a light Higgs boson can be discovered\nimmediately during the run of a future $e^{+} e^{-}$ collider.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study optimal distributed first-order optimization algorithms when the\nnetwork (i.e., communication constraints between the agents) changes with time.\nThis problem is motivated by scenarios where agents experience network\nmalfunctions. We provide a sufficient condition that guarantees a convergence\nrate with optimal (up lo logarithmic terms) dependencies on the network and\nfunction parameters if the network changes are constrained to a small\npercentage $\\alpha$ of the total number of iterations. We call such networks\nslowly time-varying networks. Moreover, we show that Nesterov's method has an\niteration complexity of $\\Omega \\big( \\big(\\sqrt{\\kappa_\\Phi \\cdot \\bar{\\chi}}\n+ \\alpha \\log(\\kappa_\\Phi \\cdot \\bar{\\chi})\\big) \\log(1 / \\varepsilon)\\big)$\nfor decentralized algorithms, where $\\kappa_\\Phi$ is condition number of the\nobjective function, and $\\bar\\chi$ is a worst case bound on the condition\nnumber of the sequence of communication graphs. Additionally, we provide an\nexplicit upper bound on $\\alpha$ in terms of the condition number of the\nobjective function and network topologies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We have investigated the thorium (Th) abundance in a sample of 53 thin disc\nsolar twins covering a wide range of ages. These data provide constrains on the\nmantle energy budget of terrestrial planets that can be formed over the\nevolution of the Galaxy's thin disc. We have estimated Th abundances with an\naverage precision of 0.025\\,dex (in both [Th/H] and [Th/Fe]) through\ncomprehensive spectral synthesis of a Th\\,II line present at 4019.1290\\,{\\AA},\nusing very high resolution (R\\,=\\,115,000) high quality HARPS spectra obtained\nat the ESO La Silla Observatory. We have confirmed that there is a large energy\nbudget from Th decay for maintaining mantle convection inside potential rocky\nplanets around solar twins, from the Galactic thin disc formation until now,\nbecause the pristine [Th/H]$_{\\rm ZAMS}$ is super-solar on average under a\nuniform dispersion of 0.056\\,dex (varying from +0.037 up to +0.138\\,dex based\non linear fits against isochrone stellar age). Comparing to neodymium (Nd) and\neuropium (Eu), two others neutron-capture elements, the stellar pristine\nabundance of Th follows Eu along the Galactic thin disc evolution, but it does\nnot follow Nd, probably because neodymium has a significant contribution from\nthe $s$-process (about 60\\,per\\,cent).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Modification of the photon dispersion relation in chiral matter enables $1\\to\n2$ scattering. As a result, the single fermion and photon states are unstable\nto photon radiation and pair production respectively. In particular, a fast\nfermion moving through chiral matter can spontaneously radiate a photon, while\na photon can spontaneously radiate a fast fermion and anti-fermion pair. The\ncorresponding spectra are derived in the ultra-relativistic approximation. It\nis shown that the polarization of the produced and decayed photons is\ndetermined by the sign of the chiral conductivity. Impact of a flat thin domain\nwall on the spectra is computed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate quantum authentication schemes constructed from quantum\nerror-correcting codes. We show that if the code has a property called purity\ntesting, then the resulting authentication scheme guarantees the integrity of\nciphertexts, not just plaintexts. On top of that, if the code is strong purity\ntesting, the authentication scheme also allows the encryption key to be\nrecycled, partially even if the authentication rejects. Such a strong notion of\nauthentication is useful in a setting where multiple ciphertexts can be present\nsimultaneously, such as in interactive or delegated quantum computation. With\nthese settings in mind, we give an explicit code (based on the trap code) that\nis strong purity testing but, contrary to other known strong-purity-testing\ncodes, allows for natural computation on ciphertexts.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Graphite has been one of the promising materials in diverse application\ndomains owing to its high conductivity, tunability into different structures\nand mechanical strength its. The effectiveness of graphite and its derivatives\nhas been studied for electromagnetic domains as well. Pencil strokes on paper\ncreate a film of graphite composites which is reported to be useful for\nfabrication of electronic components. In our study, we extend use of pencil\ntraces on paper for studying its electromagnetic properties. The pencil traces\non paper is facile method of coating graphite composite films with relatively\nlower cost and ease of processing. The interaction of electromagnetic wave with\ngraphite composites produces in modulation of the incident RF power. The RF\npower was observed to get attenuated with pencil coating on paper as compared\nto plain paper. The attenuation increased with increasing the signal frequency.\nFurther, stacking more pencil coated papers onto each other results in\nincreasing attenuation factor. Additionally, these pencil coated paper roll was\nable to attenuate the incoming noise signals in the radio signal reception.\nThis demonstrates potential ability of pencil coated papers to be used for\nsmall RF power attenuation applications.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The hierarchy of channel networks in landscapes displays features that are\ncharacteristic of non-equilibrium complex systems. Here we show that a sequence\nof increasingly complex ridge and valley networks is produced by a system of\npartial differential equations coupling landscape evolution dynamics with a\nspecific catchment area equation. By means of a linear stability analysis we\nidentify the critical conditions triggering channel formation and the emergence\nof characteristic valley spacing. The ensuing channelization cascade, described\nby a dimensionless number accounting for diffusive soil creep, runoff erosion,\nand tectonic uplift, is reminiscent of the subsequent instabilities in fluid\nturbulence, while the structure of the simulated patterns is indicative of a\ntendency to evolve toward optimal configurations, with anomalies similar to\ndislocation defects observed in pattern-forming systems. The choice of specific\ngeomorphic transport laws and boundary conditions strongly influences the\nchannelization cascade, underlying the nonlocal and nonlinear character of its\ndynamics.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Dual structures on causal sets called timelets are introduced, being discrete\nanalogs of global time coordinates. Algebraic and geometrical features of the\nset of timelets on a causal set are studied. A characterization of timelets in\nterms of incidence matrix of causal set is given. The connection between\ntimelets and preclusive coevents is established, it is shown that any timelet\nhas a unique decomposition over preclusive coevents. The equivalence classes of\ntimelets with respect to reascaling are shown to form a simplicial complex.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Quantum open systems evolve according to completely positive, trace\npreserving maps acting on the density operator, which can equivalently be\nunraveled in term of so-called quantum trajectories. These stochastic sequences\nof pure states correspond to the actual dynamics of the quantum system during\nsingle realizations of an experiment in which the system's environment is\nmonitored. In this chapter, we present an extension of stochastic\nthermodynamics to the case of open quantum systems, which builds on the analogy\nbetween the quantum trajectories and the trajectories in phase space of\nclassical stochastic thermodynamics. We analyze entropy production, work and\nheat exchanges at the trajectory level, identifying genuinely quantum\ncontributions due to decoherence induced by the environment. We present three\nexamples: the thermalization of a quantum system, the fluorescence of a driven\nqubit and the continuous monitoring of a qubit's observable.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Clinical Named Entity Recognition (CNER) aims to identify and classify\nclinical terms such as diseases, symptoms, treatments, exams, and body parts in\nelectronic health records, which is a fundamental and crucial task for clinical\nand translational research. In recent years, deep neural networks have achieved\nsignificant success in named entity recognition and many other Natural Language\nProcessing (NLP) tasks. Most of these algorithms are trained end to end, and\ncan automatically learn features from large scale labeled datasets. However,\nthese data-driven methods typically lack the capability of processing rare or\nunseen entities. Previous statistical methods and feature engineering practice\nhave demonstrated that human knowledge can provide valuable information for\nhandling rare and unseen cases. In this paper, we address the problem by\nincorporating dictionaries into deep neural networks for the Chinese CNER task.\nTwo different architectures that extend the Bi-directional Long Short-Term\nMemory (Bi-LSTM) neural network and five different feature representation\nschemes are proposed to handle the task. Computational results on the CCKS-2017\nTask 2 benchmark dataset show that the proposed method achieves the highly\ncompetitive performance compared with the state-of-the-art deep learning\nmethods.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Retinal images have the highest resolution and clarity among medical images.\nThus, vessel analysis in retinal images may facilitate early diagnosis and\ntreatment of many chronic diseases. In this paper, we propose a novel\nmulti-scale residual convolutional neural network structure based on a\n\\emph{scale-space approximation (SSA)} block of layers, comprising subsampling\nand subsequent upsampling, for multi-scale representation. Through analysis in\nthe frequency domain, we show that this block structure is a close\napproximation of Gaussian filtering, the operation to achieve scale variations\nin scale-space theory. Experimental evaluations demonstrate that the proposed\nnetwork outperforms current state-of-the-art methods. Ablative analysis shows\nthat the SSA is indeed an important factor in performance improvement.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We examine catalogs of white dwarfs (WDs) and find that there are sufficient\nnumber of massive WDs, M_WD > 1.35Mo, that might potentially explode as type Ia\nsupernovae (SNe Ia) in the frame of the core degenerate scenario. In the core\ndegenerate scenario a WD merges with the carbon-oxygen core of a giant star,\nand they form a massive WD that might explode with a time delay of years to\nbillions of years. If the core degenerate scenario accounts for all SNe Ia,\nthen we calculate that about 0.2 per cent of the present WDs in the Galaxy are\nmassive. Furthermore, we find from the catalogs that the fraction of massive\nWDs relative to all WDs is about 1-3 per cent, with large uncertainties.\nNamely, five to ten times the required number. If there are many SNe Ia that\nresult from lower mass WDs, M_WD < 1.3Mo, for which another scenario is\nresponsible for, and the core degenerate scenario accounts only for the SNe Ia\nthat explode as massive WDs, then the ratio of observed massive WDs to required\nis larger even. Our finding leaves the core degenerate scenario as a viable and\npromising SN Ia scenario.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Gaussian processes (GPs) with derivatives are useful in many applications,\nincluding Bayesian optimization, implicit surface reconstruction, and terrain\nreconstruction. Fitting a GP to function values and derivatives at $n$ points\nin $d$ dimensions requires linear solves and log determinants with an ${n(d+1)\n\\times n(d+1)}$ positive definite matrix -- leading to prohibitive\n$\\mathcal{O}(n^3d^3)$ computations for standard direct methods. We propose\niterative solvers using fast $\\mathcal{O}(nd)$ matrix-vector multiplications\n(MVMs), together with pivoted Cholesky preconditioning that cuts the iterations\nto convergence by several orders of magnitude, allowing for fast kernel\nlearning and prediction. Our approaches, together with dimensionality\nreduction, enables Bayesian optimization with derivatives to scale to\nhigh-dimensional problems and large evaluation budgets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Detecting the cosmological sky-averaged (global) 21 cm signal as a function\nof observed frequency will provide a powerful tool to study the ionization and\nthermal history of the intergalactic medium (IGM) in the early Universe ($\\sim$\n400 million years after the Big Bang). The greatest challenge in conventional\ntotal-power global 21 cm experiments is the removal of the foreground\nsynchrotron emission ($\\sim 10^3$-$10^4$ K) to uncover the weak cosmological\nsignal (tens to hundreds of mK), especially since the intrinsic smoothness of\nthe foreground spectrum is corrupted by instrumental effects. Although the\nEDGES team has recently reported an absorption profile at 78 MHz in the\nsky-averaged spectrum, it is necessary to confirm this detection with an\nindependent approach. The projection effect from observing anisotropic\nforeground source emission with a wide-view antenna pointing at the North\nCelestial Pole (NCP) can induce a net polarization, referred as the\nProjection-Induced Polarization Effect (PIPE). Due to Earth's rotation,\nobservation centered at the circumpolar region will impose a dynamic sky\nmodulation on the net polarization's waveforms which is unique to the\nforeground component. In this study, we review the implementation practicality\nand underlying instrumental effects of this new polarimetry-based technique\nwith detailed numerical simulation and a testbed instrument, the Cosmic\nTwilight Polarimeter (CTP). In addition, we explore an SVD-based analysis\napproach for separating the foreground and instrumental effects from the\nbackground global 21 cm signal using the sky-modulated PIPE.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Maxwell equations generally explain the propagation of light through an\narbitrary medium by using wave mechanics. However, scientific evidence since\nNewton suggest a discrete interpretation of light more generally explains its\nnature. This interpretation lends itself well to the discrete form of computer\nsimulation. While current simulations attempt to discretize Maxwell equations,\nwe present an inherently discrete physical model of light propagation that\nnaturally forms a causal space-time scattering network (STSN). STSN has the\ntopology of neural networks, inverse design and tomography based on STSN can be\nreadily implemented in a variety of software and hardware that are optimized\nfor deep learning. Also, STSN inherently includes the physics of light\npropagation, and hence the number of unknown weights in STSN is at a minimum.\nWe show this property leads to orders of magnitude smaller number of unknown\nweights, and a much faster convergence, compared with inverse design methods\nusing conventional neural networks. In addition, the intrinsic presence of\nspace-time fabric in STSN allows time-dependent inverse design and tomography.\nWe show examples of the fast convergence of STSN in predicting time-dependent\nindex profiles while avoiding approximations typically used.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report the discovery of a new actinide-boost star, 2MASS\nJ09544277+5246414, originally identified as a very bright (V = 10.1), extremely\nmetal-poor ([Fe/H] = -2.99) K giant in the LAMOST survey, and found to be\nhighly r-process-enhanced (r-II; [Eu/Fe]= +1.28]), during the snapshot phase of\nthe R-Process Alliance (RPA). Based on a high S/N, high-resolution spectrum\nobtained with the Harlan J. Smith 2.7-m telescope, this star is the first\nconfirmed actinide-boost star found by RPA efforts. With an enhancement of\n[Th/Eu] = +0.37, 2MASS J09544277+5246414 is also the most actinide-enhanced\nr-II star yet discovered, and only the sixth metal-poor star with a measured\nuranium abundance ([U/Fe] = +1.40). Using the Th/U chronometer, we estimate an\nage of 13.0+/-4.7 Gyr for this star. The unambiguous actinide-boost signature\nof this extremely metal-poor star, combined with additional r-process-enhanced\nand actinide-boost stars identified by the RPA, will provide strong constraints\non the nature and origin of the r-process at early times.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A new design of a detector plane of sub-millimetre thickness for an\nelectromagnetic sampling calorimeter is presented. It is intended to be used in\nthe luminometers LumiCal and BeamCal in future linear $e^+e^-$ collider\nexperiments. The detector planes were produced utilising novel connectivity\nscheme technologies. They were installed in a compact prototype of the\ncalorimeter and tested at DESY with an electron beam of energy 1-5 GeV. The\nperformance of a prototype of a compact LumiCal comprising eight detector\nplanes was studied. The effective Moli`ere radius at 5 GeV was determined to be\n(8.1 +/- 0.1 (stat) +/- 0.3 (syst)) mm, a value well reproduced by the Monte\nCarlo (MC) simulation (8.4 +/- 0.1) mm. The dependence of the effective\nMoli`ere radius on the electron energy in the range 1-5 GeV was also studied.\nGood agreement was obtained between data and MC simulation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present CGO-AS, a generalized Ant System (AS) implemented in the framework\nof Cooperative Group Optimization (CGO), to show the leveraged optimization\nwith a mixed individual and social learning. Ant colony is a simple yet\nefficient natural system for understanding the effects of primary intelligence\non optimization. However, existing AS algorithms are mostly focusing on their\ncapability of using social heuristic cues while ignoring their individual\nlearning. CGO can integrate the advantages of a cooperative group and a\nlow-level algorithm portfolio design, and the agents of CGO can explore both\nindividual and social search. In CGO-AS, each ant (agent) is added with an\nindividual memory, and is implemented with a novel search strategy to use\nindividual and social cues in a controlled proportion. The presented CGO-AS is\ntherefore especially useful in exposing the power of the mixed individual and\nsocial learning for improving optimization. The optimization performance is\ntested with instances of the Traveling Salesman Problem (TSP). The results\nprove that a cooperative ant group using both individual and social learning\nobtains a better performance than the systems solely using either individual or\nsocial learning. The best performance is achieved under the condition when\nagents use individual memory as their primary information source, and\nsimultaneously use social memory as their searching guidance. In comparison\nwith existing AS systems, CGO-AS retains a faster learning speed toward those\nhigher-quality solutions, especially in the later learning cycles. The leverage\nin optimization by CGO-AS is highly possible due to its inherent feature of\nadaptively maintaining the population diversity in the individual memory of\nagents, and of accelerating the learning process with accumulated knowledge in\nthe social memory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  One of the most fascinating topics in current quantum physics are hybridised\nsystems, in which different quantum resonators are strongly coupled. Prominent\nexamples are circular resonators with high quality factors that allow the\ncoupling of optical whispering gallery modes to microwave cavities or magnon\nresonances in optomagnonics. Whispering gallery modes play a special role in\nthis endeavour because of their high quality factor and strong localisation,\nwhich ultimately increases the overlap of the wavefunctions of quantum\nparticles in hybridised systems. The hybridisation with magnons, the collective\nquantum excitations of the electron spins in a magnetically ordered material,\nis of particular interest because magnons can take over two functionalities:\ndue to their collective nature they are robust and can serve as a quantum\nmemory and, moreover, they can act as a wavelength converter between microwave\nand THz photons. However, the observation of whispering gallery magnons has not\nyet been achieved due to the lack of efficient excitation schemes for magnons\nwith large wave vectors in a circular geometry. To tackle this problem, we\nstudied nonlinear 3-magnon scattering as a means to generate whispering gallery\nmagnons. This Letter discusses the basics of this nonlinear mechanism in a\nconfined, circular geometry from experimental and theoretical point of view.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we investigate the geodesic motion of massive and massless\ntest particles in the vicinity of a black hole space-time surrounded by perfect\nfluid (quintessence, dust, radiation, cosmological constant and phantom) in\nRastall theory. We obtain the full set of analytical solutions of the geodesic\nequation of motion in the space-time of this black hole. For all cases of\nperfect fluid, we consider some different values of Rastall coupling constant\n$k\\lambda$ so that the equations of motion have integer powers of $\\tilde{r}$\nand also can be solved analytically. These analytical solutions are presented\nin the form of elliptic and also hyperelliptic functions. In addition, using\nobtained analytical solution and also figures of effective potential and\n$L-E^2$ diagrams, we plot some examples of possibles orbits. moreover we use of\nthe angular momentum, conserved energy, electrical charge and also Rastall\nparameter, to classify the different types of the possible gained orbits.\nMoreover, we show that when Rastall field structure constant becomes zero\n($N=0$) our results are consistent with the analysis of a Reissner-Nordstr\\\"om\nblack hole, however when both Rastall geometric parameter and electric charge\nvanish $(N=Q=0)$, the metric and results are same as analysis of a\nSchwarzschild black hole.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we propose a joint dynamic power control and user pairing\nalgorithm for power-efficient and low-latency hybrid multiple access systems.\nIn a hybrid multiple access system, user pairing determines whether the\ntransmitter should serve a certain user by orthogonal multiple access (OMA) or\nnon-orthogonal multiple access (NOMA). The proposed optimization framework\nminimizes the long-term time-average transmit power expenditure while reducing\nthe queueing delay and satisfying time-average data rate requirements. The\nproposed technique observes channel and queue state information and adjusts\nqueue backlogs to avoid an excessive queueing delay by appropriate user pairing\nand power allocation. Further, user scheduling for determining the activation\nof a given user link as well as flexible use of resources are captured in the\nproposed algorithm. Data-intensive simulation results show that the proposed\nscheme guarantees an end-to-end delay smaller than 1 ms with high\npower-efficiency and high reliability, based on the short frame structure\ndesigned for ultra-reliable low-latency communications (URLLC).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We generalize the swampland criterion forbidding stable non-supersymmetric\nAdS vacua and propose a new swampland conjecture forbidding stable\nnon-supersymmetric \"locally AdS\" warped throats. The conjecture is motivated by\nthe properties of systems of fractional D3-branes at singularities, and can be\nused to rule out large classes of warped throats with supersymmetry breaking\ningredients, and their possible application to de Sitter uplift. In particular,\nthis allows to reinterpret the runaway instabilities of the gravity dual of\nfractional branes in the dP$_1$ theory, and to rule out warped throats with\nDynamical Supersymmetry Breaking D-brane sectors at their bottom. We also\ndiscuss the instabilities of warped throats with supersymmetry broken by the\nintroduction of anti-orientifold planes. These examples lead to novel decay\nmechanisms in explicit non-supersymmetric examples of locally AdS warped\nthroats, and also of pure AdS backgrounds.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A spreading process on a network is influenced by the network's underlying\nspatial structure, and it is insightful to study the extent to which a\nspreading process follows such structure. We consider a threshold contagion\nmodel on a network whose nodes are embedded in a manifold and which has both\n`geometric edges', which respect the geometry of the underlying manifold, and\n`nongeometric edges' that are not constrained by that geometry. Building on\nideas from Taylor et al. \\cite{Taylor2015}, we examine when a contagion\npropagates as a wave along a network whose nodes are embedded in a torus and\nwhen it jumps via long nongeometric edges to remote areas of the network. We\nbuild a `contagion map' for a contagion spreading on such a `noisy geometric\nnetwork' to produce a point cloud; and we study the dimensionality, geometry,\nand topology of this point cloud to examine qualitative properties of this\nspreading process. We identify a region in parameter space in which the\ncontagion propagates predominantly via wavefront propagation. We consider\ndifferent probability distributions for constructing nongeometric edges --\nreflecting different decay rates with respect to the distance between nodes in\nthe underlying manifold -- and examine the effect of such choices on the\nqualitative properties of the spreading dynamics. Our work generalizes the\nanalysis in Taylor et al. and consolidates contagion maps both as a tool for\ninvestigating spreading behavior on spatial networks and as a technique for\nmanifold learning.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We reconsider the theory of Hall effect in the systems with hopping\nconduction. The purpose of the present study is to compare the percolation\napproach based on the optimal triad model with numerical simulations and recent\nexperimental results. We show that, in the nearest neighbor hopping regime, the\nresults of the percolation theory agree to the simulation. However, in the\nvariable range hopping (VRH) regime, the optimal triad model fails to describe\nthe numerical results. It is related to the extremely small probability to find\nthe optimal triad of sites in the percolation cluster in the VRH regime. The\ncontribution of these triads to the Hall effect appears to be small. We\ndescribe the Hall mobility in the VRH regime with the empirical law obtained\nfrom the numerical results. The law is in agreement with our recent\nexperimental data in 2D quantum dot arrays with the hopping transport.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $G$ be a locally compact totally disconnected topological group. Under a\nnecessary mild assumption, we show that the irreducible unitary representations\nof $G$ are uniformly admissible if and only if the irreducible smooth\nrepresentations of $G$ are uniformly admissible. We also show that the latter\nproperty is inherited by finite-index subgroups and overgroups of $G$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Kolmogorov $n$-widths and Hankel singular values are two commonly used\nconcepts in model reduction. Here we show that for the special case of linear\ntime-invariant dynamical (LTI) systems, these two concepts are directly\nconnected. More specifically, the greedy search applied to the Hankel operator\nof an LTI system resembles the minimizing subspace for the Kolmogorov n-width\nand the Kolmogorov $n$-width of an LTI system equals its $(n+1)st$ Hankel\nsingular value once the subspaces are appropriately defined. We also establish\na lower bound for the Kolmorogov $n$-width for parametric LTI systems and\nillustrate that the method of active subspaces can be viewed as the dual\nconcept to the minimizing subspace for the Kolmogorov $n$-width.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Hydrogen atoms absorbed by metals in the hydrogen-containing environments can\nlead to the premature fracture of the metal components used in load-bearing\nconditions. Since metals used in practice are mostly polycrystalline, grain\nboundaries (GBs) can play an important role in hydrogen embrittlement of\nmetals. Here we show that the reaction of GB with lattice dislocations is a key\ncomponent in hydrogen embrittlement mechanism for polycrystalline metals. We\nuse atomistic modeling methods to investigate the mechanical response of GBs in\nalpha-iron with various hydrogen concentrations. Analysis indicates that\ndislocations impingement and emission on the GB cause the GB to locally\ntransform into an activated state with a more disordered atomistic structure,\nand introduce a local stress concentration. The activation of the GB segregated\nwith hydrogen atoms can greatly facilitate decohesion of the GB. We show that\nthe hydrogen embrittlement model proposed here can give better explanation of\nmany experimental observations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the dynamics of 2+1 dimensional theories with ${\\cal N}=1$\nsupersymmetry. In these theories the supersymmetric ground states behave\ndiscontinuously at co-dimension one walls in the space of couplings, with new\nvacua coming in from infinity in field space. We show that the dynamics near\nthese walls is calculable: the two-loop effective potential yields exact\nresults about the ground states near the walls. Far away from the walls the\nground states can be inferred by decoupling arguments. In this way, we are able\nto follow the ground states of ${\\cal N}=1$ theories in 2+1 dimensions and\nconstruct the infrared phases of these theories. We study two examples in\ndetail: Adjoint SQCD and SQCD with one fundamental quark. In Adjoint QCD we\nshow that for sufficiently small Chern-Simons level the theory has a\nnon-perturbative metastable supersymmetry-breaking ground state. We also\nbriefly discuss the critical points of this theory. For SQCD with one quark we\nestablish an infrared duality between a $U(N)$ gauge theory and an $SU(N)$\ngauge theory. The duality crucially involves the vacua that appear from\ninfinity near the walls.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It is widely accepted that astrophysical magnetic fields are generated by\ndynamo action. In many cases these fields exhibit organisation on a scale\nlarger than that of the underlying turbulent flow (e.g., the eleven-year solar\ncycle). The mechanism for the generation of so-called large scale fields\nremains an open problem. In cases where the magnetic Reynolds number ($Rm$) is\nsmall, dynamo-generated fields are coherent but at (the astrophysically\nrelevant) high $Rm$, the fields are overwhelmed by small scale fluctuating\nfield. Recently Tobias and Cattaneo (2013) have shown that an imposed large\nscale shear flow can suppress the small scale fluctuations and allow the large\nscale temporal behaviour to emerge. Shear is also believed to modify the\nelectromotive force by introducing correlations between the flow and the field.\nHowever in previous models at high $Rm$ the shear is often artificially imposed\nor driven by an arbitrary body force. Here we consider a simple kinematic model\nof a convective dynamo in which shear is self consistently driven by the\npresence of a horizontal temperature gradient (resulting in a thermal wind) and\na rotation vector that is oblique to gravity. By considering a\n$2.5$-dimensional system, we are able to reach high $Rm$ so that the dynamo\napproaches the asymptotic regime where the growth rate becomes approximately\nindependent of $Rm$. We find the flows studied here to be excellent small-scale\ndynamos, but with very little systematic behaviour evident at large $Rm$. We\nattribute this to being unable to self-consistently generate flows with both\nlarge (net) helicity and strong shear in this setup.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We describe an algorithm to compute the Wiener index of a sequence of finite\ngraphs approximating the Sierpinski carpet.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The conical Radon transform, which assigns to a given function $f$ on\n$\\mathbb R^3$ its integrals over conical surfaces, arises in several imaging\ntechniques, e.g. in astronomy and homeland security, especially when the\nso-called Compton cameras are involved. In many practical situations we know\nthis transform only on a subset of its domain. In these situations, it is a\nnatural question what we can say about $f$ from partial information. In this\npaper, we investigate some uniqueness theorems regarding a conical Radon\ntransform.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  While there has been some discussion on how Symbolic Computation could be\nused for AI there is little literature on applications in the other direction.\nHowever, recent results for quantifier elimination suggest that, given enough\nexample problems, there is scope for machine learning tools like Support Vector\nMachines to improve the performance of Computer Algebra Systems. We survey the\nauthors own work and similar applications for other mathematical software.\n  It may seem that the inherently probabilistic nature of machine learning\ntools would invalidate the exact results prized by mathematical software.\nHowever, algorithms and implementations often come with a range of choices\nwhich have no effect on the mathematical correctness of the end result but a\ngreat effect on the resources required to find it, and thus here, machine\nlearning can have a significant impact.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Kondo and Periodic Anderson Model (PAM) are known to provide a\nmicroscopic picture of many of the fundamental properties of heavy fermion\nmaterials and, more generally, a variety of strong correlation phenomena in\n$4f$ and $5f$ systems. In this paper, we apply the Determinant Quantum Monte\nCarlo (DQMC) method to include disorder in the PAM, specifically the removal of\na fraction $x$ of the localized orbitals. We determine the evolution of the\ncoherence temperature $T^*$, where the local moments and conduction electrons\nbecome entwined in a heavy fermion fluid, with $x$ and with the hybridization\n$V$ between localized and conduction orbitals. We recover several of the\nprincipal observed trends in $T^*$ of doped heavy fermions, and also show that,\nwithin this theoretical framework, the calculated Nuclear Magnetic Resonance\n(NMR) relaxation rate tracks the experimentally measured behavior in pure and\ndoped CeCoIn$_5$. Our results contribute to important issues in the\ninterpretation of local probes of disordered, strongly correlated systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Current and emerging trends such as cloud computing, fog computing, and more\nrecently, multi-access edge computing (MEC) increase the interest in finding\nsolutions to the verifiable computation problem. Furthermore, the number of\ncomputationally weak devices have increased drastically in recent years due to\nthe ongoing realization of the Internet of Things. This work proposes a\nsolution which enjoys the following two desirable properties: (1) cost of input\npreparation and verification is very low (low enough to allow verifiable\noutsourcing of computations by resource-constrained devices on constrained\nnetworks); (2) the running time of the verifiable computation is RAM-like.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider a multi-cell Massive MIMO system in a line-of-sight (LoS)\npropagation environment, for which each user is served by one base station,\nwith no cooperation among the base stations. Each base station knows the\nchannel between its service antennas and its users, and uses these channels for\nprecoding and decoding. Under these assumptions we derive explicit downlink and\nuplink effective SINR formulas for maximum-ratio (MR) processing and\nzero-forcing (ZF) processing. We also derive formulas for power control to meet\npre-determined SINR targets. A numerical example demonstrating the usage of the\nderived formulas is provided.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The present work shows the application of transfer learning for a pre-trained\ndeep neural network (DNN), using a small image dataset ($\\approx$ 12,000) on a\nsingle workstation with enabled NVIDIA GPU card that takes up to 1 hour to\ncomplete the training task and archive an overall average accuracy of $94.7\\%$.\nThe DNN presents a $20\\%$ score of misclassification for an external test\ndataset. The accuracy of the proposed methodology is equivalent to ones using\nHSI methodology $(81\\%-91\\%)$ used for the same task, but with the advantage of\nbeing independent on special equipment to classify wheat kernel for FHB\nsymptoms.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We tackle the problem of learning concept classifiers from videos on the web\nwithout using manually labeled data. Although metadata attached to videos\n(e.g., video titles, descriptions) can be of help collecting training data for\nthe target concept, the collected data is often very noisy. The main challenge\nis therefore how to select good examples from noisy training data. Previous\napproaches firstly learn easy examples that are unlikely to be noise and then\ngradually learn more complex examples. However, hard examples that are much\ndifferent from easy ones are never learned. In this paper, we propose an\napproach called multimodal co-training (MMCo) for selecting good examples from\nnoisy training data. MMCo jointly learns classifiers for multiple modalities\nthat complement each other to select good examples. Since MMCo selects examples\nby consensus of multimodal classifiers, a hard example for one modality can\nstill be used as a training example by exploiting the power of the other\nmodalities. The algorithm is very simple and easily implemented but yields\nconsistent and significant boosts in example selection and classification\nperformance on the FCVID and YouTube8M benchmarks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  One promising route toward encoding information is to utilize the two stable\nelectronic states of a spin crossover molecule. However, while this property is\nclearly manifested in transport across single molecule junctions, evidence\nlinking charge transport across a solid-state device to the molecular film's\nspin state has thus far remained indirect. To establish this link, we deploy\nmaterials-centric and device-centric operando experiments involving X-ray\nabsorption spectroscopy. We find a correlation between the temperature\ndependencies of the junction resistance and the Fe spin state within the\ndevice's Fe(bpz)2(phen) molecular film. We also factually observe that the Fe\nmolecular site mediates charge transport. Our dual operando studies reveal that\ntransport involves a subset of molecules within an electronically heterogeneous\nspin crossover film. Our work confers an insight that substantially improves\nthe state-of-the-art regarding spin crossover-based devices, thanks to a\nmethodology that can benefit device studies of other next-generation molecular\ncompounds.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The gas-driven dust activity of comets is still an unresolved question in\ncometary science. In the past, it was believed that comets are dirty snowballs\nand that the dust is ejected when the ice retreats. However, thanks to the\nvarious space missions to comets, it has become evident that comets have a much\nhigher dust-to-ice ratio than previously thought and that most of the dust mass\nis ejected in large particles. Here we report on new comet-simulation\nexperiments dedicated to the study of the ejection of dust aggregates caused by\nthe sublimation of solid water ice. We find that dust ejection exactly occurs\nwhen the pressure of the water vapor above the ice surface exceeds the tensile\nstrength plus the gravitational load of the covering dust layer. Furthermore,\nwe observed the ejection of clusters of dust aggregates, whose sizes increase\nwith increasing thickness of the ice-covering dust-aggregate layer. In\naddition, the trajectories of the ejected aggregates suggest that most of the\naggregates obtained a non-vanishing initial velocity from the ejection event.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We discuss a recently proposed interpretation of some model descriptions of\nthe proton-proton elastic scattering data as a manifestation of alleged\nrelative transparency of the central part of the interaction region in the\nimpact parameter space. We argue that the presence of nonzero real part of the\nelastic scattering amplitude in the unitarity condition enables to conserve the\ntraditional interpretation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we consider the nonlinear Schr\\\"odinger system (NLS) with\nquadratic interaction in five dimensions. We determine the global behavior of\nthe solutions to the system with data below the ground state. Our proof of the\nscattering result is based on an argument by Kenig Merle [16]. In particular,\nthe new part of this paper is to deal with asymmetric interaction. A blowing up\nor growing up result is proved by combining the argument by Du Wu Zhang in [6]\nand a variational characterization of minimizers. Moreover, we show a\nblowing-up result if the data has finite variance or is radial.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Dense and narrow rings have been discovered recently around the small Centaur\nobject Chariklo and the dwarf planet Haumea, while being suspected around the\nCentaur Chiron. They are the first rings observed in the Solar System elsewhere\nthan around giant planets. Contrarily to the latters, gravitational fields of\nsmall bodies may exhibit large non-axisymmetric terms that create strong\nresonances between the spin of the object and the mean motion of rings\nparticles. Here we show that modest topographic features or elongations of\nChariklo and Haumea explain why their rings are relatively far away from the\ncentral body, when scaled to those of the giant planets. Lindblad-type\nresonances actually clear on decadal time-scales an initial collisional disk\nthat straddles the corotation resonance (where the particles mean motion\nmatches the spin rate of the body). The disk material inside the corotation\nradius migrates onto the body, while the material outside the corotation radius\nis pushed outside the 1/2 resonance, where the particles complete one\nrevolution while the body completes two rotations. Consequently, the existence\nof rings around non-axisymmetric bodies requires that the 1/2 resonance resides\ninside the Roche limit of the body, favoring fast rotators for being surrounded\nby rings.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report on the first femtoscopic measurement of baryon pairs, such as p-p,\np-$\\Lambda$ and $\\Lambda$-$\\Lambda$, measured by ALICE at the Large Hadron\nCollider (LHC) in proton-proton collisions at $\\sqrt{s}$ = 7 TeV. This study\ndemonstrates the feasibility of such measurements in pp collisions at\nultrarelativistic energies. The femtoscopy method is employed to constrain the\nhyperon-nucleon and hyperon-hyperon interactions, which are still rather poorly\nunderstood. A new method to evaluate the influence of residual correlations\ninduced by the decays of resonances and experimental impurities is hereby\npresented. The p-p, p-$\\Lambda$ and $\\Lambda$-$\\Lambda$ correlation functions\nwere fitted simultaneously with the help of a new tool developed specifically\nfor the femtoscopy analysis in small colliding systems 'Correlation Analysis\nTool using the Schr\\\"odinger Equation' (CATS). Within the assumption that in pp\ncollisions the three particle pairs originate from a common source, its radius\nis found to be equal to $r_{0} = 1.125\\pm0.018$ (stat) $^{+0.058}_{-0.035}$\n(syst) fm. The sensitivity of the measured p-$\\Lambda$ correlation is tested\nagainst different scattering parameters which are defined by the interaction\namong the two particles, but the statistics is not sufficient yet to\ndiscriminate among different models. The measurement of the $\\Lambda$-$\\Lambda$\ncorrelation function constrains the phase space spanned by the effective range\nand scattering length of the strong interaction. Discrepancies between the\nmeasured scattering parameters and the resulting correlation functions at LHC\nand RHIC energies are discussed in the context of various models.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The normal form and zero dynamics are powerful tools useful in analysis and\ncontrol of both linear and nonlinear systems. There are no simple closed form\nsolutions to the general zero dynamics problem for nonlinear systems. A few\nalgorithms exist for determining the zero dynamics, but none is straightforward\nand all are difficult to apply to large dimensional problems. A Closed form\nsolution to the zero dynamics problem would motivate more usage of this\npowerful technique. The author presents here a simple algebraic methodology for\nthe normal form and zero dynamics calculation of a class of nonlinear systems,\nmostly found in dynamical mechanical systems. The solution is in closed form so\nthat application of the theorem presented is straight forward. As an\nillustration, the zero dynamics calculations for the complex dynamics of a\nflexible spacecraft is presented to demonstrate the simplicity and usefulness\nof the proposed closed form solution.\n  Keywords: Control, Differential Geometry, Normal Form, Zero Dynamics,\nNonlinear Systems, Feedback Linearization, Attitude Dynamics, Flexible\nSpacecraft.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove that reflected Brownian motion with normal reflections in a convex\ndomain satisfies a dimension free Talagrand type transportation\ncost-information inequality. The result is generalized to other reflected\ndiffusions with suitable drifts and diffusions. We apply this to get such an\ninequality for interacting Brownian particles with rank-based drift and\ndiffusion coefficients such as the infinite Atlas model. This is an improvement\nover earlier dimension-dependent results.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This article deals with the following simpler version of an open problem in\nsystem realization theory which has several important engineering applications:\nGiven a collection of masses and a set of linear springs with a specified cost\nand stiffness, a resource constraint in terms of a budget on the total cost,\nthe problem is to determine an optimal connection of masses and springs so that\nthe resulting structure is as stiff as possible, i.e., the structure is\nconnected and its smallest non-zero natural frequency is as large as possible.\nIn this article, algebraic connectivity, or its mechanical analog - the\nsmallest non-zero natural frequency of a connected structure was chosen as a\nperformance objective. Algebraic connectivity determines the convergence rate\nof consensus protocols and error attenuation in Unmanned Aerial Vehicle (UAV)\nformations and is chosen to be a performance objective as it can be viewed as a\nmeasure of robustness in UAV communication networks to random node failures.\nUnderlying the mechanical and UAV network synthesis problems is a Mixed Integer\nSemi-Definite Program (MISDP), an NP-hard problem. The novel contributions of\nthis article lies in developing efficient algorithms to solve the MISDPs based\non iterative primal-dual algorithm, cutting-plane methods for polyhedral\nouter-approximation, capturing the feasible set of MISDPs using Fiedler vectors\nor Laplacian with equivalency guarantees, and efficient\nneighborhood-search-based heuristic algorithms.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The origin of Fast Radio Bursts (FRBs) is still mysterious. All FRBs to date\nshow extremely high brightness temperatures, requiring a coherent emission\nmechanism. Using constraints derived from the physics of one of these\nmechanisms, the synchrotron maser, as well as observations, we show that\naccretion induced explosions of neutron stars with surface magnetic fields of\n$B_*\\lesssim10^{11}$ G are favoured as FRB progenitors.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This work introduces two 11-node triangular prism elements for 3D elliptic\nproblems. The degrees of freedom (DoFs) of both elements are at the vertices\nand face centroids of a prism cell. The first element is $H^1$-nonconforming\nand works for second order problems, which achieves a second order convergence\nrate in discrete $H^1$-norm. The other is $H^2$-nonconforming and solves fourth\norder problems, with a first order convergence rate in discrete $H^2$-norm.\nNumerical examples verify our theoretical results.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a practical algorithm to test whether a 3-manifold given by a\ntriangulation or an ideal triangulation contains a closed essential surface.\nThis property has important theoretical and algorithmic consequences. As a\ntestament to its practicality, we run the algorithm over a comprehensive body\nof closed 3-manifolds and knot exteriors, yielding results that were not\npreviously known.\n  The algorithm derives from the original Jaco-Oertel framework, involves both\nenumeration and optimisation procedures, and combines several techniques from\nnormal surface theory. Our methods are relevant for other difficult\ncomputational problems in 3-manifold theory, such as the recognition problem\nfor knots, links and 3-manifolds.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Radio wavelength astrometry of stars and other objects has a long and\nproductive history. The use of that technique to determine whether stars have\nplanets around them would cover a nearly unique part of the parameter space for\ndetection of those systems. Namely, astrometric observations are most sensitive\nto systems with large planets in moderately wide orbits (a few to ~10 AU),\nbecause it is those systems that produce large reflex motion of the star, in a\nshort enough measurement period (years to tens of years). In addition,\nastrometric observations are most sensitive to systems which are nearly\nface-on. Other techniques (radial velocity, or the photometric method of\nKepler) are more sensitive to systems with planets in close orbits (less than\n$\\sim$1 AU), which are nearly edge-on. We describe here, using the Hipparcos\nand Gaia star catalogs, how ngVLA could use this technique on hundreds of\nstars, some tens of which are solar analogs, to determine whether these stars\nhave planets orbiting them.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Fractional quantum Hall (FQH) system at Landau level filling fraction\n$\\nu=5/2$ has long been suggested to be non-Abelian, either Pfaffian (Pf) or\nantiPfaffian (APf) states by numerical studies, both with quantized Hall\nconductance $\\sigma_{xy}=5e^2/2h$. Thermal Hall conductances of the Pf and APf\nstates are quantized at $\\kappa_{xy}=7/2$ and $\\kappa_{xy}=3/2$ respectively in\na proper unit. However, a recent experiment shows the thermal Hall conductance\nof $\\nu=5/2$ FQH state is $\\kappa_{xy}=5/2$. It has been speculated that the\nsystem contains random Pf and APf domains driven by disorders, and the neutral\nchiral Majorana modes on the domain walls may undergo a percolation transition\nto a $\\kappa_{xy}=5/2$ phase. In this work, we do perturbative and\nnon-perturbative analyses on the domain walls between Pf and APf. We show the\ndomain wall theory possesses an emergent SO(4) symmetry at energy scales below\na threshold $\\Lambda_1$, which is lowered to an emergent U(1)$\\times$U(1)\nsymmetry at energy scales between $\\Lambda_1$ and a higher value $\\Lambda_2$,\nand is finally lowered to the composite fermion parity symmetry\n$\\mathbb{Z}_2^F$ above $\\Lambda_2$. Based on the emergent symmetries, we\npropose a phase diagram of the disordered $\\nu=5/2$ FQH system, and show that a\n$\\kappa_{xy}=5/2$ phase arises at disorder energy scales $\\Lambda>\\Lambda_1$.\nFurthermore, we show the gapped double-semion sector of $N_D$ compact domain\nwalls contributes non-local topological degeneracy $2^{N_D-1}$, causing a\nlow-temperature peak in the heat capacity. We implement a non-perturbative\nmethod to bootstrap generic topological 1+1D domain walls (2-surface defects)\napplicable to any 2+1D non-Abelian topological order. We identify potentially\nrelevant spin TQFTs for various $\\nu = 5/2$ FQH states in terms of fermionic\nversion of U(1)$_{\\pm 8}$ Chern-Simons theory $\\times \\mathbb{Z}_8$-class\nTQFTs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper addresses the problem of mapping natural language text to\nknowledge base entities. The mapping process is approached as a composition of\na phrase or a sentence into a point in a multi-dimensional entity space\nobtained from a knowledge graph. The compositional model is an LSTM equipped\nwith a dynamic disambiguation mechanism on the input word embeddings (a\nMulti-Sense LSTM), addressing polysemy issues. Further, the knowledge base\nspace is prepared by collecting random walks from a graph enhanced with textual\nfeatures, which act as a set of semantic bridges between text and knowledge\nbase entities. The ideas of this work are demonstrated on large-scale\ntext-to-entity mapping and entity classification tasks, with state of the art\nresults.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study continuum-wise expansive flows with fixed points on metric spaces\nand low dimensional manifolds. We give sufficient conditions for a surface flow\nto be singular cw-expansive and examples showing that cw-expansivity does not\nimply expansivity. We also construct a singular Axiom A vector field on a\nthree-manifold being singular cw-expansive and with a Lorenz attractor and a\nLorenz repeller in its non-wandering set.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we obtain the differential equations of the space-like\nloxodromes on the non-degenerate canal surfaces depending on the causal\ncharacters of these canal surfaces and their meridians in Minkowski 3-space.\nAlso we give an example by using Mathematica computer programme.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Iterative methods for nonlinear monotone equations do not require the\ndifferentiability assumption on the residual function. This special property of\nthe methods makes them suitable for solving large-scale nonsmooth monotone\nequations. In this work, we present a diagonal Polak-Ribeire-Polyk (PRP)\nconjugate gradient-type method for solving large-scale nonlinear monotone\nequations with convex constraints. The search direction is a combine form of a\nmultivariate (diagonal) spectral method and a modified PRP conjugate gradient\nmethod. Proper safeguards are devised to ensure positive definiteness of the\ndiagonal matrix associated with the search direction. Based on Lipschitz\ncontinuity and monotonicity assumptions the method is shown to be globally\nconvergent. Numerical results are presented by means of comparative experiments\nwith a recently proposed multivariate spectral conjugate gradient-type method.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Metric spaces satisfying properties stronger than completeness and weaker\nthan compactness have been studied by many authors over the years. One such\nsignificant family is that of cofinally complete metric spaces. We discuss the\nrelationship between cofinally complete metric spaces and the family of almost\nuniformly continuous functions, which has recently been introduced by Kyriakos\nKeremedis in \\cite{[K]}. We also discuss several equivalent conditions for\nmetric spaces whose completions are cofinally complete in terms of some\ngeometric functional.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present an approach to event coreference resolution by developing a\ngeneral framework for clustering that uses supervised representation learning.\nWe propose a neural network architecture with novel Clustering-Oriented\nRegularization (CORE) terms in the objective function. These terms encourage\nthe model to create embeddings of event mentions that are amenable to\nclustering. We then use agglomerative clustering on these embeddings to build\nevent coreference chains. For both within- and cross-document coreference on\nthe ECB+ corpus, our model obtains better results than models that require\nsignificantly more pre-annotated information. This work provides insight and\nmotivating results for a new general approach to solving coreference and\nclustering problems with representation learning.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper describes BlockPKI, a blockchain-based public-key infrastructure\nthat enables an automated, resilient, and transparent issuance of digital\ncertificates. Our goal is to address several shortcomings of the current TLS\ninfrastructure and its proposed extensions. In particular, we aim at reducing\nthe power of individual certification authorities and make their actions\npublicly visible and accountable, without introducing yet another trusted third\nparty. To demonstrate the benefits and practicality of our system, we present\nevaluation results and describe our prototype implementation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a clear definition of the gluon condensate within the\nlarge-$\\beta_0$ approximation as an attempt toward a systematic argument on the\ngluon condensate. We define the gluon condensate such that it is free from a\nrenormalon uncertainty, consistent with the renormalization scale independence\nof each term of the operator product expansion (OPE), and an identical object\nirrespective of observables. The renormalon uncertainty of\n$\\mathcal{O}(\\Lambda^4)$, which renders the gluon condensate ambiguous, is\nseparated from a perturbative calculation by using a recently suggested\nanalytic formulation. The renormalon uncertainty is absorbed into the gluon\ncondensate in the OPE, which makes the gluon condensate free from the\nrenormalon uncertainty. As a result, we can define the OPE in a renormalon-free\nway. Based on this renormalon-free OPE formula, we discuss numerical extraction\nof the gluon condensate using the lattice data of the energy density operator\ndefined by the Yang--Mills gradient flow.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recent Atacama Large Millimeter and Submillimeter Array (ALMA) observations\nof the protoplanetary disk around the Herbig Ae star HD 163296 revealed three\ndepleted dust gaps at 60, 100 and 160 au in the 1.3 mm continuum as well as CO\ndepletion in the middle and outer dust gaps. However, no CO depletion was found\nin the inner dust gap. To examine the planet--disk interaction model, we\npresent results of two-dimensional two fluid (gas + dust) hydrodynamic\nsimulations coupled with three-dimensional radiative transfer simulations. In\norder to fit the high gas-to-dust ratio of the first gap, we find the\nShakura--Sunyaev viscosity parameter $\\alpha$ must be very small ($\\lesssim\n10^{-4}$) in the inner disk. On the other hand, a relatively large $\\alpha$\n($\\sim 7.5\\times 10^{-3}$) is required to reproduce the dust surface density in\nthe outer disk. We interpret the variation of $\\alpha$ as an indicator of the\ntransition from an inner dead zone to the outer magnetorotational instability\n(MRI) active zone. Within $\\sim 100$ au, the HD 163296 disk's ionization level\nis low, and non-ideal magnetohydrodynamic (MHD) effects could suppress the MRI,\nso the disk can be largely laminar. The disk's ionization level gradually\nincreases toward larger radii, and the outermost disk ($r > 300$ au) becomes\nturbulent due to MRI. Under this condition, we find that the observed dust\ncontinuum and CO gas line emissions can be reasonably fit by three\nhalf-Jovian-mass planets (0.46, 0.46 and 0.58 $M_\\textrm{J}$) at 59, 105 and\n160 au, respectively.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Associated with an augmented differential graded algebra $R= R^{\\geq 0}$ is a\nhomotopy invariant ${\\mathcal T}(R)$. This is a graded vector space, and if\n$H^0(R)$ is the ground field and $H^{>N}(R)= 0$ then dim$\\, {\\mathcal T}(R)= 1$\nif and only if $H(R)$ is a Poincar\\'e duality algebra. In the case of Sullivan\nextensions $\\land W\\to \\land W\\otimes \\land Z\\to \\land Z$ in which dim$\\,\nH(\\land Z)<\\infty$ we show that $${\\mathcal T}(\\land W\\otimes \\land Z)=\n{\\mathcal T}(\\land W)\\otimes {\\mathcal T}(\\land Z).$$ This is applied to finite\ndimensional CW complexes $X$ where the fundamental group $G$ acts nilpotently\nin the cohomology $H(\\widetilde{X};\\mathbb Q)$ of the universal covering space.\nIf $H(X;\\mathbb Q)$ is a Poincar\\'e duality algebra and\n$H(\\widetilde{X};\\mathbb Q)$ and $H(BG;\\mathbb Q)$ are finite dimensional then\nthey are also Poincar\\'e duality algebras.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A Lagrangian subspace $L$ of a weak symplectic vector space is called\n\\emph{split Lagrangian} if it has an isotropic (hence Lagrangian) complement.\nWhen the symplectic structure is strong, it is sufficient for $L$ to have a\nclosed complement, which can then be moved to become isotropic. The purpose of\nthis note is to develop the theory of compositions and reductions of split\ncanonical relations for symplectic vector spaces. We give conditions on a\ncoisotropic subspace $C$ of a weak symplectic space $V$ which imply that the\ninduced canonical relation $L_C$ from $V$ to $C/C^{\\omega}$ is split, and, from\nthese, we find sufficient conditions for split canonical relations to compose\nwell. We prove that the canonical relations arising in the Poisson sigma model\nfrom the Lagrangian field theoretical approach are split, giving a description\nof symplectic groupoids integrating Poisson manifolds in terms of split\ncanonical relations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Quantum key distribution (QKD) protocol has been proved to provide\nunconditionally secure key between two remote legitimate users in theory. Key\ndistribution signals are transmitted in a quantum channel which is established\nby the calibration process to meet the requirement of high count rate and low\nerror rate. All QKD security proofs implicitly assume that the quantum channel\nhas been established securely. However, the eavesdropper may attack the\ncalibration process to break the security assumption of QKD and provide\nprecondition to steal information about the final key successfully. Inspired by\nN. Jain et al., Phys. Rev. Lett.107,110501(2011), we reveal the security risk\nof the calibration process of a passive-basis-choice BB84 QKD system by\nlaunching a quantum man-in-the-middle attack which intercepts all calibration\nsignals and resends faked ones. Large temporal bit-dependent or basis-dependent\ndetector efficiency mismatch can be induced. Then we propose a basis-dependent\ndetector efficiency mismatch (BEM) based faked states attack on a single photon\nBB84 QKD to stress the threat of BEM. Moreover, the security of single photon\nQKD systems with BEM is studied simply and intuitively. Two effective\ncountermeasures are suggested to remove the general security risk of the\ncalibration process.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Roles of electron correlation effects in the determination of attachment\nenergies, magnetic dipole hyperfine structure constants and electric dipole\n(E1) matrix elements of the low-lying states in the singly charged cadmium ion\n(Cd$^+$) have been analyzed. We employ the singles and doubles approximated\nrelativistic coupled-cluster (RCC) method to calculate these properties.\nIntermediate results from the Dirac-Hartree-Fock approximation, second-order\nmany-body perturbation theory and considering only the linear terms of the RCC\nmethod are given to demonstrate propagation of electron correlation effects in\nthis ion. Contributions from important RCC terms are also given to highlight\nimportance of various correlation effects in the evaluation of these\nproperties. At the end, we also determine E1 polarizabilities ($\\alpha^{E1}$)\nof the ground and $5p \\ ^2P_{1/2;3/2}$ states of Cd$^+$ in the {\\it ab initio}\napproach. We estimate them again by replacing some of the E1 matrix elements\nand energies from the measurements to reduce their uncertainties so that they\ncan be used in the high precision experiments of this ion.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We develop techniques to analyse the statistics of completion times of\nnon-deterministic elements in quantum entanglement generation, and how they\naffect the overall performance as measured by the secret key rate. By\nconsidering such processes as Markov chains, we show how to obtain exact\nexpressions for the probability distributions over the number of errors that a\nnetwork acquires, as well as the distribution of entanglement establishment\ntimes. We show how results from complex analysis can be used to analyse Markov\nmatrices to extract information with a lower computational complexity than\nprevious methods. We apply these techniques to the Innsbruck quantum repeater\nprotocol, and find that consideration of the effect of statistical fluctuations\ntightens bounds on the secret key rate by 3 orders of magnitude. We also use\nthe theory of order statistics to derive tighter bounds on the minimum quantum\nmemory lifetimes that are required in order to communicate securely.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $X$ be an irreducible smooth projective curve of genus $g \\geq 2$ over\n$\\mathbb{C}$. Let $G$ be a connected reductive affine algebraic group over\n$\\mathbb{C}$. Let $\\mathrm{M}_{G, {\\rm Higgs}}^{\\delta}$ be the moduli space of\nsemistable principal $G$--Higgs bundles on $X$ of topological type $\\delta \\in\n\\pi_1(G)$. In this article, we compute the fundamental group and Picard group\nof $\\mathrm{M}_{G, {\\rm Higgs}}^{\\delta}$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In the past decades, intensive efforts have been put to design various loss\nfunctions and metric forms for metric learning problem. These improvements have\nshown promising results when the test data is similar to the training data.\nHowever, the trained models often fail to produce reliable distances on the\nambiguous test pairs due to the distribution bias between training set and test\nset. To address this problem, the Adversarial Metric Learning (AML) is proposed\nin this paper, which automatically generates adversarial pairs to remedy the\ndistribution bias and facilitate robust metric learning. Specifically, AML\nconsists of two adversarial stages, i.e. confusion and distinguishment. In\nconfusion stage, the ambiguous but critical adversarial data pairs are\nadaptively generated to mislead the learned metric. In distinguishment stage, a\nmetric is exhaustively learned to try its best to distinguish both the\nadversarial pairs and the original training pairs. Thanks to the challenges\nposed by the confusion stage in such competing process, the AML model is able\nto grasp plentiful difficult knowledge that has not been contained by the\noriginal training pairs, so the discriminability of AML can be significantly\nimproved. The entire model is formulated into optimization framework, of which\nthe global convergence is theoretically proved. The experimental results on toy\ndata and practical datasets clearly demonstrate the superiority of AML to the\nrepresentative state-of-the-art metric learning methodologies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The sensitivity of beam dump experiments to heavy neutrinos depends on the\nrelative size of their mixings with the lepton flavours in the Standard Model.\nWe study the impact of present neutrino oscillation data on these mixing angles\nin the minimal type I seesaw model. We find that current data significantly\nconstrains the allowed heavy neutrino flavour mixing patterns. Based on this,\nwe discuss the implications for the sensitivity of the NA62 experiment to heavy\nneutrinos when operated in the beam dump mode. We find that NA62 is currently\nthe most sensitive experiment in the world for heavy neutrino masses between\nthat of the kaon and the $D$-mesons. The sensitivity can vary by almost two\norders of magnitude if the heavy neutrinos exclusively couple to the tau\nflavour, but depends only comparably weakly on the flavour mixing pattern\nwithin the parameter range preferred by light neutrino oscillation data.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Optimal mechanism design enjoys a beautiful and well-developed theory, and\nalso a number of killer applications. Rules of thumb produced by the field\ninfluence everything from how governments sell wireless spectrum licenses to\nhow the major search engines auction off online advertising. There are,\nhowever, some basic problems for which the traditional optimal mechanism design\napproach is ill-suited---either because it makes overly strong assumptions, or\nbecause it advocates overly complex designs. This survey reviews several common\nissues with optimal mechanisms, including exorbitant communication,\ncomputation, and informational requirements; and it presents several examples\ndemonstrating that passing to the relaxed goal of an approximately optimal\nmechanism allows us to reason about fundamental questions that seem out of\nreach of the traditional theory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove (Theorem 2.4) that the symmetrized deleted join\n$SymmDelJoin(\\mathcal{K})$ of a \"balanced family\" $\\mathcal{K} = \\langle\nK_i\\rangle_{i=1}^r$ of collectively $r$-unavoidable subcomplexes of $2^{[m]}$\nis $(m-r-1)$-connected. As a consequence we obtain a Tverberg-Van Kampen-Flores\ntype result (Theorem 3.2) which is more conceptual and more general then\npreviously known results. Already the case $r=2$ of Theorem 3.2 seems to be new\nas an extension of the classical Van Kampen-Flores theorem. The main tool used\nin the paper is R. Forman's discrete Morse theory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a solid state maser based on Cu2O, where ensemble of highly\nexcited Rydberg exciton states serves as a gain medium. We show that the system\nis highly tunable with external electric field, allowing for a wide range of\nemission frequencies. Numerical simulations of system dynamics are performed to\noptimize the conditions for efficient masing and estimate the emission power.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The fundamental frequency (F0) represents pitch in speech that determines\nprosodic characteristics of speech and is needed in various tasks for speech\nanalysis and synthesis. Despite decades of research on this topic, F0\nestimation at low signal-to-noise ratios (SNRs) in unexpected noise conditions\nremains difficult. This work proposes a new approach to noise robust F0\nestimation using a recurrent neural network (RNN) trained in a supervised\nmanner. Recent studies employ deep neural networks (DNNs) for F0 tracking as a\nframe-by-frame classification task into quantised frequency states but we\npropose waveform-to-sinusoid regression instead to achieve both noise\nrobustness and accurate estimation with increased frequency resolution.\n  Experimental results with PTDB-TUG corpus contaminated by additive noise\n(NOISEX-92) demonstrate that the proposed method improves gross pitch error\n(GPE) rate and fine pitch error (FPE) by more than 35 % at SNRs between -10 dB\nand +10 dB compared with well-known noise robust F0 tracker, PEFAC.\nFurthermore, the proposed method also outperforms state-of-the-art DNN-based\napproaches by more than 15 % in terms of both FPE and GPE rate over the\npreceding SNR range.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present an extension to the Tacotron speech synthesis architecture that\nlearns a latent embedding space of prosody, derived from a reference acoustic\nrepresentation containing the desired prosody. We show that conditioning\nTacotron on this learned embedding space results in synthesized audio that\nmatches the prosody of the reference signal with fine time detail even when the\nreference and synthesis speakers are different. Additionally, we show that a\nreference prosody embedding can be used to synthesize text that is different\nfrom that of the reference utterance. We define several quantitative and\nsubjective metrics for evaluating prosody transfer, and report results with\naccompanying audio samples from single-speaker and 44-speaker Tacotron models\non a prosody transfer task.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the stability and dynamics of traveling-front solutions of a\nmodified Kuramoto--Sivashinsky equation arising in the modeling of nanoscale\nripple patterns that form when a nominally flat solid surface is bombarded with\na broad ion beam at an oblique angle of incidence. Structurally, the linearized\noperators associated with these fronts have unstable essential\nspectrum---corresponding to instability of the spatially asymptotic\nstates---and stable point spectrum---corresponding to stability of the\ntransition profile of the front. We show that these waves are linearly\norbitally asymptotically stable in appropriate exponentially weighted spaces.\nWhile the technical device of exponential weights allows us to accommodate the\nunstable essential spectrum of individual waves in our linear analysis, it does\nnot shed light on the long-time pattern formation that is observed\nexperimentally and in numerical simulations. To begin to address this issue, we\nconsider a periodic array of unstable front and back solutions. While not an\nexact solution of the governing equation, this periodic pattern mimics\nexperimentally observed phenomena. Our numerical experiments suggest that the\nconvecting instabilities associated with each individual wave are damped as\nthey pass through transition layers and that this stabilization mechanism\nunderlies the pattern formation seen in experiments.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Yield stress materials form an interesting class of materials that behave\nlike solids at small stresses, but start to flow once a critical stress is\nexceeded. It has already been reported both in experimental and simulation work\nthat flow curves of different yield stress materials can be scaled with the\ndistance to jamming or with the confining pressure. However, different scaling\nexponents are found between experiments and simulations. In this paper we\nidentify sources of this discrepancy. We numerically relate the volume fraction\nwith the confining pressure and discuss the similarities and differences\nbetween rotational and oscillatory measurements. Whereas simulations are\nperformed in the elastic response regime close to the jamming transition and\nwith very small amplitudes to calculate the scaling exponents, these conditions\nare hardly possible to achieve experimentally. Measurements are often performed\nfar away from the critical volume fraction and at large amplitudes. We show\nthat these differences are the underlying reason for the different exponents\nfor rescaling flow curves.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We use geometric ideas coming from certain classic algebraic constructions to\nassociate, to every classical field theory, a symmetric monoidal double functor\nfrom the double category of cobordisms with corners to a certain symmetric\nmonoidal double category. We call symmetric monoidal double functors so\nconstructed cylinder topological quantum field theories. Our initial\nformulation of cylinder topological quantum field theory is presented in a\npurely topological context. We present appropriate refinements in order to\naccommodate information relevant to classical field theory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Massive early-type galaxies typically have two subpopulations of globular\nclusters (GCs) which often reveal radial colour (metallicity) gradients.\nCollating gradients from the literature, we show that the gradients in the\nmetal-rich and metal-poor GC subpopulations are the same, within measurement\nuncertainties, in a given galaxy. Furthermore, these GC gradients are similar\nin strength to the {\\it stellar} metallicity gradient of the host galaxy. At\nthe very largest radii (e.g. greater than 8 galaxy effective radii) there is\nsome evidence that the GC gradients become flat with near constant mean\nmetallicity. Using stellar metallicity gradients as a proxy, we probe the\nassembly histories of massive early-type galaxies with hydrodynamical\nsimulations from the Magneticum suite of models. In particular, we measure the\nstellar metallicity gradient for the in-situ and accreted components over a\nsimilar radial range as those observed for GC subpopulations. We find that the\nin-situ and accreted stellar metallicity gradients are similar but have a\nlarger scatter than the metal-rich and metal-poor GC subpopulations gradients\nin a given galaxy. We conclude that although metal-rich GCs are predominately\nformed during the in-situ phase and metal-poor GCs during the accretion phase\nof massive galaxy formation, they do not have a strict one-to-one connection.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper presents a solution to the landing gear system case study using\nEvent-B and Rodin. We study the whole system (both the digital part and the\ncontrolled part). We use feature augmentation to build an abstract model of the\nwhole system and structural refinement to detail more specifically the digital\npart. The required safety properties are formalised and proved. We propose a\nspecific approach to deal with a family of reachability properties. The\nexperimentations conducted during the study are supported by the Rodin tools.\nWe show that the presented solution is systematic and it can be applied to\nsimilar case studies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  After defining a pure-action profile in a nonatomic aggregative game, where\nplayers have specific compact convex pure-action sets and nonsmooth convex cost\nfunctions, as a square-integrable function, we characterize a Wardrop\nequilibrium as a solution to an infinite-dimensional generalized variational\ninequality. We show the existence of Wardrop equilibrium and variational\nWardrop equilibrium, a concept of equilibrium adapted to the presence of\ncoupling constraints, in monotone nonatomic aggregative games. The uniqueness\nof (variational) Wardrop equilibrium is proved for strictly or aggregatively\nstrictly monotone nonatomic aggregative games. We then show that, for a\nsequence of finite-player aggregative games with aggregative constraints, if\nthe players' pure-action sets converge to those of a strongly (resp.\naggregatively strongly) monotone nonatomic aggregative game, and the\naggregative constraints in the finite-player games converge to the aggregative\nconstraint of the nonatomic game, then a sequence of so-called variational Nash\nequilibria in these finite-player games converge to the variational Wardrop\nequilibrium in pure-action profile (resp. aggregate-action profile). In\nparticular, it allows the construction of an auxiliary sequence of games with\nfinite-dimensional equilibria to approximate the infinite-dimensional\nequilibrium in such a nonatomic game. Finally, we show how to construct\nauxiliary finite-player games for two general classes of nonatomic games.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The decay $\\Lambda_b^0 \\to \\Lambda_c^+ p \\overline{p} \\pi^-$ is observed\nusing $pp$ collision data collected with the LHCb detector at centre-of-mass\nenergies of $\\sqrt{s}=$ 7 and 8 TeV, corresponding to an integrated luminosity\nof 3 $fb^{-1}$. The ratio of branching fractions between $\\Lambda_b^0 \\to\n\\Lambda_c^+ p \\overline{p} \\pi^-$ and $\\Lambda_b^0 \\to \\Lambda_c^+ \\pi^-$\ndecays is measured to be \\begin{equation*}\n  \\frac{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+ p\n\\overline{p}\\pi^-)}{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+ \\pi^-)} = 0.0540\n\\pm 0.0023 \\pm 0.0032. \\end{equation*} Two resonant structures are observed in\nthe $ \\Lambda_c^+ \\pi^-$ mass spectrum of the ${\\Lambda_b^0 \\to \\Lambda_c^+\np\\overline{p} \\pi^-}$ decays, corresponding to the $\\Sigma_c(2455)^0$ and\n$\\Sigma_c^{*}(2520)^0$ states. The ratios of branching fractions with respect\nto the decay $\\Lambda_b^0 \\to \\Lambda_c^+ p \\overline{p} \\pi^-$ are\n\\begin{align*}\n  \\frac{\\mathcal{B}(\\Lambda_b^0 \\to \\Sigma_c^0\np\\overline{p})\\times\\mathcal{B}(\\Sigma_c^0\\to \\Lambda_c^+\n\\pi^-)}{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+ p \\overline{p}\\pi^-)} =\n0.089\\pm0.015\\pm0.006,\n  \\frac{\\mathcal{B}(\\Lambda_b^0 \\to \\Sigma_c^{*0}\np\\overline{p})\\times\\mathcal{B}(\\Sigma_c^{*0}\\to \\Lambda_c^+\n\\pi^-)}{\\mathcal{B}(\\Lambda_b^0 \\to \\Lambda_c^+ p \\overline{p}\\pi^-)} =\n0.119\\pm0.020\\pm0.014. \\end{align*} In all of the above results, the first\nuncertainty is statistical and the second is systematic. The phase space is\nalso examined for the presence of dibaryon resonances. No evidence for such\nresonances is found.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The effect of graded or constant bias voltages (-40 V, -80 V and -40/60/80 V)\non size grain and surface defects of arc PVD deposited CrN films was\ninvestigated. Corrosion resistance evaluated using electrochemical impedance\nspectroscopy (EIS) and potentiodynamic curves (Tafel) and the mechanical\nbehavior evaluated by means of instrumented nanoindentation and scratch testing\nwas correlated with the microstructural changes. It was found that the bias\nvoltage variation affects corrosion behavior due to the presence of defects\n(i.e. open voids, droplets) which also affects the failure mechanisms and\nincreasing spallation. High bias voltage (-80 V) increases nano-hardness and\nthe elastic modulus due to the dense microstructure of the CrN coating.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In 2011 Deshouillers and Ruzsa tried to argument that the sequence of the\nlast nonzero digit of $n!$ in base 12 is not automatic. This statement was\nproved few years later by Deshoulliers. In this paper we provide alternate\nproof that lets us generalize the problem and give an exact characterization in\nwhich bases the sequence of the last nonzero digits of $n!$ is automatic.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Orthogonal frequency division multiplexing with index modulation (OFDM-IM) is\na novel multicarrier scheme, which uses the indices of the active subcarriers\nto transmit data. OFDM-IM also inherits the high peak-to-average power ratio\n(PAPR) problem, which induces in-band distortion and out-of-band radiation when\nOFDM-IM signal passes through high power amplifier (HPA). In this letter,\ndither signals are added in the idle subcarriers to reduce the PAPR. Unlike the\nprevious work using single level dither signals, multilevel dither signals are\nused by exploiting that the amplitudes of the active subcarriers are variously\ndistributed for different subblocks. As a result, the proposed scheme gives the\ndither signals more freedom (a larger radius of dithering) in average.\nSimulation results show that the proposed scheme can achieve better PAPR\nreduction performance than the previous work.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The chromo magnetic dipole moment (CMDM) and chromo electric dipole moment\n(CEDM) of the top quark are calculated at the one-loop level in the framework\nof the two-Higgs doublet model with four fermion generations (4GTHDM), which is\nstill consistent with experimental data and apart from new scalar bosons\n($H^0$, $A^0$, and $H^\\pm$) and quarks ($b'$ and $t'$) predicts new sources of\n$CP$ violation via the extended $4\\times 4$ CKM matrix. Analytical expressions\nfor the CMDM and CEDM of a quark are presented both in terms of Feynman\nparameter integrals and Passarino-Veltman scalar functions, with the main\ncontributions arising from loops carrying the scalar bosons accompanied by the\nthird- and fourth-generation quarks. The current bounds on the parameter space\nof the 4GTHDM are discussed and a region still consistent with the LHC data on\nthe 125 GeV Higgs boson is identified. It is found that the top quark CMDM,\nwhich is induced by all the scalar bosons, can reach values of the order of\n$10^{-4}$-$10^{-3}$, with the dominant contributions arising from the fourth\ngeneration quarks, though may also be large cancellations for some parameter\nvalues, thereby giving a negligible CMDM. As for the top quark CEDM, it only\nreceives contributions from the charged scalar boson and can reach values of\nthe order of $10^{-19}$-$10^{-18}$ ecm for relatively light $m_{H^\\pm}$ and\nlarge $m_{b'}$, with the dominant contribution arising from the $b'$ quark. The\nlatter would be the most interesting prediction of this model as can be larger\nthan the value predicted by the usual THDMs by one or two orders of magnitude.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Machine learning has an emerging critical role in high-performance computing\nto modulate simulations, extract knowledge from massive data, and replace\nnumerical models with efficient approximations. Decision forests are a critical\ntool because they provide insight into model operation that is critical to\ninterpreting learned results. While decision forests are trivially\nparallelizable, the traversals of tree data structures incur many random memory\naccesses and are very slow. We present memory packing techniques that\nreorganize learned forests to minimize cache misses during classification. The\nresulting layout is hierarchical. At low levels, we pack the nodes of multiple\ntrees into contiguous memory blocks so that each memory access fetches data for\nmultiple trees. At higher levels, we use leaf cardinality to identify the most\npopular paths through a tree and collocate those paths in cache lines. We\nextend this layout with out-of-order execution and cache-line prefetching to\nincrease memory throughput. Together, these optimizations increase the\nperformance of classification in ensembles by a factor of four over an\noptimized C++ implementation and a actor of 50 over a popular R language\nimplementation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The current deployed multipath congestion control algorithms couple all the\nsubflows together to avoid bandwidth occupation aggressiveness if the subflows\nof multipath transmission protocol share common bottleneck with single path\nTCP. The coupled congestion control algorithms can guarantee well fairness\nproperty in common bottleneck but result in rate increase conservativeness in\nnone-sharing bottleneck situation. Thus, the throughput of multipath session\ncan be further improved when combing with effective shared bottleneck detection\nmechanism. This paper proposes a delay trend line regression method to detect\nif flows share common bottleneck. Deduced from TCP fluid model, the packet\nround trip delay signal shows linear increase property during the queue\nbuilding up process of the narrowest link and the delay trend line slopes of\ntwo flows are in close proximity if they traverse the same bottleneck link. The\nproposed method is implemented on multipath QUIC golang codebase and extensive\nsimulations are performed to validate its effectiveness in detecting out flows\ntraversing common bottleneck. If the subflows are detected out via a common\nbottleneck, the sender would perform coupled congestion control algorithm and\nperform congestion control seperately on flow level in none sharing bottleneck\ncase. Results show a multipath session with two subflows can obtain 74\\% gain\non average in throughput compared with single path connection when Linked\nIncreases Algorithm (LIA) is in combination with trend line regession shared\nbottlenck detection algorithm in none shared bottleneck, and show well fairness\nproperty in common bottleneck scenarios.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We give a new proof of the norm relations for the Asai-Flach Euler system\nbuilt by Lei-Loeffler-Zerbes. More precisely, we redefine Asai-Flach classes in\nthe language used by Loeffler-Skinner-Zerbes for Lemma-Eisenstein classes and\nprove both the vertical and the tame norm relations using local zeta integrals.\nThese Euler system norm relations for the Asai representation attached to a\nHilbert modular form over a quadratic real field $F$ have been already proved\nby Lei-Loeffler-Zerbes for primes which are inert in $F$ and for split primes\nsatisfying some assumption; with this technique we are able to remove it and\nprove tame norm relations for all inert and split primes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, we extend the fractional linear multistep methods in [C.\nLubich, SIAM J. Math. Anal., 17 (1986), pp.704--719] to the tempered fractional\nintegral and derivative operators in the sense that the tempered fractional\nderivative operator is interpreted in terms of the Hadamard finite-part\nintegral. We develop two fast methods, Fast Method I and Fast Method II, with\nlinear complexity to calculate the discrete convolution for the approximation\nof the (tempered) fractional operator. Fast Method I is based on a local\napproximation for the contour integral that represents the convolution weight.\nFast Method II is based on a globally uniform approximation of the trapezoidal\nrule for the integral on the real line. Both methods are efficient, but\nnumerical experimentation reveals that Fast Method II outperforms Fast Method I\nin terms of accuracy, efficiency, and coding simplicity. The memory requirement\nand computational cost of Fast Method II are $O(Q)$ and $O(Qn_T)$,\nrespectively, where $n_T$ is the number of the final time steps and $Q$ is the\nnumber of quadrature points used in the trapezoidal rule. The effectiveness of\nthe fast methods is verified through a series of numerical examples for\nlong-time integration, including a numerical study of a fractional\nreaction-diffusion model.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show the existence of a Lipschitz viscosity solution $u$ in $\\Omega$ to a\nsystem of fully nonlinear equations involving Pucci-type operators. We study\nthe regularity of the interface $\\partial \\{ u> 0 \\}\\cap\\Om$ and we show that\nthe viscosity inequalities of the system imply, in the weak sense, the free\nboundary condition $u^{+}_{\\nu_{+}} = u^{-}_{\\nu_{-}}$, and hence $u$ is a\nsolution to a two-phase free boundary problem. We show that we can apply the\nclassical method of sup-convolutions developed by the first author in\n\\cite{caffarelli_harnack_1987,caffarelli_harnack_1989}, and generalized by Wang\n\\cite{wang_regularity_2000,wang_regularity_2002} and Feldman \\cite{Fel} to\nfully nonlinear operators, to conclude that the regular points in $\\partial \\{\nu> 0 \\}\\cap\\Om$ form an open set of class $C^{1,\\alpha}$. A novelty in our\nproblem is that we have different operators, $\\puccip$ and $\\puccin$, on each\nside of the free boundary. In the particular case when these operators are the\nPucci's extremal operators $\\ppuccip$ and $\\ppuccin$, our results provide an\nalternative approach to obtain the stationary limit %proof of existence to the\none obtained from of a segregation model of populations with nonlinear\ndiffusion in \\cite{quitalo_free_2013}.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce a discrete delayed exponential depending on sequence of\nmatrices. This discrete matrix gives a representation of a solution to the\nCauchy problem for a discrete linear system with pure delay with sequence of\nmatrices. We discard the commutativity condition used in recent works related\nto the representation of solutions for discrete delay linear systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  What determines precipitate morphologies in co-precipitating alloy systems?\nWe focus on alloys of two precipitating phases, with precipitates of the\nfast-precipitating phase acting as heterogeneous nucleation sites for a second\nphase manifesting slower kinetics. We study a FeCuMnNiSi alloy using the\ncombination of atom probe tomography and kinetic Monte Carlo simulations. It is\nshown that the interplay between interfacial and ordering energies, plus active\ndiffusion paths, strongly affect the selection of core-shell verses appendage\nmorphologies. Specifically, the ordering energy reduction of the MnNiSi phase\nheterogeneously nucleated on a pre-existing copper-rich precipitate exceeds the\nenergy penalty of a predominantly Fe/Cu interface, leading to initial\nappendage, rather than core-shell, formation. Diffusion of Mn, Ni and Si around\nand through the Cu core towards the ordered phase results in subsequent\nappendage growth. We further show that in cases with higher primary precipitate\ninterface energies and/or suppressed ordering, the core-shell morphology is\nfavored.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce AREPO-RT, a novel radiation hydrodynamic (RHD) solver for the\nunstructured moving-mesh code AREPO. Our method solves the moment-based\nradiative transfer equations using the M1 closure relation. We achieve second\norder convergence by using a slope limited linear spatial extrapolation and a\nfirst order time prediction step to obtain the values of the primitive\nvariables on both sides of the cell interface. A Harten-Lax-Van Leer flux\nfunction, suitably modified for moving meshes, is then used to solve the\nRiemann problem at the interface. The implementation is fully conservative and\ncompatible with the individual timestepping scheme of AREPO. It incorporates\natomic Hydrogen (H) and Helium (He) thermochemistry, which is used to couple\nthe ultra-violet (UV) radiation field to the gas. Additionally, infrared\nradiation is coupled to the gas under the assumption of local thermodynamic\nequilibrium between the gas and the dust. We successfully apply our code to a\nlarge number of test problems, including applications such as the expansion of\n${\\rm H_{II}}$ regions, radiation pressure driven outflows and the levitation\nof optically thick layer of gas by trapped IR radiation. The new implementation\nis suitable for studying various important astrophysical phenomena, such as the\neffect of radiative feedback in driving galactic scale outflows, radiation\ndriven dusty winds in high redshift quasars, or simulating the reionisation\nhistory of the Universe in a self consistent manner.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In software engineering, impact analysis involves predicting the software\nelements (e.g., modules, classes, methods) potentially impacted by a change in\nthe source code. Impact analysis is required to optimize the testing effort. In\nthis paper, we propose an evaluation technique to predict impact propagation.\nBased on 10 open-source Java projects and 5 classical mutation operators, we\ncreate 17,000 mutants and study how the error they introduce propagates. This\nevaluation technique enables us to analyze impact prediction based on four\ntypes of call graph. Our results show that graph sophistication increases the\ncompleteness of impact prediction. However, and surprisingly to us, the most\nbasic call graph gives the best trade-off between precision and recall for\nimpact prediction.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show that for human-object interaction detection a relatively simple\nfactorized model with appearance and layout encodings constructed from\npre-trained object detectors outperforms more sophisticated approaches. Our\nmodel includes factors for detection scores, human and object appearance, and\ncoarse (box-pair configuration) and optionally fine-grained layout (human\npose). We also develop training techniques that improve learning efficiency by:\n(1) eliminating a train-inference mismatch; (2) rejecting easy negatives during\nmini-batch training; and (3) using a ratio of negatives to positives that is\ntwo orders of magnitude larger than existing approaches. We conduct a thorough\nablation study to understand the importance of different factors and training\ntechniques using the challenging HICO-Det dataset.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The entanglement in a quantum system that possess an internal symmetry,\ncharacterized by the Sz-magnetization or U(1)-charge, is distributed among\ndifferent sectors. The aim of this letter is to gain a deeper understanding of\nthe contribution to the entanglement entropy in each of those sectors for the\nground state of conformal invariant critical one dimensional systems. We find\nsurprisingly that the entanglement entropy is equally distributed among the\ndifferent magnetization sectors. Its value is given by the standard area law\nviolating logarithmic term, that depends on the central charge c, minus a\ndouble logarithmic correction related to the zero temperature susceptibility.\nThis result provides a new method to estimate simultaneously the central charge\nc and the critical exponents of U(1)-symmetric quantum chains. The method is\nnumerically simple and gives precise results for the spin-1/2 quantum XXZ\nchain. We also compute the probability distribution of the magnetization in\ncontiguous sublattices.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the coherent energy and thermal transport in a\ntemperature-biased long Josephson tunnel junction, when a Josephson vortex,\ni.e., a soliton, steadily drifts driven by an electric bias current. We\ndemonstrate that thermal transport through the junction can be controlled by\nthe bias current, since it determines the steady-state velocity of the drifting\nsoliton. We study the effects on thermal transport of the damping affecting the\nsoliton dynamics. In fact, a soliton locally influences the power flowing\nthrough the junction and can cause the variation of the temperature of the\ndevice. When the soliton speed increases approaching its limiting value, i.e.,\nthe Swihart velocity, we demonstrate that the soliton-induces thermal effects\nsignificantly modify. Finally, we discuss how the appropriate material\nselection of the superconductors forming the junction is essential, since short\nquasiparticle relaxation times are required to observe fast thermal effects.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Convexity plays a prominent role in a number of problems, but practical\nconsiderations frequently give rise to non-convex functions. We suggest a\nmethod for determining convex regions, and also for assessing the lack of\nconvexity in the other regions. The method relies on a specially constructed\ndecomposition of symmetric matrices, such as the Hessian. We illustrate\ntheoretical results using several examples, one of which analyses a problem\narising in risk measurement and management in insurance and finance.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  EFOSC2 (the European Southern Observatory Faint Object Spectrograph and\nCamera v2) is one of the workhorse instruments on ESO's New Technology\nTelescope (NTT), and is one of the most popular instruments at La Silla\nobservatory. It is mounted at a Nasmyth focus, and therefore exhibits strong,\nwavelength and pointing-direction dependent instrumental polarisation. In this\ndocument we describe our efforts to calibrate the broadband imaging polarimetry\nmode, and provide a calibration for broadband B, V, R filters to a level that\nsatisfies most use cases (i.e. polarimetric calibration uncertainty ~0.1%). We\nmake our calibration codes public. This calibration effort can be used to\nenhance the yield of future polarimetric programmes with EFOSC2, by allowing\ngood calibration with a greatly reduced number of standard star observations.\nSimilarly, our calibration model can be combined with archival calibration\nobservations to post-process data taken in past years, to form a EFOSC2 legacy\narchive with substantial scientific potential.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We explore a method for automatically recompiling a quantum circuit A into a\ntarget circuit B, with the goal that both circuits have the same action on a\nspecific input i.e. B|in> = A|in>. This is of particular relevance to hybrid,\nNISQ-era algorithms for dynamical simulation or eigensolving. The user\ninitially specifies B as a blank template: a layout of parameterised unitary\ngates configured to the identity. The compilation then proceeds using quantum\nhardware to perform an isomorphic energy-minimisation task, and an optional\ngate elimination phase to compress the circuit. If B is insufficient for\nperfect recompilation then the method will result in an approximate solution.\nWe optimise using imaginary time evolution, and a recent extension of quantum\nnatural gradient for noisy settings. We successfully recompile a 7-qubit\ncircuit involving 186 gates of multiple types into an alternative form with a\ndifferent topology, far fewer two-qubit gates, and a smaller family of gate\ntypes. Moreover we verify that the process is robust, finding that per-gate\nnoise of up to 1% can still yield near-perfect recompilation. We test the\nscaling of our algorithm on up to 20 qubits, recompiling into circuits with up\nto 400 parameterized gates, and incorporate a custom adaptive timestep\ntechnique. We note that a classical simulation of the process can be useful to\noptimise circuits for today's prototypes, and more generally the method may\nenable 'blind' compilation i.e. harnessing a device whose response to control\nparameters is deterministic but unknown.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In a Private Information Retrieval (PIR) protocol, a user can download a file\nfrom a database without revealing the identity of the file to each individual\nserver. A PIR protocol is called $t$-private if the identity of the file\nremains concealed even if $t$ of the servers collude. Graph based replication\nis a simple technique, which is prevalent in both theory and practice, for\nachieving erasure robustness in storage systems. In this technique each file is\nreplicated on two or more storage servers, giving rise to a (hyper-)graph\nstructure. In this paper we study private information retrieval protocols in\ngraph based replication systems. The main interest of this work is maximizing\nthe parameter $t$, and in particular, understanding the structure of the\ncolluding sets which emerge in a given graph. Our main contribution is a\n$2$-replication scheme which guarantees perfect privacy from acyclic sets in\nthe graph, and guarantees partial-privacy in the presence of cycles.\nFurthermore, by providing an upper bound, it is shown that the PIR rate of this\nscheme is at most a factor of two from its optimal value for an important\nfamily of graphs. Lastly, we extend our results to larger replication factors\nand to graph-based coding, which is a similar technique with smaller storage\noverhead and larger PIR rate.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Estimating the causal effects of an intervention in the presence of\nconfounding is a frequently occurring problem in applications such as medicine.\nThe task is challenging since there may be multiple confounding factors, some\nof which may be missing, and inferences must be made from high-dimensional,\nnoisy measurements. In this paper, we propose a decision-theoretic approach to\nestimate the causal effects of interventions where a subset of the covariates\nis unavailable for some patients during testing. Our approach uses the\ninformation bottleneck principle to perform a discrete, low-dimensional\nsufficient reduction of the covariate data to estimate a distribution over\nconfounders. In doing so, we can estimate the causal effect of an intervention\nwhere only partial covariate information is available. Our results on a causal\ninference benchmark and a real application for treating sepsis show that our\nmethod achieves state-of-the-art performance, without sacrificing\ninterpretability.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate percolation on a randomly directed lattice, an intermediate\nbetween standard percolation and directed percolation, focusing on the\nisotropic case in which bonds on opposite directions occur with the same\nprobability. We derive exact results for the percolation threshold on planar\nlattices, and present a conjecture for the value the percolation-threshold for\nin any lattice. We also identify presumably universal critical exponents,\nincluding a fractal dimension, associated with the strongly-connected\ncomponents both for planar and cubic lattices. These critical exponents are\ndifferent from those associated either with standard percolation or with\ndirected percolation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  OAuth 2.0 is a framework for authorization. Being a framework, OAuth 2.0\nallows extensions to build on top of it. OpenID Connect is one such extension\nwhich adds authentication layer using identity details. OAuth 2.0 define\nseveral roles that are required to complete the protocol. Both OAuth 2.0 and\nOpenID Connect involve interactions between these roles. These interactions\nrequire a pre-established trust or a trust establishment while protocol\noperate. This paper analyzes trust establishments between OAuth 2.0 roles and\ndiscuss important aspects of them. Such analysis is required for proper\nunderstanding of the protocols.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the (Lascar) Galois group of any countable theory as a quotient of\na compact Polish group by an $F_\\sigma$ normal subgroup: in general, as a\ntopological group, and under NIP, also in terms of Borel cardinality. This\nallows us to obtain similar results for arbitrary strong types defined on a\nsingle complete type over $\\emptyset$. As an easy conclusion of our main\ntheorem, we get the main result from our recent paper joint with Andand Pillay,\nwhich says that for any strong type defined on a single complete type over\n$\\emptyset$, smoothness is equivalent to type-definability.\n  We also explain how similar results are obtained in the case of bounded\nquotients of type-definable groups. This gives us a generalization of a former\nresult from the aforementioned paper about bounded quotients of type-definable\nsubgroups of definable groups.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Azimuthal distributions of radial velocities of charged hadrons produced in\nnucleus-nucleus $(AB)$ collisions are compared with the corresponding azimuthal\ndistribution of charged hadron multiplicity in the framework of a multiphase\ntransport (AMPT) model at two different collision energies. The mean radial\nvelocity seems to be a good probe for studying radial expansion. While the\nanisotropic part of the distributions indicates a kind of collective nature of\nradial expansion, the isotropic part characterizes a thermal motion. The\npresent investigation is carried out keeping the upcoming Compressed Baryonic\nMatter (CBM) experiment to be held at the Facility for Anti-proton Ion Research\n(FAIR) in mind. As far as high-energy heavy-ion interactions are concerned, CBM\nwill supplement the Relativistic Heavy Ion Collider (RHIC) and Large Hadron\nCollider (LHC) experiments. In this context our simulation results at high\nbaryochemical potential would be interesting, when scrutinized from the\nperspective of almost a baryon free environment achieved at RHIC and LHC.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The electromagnetic transitions of $^9$Be with linearly polarized\n$\\gamma$-rays are calculated by using the $\\alpha$~+~$\\alpha$~+~$n$ three-body\nmodel and the complex-scaled solutions of the Lippmann-Schwinger equation; the\nazimuthal angle distributions of the emitted neutrons are investigated. We\ncalculate the anisotropy parameter as a function of the photon incident energy\n$E_\\gamma$, and discuss how sensitive the anisotropy parameter is to nuclear\nstructure and transition modes. The result suggests that the azimuthal angle\ndistribution of neutrons emitted from the $^9$Be($\\gamma$,$n$) reaction with\nthe linearly polarized $\\gamma$-rays is useful to identify the resonances in\nthe final states even if it is not clearly observed in the cross section.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Using (casual) images to texture 3D models is a common way to create\nrealistic 3D models, which is a very important task in computer graphics.\nHowever, if the shape of the casual image does not look like the target model\nor the target mapping area, the textured model will become strange since the\nimage will be distorted very much. In this paper, we present a novel texturing\nand deforming approach for mapping the pattern and shape of a casual image to a\n3D model at the same time based on an alternating least-square approach.\nThrough a photogrammetric method, we project the target model onto the source\nimage according to the estimated camera model. Then, the target model is\ndeformed according to the shape of the source image using a surface-based\ndeformation method while minimizing the image distortion simultaneously. The\nprocesses are performed iteratively until convergence. Hence, our method can\nachieve texture mapping, shape deformation, and detail-preserving at once, and\ncan obtain more reasonable texture mapped results than traditional methods.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Classical extreme value statistics consists of two fundamental approaches:\nthe block maxima (BM) method and the peak-over-threshold (POT) approach. It\nseems to be general consensus among researchers in the field that the POT\nmethod makes use of extreme observations more efficiently than the BM method.\nWe shed light on this discussion from three different perspectives. First,\nbased on recent theoretical results for the BM approach, we provide a\ntheoretical comparison in i.i.d.\\ scenarios. We argue that the data generating\nprocess may favour either one or the other approach. Second, if the underlying\ndata possesses serial dependence, we argue that the choice of a method should\nbe primarily guided by the ultimate statistical interest: for instance, POT is\npreferable for quantile estimation, while BM is preferable for return level\nestimation. Finally, we discuss the two approaches for multivariate\nobservations and identify various open ends for future research.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the momentum alignment phenomenon and the optical control of valley\npopulation in gapless and gapped graphene-like materials. We show that the\ntrigonal warping effect allows for the spatial separation of carriers belonging\nto different valleys via the application of linearly polarized light. Valley\nseparation in gapped materials can be detected by measuring the degree of\ncircular polarization of band-edge photoluminescence at different sides of the\nsample or light spot (optical valley Hall effect). We also show that the\nmomentum alignment phenomenon leads to the giant enhancement of near-band-edge\ninterband optical transitions in narrow-gap carbon nanotubes and graphene\nnanoribbons independent of the mechanism of the gap formation. A detection\nscheme to observe these giant interband transitions is proposed which opens a\nroute for creating novel terahertz radiation emitters.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper investigates a new spectrum sharing scenario between unmanned\naerial vehicle (UAV) and terrestrial wireless communication systems. We\nconsider that a cognitive/secondary UAV transmitter communicates with a ground\nsecondary receiver (SR), in the presence of a number of primary terrestrial\ncommunication links that operate over the same frequency band. We exploit the\nUAV's controllable mobility via trajectory design, to improve the cognitive UAV\ncommunication performance while controlling the co-channel interference at each\nof the primary receivers (PRs). In particular, we maximize the average\nachievable rate from the UAV to the SR over a finite mission/communication\nperiod by jointly optimizing the UAV trajectory and transmit power allocation,\nsubject to constraints on the UAV's maximum speed, initial/final locations, and\naverage transmit power, as well as a set of interference temperature (IT)\nconstraints imposed at each of the PRs for protecting their communications.\nHowever, the joint trajectory and power optimization problem is non-convex and\nthus difficult to be solved optimally. To tackle this problem, we propose an\nefficient algorithm that ensures to obtain a locally optimal solution by\napplying the techniques of alternating optimization and successive convex\napproximation (SCA). Numerical results show that our proposed joint UAV\ntrajectory and power control scheme significantly enhances the achievable rate\nof the cognitive UAV communication system, as compared to benchmark schemes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We extend our previous study of Markov chains on finite commutative rings\n(arXiv:1605.05089) to arbitrary finite rings with identity. At each step, we\neither add or multiply by a randomly chosen element of the ring, where the\naddition (resp. multiplication) distribution is uniform (resp. conjugacy\ninvariant). We prove explicit formulas for some of the eigenvalues of the\ntransition matrix and give lower bounds on their multiplicities. We also give\nrecursive formulas for the stationary distribution and prove that the mixing\ntime is bounded by an absolute constant. For the matrix rings $M_2(\\mathbb\nF_q),$ we compute the entire spectrum explicitly using the representation\ntheory of $\\text{GL}_2(\\mathbb F_q),$ as well as the stationary probabilities.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We revisit the problem of counting the number of copies of a fixed graph in a\nrandom graph or multigraph, for various models of random (multi)graphs. For our\nproofs we introduce the notion of \\emph{patchworks} to describe the possible\noverlappings of copies of subgraphs. Furthermore, the proofs are based on\nanalytic combinatorics to carry out asymptotic computations. The flexibility of\nour approach allows us to tackle a wide range of problems. We obtain the\nasymptotic number and the limiting distribution of the number of subgraphs\nwhich are isomorphic to a graph from a given set of graphs. The results apply\nto multigraphs as well as to (multi)graphs with degree constraints. One\napplication is to scale-free multigraphs, where the degree distribution follows\na power law, for which we show how to obtain the asymptotic number of copies of\na given subgraph and give as an illustration the expected number of small\ncycles.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We analyze in detail the LHC prospects at the center-of-mass enery of 14 TeV\nfor charged electroweakino searches, decaying to leptons, in compressed\nsupersymmetry scenarios, via exclusive photon-initiated pair production. This\nprovides a potentially increased sensitivity in comparison to inclusive\nchannels, where the background is often overwhelming. We pay particular\nattention to the challenges that such searches would face in the hostile high\npile--up environment of the LHC, giving close consideration to the backgrounds\nthat will be present. The signal we focus on is the exclusive production of\nsame-flavour muon and electron pairs, with missing energy in the final state,\nand with two outgoing intact protons registered by the dedicated forward proton\ndetectors installed in association with ATLAS and CMS. We present results for\nslepton masses of 120--300 GeV and slepton--neutralino mass splitting of 10--20\nGeV, and find that the relevant backgrounds can be controlled to the level of\nthe expected signal yields. The most significant such backgrounds are due to\nsemi--exclusive lepton pair production at lower masses, with a proton produced\nin the initial proton dissociation system registering in the forward detectors,\nand from the coincidence of forward protons produced in pile-up events with an\ninclusive central event that mimics the signal. We also outline a range of\npotential methods to further suppress these backgrounds as well as to enlarge\nthe signal yields.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  More than a decade after astronomers realized that disrupted planetary\nmaterial likely pollutes the surfaces of many white dwarf stars, the discovery\nof transiting debris orbiting the white dwarf WD 1145+017 has opened the door\nto new explorations of this process. We describe the observational evidence for\ntransiting planetary material and the current theoretical understanding (and in\nsome cases lack thereof) of the phenomenon.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this letter, we stress that the simplest cosmological model consisting in\na massless scalar field minimally coupled to homogeneous and isotropic gravity\nhas an in-built $\\SL(2,\\mathbb{R})$ symmetry. Protecting this symmetry\nnaturally provides an efficient way to constrain the quantization of this\ncosmological system whatever the quantization scheme and allows in particular\nto fix the quantization ambiguities arising in the canonical quantization\nprogram. Applying this method to the loop quantization of the FLRW cosmology\nleads to a new loop quantum cosmology model which preserves the\n$\\SL(2,\\mathbb{R})$ symmetry of the classical system. This new polymer\nregularization consistent with the conformal symmetry can be derived as a\nnon-linear canonical transformation of the classical FLRW phase space, which\nmaps the classical singular dynamics into a regular effective bouncing\ndynamics. This improved regularization preserves the scaling properties of the\nvolume and Hamiltonian constraint. 3d scale transformations, generated by the\ndilatation operator, are realized as unitary transformations despite the\nminimal length scale hardcoded in the theory. Finally, we point out that the\nresulting cosmological dynamics exhibits an interesting duality between short\nand long distances, reminiscent of the T-duality in string theory, with the\nnear-singularity regime dual to the semi-classical regime at large volume. The\ntechnical details of the construction of this model are presented in a longer\ncompanion paper \\cite{BenAchour:2019ywl}.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We develop a theory for interlayer tunneling in van der Waals\nheterostructures driven under a strong electromagnetic field, using\ngraphene/{\\it h}-BN/graphene as a paradigmatic example. Our theory predicts\nthat strong anti-resonances appear at bias voltage values equal to an integer\nmultiple of the light frequency. These features are found to originate from\nphoton-assisted resonant tunneling transitions between Floquet sidebands of\ndifferent graphene layers, and are unique to two-band systems due to the\ninterplay of both intraband and interband tunneling transitions. Our results\npoint to the possibility of tunneling localization in van der Waals\nheterostructures using strong electromagnetic fields.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We formulate and study a novel multi-armed bandit problem called the\nqualitative dueling bandit (QDB) problem, where an agent observes not numeric\nbut qualitative feedback by pulling each arm. We employ the same regret as the\ndueling bandit (DB) problem where the duel is carried out by comparing the\nqualitative feedback. Although we can naively use classic DB algorithms for\nsolving the QDB problem, this reduction significantly worsens the\nperformance---actually, in the QDB problem, the probability that one arm wins\nthe duel over another arm can be directly estimated without carrying out actual\nduels. In this paper, we propose such direct algorithms for the QDB problem.\nOur theoretical analysis shows that the proposed algorithms significantly\noutperform DB algorithms by incorporating the qualitative feedback, and\nexperimental results also demonstrate vast improvement over the existing DB\nalgorithms.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Low redshift, spatially resolved Lyman continuum (LyC) emitters allow us to\nclarify the processes for LyC escape from these starburst galaxies. We use\nHubble Space Telescope (HST) WFC3 and ACS imaging of the confirmed low-redshift\nLyC emitter Tol 1247-232 to study the ionization structure of the gas and its\nrelation to the ionizing star clusters. We perform ionization parameter mapping\n(IPM) using [O III]4959, 5007 and [O II]3727 imaging as the high- and\nlow-ionization tracers, revealing broad, large-scale, optically thin regions\noriginating from the center, and reaching the outskirts of the galaxy,\nconsistent with LyC escape. We carry out stellar population synthesis modeling\nof the 26 brightest clusters using our HST photometry. Combining these data\nwith the nebular photometry, we find a global LyC escape fraction of f_esc =\n0.12, with uncertainties also consistent with zero escape and with all measured\nf_esc values for this galaxy. Our analysis suggests that, similar to other\ncandidate LyC emitters, a two-stage starburst has taken place in this galaxy,\nwith a 12 Myr old, massive, central cluster likely having pre-cleared regions\nin and around the center, and the second generation of 2 - 4 Myr old clusters\ndominating the current ionization, including some escape from the galaxy.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The spin of a single atom adsorbed on a substrate is a promising building\nblock for future spintronics and quantum computation schemes. To process spin\ninformation and also for increased magnetic stability, these building blocks\nhave to be coupled. For a single atom, a high symmetry of the environment is\nknown to lead to increased spin stability. However, little is known about the\nrole of the nature and symmetry of the magnetic couplings. Here, we study\narrays of atomic spins coupled via the ubiquitous Ruderman-Kittel-Kasuya-Yosida\n(RKKY) interaction, focusing on its two anisotropic parts: the\nDzyaloshinskii-Moriya (DM) and the symmetric anisotropic exchange interactions.\nFirst, we show that the high spin stability of an iron trimer can be remotely\ndetected by a nearby iron atom, and how the DM interaction can lead to its\ndestabilization. Second, we find that adding more nearby iron atoms almost\nalways leads to a destabilization of the trimer, due to a non-local effective\ntransverse anisotropy originating in the symmetric anisotropic exchange\ninteraction. This transverse anisotropy can be quenched only for highly\nsymmetric structures, for which the spin lifetime of the array is increased by\norders of magnitude.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The guaranteed-performance consensualization for high-order linear and\nnonlinear multiagent systems with switching topologies is respectively realized\nin a completely distributed manner in the sense that consensus design criteria\nare independent of interaction topologies and switching motions. The current\npaper firstly proposes an adaptive consensus protocol with\nguaranteed-performance constraints and switching topologies, where interaction\nweights among neighboring agents are adaptively adjusted and state errors among\nall agents can be regulated. Then, a new translation-adaptive strategy is shown\nto realize completely distributed guaranteed-performance consensus control and\nan adaptive guaranteed-performance consensualization criterion is given on the\nbasis of the Riccati inequality. Furthermore, an approach to regulate the\nconsensus control gain and the guaranteed-performance cost is proposed in terms\nof linear matrix inequalities. Moreover, main conclusions for linear multiagent\nsystems are extended to Lipschitz nonlinear cases. Finally, two numerical\nexamples are provided to demonstrate theoretical results.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Active manipulation of mechanical waves at high frequencies opens\nopportunities in heat management, radio-frequency (RF) signal processing, and\nquantum technologies. Nanoelectromechanical systems (NEMS) are appropriate\nplatforms for developing these technologies, offering energy transducibility\nbetween different physical domains, for example, converting optical or\nelectrical signals into mechanical vibrations and viceversa. Existing NEMS\nplatforms, however, are mostly linear, passive, and not dynamically\ncontrollable. Here, we report the realization of active manipulation of\nfrequency band dispersion in one-dimensional (1D) nonlinear\nnanoelectromechanical lattices (NEML) in the RF domain (10-30 MHz). Our NEML is\ncomprised of a periodic arrangement of mechanically coupled free-standing\nnano-membranes, with circular clamped boundaries. This design forms a flexural\nphononic crystals with a well-defined band gaps, 1.8 MHz wide. The application\na DC gate voltage creates voltage-dependent on-site potentials, which can\nsignificantly shift the frequency bands of the device. Dynamic modulation of\nthe voltage triggers nonlinear effects, which induce the formation of phononic\nband gaps in the acoustic branch. These devices could be used in tunable\nfilters, ultrasonic delay lines and transducers for implantable medical\ndevices.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Bounded Real Lemma, i.e., the state-space linear matrix inequality\ncharacterization (referred to as Kalman-Yakubovich-Popov or KYP inequality) of\nwhen an input/state/output linear system satisfies a dissipation inequality,\nhas recently been studied for infinite-dimensional discrete-time systems in a\nnumber of different settings: with or without stability assumptions, with or\nwithout controllability/observability assumptions, with or without strict\ninequalities. In these various settings, sometimes unbounded solutions of the\nKYP inequality are required while in other instances bounded solutions suffice.\nIn a series of reports we show how these diverse results can be reconciled and\nunified. This first instalment focusses on the state-space-similarity approach\nto the bounded real lemma. We shall show how these results can be seen as\ncorollaries of a new State-Space-Similarity theorem for infinite-dimensional\nlinear systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate to what extent a generic, generation-dependent $U(1)$ symmetry\nacting on the quark Yukawa operators can reduce the number of free parameters\nby forcing some entries in the Yukawa matrices to vanish. The maximal reduction\ncompatible with CP violation yields nine real parameters and one phase, which\nmatches the number of physical observables, implying that such models have no\nfree parameters. We derive a set of results: (i) the only possible structures\nhave the form $M_4 \\oplus M_5$, where the subscripts indicate the number of\nreal parameters in the Yukawa matrices, (ii) there are only two inequivalent\nYukawa structures, each one giving rise to six different models depending on\nquark flavour assignments, (iii) the $U(1)$ symmetries that generate these\ntextures all have a QCD anomaly, and hence are Peccei-Quinn symmetries,\nreinforcing the idea of a possible connection between the quark flavour puzzle\nand the axion solution to the strong CP problem, (iv) in some cases the\ncontributions to the QCD anomaly of two generations cancels out, and this opens\nthe possibility that the axion coupling to nucleons could be strongly\nsuppressed. Flavour-violating axion couplings to quarks are completely fixed,\nup to the axion decay constant, providing a non-trivial complementarity between\nlow-energy flavour-violating processes and standard axion searches.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we first define the equivariant infinitesimal $\\eta$-form,\nthen we compare it with the equivariant $\\eta$-form, modulo exact forms, by a\nlocally computable form. As a consequence, we obtain the singular behavior of\nthe equivariant $\\eta$-form, modulo exact forms, as a function on the acting\nLie group. This result extends a result of Goette and it plays an important\nrole in our recent work on the localization of $\\eta$-invariants and on the\ndifferential $K$-theory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A method is proposed to extend the zero-temperature Hall-Klemm microscopic\ntheory of the Knight shift $K$ in an anisotropic and correlated, multi-band\nmetal to calculate $K(T)$ at finite temperatures $T$ both above and into its\nsuperconducting state. The transverse part of the magnetic induction ${\\bf\nB}(t)={\\bf B}_0+{\\bf B}_1(t)$ causes adiabatic changes suitable for treatment\nwith the Keldysh contour formalism and analytic continuation onto the real\naxis. We propose that the Keldysh-modified version of the Gor'kov method can be\nused to evaluate $K(T)$ at high ${\\bf B}_0$ both in the normal state, and by\nquantizing the conduction electrons or holes with Landau orbits arising from\n${\\bf B}_0$, also in the entire superconducting regime for an anisotropic,\nmultiband Type-II BCS superconductor. Although the details have not yet been\ncalculated in detail, it appears that this approach could lead to the simple\nresult $K_S(T)\\approx a({\\bf B}_0)-b({\\bf B}_0)|\\Delta({\\bf B}_0,T)|^2$, where\n$2|\\Delta({\\bf B}_0,T)|$ is the effective superconducting gap. More generally,\nthis approach can lead to analytic expressions for $K_S(T)$ for anisotropic,\nmultiband Type-II superconductors of various orbital symmetries that could aid\nin the interpretation of experimental data on unconventional superconductors.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we consider the solution of a nonlocal parabolic equation.\nFocusing on the solutions with initial data at high energy level, we find the\ncriteria for global existence and finite time blow up for the corresponding\nsolution respectively. Moreover, we prove that there always exists blow up\nsolution with negative Nehari functional no matter how large the energy is.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This work aims to numerically investigate the linear global instability of\nlong separation bubbles origin from the changes in the adverse pressure\ngradient inside a laminar flat plate boundary layer disturbed by placing a\nbluff body with small clearances. The boundary layer starts at\n$Re_{\\delta^\\ast}$=121.7 and is steady in the computational extent after being\ndisturbed by a NACA 4415 airfoil and a cylinder with clearance $h\\leqslant\n0.2$, respectively. It is found that the dominant stability is associated with\ntwo- and three-dimensional stationary eigenmodes. There is a less damped\noscillation mode at a small wavenumbers range. The strong effect of\nthree-dimensionality is further confirmed in a non-modal analysis framework.\nTransient growth analysis shows that the most strongest optimal perturbation is\nthree-dimensional in the range of parameters studied. The modal analysis\nreveals that the instability grows with reducing the clearance, while the\noptimal perturbations grow with increasing the clearance. It is found that the\nseparated boundary layer stability analysis is less dependent on the bluff body\ngeometries.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Suppose $n\\geq 2$ and $\\mathcal{A}_{i}\\subset \\{0,1,\\cdots ,(n-1)\\}$ for $\ni=1,\\cdots ,l,$ let $K_{i}=\\bigcup\\nolimits_{a\\in\n\\mathcal{A}_{i}}n^{-1}(K_{i}+a)$ be self-similar sets contained in $[0,1].$\nGiven $ m_{1},\\cdots ,m_{l}\\in \\mathbb{Z}$ with $\\prod\\nolimits_{i}m_{i}\\neq\n0,$ we let \\begin{equation*} S_{x}=\\left\\{ \\mathbf{(}y_{1},\\cdots\n,y_{l}\\mathbf{)}:m_{1}y_{1}+\\cdots +m_{l}y_{l}=x\\text{ with }y_{i}\\in\nK_{i}\\text{ }\\forall i\\right\\} . \\end{equation*} In this paper, we analyze the\nHausdorff dimension and Hausdorff measure of the following set\n\\begin{equation*} U_{r}=\\{x:\\mathbf{Card}(S_{x})=r\\}, \\end{equation*} where\n$\\mathbf{Card}(S_{x})$ denotes the cardinality of $S_{x}$, and $r\\in\n\\mathbb{N}^{+}$. We prove under the so-called covering condition that the\nHausdorff dimension of $U_{1}$ can be calculated in terms of some matrix.\nMoreover, if $r\\geq 2$, we also give some sufficient conditions such that the\nHausdorff dimension of $U_{r}$ takes only finite values, and these values can\nbe calculated explicitly. Furthermore, we come up with some sufficient\nconditions such that the dimensional Hausdorff measure of $U_{r}$ is infinity.\nVarious examples are provided. Our results can be viewed as the exceptional\nresults for the classical slicing problem in geometric measure theory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We construct a high order discontinuous Galerkin method for solving general\nhyperbolic systems of conservation laws. The method is CFL-less, matrix-free,\nhas the complexity of an explicit scheme and can be of arbitrary order in space\nand time. The construction is based on: (a) the representation of the system of\nconservation laws by a kinetic vectorial representation with a stiff relaxation\nterm; (b) a matrix-free, CFL-less implicit discontinuous Galerkin transport\nsolver; and (c) a stiffly accurate composition method for time integration. The\nmethod is validated on several one-dimensional test cases. It is then applied\non two-dimensional and three-dimensional test cases: flow past a cylinder,\nmagnetohydrodynamics and multifluid sedimentation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the physics that drives the gas accretion rates onto galaxies\nat the centers of dark matter haloes using the EAGLE suite of hydrodynamical\ncosmological simulations. We find that at redshifts $z{\\le}2$ the accretion\nrate onto the galaxy increases with halo mass in the halo mass range\n$10^{10}-10^{11.7}M_{\\odot}$, flattens between the halo masses\n$10^{11.7}-10^{12.7}M_{\\odot}$, and increases again for higher-mass haloes.\nHowever, the galaxy gas accretion does not flatten at intermediate halo masses\nwhen AGN feedback is switched off. To better understand these trends, we\ndevelop a physically motivated semi-analytic model of galaxy gas accretion. We\nshow that the flattening is produced by the rate of gas cooling from the hot\nhalo. The ratio of the cooling radius and the virial radius does not decrease\ncontinuously with increasing halo mass as generally thought. While it decreases\nup to ${\\sim}10^{13}M_{\\odot}$ haloes, it increases for higher halo masses,\ncausing an upturn in the galaxy gas accretion rate. This may indicate that in\nhigh-mass haloes AGN feedback is not sufficiently efficient. When there is no\nAGN feedback, the density of the hot halo is higher, the ratio of the cooling\nand virial radii does not decrease as much and the cooling rate is higher.\nChanges in the efficiency of stellar feedback can also increase or decrease the\naccretion rates onto galaxies. The trends can plausibly be explained by the\nre-accretion of gas ejected by progenitor galaxies and by the suppression of\nblack hole growth, and hence AGN feedback, by stellar feedback.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the two-species diffusion-annihilation process, $A+B\\rightarrow$ \\O,\non the fully-connected lattice. Probability distributions for the number of\nparticles and the reaction time are obtained for a finite-size system using a\nmaster equation approach. Mean values and variances are deduced from generating\nfunctions. When the reaction is far from complete, i.e., for a large number of\nparticles of each species, mean-field theory is exact and the fluctuations are\nGaussian. In the scaling limit the reaction time displays extreme-value\nstatistics in the vicinity of the absorbing states. A generalized Gumbel\ndistribution is obtained for unequal initial densities, $\\rho_A>\\rho_B$. For\nequal or almost equal initial densities, $\\rho_A\\simeq\\rho_B$, the fluctuations\nof the reaction time near the absorbing state are governed by a probability\ndensity involving derivatives of $\\vartheta_4$, the Jacobi theta function.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Although piecewise isometries (PWIs) are higher dimensional generalizations\nof one dimensional interval exchange transformations (IETs), their generic\ndynamical properties seem to be quite different. In this paper we consider\nembeddings of IET dynamics into PWI with a view to better understanding their\nsimilarities and differences. We derive some necessary conditions for existence\nof such embeddings using combinatorial, topological and measure theoretic\nproperties of IETs. In particular, we prove that continuous embeddings of\nminimal $2$-IETs into orientation preserving PWIs are necessarily trivial and\nthat any $3$-PWI has at most one non-trivially continuously embedded minimal\n$3$-IET with the same underlying permutation. Finally, we introduce a family of\n$4$-PWIs with apparent abundance of invariant nonsmooth fractal curves\nsupporting IETs, that limit to a trivial embedding of an IET.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This work investigates the motion of neutrally-buoyant, slightly deformable\nstraight and curved prolate capsules in unbounded simple shear flow at zero\nReynolds number using direct simulations. The curved capsules serve as a model\nfor the typical crescent-shaped sickle red blood cells in sickle cell disease\n(SCD). The effects of deformability and curvature on the dynamics are revealed.\nWe show that with low deformability, straight prolate spheroidal capsules\ntumble in the shear plane as their unique asymptotically stable orbit, which\ncontrasts with that for rigid spheroids where infinitely many neutrally stable\nJeffery orbits exist. The dynamics of curved prolate capsules are more\ncomplicated due to a combined effect of deformability and curvature. At short\ntimes, depending on the initial orientation, slightly deformable curved prolate\ncapsules exhibit either a Jeffery-like motion such as tumbling or kayaking, or\na non-Jeffery-like behavior in which the end-to-end vector of the capsule\ncrosses the shear-gradient plane back and forth. At long times, however, a\nJeffery-like quasi-periodic orbit is taken regardless of the initial\norientation. We further show that the average of the long-time trajectory can\nbe well approximated using the analytical solution for Jeffery orbits with an\neffective orbit constant $C_{\\textnormal{eff}}$ and aspect ratio\n$\\ell_{\\textnormal{eff}}$. As the capsule becomes more deformable or curved,\n$C_{\\textnormal{eff}}$ decreases, indicating a shift of the orbit towards\nlog-rolling motion, while $\\ell_{\\textnormal{eff}}$ increases weakly as the\ndegree of curvature increases but shows negligible dependency on deformability.\nAs cell deformability, cell shape, and cell-cell interactions are all\npathologically altered in blood disorders such as SCD, these results will have\nclear implications on improving our understanding of the pathophysiology of\nhematologic disease.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The production of $\\Lambda^+_c$ baryons produced directly at the interacting\npoint is studied in proton-lead collisions collected with the LHCb detector at\nthe LHC. The data sample corresponds to an integrated luminosity of\n$1.58\\mathrm{nb}^{-1}$ recorded at a nucleon-nucleon centre-of-mass energy of\n$\\sqrt{s_{NN}}=5.02$ TeV. Measurements of the differential cross-section and\nthe forward-backward production ratio are reported for $\\Lambda^+_c$ baryons\nwith transverse momenta in the range $2<p_{T}<10$GeV/$c$ and rapidities in the\nranges $1.5<y^*<4.0$ and $-4.5<y^*<-2.5$ in the nucleon-nucleon centre-of-mass\nsystem. The ratio of cross-sections of $\\Lambda^+_c$ baryons and $D^0$ mesons\nis also reported. The results are compared with next-to-leading order\ncalculations that use nuclear parton distribution functions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Weyl fermions are massless chiral quasiparticles existing in materials known\nas Weyl semimetals. Topological surface states, associated with the unusual\nelectronic structure in the Weyl semimetals, have been recently demonstrated in\nlinear systems. Ultracold atomic gases, featuring laser-assisted tunneling in\nthree-dimensional optical lattices, can be used for the emulation of Weyl\nsemimetals, including nonlinear effects induced by the collisional nonlinearity\nof atomic Bose-Einstein condensates. We demonstrate that this setting gives\nrise to topological states in the form of Weyl solitons at the surface of the\nunderlying optical lattice. These nonlinear modes, being exceptionally robust,\nbifurcate from linear states for a given quasi-momentum. The Weyl solitons may\nbe used to design an efficient control scheme for topologically-protected\nunidirectional propagation of excitations in light-matter-interaction physics.\nAfter the recently introduced Majorana and Dirac solitons, the Weyl solitons\nproposed in this work constitute the third (and the last) member in this family\nof topological solitons.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The development of astronomy and space science in Africa has grown\nsignificantly over the past few years. These advancements make the United\nNations Sustainable Development Goals more achievable, and open up the\npossibility of new beneficial collaborations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Vibrational spectroscopy has been widely employed to unravel\nphysical-chemical properties of biological systems. Due to its high sensitivity\nto monitor real time \"in situ\" changes, Raman spectroscopy has been\nsuccessfully employed, e.g., in biomedicine, metabolomics, and biomedical\nengineering. The grounds of interpretation of Raman spectra in these cases is\nthe isolated macromolecules constituent vibrational assignment. Due to this,\nprobe the anharmonic interactions or the mutual interactions among specific\nmoieties/side chains to name but a few is a challenge. We present a complete\nvibrational modes calculation for connective tissue in the fingerprint region\n($800-1800$ cm$^{-1}$) using first-principles Density Functional Theory. Our\nresults indicated that important spectral features correlated to molecular\ncharacteristics have been ignored within the usual tissue spectral bands\nassignments. In particular, we found that the presence of confined water is the\nmain responsible for the observed spectral complexity. Our calculations\naccounted for the inherent complexity of the spectral features in this region\nand useful spectral markers for biological processes were unambiguously\nidentified.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Three- and two-level mixing models are proposed to understand the doubling of\nstates at the same spin and parity in triaxially-deformed atomic nuclei with\nodd numbers of protons and neutrons. The Particle-Rotor Model for such nuclei\nis solved using the newly proposed basis which couples angular momenta of two\nvalence nucleons and the rotating triaxial mean-field into left-handed\n$|\\mathcal{L}\\rangle$, right-handed $|\\mathcal{R}\\rangle$, and planar\n$|\\mathcal{P}\\rangle$ configurations. The presence and the impact of the planar\ncomponent is investigated as a function of the total spin for mass\nA$\\approx$130 nuclei with the valence h$_{11/2}$ proton particle, valence\nh$_{11/2}$ neutron hole and the maximum difference between principle axes\nallowed by the quadrupole deformation of the mean field. It is concluded that\nat each spin value the higher-energy member of a doublet of states is built on\nthe anti-symmetric combination of $|\\mathcal{L}\\rangle$ and\n$|\\mathcal{R}\\rangle$ and is free of the $|\\mathcal{P}\\rangle$ component,\nindicating that it is of pure chiral geometry. For the lower-energy member of\nthe doublet, the contribution of the $|\\mathcal{P}\\rangle$ component to the\neigenfunction first decreases and then increases as a function of the total\nspin. This trend as well as the energy splitting between the doublet states are\nboth determined by the Hamiltonian matrix elements between the planar\n($|\\mathcal{P}\\rangle$) and non-planar ($|\\mathcal{L}\\rangle$ and\n$|\\mathcal{R}\\rangle$) subspaces of the full Hilbert space.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A key feature of magnetic resonance (MR) imaging is its ability to manipulate\nhow the intrinsic tissue parameters of the anatomy ultimately contribute to the\ncontrast properties of the final, acquired image. This flexibility, however,\ncan lead to substantial challenges for segmentation algorithms, particularly\nsupervised methods. These methods require atlases or training data, which are\ncomposed of MR image and labeled image pairs. In most cases, the training data\nare obtained with a fixed acquisition protocol, leading to suboptimal\nperformance when an input data set that requires segmentation has differing\ncontrast properties. This drawback is increasingly significant with the recent\nmovement towards multi-center research studies involving multiple scanners and\nacquisition protocols. In this work, we propose a new framework for supervised\nsegmentation approaches that is robust to contrast differences between the\ntraining MR image and the input image. Our approach uses a generative\nsimulation model within the segmentation process to compensate for the contrast\ndifferences. We allow the contrast of the MR image in the training data to vary\nby simulating a new contrast from the corresponding label image. The model\nparameters are optimized by a cost function measuring the consistency between\nthe input MR image and its simulation based on a current estimate of the\nsegmentation labels. We provide a proof of concept of this approach by\ncombining a supervised classifier with a simple simulation model, and apply the\nresulting algorithm to synthetic images and actual MR images.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we study first the relationship between Pommaret bases and\nHilbert series. Given a finite Pommaret basis, we derive new explicit formulas\nfor the Hilbert series and for the degree of the ideal generated by it which\nexhibit more clearly the influence of each generator. Then we establish a new\ndimension depending Bezout bound for the degree and use it to obtain a\ndimension depending bound for the ideal membership problem.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Newton's gravitational constant $G$ may vary with time at an extremely low\nlevel. The time variability of $G$ will affect the orbital motion of a\nmillisecond pulsar in a binary system and cause a tiny difference between the\norbital period-dependent measurement of the kinematic distance and the direct\nmeasurement of the annual parallax distance. PSR J0437$-$4715 is the nearest\nmillisecond pulsar and the brightest at radio. To explore the feasibility of\nachieving a parallax distance accuracy of one light-year, comparable to the\nrecent timing result, with the technique of differential astrometry, we\nsearched for compact radio sources quite close to PSR J0437$-$4715. Using\nexisting data from the Very Large Array and the Australia Telescope Compact\nArray, we detected two sources with flat spectra, relatively stable flux\ndensities of 0.9 and 1.0 mJy at 8.4 GHz and separations of 13 and 45 arcsec.\nWith a network consisting of the Long Baseline Array and the Kunming 40-m radio\ntelescope, we found that both sources have a point-like structure and a\nbrightness temperature of $\\geq$10$^7$ K. According to these radio inputs and\nthe absence of counterparts in the other bands, we argue that they are most\nlikely the compact radio cores of extragalactic active galactic nuclei rather\nthan Galactic radio stars. The finding of these two radio active galactic\nnuclei will enable us to achieve a sub-pc distance accuracy with the in-beam\nphase-referencing very-long-baseline interferometric observations and provide\none of the most stringent constraints on the time variability of $G$ in the\nnear future.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Using atomistic simulations, dislocation dynamics modeling, and continuum\nelastic-plastic stress-wave theory, we present a systematic investigation on\nshock-induced plasticity in semi-coherent CuNi multilayers. The features of\nstress wave evolutions in the multilayers, including wave-front stress\nattenuation and strong interfacial discontinuities, are revealed by atomistic\nsimulations. Continuum models are proposed to explain the shockwave propagation\nfeatures. The simulations provide insight into microplasticity behaviors\nincluding interactions between lattice and misfit dislocations. The formation\nof hybrid Lomer-Cottrell locks through the attraction and combination of\nlattice and misfit dislocations is a major mechanism for trapping gliding\nlattice dislocations at interfaces. The relationship between dislocation\nactivity and dynamic stress wave evolution history is explored. The hybrid\nLomer-Cottrell locks can dissociate under shock compression or reverse\nyielding. This dissociation facilitates slip transmission. The influence of\ncoherent stress causes direction dependency in the slip transmission: a lattice\ndislocation is transmitted more smoothly across an interface from Ni to Cu than\nfrom Cu to Ni. The interaction forces between lattice and misfit dislocations\nare calculated using dislocation dynamics code. Lattice dislocation nucleation\nfrom semi-coherent interfaces under shock compression is also reported.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A distributed data warehouse system is one of the actual issues in the field\nof astroparticle physics. Famous experiments, such as TAIGA, KASCADE-Grande,\nproduce tens of terabytes of data measured by their instruments. It is critical\nto have a smart data warehouse system on-site to store the collected data for\nfurther distribution effectively. It is also vital to provide scientists with a\nhandy and user-friendly interface to access the collected data with proper\npermissions not only on-site but also online. The latter case is handy when\nscientists need to combine data from different experiments for analysis. In\nthis work, we describe an approach to implementing a distributed data warehouse\nsystem that allows scientists to acquire just the necessary data from different\nexperiments via the Internet on demand. The implementation is based on\nCernVM-FS with additional components developed by us to search through the\nwhole available data sets and deliver their subsets to users' computers.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we introduce a new vulnerability of cyber-physical systems to\nmalicious attack. It arises when the physical plant, that is modeled as a\ncontinuous-time LTI system, is controlled by a digital controller. In the\nsampled-data framework, most anomaly detectors monitor the plant's output only\nat discrete time instants, and thus, nothing abnormal can be detected as long\nas the sampled output behaves normal. This implies that if an actuator attack\ndrives the plant's state to pass through the kernel of the output matrix at\neach sensing time, then the attack compromises the system while remaining\nstealthy. We show that this type of attack always exists when the sampled-data\nsystem has an input redundancy, i.e., the number of inputs being larger than\nthat of the outputs or the sampling rate of the actuators being higher than\nthat of the sensors. Simulation results for the X-38 vehicle and for the other\nnumerical examples illustrate this new attack strategy possibly brings\ndisastrous consequences.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, we propose a class of importance sampling (IS) estimators for\nestimating the right tail probability of a sum of continuous random variables\nbased on a change of variables to $L^1$ polar coordinates in which the radial\nand angular components of the IS distribution are considered separately.\n  When the asymptotic behaviour of the sum is known we exploit it for the\nradial change of measure, and the resulting estimator has the appealing form of\nthe (known) asymptotic multiplied by a random multiplicative correction factor.\nGiven we assume knowledge of the asymptotic behaviour of the sum in this\nframework, traditional notions of efficiency that appear in the rare-event\nliterature hold little practical meaning here. Instead, we focus on the\npractical behaviour of the proposed estimator in the pre-asymptotic regime for\nright tail probabilities between roughly $10^{-3}$ and $10^{-7}$.\n  The proposed estimator and procedure are applicable in both the heavy- and\nlight-tailed settings, as well as for independent and dependent summands. In\nthe case of independent summands, we find that our estimator compares\nfavourably with exponential tilting (iid light-tailed summands) and the\nAsmussen--Kroese method (independent subexponential summands).\n  However, for dependent subexponential summands using the same simple angular\ndistribution as for the independent case, the performance of our estimator\nrapidly degenerates with increasing dimension, suggesting an open avenue for\nfurther research.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We develop an analytic formalism for computing the merger rate of primordial\nblack hole binaries with a general mass function by taking into account the\ntorques by the surrounding primordial black holes and linear density\nperturbations. We find that $\\alpha=-(m_{i}+m_{j})^2\\partial^{2} \\ln {\\mathcal\nR}(m_{i},m_{j})/\\partial m_{i} \\partial m_{j}=36/37$ is independent of the mass\nfunction. Moreover, the ratio of the merger rate density of primordial black\nhole binaries by taking into account the torques by the surrounding primordial\nblack holes to by the nearest primordial black hole is independent of the\nmasses of binaries.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  General scenarios of transitions between different spot patterns on\nelectrodes of dc gas discharges and their relation to bifurcations of\nsteady-state solutions are analyzed. In the case of cathodes of arc discharges,\nit is shown that any transition between different modes of current transfer is\nrelated to a bifurcation of steady-state solutions. In particular, transitions\nbetween diffuse and spot modes on axially symmetric cathodes, frequently\nobserved in the experiment, represent an indication of the presence of\npitchfork or fold bifurcations of steady-state solutions. Experimental\nobservations of transitions on cathodes of dc glow microdischarges are analyzed\nand those potentially related to bifurcations of steady-state solutions are\nidentified. The relevant bifurcations are investigated numerically and the\ncomputed patterns are found to conform to those observed in the course of the\ncorresponding transitions in the experiment.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We construct models of involution surface bundles over algebraic surfaces,\ndegenerating over normal crossing divisors, and with controlled singularities\nof the total space.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove a conjecture of Thomas Lam that the face posets of stratified spaces\nof planar resistor networks are shellable. These posets are called uncrossing\npartial orders. This shellability result combines with Lam's previous result\nthat these same posets are Eulerian to imply that they are CW posets, namely\nthat they are face posets of regular CW complexes. Certain subsets of\nuncrossing partial orders are shown to be isomorphic to type A Bruhat order\nintervals; our shelling is shown to coincide on these intervals with a Bruhat\norder shelling which was constructed by Matthew Dyer using a reflection order.\n  Our shelling for uncrossing posets also yields an explicit shelling for each\ninterval in the face posets of the edge product spaces of phylogenetic trees,\nnamely in the Tuffley posets, by virtue of each interval in a Tuffley poset\nbeing isomorphic to an interval in an uncrossing poset. This yields a more\nexplicit proof of the result of Gill, Linusson, Moulton and Steel that the CW\ndecomposition of Moulton and Steel for the edge product space of phylogenetic\ntrees is a regular CW decomposition.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Whole brain neuroanatomy using tera-voxel light-microscopic data sets is of\nmuch current interest. A fundamental problem in this field is the mapping of\nindividual brain data sets to a reference space. Previous work has not\nrigorously quantified the distortions in brain geometry from in-vivo to ex-vivo\nbrains due to the tissue processing, which will be important when computing\nproperties such as local cell and process densities at the voxel level in\ncreating reference brain maps. Further, existing approaches focus on\nregistering uni-modal volumetric data; however, given the increasing interest\nin the marmoset model for neuroscience research, it is necessary to\ncross-register multi-modal data sets including MRIs and multiple histological\nseries that can help address individual variations in brain architecture. Here\nwe present a computational approach for same-subject multimodal MRI guided\nreconstruction of a histological series, jointly with diffeomorphic mapping to\na reference atlas. We quantify the scale change during the different stages of\nhistological processing of the brains using the Jacobian determinant of the\ndiffeomorphic transformations involved. There are two major steps in the\nhistology process with associated scale distortions (a) brain perfusion (b)\nhistological sectioning and reassembly. By mapping the final image stacks to\nthe ex-vivo post fixation MRI, we show that tape-transfer histology can be\nreassembled accurately into 3D volumes with a local scale change of 2.0 $\\pm$\n0.4% per axis dimension. In contrast, the perfusion step, as assessed by\nmapping the in-vivo MRIs to the ex-vivo post fixation MRIs, shows a larger\nlocal scale change of 6.9 $\\pm$ 2.1% per axis dimension. This is the first\nsystematic quantification of the local metric distortions associated with\nwhole-brain histological processing, and we expect that the results will\ngeneralize to other species.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, we present a non-linear difference equation for calculation of\nthe zeros of the Riemann's zeta-function on the critical line. Our proposed\nnon-linear map uses the Lambert W function and it can be easily implemented in\na mathematical software. In order to check the quality of the zeros calculated,\nwe show the factorization of an integer number by the calculation of the\ndiscrete cosine Riemann transform.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The object of this paper is to study (infinite) groups whose integral group\nrings have only trivial central units. This property is closely related to a\nproperty, here called the RS-property (\\cite{DMS05}, \\cite{RS90}), involving\nconjugacy in the group.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Background: Requirement engineering is often considered a critical activity\nin system development projects. The increasing complexity of software, as well\nas number and heterogeneity of stakeholders, motivate the development of\nmethods and tools for improving large-scale requirement engineering. Aims: The\nempirical study presented in this paper aims to identify and understand the\ncharacteristics and challenges of a platform, as desired by experts, to support\nrequirement engineering for individual stakeholders, based on the current\npain-points of their organizations when dealing with a large number\nrequirements. Method: We conducted a multiple case study with three companies\nin different domains. We collected data through ten semi-structured interviews\nwith experts from these companies. Results: The main pain-point for\nstakeholders is handling the vast amount of data from different sources. The\nforeseen platform should leverage such data to manage changes in requirements\naccording to customers' and users' preferences. It should also offer\nstakeholders an estimation of how long a requirements engineering task will\ntake to complete, along with an easier requirements dependency identification\nand requirements reuse strategy. Conclusions: The findings provide empirical\nevidence about how practitioners wish to improve their requirement engineering\nprocesses and tools. The insights are a starting point for in-depth\ninvestigations into the problems and solutions presented. Practitioners can use\nthe results to improve existing or design new practices and tools.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The capture and translocation of biomolecules through nanometer-scale pores\nare processes with a potential large number of applications, and hence they\nhave been intensively studied in the recent years. The aim of this paper is to\nreview existing models of the capture process by a nanopore, together with some\nrecent experimental data of short single- and double-stranded DNA captured by\nCytolysin A (ClyA) nanopore. ClyA is a transmembrane protein of bacterial\norigin which has been recently engineered through site-specific mutations, to\nallow the translocation of double- and single-stranded DNA. A comparison\nbetween theoretical estimations and experiments suggests that for both cases\nthe capture is a reaction-limited process. This is corroborated by the observed\nsalt dependence of the capture rate, which we find to be in quantitative\nagreement with the theoretical predictions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the problem of long term power allocation in dense wireless\nnetworks. The framework considered in this paper is of interest for\nmachine-type communications (MTC). In order to guarantee an optimal operation\nof the system while being as power efficient as possible, the allocation policy\nmust take into account both the channel and queue states of the devices. This\nis a complex stochastic optimization problem, that can be cast as a Markov\nDecision Process (MDP) over a huge state space. In order to tackle this state\nspace explosion, we perform a mean-field approximation on the MDP. Letting the\nnumber of devices grow to infinity the MDP converges to a deterministic control\nproblem. By solving the Hamilton-Jacobi-Bellman Equation, we obtain a\nwell-performing power allocation policy for the original stochastic problem,\nwhich turns out to be a threshold-based policy and can then be easily\nimplemented in practice.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Distributed calibration based on consensus optimization is a computationally\nefficient method to calibrate large radio interferometers such as LOFAR and\nSKA. Calibrating along multiple directions in the sky and removing the bright\nforeground signal is a crucial step in many science cases in radio\ninterferometry. The residual data contain weak signals of huge scientific\ninterest and of particular concern is the effect of incomplete sky models used\nin calibration on the residual. In order to study this, we consider the mapping\nbetween the input uncalibrated data and the output residual data. We derive an\nanalytical relationship between the input and output probability density\nfunctions which can be used to study the performance of calibration.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A systematic study of magnetocrystalline anisotropy is performed for\nR(La/Ce/Nd)2Fe14B tetragonal compound with the site substitution mechanism.\nTheoretical calculation suggests the 50% doping with Ce at 4f-site can lead to\ncompetitive magnetic anisotropy to that of the champion magnet Nd2Fe14B.\nElectronic structure calculations are performed using the full-potential\nlinearized augmented plane wave method by inclusion of the spin-orbit coupling\nand Hubbard (U) interaction in the calculation for the rare-earth elements to\nget the correct influence of the localized 4f orbitals. Detailed analysis of\nthe magnetic moment and magnetic anisotropy change has been studied by\nindividually inserting the La and Ce atoms at the two inequivalent sites (4g\nand 4f sites) of the 2-14-B tetragonal structure. Accurate prediction of the\ntotal magnetic moment with the orbital contribution in the 2-14-B structure\nshows the maximum moment for Ce2Fe14B (3.86 {\\mu}B/f.u less) compared to\nNd2Fe14B. Theoretical analysis confirms that regardless of the anti-parallel\nspin moment emerging in the Ce atom the complex structure of the Ce substituted\ncompound at 4f-site gives the maximum anisotropy of 2.27 meV/cell with lowering\nthe magnetic moment by 1.26 {\\mu}B/f.u. compared to the Nd2Fe14B compound.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In network analysis, within-community members are more likely to be connected\nthan between-community members, which is reflected in that the edges within a\ncommunity are intercorrelated. However, existing probabilistic models for\ncommunity detection such as the stochastic block model (SBM) are not designed\nto capture the dependence among edges. In this paper, we propose a new\ncommunity detection approach to incorporate within-community dependence of\nconnectivities through the Bahadur representation. The proposed method does not\nrequire specifying the likelihood function, which could be intractable for\ncorrelated binary connectivities. In addition, the proposed method allows for\nheterogeneity among edges between different communities. In theory, we show\nthat incorporating correlation information can lower estimation bias and\naccelerate algorithm convergence. Our simulation studies show that the proposed\nalgorithm outperforms the popular variational EM algorithm assuming conditional\nindependence among edges. We also demonstrate the application of the proposed\nmethod to agricultural product trading networks from different countries.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce a novel generative formulation of deep probabilistic models\nimplementing \"soft\" constraints on their function dynamics. In particular, we\ndevelop a flexible methodological framework where the modeled functions and\nderivatives of a given order are subject to inequality or equality constraints.\nWe then characterize the posterior distribution over model and constraint\nparameters through stochastic variational inference. As a result, the proposed\napproach allows for accurate and scalable uncertainty quantification on the\npredictions and on all parameters. We demonstrate the application of equality\nconstraints in the challenging problem of parameter inference in ordinary\ndifferential equation models, while we showcase the application of inequality\nconstraints on the problem of monotonic regression of count data. The proposed\napproach is extensively tested in several experimental settings, leading to\nhighly competitive results in challenging modeling applications, while offering\nhigh expressiveness, flexibility and scalability.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The computation of a cyber-physical system's reaction to a stimulus typically\ninvolves the execution of several tasks. The delay between stimulus and\nreaction thus depends on the interaction of these tasks and is subject to\ntiming constraints. Such constraints exist for a number of reasons and range\nfrom possible impacts on customer experiences to safety requirements. We\npresent a technique to determine end-to-end latencies of such task sequences.\nThe technique is demonstrated on the example of electronic control units (ECUs)\nin automotive embedded real-time systems. Our approach is able to deal with\nmulti-core architectures and supports four different activation patterns,\nincluding interrupts. It is the first formal analysis approach making use of\nload assumptions in order to exclude infeasible data propagation paths without\nthe knowledge of worst-case execution times or worst-case response times. We\nemploy a constraint programming solver to compute bounds on end-to-end\nlatencies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce a $p$-adic analytic analogue of Backelin and Kremnizer's\nconstruction of the quantum flag variety of a semisimple algebraic group, when\n$q$ is not a root of unity and $| q-1|<1$. We then define a category of\n$\\lambda$-twisted $D$-modules on this analytic quantum flag variety. We show\nthat when $\\lambda$ is regular and dominant and when the characteristic of the\nresidue field does not divide the order of the Weyl group, the global section\nfunctor gives an equivalence of categories between the coherent\n$\\lambda$-twisted $D$-modules and the category of finitely generated modules\nover $\\widehat{U_q^\\lambda}$, where the latter is a completion of the ad-finite\npart of the quantum group with central character corresponding to $\\lambda$.\nAlong the way, we also show that Banach comodules over the Banach completion\n$\\widehat{\\mathcal{O}_q(B)}$ of the quantum coordinate algebra of the Borel can\nbe naturally identified with certain topologically integrable modules.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the question under which conditions the zero set of a (cross-)\nWigner distribution W (f, g) or a short-time Fourier transform is empty. This\nis the case when both f and g are generalized Gaussians, but we will construct\nless obvious examples consisting of exponential functions and their\nconvolutions. The results require elements from the theory of totally positive\nfunctions, Bessel functions, and Hurwitz polynomials. The question of zero-free\nWigner distributions is also related to Hudson's theorem for the positivity of\nthe Wigner distribution and to Hardy's uncertainty principle. We then construct\na class of step functions S so that the Wigner distribution W (f, 1 (0,1))\nalways possesses a zero f $\\in$ S $\\cap$ L p for p < $\\infty$, but may be\nzero-free for f $\\in$ S $\\cap$ L $\\infty$. The examples show that the question\nof zeros of the Wigner distribution may be quite subtle and relate to several\nbranches of analysis.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Attributed network data is becoming increasingly common across fields, as we\nare often equipped with information about nodes in addition to their pairwise\nconnectivity patterns. This extra information can manifest as a classification,\nor as a multidimensional vector of features. Recently developed methods that\nseek to extend community detection approaches to attributed networks have\nexplored how to most effectively combine connectivity and attribute information\nto identify quality communities. These methods often rely on some assumption of\nthe dependency relationships between attributes and connectivity. In this work,\nwe seek to develop a statistical test to assess whether node attributes align\nwith network connectivity. The objective is to quantitatively evaluate whether\nnodes with similar connectivity patterns also have similar attributes. To\naddress this problem, we use a node sampling and label propagation approach. We\napply our method to several synthetic examples that explore how network\nstructure and attribute characteristics affect the empirical p-value computed\nby our method. Finally, we apply the test to a network generated from a single\ncell mass cytometry (CyTOF) dataset and show that our test can identify markers\nassociated with distinct sub populations of single cells.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Ever since the high thermal conductivity in cubic boron arsenide (c-BAs) was\npredicted theoretically by Lindsay et. al in 2013, countless studies have\nzeroed in on this particular material. Most recently, c-BAs has been confirmed\nexperimentally to have a thermal conductivity of around 1,100 W/m-K. In this\nstudy, we investigate the seldom studied two dimensional hexagonal form of\nboron arsenide (h-BAs) using a first-principles approach and by solving the\nBoltzmann Transport Equation for phonons. Traditionally, a good indicator of a\nhigh thermal conductivity material is its high Debye temperature and high\nphonon group velocity. However, we determine h-BAs to have a much lower Debye\ntemperature and average phonon group velocity compared to the other monolayer\nboron-V compounds of boron nitride (h-BN) and boron phosphide (h-BP), yet\ncuriously it possesses a higher thermal conductivity. Further investigation\nreveals that this is due to the phonon frequency gap caused by large mass\nimbalances, which results in a restricted Umklapp phonon-phonon scattering\nchannel and consequently a higher thermal conductivity. We determine the\nintrinsic lattice thermal conductivity of monolayer h-BAs to be 362.62 W/m-K at\nroom temperature, which is considerably higher compared to the other monolayer\nboron-V compounds of h-BN (231.96 W/m-K), h-BP (187.11 W/m-K), and h-BSb (87.15\nW/m-K). This study opens the door for investigation into a new class of\nmonolayer structures and the properties they possess.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The mass of the top quark is measured using a sample of $\\rm{t}\\bar{\\rm t}$\ncandidate events with one lepton, muon or electron, and at least four jets in\nthe final state, collected by the CMS detector in pp collisions at\n$\\sqrt{s}=13~\\mathrm{TeV}$ at the CERN LHC. The candidate events are selected\nfrom data corresponding to an integrated luminosity of $35.9~\\mathrm{fb}^{-1}$.\nFor each event the mass is reconstructed from a kinematic fit of the decay\nproducts to a $\\rm{t}\\bar{\\rm t}$ hypothesis. The top quark mass is determined\nsimultaneously with an overall jet energy scale factor (JSF), constrained by\nthe mass of the W boson in $\\rm{q}\\bar{\\rm q}$ decays. The measurement is\ncalibrated on samples simulated at next-to-leading order matched to parton\nshower. The top quark mass is found to be $172.25\\pm 0.08\\,\\rm{(stat+JSF)} \\pm\n0.62\\,\\rm{(syst)}~\\mathrm{GeV}$. The dependence of this result on event\nkinematical properties is studied and compared to predictions of different\nmodels of $\\rm{t}\\bar{\\rm t}$ production.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Understanding the response of ceramics operating in extreme environments is\nof interest for a variety of applications. Ab initio molecular dynamic\nsimulations have been used to investigate the effect of structure and $B$-site\n(=Ti, Zr) cation composition of lanthanum-based oxides (La$_2$$B_2$O$_7$) on\nelectronic-excitation-induced amorphization. We find that the amorphous\ntransition in monoclinic layered perovskite La$_2$Ti$_2$O$_7$ occurs for a\nlower degree of electronic excitation than for cubic pyrochlore\nLa$_2$Zr$_2$O$_7$. While in each case the formation of O$_2$-like molecules\ndrives the structure to an amorphous state, an analysis of the polyhedral\nconnection network reveals that the rotation of TiO$_6$ octahedra in the\nmonoclinic phase can promote such molecule formation, while such octahedral\nrotation is not possible in the cubic phase. However, once the symmetry of the\ncubic structure is broken by substituting Ti for Zr, it becomes less resistant\nto amorphization. A compound made of 50% Ti and 50% Zr (La$_2$TiZrO$_7$) is\nfound to be more resistant in the monoclinic than in the cubic phase, which may\nbe related to the lower bandgap of the cubic phase. These results illustrate\nthe complex interplay of structure and composition that give rise to the\nradiation resistance of these important functional materials.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Extreme events and the heavy tail distributions driven by them are ubiquitous\nin various scientific, engineering and financial research. They are typically\nassociated with stochastic instability caused by hidden unresolved processes.\nPrevious studies have shown that such instability can be modeled by a\nstochastic damping in conditional Gaussian models. However, these results are\nmostly obtained through numerical experiments, while a rigorous understanding\nof the underlying mechanism is sorely lacking. This paper contributes to this\nissue by establishing a theoretical framework, in which the tail density of\nconditional Gaussian models can be rigorously determined. In rough words, we\nshow that if the stochastic damping takes negative values, the tail is\npolynomial; if the stochastic damping is nonnegative but takes value zero, the\ntail is between exponential and Gaussian. The proof is established by\nconstructing a novel, product-type Lyapunov function, where a Feynman-Kac\nformula is applied. The same framework also leads to a non-asymptotic large\ndeviation bound for long-time averaging processes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a valence transition model for electron- and hole-doped cuprates,\nwithin which there occurs a discrete jump in ionicity Cu$^{2+} \\to$ Cu$^{1+}$\nupon doping, at or near optimal doping in the electron-doped compounds and at\nthe pseudogap phase transition in the hole-doped materials. Doped cuprates have\nnegative charge-transfer gaps, just as rare earth nickelates and BaBiO$_3$.\nBecause of strong correlations and small $d-p$ electron hoppings the systems\nbehave as effective $\\frac{1}{2}$-filled Cu-band in the undoped state, and as\ncorrelated two-dimensional geometrically frustrated nearly $\\frac{1}{4}$-filled\nO-band in the doped state. The theory gives the simplest yet most comprehensive\nunderstanding of experiments in the normal states. The robust\nantiferromagnetism in the conventional T$^\\prime$ crystals, the strong role of\noxygen deficiency in driving superconductivity and charge carrier sign\ncorresponding to holes at optimal doping are all manifestations of the same\nquantum state. In the hole-doped pseudogapped state, a biaxial commensurate\nperiod 4 charge density wave state of O$^{1-}$-Cu$^{1+}$-O$^{1-}$ spin-singlets\ncoexists with broken rotational C$_4$ symmetry. Finite domains of this broken\nsymmetry state will exhibit the polar Kerr effect. Superconductivity within the\nmodel results from a destabilization of the $\\frac{1}{4}$-filled band paired\nWigner crystal [Phys. Rev. B {\\bf 93}, 165110 and {\\bf 93}, 205111]. We posit\nthat a similar valence transition, Ir$^{4+} \\to$ Ir$^{3+}$, occurs in\nelectron-doped SrIr$_2$O$_4$. We make testable theoretical predictions on\ncuprates and iridates. Finally, we note that there exist an unusually large\nnumber of unconventional superconductors that exhibit superconductivity\nproximate to exotic charge ordered states, whose bandfillings are also\n$\\frac{1}{4}$, exactly where the paired Wigner crystal is most stable.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper defines symplectic scale manifolds based on\nHofer-Wysocki-Zehnder's scale calculus. We introduce Hamiltonian vector fields\nand flows on these by narrowing down sc-smoothness to what we denote by strong\nsc-smoothness, a concept which effectively formalizes the desired smoothness\nproperties for Hamiltonian functions. We show the concept to be invariant under\nsc-smooth symplectomorphisms, whence it is compatible with Hofer's scale\nmanifolds. We develop and verify the theory at the hand of the free\nSchr\\\"odinger equation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  From the viewpoint of differential geometry and topology, we investigate the\ncharacterization of the shadows in a Kerr spacetime. Two new quantities, the\nlength of the shadow boundary and the local curvature radius are introduced.\nEach shadow can be uniquely determined by these two quantities. For the black\nhole case, the result shows that we can constrain the black hole spin and the\nangular coordinate of the observer only by measuring the maximum and minimum of\nthe curvature radius. While for the naked singularity case, we adopt the length\nparameter and the maximum of the curvature radius. This technique is completely\nindependent of the coordinate system and the location of the shadow, and is\nexpected to uniquely determine the parameters of the spacetime. Moreover, we\npropose a topological covariant quantity to measure and distinguish different\ntopological structures of the shadows.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Light field cameras can capture both spatial and angular information of light\nrays, enabling 3D reconstruction by a single exposure. The geometry of 3D\nreconstruction is affected by intrinsic parameters of a light field camera\nsignificantly. In the paper, we propose a multi-projection-center (MPC) model\nwith 6 intrinsic parameters to characterize light field cameras based on\ntraditional two-parallel-plane (TPP) representation. The MPC model can\ngenerally parameterize light field in different imaging formations, including\nconventional and focused light field cameras. By the constraints of 4D ray and\n3D geometry, a 3D projective transformation is deduced to describe the\nrelationship between geometric structure and the MPC coordinates. Based on the\nMPC model and projective transformation, we propose a calibration algorithm to\nverify our light field camera model. Our calibration method includes a\nclose-form solution and a non-linear optimization by minimizing re-projection\nerrors. Experimental results on both simulated and real scene data have\nverified the performance of our algorithm.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Gaia mission will provide precise astrometry for an unprecedented number\nof white dwarfs (WDs), encoding information on stellar evolution, Type Ia\nsupernovae progenitor scenarios, and the star formation and dynamical history\nof the Milky Way. With such a large data set, it is possible to infer\nproperties of the WD population using only astrometric and photometric\ninformation. We demonstrate a framework to accomplish this using a mock data\nset with SDSS ugriz photometry and Gaia astrometric information. Our technique\nutilises a Bayesian hierarchical model for inferring properties of a WD\npopulation while also taking into account all observational errors of\nindividual objects, as well as selection and incompleteness effects. We\ndemonstrate that photometry alone can constrain the WD population's\ndistributions of temperature, surface gravity and phenomenological type, and\nthat astrometric information significantly improves determination of the WD\nsurface gravity distribution. We also discuss the possibility of identifying\nunresolved binary WDs using only photometric and astrometric information.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we provide two new stable online algorithms for the problem of\nprediction in reinforcement learning, \\emph{i.e.}, estimating the value\nfunction of a model-free Markov reward process using the linear function\napproximation architecture and with memory and computation costs scaling\nquadratically in the size of the feature set. The algorithms employ the\nmulti-timescale stochastic approximation variant of the very popular cross\nentropy (CE) optimization method which is a model based search method to find\nthe global optimum of a real-valued function. A proof of convergence of the\nalgorithms using the ODE method is provided. We supplement our theoretical\nresults with experimental comparisons. The algorithms achieve good performance\nfairly consistently on many RL benchmark problems with regards to computational\nefficiency, accuracy and stability.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Cellular automaton (CA) approach is an important theoretical framework for\nstudying complex system behavior and has been widely applied in various\nresearch field. CA traffic flow models have the advantage of flexible evolution\nrules and high computation efficiency. Therefore, CA develops very quickly and\nhas been widely applied in transportation field. In recent two decades, traffic\nflow study quickly developed, among which \"synchronized flow\" is perhaps one of\nthe most important concepts and findings. Many new CA models have been proposed\nin this direction. This paper makes a review of development of CA models,\nconcerning their ability to reproduce synchronized flow as well as traffic\nbreakdown from free flow to synchronized flow. Finally, future directions have\nbeen discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The anatomically layered structure of a human brain results in leveled\nfunctions. In all these levels of different functions, comparison, feedback and\nimitation are the universal and crucial mechanisms. Languages, symbols and\ntools play key roles in the development of human brain and entire civilization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The axion insulator (AXI) has long been recognized as the simplest example of\na 3D magnetic topological insulator (TI). The most familiar AXI results from\nmagnetically gapping the surface states of a 3D $\\mathbb{Z}_{2}$ TI while\npreserving the bulk gap. Like the 3D TI, it exhibits a quantized\nmagnetoelectric polarizability of $\\theta=\\pi$, and can be diagnosed from bulk\nsymmetry eigenvalues when inversion symmetric. However, whereas a 3D TI is\ncharacterized by bulk Wilson loop winding, 2D surface states, and the pumping\nof the 2D $\\mathbb{Z}_{2}$ TI index, we show that an AXI with a large number of\nbulk bands displays no Wilson loop winding, exhibits chiral hinge states, and\ndoes not pump any previously identified quantity. Crucially, as the AXI\nexhibits the topological angle $\\theta=\\pi$, its occupied bands cannot be\nformed into maximally localized symmetric Wannier functions, despite its\nabsence of Wilson loop winding. In this letter, we revisit the AXI from the\nperspective of the recently introduced notion of \"fragile\" topology, and\ndiscover that it in fact can be generically expressed as the cyclic pumping of\na \"trivialized\" fragile phase: a 2D inversion-symmetric insulator with no\nWilson loop winding which nevertheless carries a nontrivial topological index,\nthe nested Berry phase $\\gamma_{2}$. We numerically show that the nontrivial\nvalue $\\gamma_{2}=\\pi$ indicates the presence of anomalous 0D corner charges in\na 2D insulator, and therefore, that the chiral pumping of $\\gamma_{2}$ in a 3D\nAXI corresponds to the presence of chiral hinge states. We also briefly\ngeneralize our results to time-reversal-symmetric higher-order TIs, and discuss\nthe related appearance of nontrivial $\\gamma_{2}$ protected by\n$C_{2}\\times\\mathcal{T}$ symmetry in twisted bilayer graphene, and its\nimplications for the presence of 0D corner states.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we consider the iterated Brownian motion $\n^{\\mu_1}_{\\mu_2}\\!I(t) = B_1^{\\mu_1} ( | B_{2}^{\\mu_2} (t)|) $ where\n$B_j^{\\mu_j} , j=1,2$ are two independent Brownian motions with drift $\\mu_j$.\nHere we study the last zero crossing of $ ^{\\mu_1}_{\\mu_2}\\!I(t) $ and for this\npurpose we derive the last zero-crossing distribution of the drifted Brownian\nmotion. We derive also the joint distribution of the last zero crossing before\n$ t $ and of the first passage time through the zero level of a Brownian motion\nwith drift $ \\mu $ after $ t $. All these results permit us to derive explicit\nformulas for ${^I_\\mu T_0} = \\sup \\{ s < \\max_{0\\leq z\\leq t} |B_2(z)| :\nB_1^\\mu (s) = 0 \\}$. Also the iterated zero-crossing $ {^{\\mu_1} T}_{0,\n{^{\\mu_2} T}_{0,t}} $ is analyzed and extended to the case where the level of\nnesting is arbitrary.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Whereas many studies have examined stabilization of emulsions and foams in\nlow salinity aqueous phases with nanoparticles (NPs) with and without added\nsurfactants, interest has grown recently in much higher salinities relevant to\nsubsurface oil and gas applications. It is shown for the first time that NPs\ngrafted with well-defined low molecular weight ligands colloidally stable in\nconcentrated brine (in particular, API brine, 8% NaCl + 2% CaCl2) and are\ninterfacially active at the brine-air interface. These properties were achieved\nfor three types of ligands: a nonionic diol called GLYMO and two short\npoly(ethylene glycol) (PEG) oligomers with 6-12 EO repeat units. Carbon\ndioxide-in-water (C/W) foams could be formed only with modified NPs with higher\nsurface pressures at the A/W interface. Furthermore, these ligands were\nsufficiently CO2-philic that the hydrophilic/CO2-philic balance of silica NPs\nwas low enough for stabilization of CO2-in-water (C/W) foam with API brine.\nAdditionally, NPs with these three ligands formed stable dispersions with\nvarious free molecular surfactants in DI water and even API brine (8% NaCl + 2%\nCaCl2) at room temperature. A wide variety of mixtures of NPs plus anionic,\nnonionic, or cationic mixtures that formed stable dispersions were also found\nto stabilize C/W foams in porous media at high salinity. These results provide\na basis for future studies of the mechanism of foam stabilization with NPs and\nNP/surfactant mixtures at high salinity.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  To facilitate the implementation of large scale photonic quantum walks, we\nhave developed a polymer waveguide platform capable of robust, polarization\ninsensitive single mode guiding over a broad range of visible and near-\ninfrared wavelengths. These devices have considerable elasticity, which we\nexploit to enable tuning of optical behaviour by precise mechanical\ndeformations. In this work, we investigate pairs of beamsplitters arranged as\ninterferometers. These systems demonstrate stable operation over a wide range\nof phases and reflectivities. We discuss device performance, and present an\noutlook on flexible polymer chips supporting large, reconfigurable optical\ncircuits.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Chinese language has evolved a lot during the long-term development.\nTherefore, native speakers now have trouble in reading sentences written in\nancient Chinese. In this paper, we propose to build an end-to-end neural model\nto automatically translate between ancient and contemporary Chinese. However,\nthe existing ancient-contemporary Chinese parallel corpora are not aligned at\nthe sentence level and sentence-aligned corpora are limited, which makes it\ndifficult to train the model. To build the sentence level parallel training\ndata for the model, we propose an unsupervised algorithm that constructs\nsentence-aligned ancient-contemporary pairs by using the fact that the aligned\nsentence pair shares many of the tokens. Based on the aligned corpus, we\npropose an end-to-end neural model with copying mechanism and local attention\nto translate between ancient and contemporary Chinese. Experiments show that\nthe proposed unsupervised algorithm achieves 99.4% F1 score for sentence\nalignment, and the translation model achieves 26.95 BLEU from ancient to\ncontemporary, and 36.34 BLEU from contemporary to ancient.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the problem of computing the measure of a regular language of\ninfinite binary trees. While the general case remains unsolved, we show that\nthe measure of a language defined by a first-order formula with no descendant\nrelation or by a Boolean combination of conjunctive queries (with descendant\nrelation) is rational and computable. Additionally, we provide an example of a\nfirst-order formula that uses descendant relation and defines a language of\ninfinite trees having an irrational measure.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We analyzed in a systematic way the public INTEGRAL observations spanning\nfrom December 2002 to September 2016, to investigate the hard X-ray properties\nof about 60 High Mass X-ray Binaries (HMXBs). We considered both persistent and\ntransient sources, hosting either a Be star (Be/XRBs) or a blue supergiant\ncompanion (SgHMXBs, including Supergiant Fast X-ray Transients, SFXTs), a\nneutron star or a black hole. INTEGRAL X-ray light curves (18-50 keV), sampled\nat a bin time of about 2 ks, were extracted for all HMXBs to derive the\ncumulative distribution of their hard X-ray luminosity, their duty cycle, the\nrange of variability of their hard X-ray luminosity. This allowed us to obtain\nan overall and quantitative characterization of the long-term hard X-ray\nactivity of the HMXBs in our sample. Putting the phenomenology observed with\nINTEGRAL into context with other known source properties (e.g. orbital\nparameters, pulsar spin periods) together with observational constraints coming\nfrom softer X-rays (1-10 keV), enabled the investigation of the way the\ndifferent HMXB sub-classes behave (and sometimes overlap). For given source\nproperties, the different sub-classes of massive binaries seem to cluster in a\nsuggestive way. However, for what concerns supergiant systems (SgHMXBs versus\nSFXTs), several sources with intermediate properties exist, suggesting a smooth\ntransition between the two sub-classes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Tropical recurrent sequences are introduced satisfying a given vector (being\na tropical counterpart of classical linear recurrent sequences). We consider\nthe case when Newton polygon of the vector has a single (bounded) edge. In this\ncase there are periodic tropical recurrent sequences which are similar to\nclassical linear recurrent sequences. A question is studied when there exists a\nnon-periodic tropical recurrent sequence satisfying a given vector, and partial\nanswers are provided to this question. Also an algorithm is designed which\ntests existence of non-periodic tropical recurrent sequences satisfying a given\nvector with integer coordinates. Finally, we introduce a tropical entropy of a\nvector and provide some bounds on it.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $st=\\{st_1,\\ldots,st_k\\}$ be a set of $k$ statistics on permutations with\n$k\\geq 1$. We say that two given subset of permutations $T$ and $T'$ are\n$st$-Wilf-equivalent if the joint distributions of all statistics in $st$ over\nthe sets of $T$-avoiding permutations $S_n(T)$ and $T'$-avoiding permutations\n$S_n(T')$ are the same. The main purpose of this paper is the\n(cr,nes)-Wilf-equivalence classes for all single patterns in $S_3$, where cr\nand nes denote respectively the statistics number of crossings and nestings.\nOne of the main tools that we use is the bijection $\\Theta:S_n(321)\\rightarrow\nS_n(132)$ which was originally exhibited by Elizalde and Pak in \\cite{ElizP}.\nThey proved that the bijection $\\Theta$ preserves the number of fixed points\nand excedances. Since the given formulation of $\\Theta$ is not direct, we show\nthat it can be defined directly by a recursive formula. Then, we prove that it\nalso preserves the number of crossings. Due to the fact that the sets of\nnon-nesting permutations and 321-avoiding permutations are the same, these\nproperties of the bijection $\\Theta$ leads to an unexpected result related to\nthe q,p-Catalan numbers of Randrianarivony defined in \\cite{ARandr}.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We give results on zeros of a polynomial of\n$\\zeta(s),\\zeta'(s),\\ldots,\\zeta^{(k)}(s)$. First, we give a zero free region\nand prove that there exist zeros corresponding to the trivial zeros of the\nRiemann zeta function. Next, we estimate the number of zeros whose imaginary\npart is in $(1,T)$. Finally, we study the distribution of the real part and the\nimaginary part of zeros, respectively.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The formation of stellar mass black holes from the remnants of Population III\nstars provides a source of initial black hole seeds with the potential to grow\ninto intermediate or, in rare cases, possibly supermassive black holes. We use\nthe Renaissance simulation suite to follow the growth of over 15,000 black\nholes born into mini-haloes in the early Universe. We compute the evolution of\nthe black holes by post-processing individual remnant Population III star\nparticles in the Renaissance simulation snapshots. The black holes populate\nhaloes from 10$^{6}$ M$_{\\odot}$ up to 10$^{9}$ M$_{\\odot}$. We find that all\nof the black holes display very inefficient growth. On average the black holes\nincrease their initial mass by a factor 10$^{-5}$, with the most active black\nholes increasing their mass by approximately 10%. Only a single black hole\nexperiences any period of super-Eddington accretion, but the duration is very\nshort and not repeated. Furthermore, we find no correlation of black hole\naccretion with halo mass in the mass range sampled. Within most haloes, we\nidentify clumps of cool, dense gas for which accretion rates would be high, but\ninstances of black holes encountering these clumps are rare and short-lived.\nStar formation competes with black hole growth by consuming available gas and\ndriving down accretion rates through feedback. We conclude that the black holes\nborn from Population III remnants do not form a significant population of\nintermediate mass black holes in the early Universe and will need to wait until\nlater times to undergo significant accretion, if at all.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Convolutional neural networks require significant memory bandwidth and\nstorage for intermediate computations, apart from substantial computing\nresources. Neural network quantization has significant benefits in reducing the\namount of intermediate results, but it often requires the full datasets and\ntime-consuming fine tuning to recover the accuracy lost after quantization.\nThis paper introduces the first practical 4-bit post training quantization\napproach: it does not involve training the quantized model (fine-tuning), nor\nit requires the availability of the full dataset. We target the quantization of\nboth activations and weights and suggest three complementary methods for\nminimizing quantization error at the tensor level, two of whom obtain a\nclosed-form analytical solution. Combining these methods, our approach achieves\naccuracy that is just a few percents less the state-of-the-art baseline across\na wide range of convolutional models. The source code to replicate all\nexperiments is available on GitHub:\n\\url{https://github.com/submission2019/cnn-quantization}.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, secure, remote estimation of a linear Gaussian process via\nobservations at multiple sensors is considered. Such a framework is relevant to\nmany cyber-physical systems and internet-of-things applications. Sensors make\nsequential measurements that are shared with a fusion center; the fusion center\napplies a certain filtering algorithm to make its estimates. The challenge is\nthe presence of a few unknown malicious sensors which can inject anomalous\nobservations to skew the estimates at the fusion center. The set of malicious\nsensors may be time-varying. The problems of malicious sensor detection and\nsecure estimation are considered. First, an algorithm for secure estimation is\nproposed. The proposed estimation scheme uses a novel filtering and learning\nalgorithm, where an optimal filter is learnt over time by using the sensor\nobservations in order to filter out malicious sensor observations while\nretaining other sensor measurements. Next, a novel detector to detect injection\nattacks on an unknown sensor subset is developed. Numerical results demonstrate\nup to 3 dB gain in the mean squared error and up to 75% higher attack detection\nprobability under a small false alarm rate constraint, against a competing\nalgorithm that requires additional side information.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The spectral properties of the adjacency matrix, in particular its largest\neigenvalue and the associated principal eigenvector, dominate many structural\nand dynamical properties of complex networks. Here we focus on the localization\nproperties of the principal eigenvector in real networks. We show that in most\ncases it is either localized on the star defined by the node with largest\ndegree (hub) and its nearest neighbors, or on the densely connected subgraph\ndefined by the maximum $K$-core in a $K$-core decomposition. The localization\nof the principal eigenvector is often strongly correlated with the value of the\nlargest eigenvalue, which is given by the local eigenvalue of the corresponding\nlocalization subgraph, but different scenarios sometimes occur. We additionally\nshow that simple targeted immunization strategies for epidemic spreading are\nextremely sensitive to the actual localization set.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Precise near-ground trajectory control is difficult for multi-rotor drones,\ndue to the complex aerodynamic effects caused by interactions between\nmulti-rotor airflow and the environment. Conventional control methods often\nfail to properly account for these complex effects and fall short in\naccomplishing smooth landing. In this paper, we present a novel\ndeep-learning-based robust nonlinear controller (Neural Lander) that improves\ncontrol performance of a quadrotor during landing. Our approach combines a\nnominal dynamics model with a Deep Neural Network (DNN) that learns high-order\ninteractions. We apply spectral normalization (SN) to constrain the Lipschitz\nconstant of the DNN. Leveraging this Lipschitz property, we design a nonlinear\nfeedback linearization controller using the learned model and prove system\nstability with disturbance rejection. To the best of our knowledge, this is the\nfirst DNN-based nonlinear feedback controller with stability guarantees that\ncan utilize arbitrarily large neural nets. Experimental results demonstrate\nthat the proposed controller significantly outperforms a Baseline Nonlinear\nTracking Controller in both landing and cross-table trajectory tracking cases.\nWe also empirically show that the DNN generalizes well to unseen data outside\nthe training domain.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The paper deals with the fundamental problem of a modeling of the physical,\nin particular, thermal hydraulic processes, in various media of fractal\nstructure of the natural, technological and technical systems and devices. The\nexamples of a few complex systems (mainly, the physical processes) are shown as\nthe different fractal structures, e.g. the ones obtained by cooling and\nsolidification of the multiphase mixtures. Some materials reveal the structural\nfeatures having a significant influence on the behaviors of these materials.\nThe thermal hydraulic processes which are going during a melts cooling, with\nthe further water and steam flow through a porous or a channeled media, are\npresenting the characteristic examples. The best models of the thermal\nhydraulic and other physical processes in such fractal media should be the ones\nbased on the fractional differential equations. An order of the fractional\nderivatives in time and space may change in the process. For example, by a\ncooling of a melt, with a change of the fractal properties of the system, it is\ngoing as follows: first, the vapor, water, melt mixture is interacting, then a\nformation of the solid structure is performing due to solidification of a melt,\nand a vapor flows through the permeable structure developed in a process. The\ndynamically changing fractal systems (dynamic fractals) must be modeled by the\ncorresponding equations changing according to the evolving process. Therefore,\nit is not surprising that so far some of such tasks have not been properly\nresolved even in a simplified formulation. There are many similar problems in\nthe modern physics, technology, etc., which are discussed in the paper.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Inspired by a recent work of Hyt\\\"onen and Naor, we solve a problem left open\nin our previous work joint with Mart\\'{\\i}nez and Torrea on the vector-valued\nLittlewood-Paley-Stein theory for symmetric diffusion semigroups. We prove a\nsimilar result in the discrete case, namely, for any $T$ which is the square of\na symmetric Markovian operator on a measure space $(\\Omega, \\mu)$. Moreover, we\nshow that $T\\otimes{\\rm Id}_X$ extends to an analytic contraction on\n$L_p(\\Omega; X)$ for any $1<p<\\infty$ and any uniformly convex Banach space\n$X$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Key properties of nine possible defect sites in hexagonal boron nitride\n(h-BN) are predicted using density-functional theory and are corrected by\napplying results from high-level ab initio calculations. Observed h-BN\nelectron-paramagnetic resonance signals at 22.4, 20.83, and 352.70 MHz are\nassigned to VN, CN, and VNO2B, respectively, while the observed photoemission\nat 1.95 eV is assigned to VNCB. Detailed consideration of the available excited\nstates, allowed spin-orbit couplings, zero-field splitting, and optical\ntransitions are made for the two related defects VNCB and VBCN. VNCB is\nproposed for realizing long-lived quantum memory in h-BN. VBCN is predicted to\nhave a triplet ground state, implying that spin initialization by optical means\nis feasible and suitable optical excitations are identified, making this defect\nof interest for possible quantum-qubit operations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove that for every positive integer k, there exists an\nMSO_1-transduction that given a graph of linear cliquewidth at most k outputs,\nnondeterministically, some cliquewidth decomposition of the graph of width\nbounded by a function of k. A direct corollary of this result is the\nequivalence of the notions of CMSO_1-definability and recognizability on graphs\nof bounded linear cliquewidth.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It is well known that any pair of random variables $(X,Y)$ with values in\nPolish spaces, provided that $Y$ is nonatomic, can be approximated in joint law\nby random variables of the form $(X',Y)$ where $X'$ is $Y$-measurable and $X'\n\\stackrel{d}{=} X$. This article surveys and extends some recent dynamic\nanalogues of this result. For example, if $X$ and $Y$ are stochastic processes\nin discrete or continuous time, then, under a nonatomic assumption as well as a\nnecessary and sufficient causality (or compatibility) condition, one can\napproximate $(X,Y)$ in law in path space by processes of the form $(X',Y)$,\nwhere $X'$ is adapted to the filtration generated by $Y$. In addition, in\nfinite discrete time, we can take $X'$ to have the same law as $X$. A similar\napproximation is valid for randomized stopping times, without the first\nmarginal fixed. Natural applications include relaxations of (mean field)\nstochastic control and causal optimal transport problems as well as new\ncharacterizations of the immersion property for progressively enlarged\nfiltrations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a discrete-time, one-dimensional quantum walk based on the\nentanglement between the momentum of ultracold rubidium atoms (the walk space)\nand two internal atomic states (the \"coin\" degree of freedom). Our scheme is\nhighly flexible and can provide a platform for a wide range of applications\nsuch as quantum search algorithms, the observation of topological phases, and\nthe realization of walks with higher dimensionality. Along with the\ninvestigation of the quantum-to-classical transition, we demonstrate the\ndistinctive features of a quantum walk and contrast them to those of its\nclassical counterpart. Also, by manipulating either the walk or coin operator,\nwe show how the walk dynamics can be steered or even reversed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We review here some of the historical highlights in exploratory studies of\nthe vertebrate embryonic structure known as the neural crest. The study of the\nmolecular properties of the cells that it produces, their migratory capacities\nand plasticity, and the still-growing list of tissues that depend on their\npresence for form and function, continue to enrich our understanding of\ncongenital malformations, pediatric cancers but also of evolutionary biology.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose an hybrid laser system consisting of a semiconductor external\ncavity laser associated to an intra-cavity diamond etalon doped with\nnitrogen-vacancy color centers. We consider laser emission tuned to the\ninfrared absorption line that is enhanced under the magnetic field dependent\nnitrogen-vacancy electron spin resonance and show that this architecture leads\nto a compact solid-state magnetometer that can be operated at room-temperature.\nThe sensitivity to the magnetic field limited by the photon shot-noise of the\noutput laser beam is estimated to be around $250~\\mathrm{fT/\\sqrt{Hz}}$. Unlike\nusual NV center infrared magnetometry, this method would not require an\nexternal frequency stabilized laser. Since the proposed system relies on the\ncompetition between the laser threshold and an intracavity absorption, such\nlaser-based optical sensor could be easily adapted to a broad variety of\nphysical systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We constrain cosmological parameters by analysing the angular power spectra\nof the Baryon Oscillation Spectroscopic Survey DR12 galaxies, a spectroscopic\nfollow-up of around 1.3 million SDSS galaxies over 9,376 deg$^2$ with an\neffective volume of $\\sim 6.5$ (Gpc $h^{-1}$)$^3$ in the redshift range $0.15\n\\leq z < 0.80$. We split this sample into 13 tomographic bins ($\\Delta z =\n0.05$); angular power spectra were calculated using a Pseudo-$C_{\\ell}$\nestimator, and covariance matrices were estimated using log-normal simulated\nmaps. Cosmological constraints obtained from these data were combined with\nconstraints from Planck CMB experiment as well as the JLA supernovae\ncompilation. Considering a $w$CDM cosmological model measured on scales up to\n$k_{max} = 0.07h$ Mpc$^{-1}$, we constrain a constant dark energy\nequation-of-state with a $\\sim 4\\%$ error at the 1-$\\sigma$ level: $w_0 =\n-0.993^{+0.046}_{-0.043}$, together with $\\Omega_m = 0.330\\pm 0.012$, $\\Omega_b\n= 0.0505 \\pm 0.002$, $S_8 \\equiv \\sigma_8 \\sqrt{\\Omega_m/0.3} = 0.863 \\pm\n0.016$, and $h = 0.661 \\pm 0.012$. For the same combination of datasets, but\nnow considering a $\\Lambda$CDM model with massive neutrinos and the same scale\ncut, we find: $\\Omega_m = 0.328 \\pm 0.009$, $\\Omega_b =\n0.05017^{+0.0009}_{-0.0008}$, $S_8 = 0.862 \\pm 0.017$, and $h =\n0.663^{+0.006}_{-0.007}$ and a 95\\% credible interval (CI) upper limit of $\\sum\nm_{\\nu} < 0.14$ eV for a normal hierarchy. These results are competitive if not\nbetter than standard analyses with the same dataset, and demonstrate this\nshould be a method of choice for future surveys, opening the door for their\nfull exploitation in cross-correlations probes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the Fast Fourier Transform (FFT) based numerical method for thin\nfilm magnetization problems [Vestg{\\aa}rden and Johansen, SuST, 25 (2012)\n104001], compare it with the finite element methods, and evaluate its accuracy.\nProposed modifications of this method implementation ensure stable convergence\nof iterations and enhance its efficiency. A new method, also based on the FFT,\nis developed for 3D bulk magnetization problems. This method is based on a\nmagnetic field formulation, different from the popular h-formulation of eddy\ncurrent problems typically employed with the edge finite elements. The method\nis simple, easy to implement, and can be used with a general current-voltage\nrelation; its efficiency is illustrated by numerical simulations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a new frequency standard based on a $4f^{14} 6s6p~ ^3\\!P_0 -\n4f^{13} 6s^2 5d ~(J=2)$ transition in neutral Yb. This transition has a\npotential for high stability and accuracy and the advantage of the highest\nsensitivity among atomic clocks to variation of the fine-structure constant\n$\\alpha$. We find its dimensionless $\\alpha$-variation enhancement factor to be\n$K=-15$, in comparison to the most sensitive current clock (Yb$^+$ E3, $K=-6$),\nand it is 18 times larger than in any neutral-atomic clocks (Hg, $K=0.8$).\nCombined with the unprecedented stability of an optical lattice clock for\nneutral atoms, this high sensitivity opens new perspectives for searches for\nultralight dark matter and for tests of theories beyond the standard model of\nelementary particles. Moreover, together with the well-established $^1\\!S_0 -\\,\n^3\\!P_0$ transition one will have two clock transitions operating in neutral\nYb, whose interleaved interrogations may further reduce systematic\nuncertainties of such clock-comparison experiments.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present explicit formulas for Hecke eigenforms as linear combinations of\nq-analogues of modified double zeta values. As an application, we obtain period\npolynomial relations and sum formulas for these modified double zeta values.\nThese relations have similar shapes as the period polynomial relations of\nGangl, Kaneko and Zagier and the usual sum formulas for classical double zeta\nvalues.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Considering the set cover problem, by modifying the approach that gives a\nlogarithmic approximation guarantee for the greedy algorithm, we obtain an\nestimation of the greedy algorithm's accuracy for a particular input. We\ncompare the presented estimation to another estimations of this type. We give\nsuch examples of the set cover problem instances that the presented estimation\nsagnificantly improves over linear programming relaxation based estimation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, by studying certain isometries on globally hyperbolic planes,\nwe prove that if $p$ is a timelike pole on a class A Lorentzian 2-torus, then\nthere exists a closed timelike geodesic passing through $p$ with any\npreassigned free homotopy class in the interior of the stable time cone. We\nalso show a non-rigid result when timelike poles appear.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the dynamics of a generalized version of the famous\nKuramoto-Sakaguchi coupled oscillator model. In the classic version of this\nsystem, all oscillators are governed by the same ODE, which depends on the\norder parameter of the oscillator configuration. The order parameter is the\narithmetic mean of the configuration of complex oscillator phases, multiplied\nby some constant complex coupling factor. In the generalized model we consider,\nthe order parameter is allowed to be any complex linear combination of the\ncomplex oscillator phases, so the oscillators are no longer necessarily\nweighted identically in the order parameter. This asymmetric version of the K-S\nmodel exhibits a much richer variety of steady-state dynamical behavior than\nthe classic symmetric version; in addition to stable synchronized states, the\nsystem may possess multiple stable (N-1,1) states, in which all but one of the\noscillators are in sync, as well as multiple families of neutrally stable\nasynchronous states or closed orbits, in which no two oscillators are in sync.\nWe present an exhaustive description of the possible steady state dynamical\nbehaviors; our classification depends on the complex coefficients that\ndetermine the order parameter. We use techniques from group theory and\nhyperbolic geometry to reduce the dynamic analysis to a 2D flow on the unit\ndisc, which has geometric significance relative to the hyperbolic metric. The\ngeometric-analytic techniques we develop can in turn be applied to study even\nmore general versions of Kuramoto oscillator networks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In practice, most spoken language understanding systems process user input in\na pipelined manner; first domain is predicted, then intent and semantic slots\nare inferred according to the semantic frames of the predicted domain. The\npipeline approach, however, has some disadvantages: error propagation and lack\nof information sharing. To address these issues, we present a unified neural\nnetwork that jointly performs domain, intent, and slot predictions. Our\napproach adopts a principled architecture for multitask learning to fold in the\nstate-of-the-art models for each task. With a few more ingredients, e.g.\northography-sensitive input encoding and curriculum training, our model\ndelivered significant improvements in all three tasks across all domains over\nstrong baselines, including one using oracle prediction for domain detection,\non real user data of a commercial personal assistant.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a machine learning framework for multi-agent systems to learn both\nthe optimal policy for maximizing the rewards and the encoding of the high\ndimensional visual observation. The encoding is useful for sharing local visual\nobservations with other agents under communication resource constraints. The\nactor-encoder encodes the raw images and chooses an action based on local\nobservations and messages sent by the other agents. The machine learning agent\ngenerates not only an actuator command to the physical device, but also a\ncommunication message to the other agents. We formulate a reinforcement\nlearning problem, which extends the action space to consider the communication\naction as well. The feasibility of the reinforcement learning framework is\ndemonstrated using a 3D simulation environment with two collaborating agents.\nThe environment provides realistic visual observations to be used and shared\nbetween the two agents.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  High Mach number shocks are ubiquitous in interstellar turbulence. The Pencil\nCode is particularly well suited to the study of magnetohydrodynamics in weakly\ncompressible turbulence and the numerical investigation of dynamos because of\nits high-order advection and time evolution algorithms. However, the high-order\nalgorithms and lack of Riemann solver to follow shocks make it less well suited\nto handling high Mach number shocks, such as those produced by supernovae\n(SNe). Here, we outline methods required to enable the code to efficiently and\naccurately model SNe, using parameters that allow stable simulation of\nSN-driven turbulence, in order to construct a physically realistic galactic\ndynamo model. These include the resolution of shocks with artificial viscosity,\nthermal conductivity, and mass diffusion; the correction of the mass diffusion\nterms; and a novel generalization of the Courant condition to include all\nsource terms in the momentum and energy equations. We test our methods with the\nnumerical solution of the one-dimensional (1D) Riemann shock tube (Sod, J.\nComput. Phys. 1978, 27), also extended to a 1D adiabatic shock with parameters\nand Mach number relevant to SN shock evolution, including shocks with radiative\nlosses. We extend our test with the three-dimensional (3D) numerical simulation\nof individual SN remnant evolution for a range of ambient gas densities typical\nof the interstellar medium and compare these to the analytical solutions of\nSedov-Taylor (adiabatic) and the snowplough and Cioffi, McKee and Bertschinger\n(Astrophys. J. 1988, 334) results incorporating cooling and heating processes.\nWe show that our new timestep algorithm leads to linear rather than quadratic\nresolution dependence as the strength of the artificial viscosity varies,\nbecause of the corresponding change in the strength of interzone gradients.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Despite its unusual payout structure, the Canadian 6/49 Lotto is one of the\nfew government sponsored lotteries that has the potential for a favorable\nstrategy we call \"buying the pot.\" By buying the pot we mean that a syndicate\nbuys each ticket in the lottery, ensuring that it holds a jackpot winner. We\nassume that the other bettors independently buy small numbers of tickets. This\npaper presents (1) a formula for the syndicate's expected return, (2)\nconditions under which buying the pot produces a significant positive expected\nreturn, and (3) the implications of these findings for lottery design.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Projective splitting is a family of methods for solving inclusions involving\nsums of maximal monotone operators. First introduced by Eckstein and Svaiter in\n2008, these methods have enjoyed significant innovation in recent years,\nbecoming one of the most flexible operator splitting frameworks available.\nWhile weak convergence of the iterates to a solution has been established,\nthere have been few attempts to study convergence rates of projective\nsplitting. The purpose of this paper is to do so under various assumptions. To\nthis end, there are three main contributions. First, in the context of convex\noptimization, we establish an $O(1/k)$ ergodic function convergence rate.\nSecond, for strongly monotone inclusions, strong convergence is established as\nwell as an ergodic $O(1/\\sqrt{k})$ convergence rate for the distance of the\niterates to the solution. Finally, for inclusions featuring strong monotonicity\nand cocoercivity, linear convergence is established.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In these proceedings we report on the status of the ALICE Time-Of-Flight\n(TOF) detector. The running performance of the Run 1 (2009-2013) and Run 2\n(2015-present) data taking campaigns are compared. The Particle IDentification\n(PID) capabilities of the detector are presented and discussed in the light of\nthe improved detector calibration that allowed to reach a timing resolution of\n56 ps.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Hybrid manufacturing (HM) technologies combine additive and subtractive\nmanufacturing (AM/SM) capabilities, leveraging AM's strengths in fabricating\ncomplex geometries and SM's precision and quality to produce finished parts. We\npresent a systematic approach to automated computer-aided process planning\n(CAPP) for HM that can identify non-trivial, qualitatively distinct, and\ncost-optimal combinations of AM/SM modalities. A multimodal HM process plan is\nrepresented by a finite Boolean expression of AM and SM manufacturing\nprimitives, such that the expression evaluates to an 'as-manufactured'\nartifact. We show that primitives that respect spatial constraints such as\naccessibility and collision avoidance may be constructed by solving inverse\nconfiguration space problems on the 'as-designed' artifact and manufacturing\ninstruments. The primitives generate a finite Boolean algebra (FBA) that\nenumerates the entire search space for planning. The FBA's canonical\nintersection terms (i.e., 'atoms') provide the complete domain decomposition to\nreframe manufacturability analysis and process planning into purely symbolic\nreasoning, once a subcollection of atoms is found to be interchangeable with\nthe design target. The approach subsumes unimodal (all-AM or all-SM) process\nplanning as special cases. We demonstrate the practical potency of our\nframework and its computational efficiency when applied to process planning of\ncomplex 3D parts with dramatically different AM and SM instruments.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  X-ray flares, lasting for $\\sim 100 - 1000$ s in the X-ray band, are often\nobserved following gamma-ray bursts (GRBs). The physical origin of X-ray flares\nis still unknown merely with the temporal/spectral information. On the other\nhand, some polarimeters are expected to be launched within several years thanks\nto the increasing interest on astronomical X-ray polarimetry. Here, by assuming\nthat X-ray flares are synchrotron radiation from relativistic spherical shells,\nwe show that the linear polarization degree during the rising phase of an X-ray\nflare is much higher for the emitting region with toroidal magnetic fields than\nthat with random magnetic fields. In the decay phase of the flare, the\nevolution of the polarization degree is determined by the curvature effect of\nthe emitting shell, which is a natural feature of jet scenarios for flares.\nTherefore, the measurement of the polarization of X-ray flares would provide a\nuseful tool to probe the configuration of magnetic fields in the emission\nregion, and may even help to test the curvature effect. The information on the\nmagnetic configuration can further help us to understand the properties of GRB\njets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show that any second eigenfunction of the Laplacian with standard vertex\nconditions on a metric tree graph attains its extremal values only at degree\none vertices, and give an example where these vertices do not realise the\ndiameter of the graph.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Functional protein-protein interactions are crucial in most cellular\nprocesses. They enable multi-protein complexes to assemble and to remain\nstable, and they allow signal transduction in various pathways. Functional\ninteractions between proteins result in coevolution between the interacting\npartners, and thus in correlations between their sequences. Pairwise\nmaximum-entropy based models have enabled successful inference of pairs of\namino-acid residues that are in contact in the three-dimensional structure of\nmulti-protein complexes, starting from the correlations in the sequence data of\nknown interaction partners. Recently, algorithms inspired by these methods have\nbeen developed to identify which proteins are functional interaction partners\namong the paralogous proteins of two families, starting from sequence data\nalone. Here, we demonstrate that a slightly higher performance for partner\nidentification can be reached by an approximate maximization of the mutual\ninformation between the sequence alignments of the two protein families. Our\nmutual information-based method also provides signatures of the existence of\ninteractions between protein families. These results stand in contrast with\nstructure prediction of proteins and of multi-protein complexes from sequence\ndata, where pairwise maximum-entropy based global statistical models\nsubstantially improve performance compared to mutual information. Our findings\nentail that the statistical dependences allowing interaction partner prediction\nfrom sequence data are not restricted to the residue pairs that are in direct\ncontact at the interface between the partner proteins.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we compute the stopping times in the game Rock-Paper-Scissors.\nBy exploiting the recurrence relation we compute the mean values of stopping\ntimes. On the other hand, by constructing a transition matrix for a Markov\nchain associated with the game, we get also the distribution of the stopping\ntimes and thereby we compute the mean stopping times again. Then we show that\nthe mean stopping times increase exponentially fast as the number of the\nparticipants increases.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Methane gas hydrates have increasingly become a topic of interest because of\ntheir potential as a future energy resource. There are significant economical\nand environmental risks associated with extraction from hydrate reservoirs, so\na variety of multiphysics models have been developed to analyze prospective\nrisks and benefits. These models generally have a large number of empirical\nparameters which are not known a priori. Traditional optimization-based\nparameter estimation frameworks may be ill-posed or computationally\nprohibitive. Bayesian inference methods have increasingly been found effective\nfor estimating parameters in complex geophysical systems. These methods often\nare not viable in cases of computationally expensive models and\nhigh-dimensional parameter spaces. Recently, methods have been developed to\neffectively reduce the dimension of Bayesian inverse problems by identifying\nlow-dimensional structures that are most informed by data. Active subspaces is\none of the most generally applicable methods of performing this dimension\nreduction. In this paper, Bayesian inference of the parameters of a\nstate-of-the-art mathematical model for methane hydrates based on experimental\ndata from a triaxial compression test with gas hydrate-bearing sand is\nperformed in an efficient way by utilizing active subspaces. Active subspaces\nare used to identify low-dimensional structure in the parameter space which is\nexploited by generating a cheap regression-based surrogate model and\nimplementing a modified Markov chain Monte Carlo algorithm. Posterior densities\nhaving means that match the experimental data are approximated in a\ncomputationally efficient way.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  When solving stochastic partial differential equations (SPDEs) driven by\nadditive spatial white noise, the efficient sampling of white noise\nrealizations can be challenging. Here, we present a new sampling technique that\ncan be used to efficiently compute white noise samples in a finite element\nmethod and multilevel Monte Carlo (MLMC) setting. The key idea is to exploit\nthe finite element matrix assembly procedure and factorize each local mass\nmatrix independently, hence avoiding the factorization of a large matrix.\nMoreover, in a MLMC framework, the white noise samples must be coupled between\nsubsequent levels. We show how our technique can be used to enforce this\ncoupling even in the case of non-nested mesh hierarchies. We demonstrate the\nefficacy of our method with numerical experiments. We observe optimal\nconvergence rates for the finite element solution of the elliptic SPDEs of\ninterest in 2D and 3D and we show convergence of the sampled field covariances.\nIn a MLMC setting, a good coupling is enforced and the telescoping sum is\nrespected.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We continue the study of enriched infinity categories, using a definition\nequivalent to that of Gepner and Haugseng. In our approach enriched infinity\ncategories are associative monoids in an especially designed monoidal category\nof enriched quivers. We prove that, in case the monoidal structure in the basic\ncategory M comes from direct product, our definition is essentially equivalent\nto the approach via Segal objects. Furthermore, we compare our notion with the\nnotion of category left-tensored over M, and prove a version of Yoneda lemma in\nthis context.\n  Version 2: An error in 2.6.2 corrected.\n  Version 3: a few minor corrections.\n  Version 4: Section 8 added, describing correspondences of enriched\ncategories. In case the basic monoidal category M is a prototopos with a\ncartesian structure, we prove that the category of correspondences is\nequivalent to the category of enriched categories over [1].\n  Version 5: terminology changed (former bicartesian fibrations became\nbifibrations), a few misprints corrected.\n  Version 6: Section 2.11 added, dealing with operadic sieves. A number of\ncorrections and clarifications made per referee's request.\n  Version 7: final version, accepted to Advances in Math.\n  Version 8: a minor correction of 2.8.9-2.8.10.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we apply the entropy principle to the relativistic version of\nthe differential equations describing a standard fluid flow, that is, the\nequations for mass, momentum, and a system for the energy matrix. These are the\nsecond order equations which have been introduced in [3]. Since the principle\nalso says that the entropy equation is a scalar equation, this implies, as we\nshow, that one has to take a trace in the energy part of the system. Thus one\narrives at the relativistic mass-momentum-energy system for the fluid. In the\nprocedure we use the well-known Liu-M\\\"uller sum [10] in order to deduce the\nGibbs relation and the residual entropy inequality.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We address the problem of finding influential training samples for a\nparticular case of tree ensemble-based models, e.g., Random Forest (RF) or\nGradient Boosted Decision Trees (GBDT). A natural way of formalizing this\nproblem is studying how the model's predictions change upon leave-one-out\nretraining, leaving out each individual training sample. Recent work has shown\nthat, for parametric models, this analysis can be conducted in a\ncomputationally efficient way. We propose several ways of extending this\nframework to non-parametric GBDT ensembles under the assumption that tree\nstructures remain fixed. Furthermore, we introduce a general scheme of\nobtaining further approximations to our method that balance the trade-off\nbetween performance and computational complexity. We evaluate our approaches on\nvarious experimental setups and use-case scenarios and demonstrate both the\nquality of our approach to finding influential training samples in comparison\nto the baselines and its computational efficiency.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The main purpose of this paper is to analyze threshold effects of official\ndevelopment assistance (ODA) on economic growth in WAEMU zone countries. To\nachieve this, the study is based on OECD and WDI data covering the period\n1980-2015 and used Hansen's Panel Threshold Regression (PTR) model to\n\"bootstrap\" aid threshold above which its effectiveness is effective. The\nevidence strongly supports the view that the relationship between aid and\neconomic growth is non-linear with a unique threshold which is 12.74% GDP.\nAbove this value, the marginal effect of aid is 0.69 points, \"all things being\nequal to otherwise\". One of the main contribution of this paper is to show that\nWAEMU countries need investments that could be covered by the foreign aid. This\nlater one should be considered just as a complementary resource. Thus, WEAMU\ncountries should continue to strengthen their efforts in internal resource\nmobilization in order to fulfil this need.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In the present work, we give a phenomenological theory of the monolayer\ngraphene where two worlds quantum and classical meet together and complete each\nother in the most natural way. It appears that the graphene is the unique\nmaterial where this complementarity could be explained in an effective way due\nto its exceptional band structure properties. We introduce the electron\nmass-vortex representation and we define surface tension excitation states in\nthe monolayer graphene. By abstracting from the usual band energy dispersion we\ncalculate the band mass of the electrons at the Dirac point by introducing the\nmathematical mass-dispersion relation. As a result, we obtain the Dirac energy\ndispersion in monolayer graphene from the classical Newton law. Within the\nsemiclassical theory, we show the presence of the surface spin tension\nvectorial field which, possibly, closely relates the surface tension and spin\ntension states on the helical surface. We calculate the surface tension related\nwith the electron band mass-vortex formation at the Dirac's point and we\npredict accurately the surface tension value related to the excitonic binding\nat the Dirac point as being formed from the electron and hole band\nmass-vortices. Moreover, we give the solution to a long-standing problem in the\nspin group theory and we construct an example which shows, phenomenologically,\nthat the manifolds on $\\rm S^{(6)}$ are not integrable. The principal reason\nfor this is attributed to the irreducibility of the spinorial group $\\rm\nSpin(6)^{\\rm R}$ at the Dirac's point, due to the band mass formation via\ngravitational field.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Uniqueness of solutions in the linear theory of non-singular dislocations,\nstudied as a special case of plasticity theory, is examined. The status of the\nclassical, singular Volterra dislocation problem as a limit of plasticity\nproblems is illustrated by a specific example that clarifies the use of the\nplasticity formulation in the study of classical dislocation theory.\nStationary, quasi-static, and dynamical problems for continuous dislocation\ndistributions are investigated subject not only to standard boundary and\ninitial conditions, but also to prescribed dislocation density. In particular,\nthe dislocation density field can represent a single dislocation line.\n  It is only in the static and quasi-static traction boundary value problems\nthat such data are sufficient for the unique determination of stress. In other\nquasi-static boundary value problems and problems involving moving\ndislocations, the plastic and elastic distortion tensors, total displacement,\nand stress are in general non-unique for specified dislocation density. The\nconclusions are confirmed by the example of a single screw dislocation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a model for a Chern insulator on the square lattice with complex\nfirst and second neighbor hoppings and a sublattice potential which displays an\nunexpectedly rich physics. Similarly to the celebrated Haldane model, the\nproposed Chern insulator has two topologically non-trivial phases with Chern\nnumbers $\\pm1$. As a distinctive feature of the present model, phase\ntransitions are associated to Dirac points that can move, merge and split in\nmomentum space, at odds with Haldane's Chern insulator where Dirac points are\nbound to the corners of the hexagonal Brillouin zone. Additionally, the\nobtained phase diagram reveals a peculiar phase transition line between two\ndistinct topological phases, in contrast to the Haldane model where such\ntransition is reduced to a point with zero sublattice potential. The model is\namenable to be simulated in optical lattices, facilitating the study of phase\ntransitions between two distinct topological phases and the experimental\nanalysis of Dirac points merging and wandering.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It is well-known that the first-order phase transition (PT) will yield a\nstochastic gravitational waves (GWs) background with a logo-like spectrum.\nHowever, we show that when such a PT happened during the primordial inflation,\nthe GWs spectrum brought by the PT will be reddened, which thus records the\nunique voiceprint of inflation. We assess the abilities of the GW detectors to\ndetect the corresponding signal.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The hulls of linear and cyclic codes over finite fields have been of interest\nand extensively studied due to their wide applications. In this paper, the\nhulls of cyclic codes of length $n$ over the ring $\\mathbb{Z}_4$ have been\nfocused on. Their characterization has been established in terms of the\ngenerators viewed as ideals in the quotient ring $\\mathbb{Z}_4[x]/\\langle\nx^n-1\\rangle$. An algorithm for computing the types of the hulls of cyclic\ncodes of arbitrary odd length over $\\mathbb{Z}_4$ has been given. The average\n$2$-dimension $E(n)$ of the hulls of cyclic codes of odd length $n$ over\n$\\mathbb{Z}_4$ has been established. A general formula for $E(n)$ has been\nprovided together with its upper and lower bounds. It turns out that $E(n)$\ngrows the same rate as $n$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The geometric discord $\\mathcal{D}$ of a state is a measure of the\nquantumness of the state and the negativity $\\mathcal{N}$ is a measure of the\nentanglement of a state. It was proved by D. Girolami and G. Adesso that for\nstates on $\\mathbb{C}^2\\otimes\\mathbb{C}^2$, the geometric discord is always\ngreater than or equal to the square of the negativity and conjectured that this\nholds in general. S. Rana and P. Parashar showed that this relation does not\nhold for all states on $\\mathbb{C}^2\\otimes\\mathbb{C}^n$ for $n>2$. We provide\nseveral analytic families of states on $\\mathbb{C}^2\\otimes\\mathbb{C}^3$\nviolating this relation. Certain upper and lower bounds for\n$\\mathcal{N}^2-\\mathcal{D}$ are obtained for states on\n$\\mathbb{C}^m\\otimes\\mathbb{C}^n$ for any $m, n\\in\\mathbb{N}$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  MUSCAT is a large format mm-wave camera scheduled for installation on the\nLarge Millimeter Telescope Alfonso Serrano (LMT) in 2018. The MUSCAT focal\nplane is based on an array of horn coupled lumped-element kinetic inductance\ndetectors optimised for coupling to the 1.1mm atmospheric window. The detectors\nare fed with fully baffled reflective optics to minimize stray-light\ncontamination. This combination will enable background-limited performance at\n1.1 mm across the full 4 arcminute field-of-view of the LMT. The easily\naccessible focal plane will be cooled to 100 mK with a new closed cycle\nminiature dilution refrigerator that permits fully continuous operation. The\nMUSCAT instrument will demonstrate the science capabilities of the LMT through\ntwo relatively short science programmes to provide high resolution follow-up\nsurveys of Galactic and extra-galactic sources previously observed with the\nHerschel space observatory, after the initial observing campaigns. In this\npaper, we will provide an overview of the overall instrument design as well as\nan update on progress and scheduled installation on the LMT.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper addresses the existence and spectral stability of traveling fronts\nfor nonlinear hyperbolic equations with a positive \"damping\" term and a\nreaction function of bistable type. Particular cases of the former include the\nrelaxed Allen-Cahn equation and the nonlinear version of the telegrapher's\nequation with bistable reaction term. The existence theory of the fronts is\nrevisited, yielding useful properties such as exponential decay to the\nasymptotic rest states and a variational formula for the unique wave speed. The\nspectral problem associated to the linearized equation around the front is\nestablished. It is shown that the spectrum of the perturbation problem is\nstable, that is, it is located in the complex half plane with negative real\npart, with the exception of the eigenvalue zero associated to translation\ninvariance, which is isolated and simple. In this fashion, it is shown that\nthere exists an spectral gap precluding the accumulation of essential spectrum\nnear the origin. To show that the point spectrum is stable we introduce a\ntransformation of the eigenfunctions that allows to employ energy estimates in\nthe frequency regime. This method produces a new proof of equivalent results\nfor the relaxed Allen-Cahn case and extends the former to a wider class of\nequations. This result is a first step in a more general program pertaining to\nthe nonlinear stability of the fronts under small perturbations, a problem\nwhich remains open.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The newly reported exotic signal $Z_c(4100)$ by the LHCb Collaboration in the\ninvariant mass spectrum of $\\eta_c\\pi^-$ in $B^0\\to \\eta_c K^+ \\pi^-$ has been\na new experimental evidence for an exotic meson containing four constituent\nquarks. Although the present experimental information is very limited, we show\nthat its correlations with some existing exotic candidates can be recognized.\nThis signal can be either caused by final state interaction effects or a\n$P$-wave resonance state arising from the $D^*\\bar{D}^*$ interaction. For the\nlatter option its neutral partner will have exotic quantum numbers of\n$I^G(J^{PC})=1^-(1^{-+})$. This signal, if confirmed, would provide important\nclues for dynamics for producing multiquark systems in $B$ meson decays and\n$e^+e^-$ annihilations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Following hep-th/0412336 we use the non-linear realisation of the semi-direct\nproduct of E11 and its vector representation to construct brane dynamics. The\nbrane moves through a spacetime which arises in the non-linear realisation from\nthe vector representation and it contains the usual embedding coordinates as\nwell as the world volume fields. The resulting equations of motion are first\norder in derivatives and can be thought of as duality relations. Each brane\ncarries the full E11 symmetry and so the Cremmer-Julia duality symmetries. We\napply this theory to find the dynamics of the IIA and IIB strings, the M2 and\nM5 branes, the IIB D3 brane as well as the one and two branes in seven\ndimensions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  First-principles studies of strongly-interacting hadronic systems using\nlattice quantum chromodynamics (QCD) have been complemented in recent years\nwith the inclusion of quantum electrodynamics (QED). The aim is to confront\nexperimental results with more precise theoretical determinations, e.g. for the\nanomalous magnetic moment of the muon and the CP-violating parameters in the\ndecay of mesons. Quantifying the effects arising from enclosing QED in a finite\nvolume remains a primary target of investigations. To this end, finite-volume\ncorrections to hadron masses in the presence of QED have been carefully studied\nin recent years. This paper extends such studies to the self-energy of moving\ncharged hadrons, both on and away from their mass shell. In particular, we\npresent analytical results for leading finite-volume corrections to the\nself-energy of spin-0 and spin-$\\frac{1}{2}$ particles in the presence of QED\non a periodic hypercubic lattice, once the spatial zero mode of the photon is\nremoved, a framework that is called $\\mathrm{QED}_{\\mathrm{L}}$. By altering\nmodes beyond the zero mode, an improvement scheme is introduced to eliminate\nthe leading finite-volume corrections to masses, with potential applications to\nother hadronic quantities. Our analytical results are verified by a dedicated\nnumerical study of a lattice scalar field theory coupled to\n$\\mathrm{QED}_{\\mathrm{L}}$. Further, this paper offers new perspectives on the\nsubtleties involved in applying low-energy effective field theories in the\npresence of $\\mathrm{QED}_{\\mathrm{L}}$, a theory that is rendered non-local\nwith the exclusion of the spatial zero mode of the photon, clarifying recent\ndiscussions on this matter.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, we investigate the practice of patch construction in the Linux\nkernel development, focusing on the differences between three patching\nprocesses: (1) patches crafted entirely manually to fix bugs, (2) those that\nare derived from warnings of bug detection tools, and (3) those that are\nautomatically generated based on fix patterns. With this study, we provide to\nthe research community concrete insights on the practice of patching as well as\nhow the development community is currently embracing research and commercial\npatching tools to improve productivity in repair. The result of our study shows\nthat tool-supported patches are increasingly adopted by the developer community\nwhile manually-written patches are accepted more quickly. Patch application\ntools enable developers to remain committed to contributing patches to the code\nbase. Our findings also include that, in actual development processes, patches\ngenerally implement several change operations spread over the code, even for\npatches fixing warnings by bug detection tools. Finally, this study has shown\nthat there is an opportunity to directly leverage the output of bug detection\ntools to readily generate patches that are appropriate for fixing the problem,\nand that are consistent with manually-written patches.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The electronic states of many Mott insulators, including iridates, are often\nconceptualized in terms of localized atomic states such as the famous\n\"$J_\\text{eff}=1/2$ state\". Although, orbital hybridization can strongly modify\nsuch states and dramatically change the electronic properties of materials,\nprobing this process is highly challenging. In this work, we directly detect\nand quantify the formation of dimer orbitals in an iridate material\nBa$_5$AlIr$_2$O$_{11}$ using resonant inelastic x-ray scattering (RIXS). Sharp\npeaks corresponding to the excitations of dimer orbitals are observed and\nanalyzed by a combination of density functional theory (DFT) calculations and\ntheoretical simulations based on a Ir-Ir cluster model. Such partially\ndelocalized dimer states lead to a re-definition of the angular momentum of the\nelectrons and changes in the magnetic and electronic behaviors of the material.\nWe use this to explain the reduction of the observed magnetic moment with\nrespect to prediction based on atomic states. This study opens new directions\nto study dimerization in a large family of materials including solids,\nheterostructures, molecules and transient states.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A novel method of color image enhancement is proposed, in which three or four\ncolor channels of the image are transformed to one channel 2-D grayscale image.\nThis paper describes different models of such transformations in the RGB and\nother color models. Color image enhancement is achieved by enhancing first the\ntransformed grayscale image and, then, transforming back the grayscale image\ninto the colors. The color image enhancement is done on the transformed 2-D\ngrayscale image rather than on the color image. New algorithms of color image\nenhancement are described in both frequency and time domains. The enhancement\nby this novel method shows good results. The enhancement of the image is\nmeasured with respect to the metric referred to as the Color Enhancement\nMeasure Estimation (CEME).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The young A0V star HR 4796A is host to a bright and narrow ring of dust,\nthought to originate in collisions between planetesimals within a belt\nanalogous to the Solar System's Edgeworth-Kuiper belt. Here we present high\nspatial resolution 880$\\mu$m continuum images from the Atacama Large Millimeter\nArray. The 80au radius dust ring is resolved radially with a characteristic\nwidth of 10au, consistent with the narrow profile seen in scattered light. Our\nmodelling consistently finds that the disk is also vertically resolved with a\nsimilar extent. However, this extent is less than the beam size, and a disk\nthat is dynamically very cold (i.e. vertically thin) provides a better\ntheoretical explanation for the narrow scattered light profile, so we remain\ncautious about this conclusion. We do not detect $^{12}$CO J=3-2 emission,\nconcluding that unless the disk is dynamically cold the CO+CO$_2$ ice content\nof the planetesimals is of order a few percent or less. We consider the range\nof semi-major axes and masses of an interior planet supposed to cause the\nring's eccentricity, finding that such a planet should be more massive than\nNeptune and orbit beyond 40au. Independent of our ALMA observations, we note a\nconflict between mid-IR pericenter-glow and scattered light imaging\ninterpretations, concluding that models where the spatial dust density and\ngrain size vary around the ring should be explored.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A simple but successful strategy for building a discrete diffusion operator\nin finite volume schemes of industrial use is to correct the standard two-point\nflux approximation with a term accounting for the local mesh non-orthogonality.\nPractical experience with a variety of different mesh typologies, including\nnon-orthogonal tetrahedral, hexahedral and polyhedral meshes, has shown that\nthis discrete diffusion operator is accurate and robust whenever the mesh is\nnot too distorted and sufficiently regular. In this work, we show that this\napproach can be interpreted as equivalent to introducing an anisotropic\noperator that accounts for the preferential directions induced by the local\nmesh non-orthogonality. This allows to derive a convergence analysis of the\ncorrected method under a quite weak global assumption on mesh distortion. This\nconvergence proof, which is obtained for the first time for this finite volume\nmethod widely employed in industrial software packages such as OpenFOAM,\nprovides a reference framework on how to interpret some of its variants\ncommonly implemented in commercial finite volume codes. Numerical experiments\nare presented that confirm the accuracy and robustness of the results.\nFurthermore, we also show empirically that a least square approach to the\ngradient computation can provide second order convergence even when the mild\nnon-orthogonality condition on the mesh is violated.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the validity of a \\emph{minimal} cosmological model derived\nfrom the renormalizable Ho$\\check{\\textrm{r}}$ava action at low redshift scales\nby using different cosmological and statistical tests. Assuming pure attractive\ngravity, i.e., $\\lambda>1/3$ in the Ho$\\check{\\textrm{r}}$ava action, we\ncompare the Union 2.1 supernova type Ia data with the kinematics following from\na model-independent approach. The two approaches, although compatible, lead to\nexplicit cosmographic constraints on the free parameters of the\nHo$\\check{\\textrm{r}}$ava action, which turn out to be in strong disagreement\nwith the $\\Lambda$CDM, $w$CDM and Chevallier-Polarski-Linder scenarios. To show\nthis, we use standard diagnostic tools of regression models, namely the Akaike\nand the Bayesian Information Criteria. Using such model-independent statistical\nmethods, we show that Ho$\\check{\\textrm{r}}$ava-Lifshitz cosmology differs from\nthe standard dark energy scenarios, \\emph{independently} of the number of free\nparameters involved in the model. Since this result is valid at small redshift\ndomains, it indicates the presence of inconsistencies in the minimal version of\nHo$\\check{\\textrm{r}}$ava-Lifshitz cosmology even at the level of background\ncosmology.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report spin-split Landau levels of quasi-two-dimensional Dirac fermions in\na layered antiferromagnet EuMnBi$_2$, as revealed by interlayer resistivity\nmeasurements in a tilted magnetic field up to $\\sim$35 T. The amplitude of\nShubnikov-de Haas (SdH) oscillation in interlayer resistivity is strongly\nmodulated by changing the tilt angle of the field, i.e., the\nZeeman-to-cyclotron energy ratio. The effective $g$ factor estimated from the\ntilt angle, where the SdH oscillation exhibits a phase inversion, differs by\napproximately 50% between two antiferromagnetic phases. This observation\nsignifies a marked impact of the magnetic order of Eu sublattice on the\nDirac-like band structure. The origin may be sought in strong exchange coupling\nwith the local Eu moments, as verified by the first-principles calculation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a method and application for animating a human subject from a\nsingle photo. E.g., the character can walk out, run, sit, or jump in 3D. The\nkey contributions of this paper are: 1) an application of viewing and animating\nhumans in single photos in 3D, 2) a novel 2D warping method to deform a posable\ntemplate body model to fit the person's complex silhouette to create an\nanimatable mesh, and 3) a method for handling partial self occlusions. We\ncompare to state-of-the-art related methods and evaluate results with human\nstudies. Further, we present an interactive interface that allows re-posing the\nperson in 3D, and an augmented reality setup where the animated 3D person can\nemerge from the photo into the real world. We demonstrate the method on photos,\nposters, and art.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It is safe to assume that, for the foreseeable future, machine learning,\nespecially deep learning will remain both data- and computation-hungry. In this\npaper, we ask: Can we build a global exchange where everyone can contribute\ncomputation and data to train the next generation of machine learning\napplications?\n  We present an early, but running prototype of DataBright, a system that turns\nthe creation of training examples and the sharing of computation into an\ninvestment mechanism. Unlike most crowdsourcing platforms, where the\ncontributor gets paid when they submit their data, DataBright pays dividends\nwhenever a contributor's data or hardware is used by someone to train a machine\nlearning model. The contributor becomes a shareholder in the dataset they\ncreated. To enable the measurement of usage, a computation platform that\ncontributors can trust is also necessary. DataBright thus merges both a data\nmarket and a trusted computation market.\n  We illustrate that trusted computation can enable the creation of an AI\nmarket, where each data point has an exact value that should be paid to its\ncreator. DataBright allows data creators to retain ownership of their\ncontribution and attaches to it a measurable value. The value of the data is\ngiven by its utility in subsequent distributed computation done on the\nDataBright computation market. The computation market allocates tasks and\nsubsequent payments to pooled hardware. This leads to the creation of a\ndecentralized AI cloud. Our experiments show that trusted hardware such as\nIntel SGX can be added to the usual ML pipeline with no additional costs. We\nuse this setting to orchestrate distributed computation that enables the\ncreation of a computation market. DataBright is available for download at\nhttps://github.com/ds3lab/databright.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present Unit-B, a formal method inspired by Event-B and UNITY. Unit-B aims\nat the stepwise design of software systems satisfying safety and liveness\nproperties. The method features the novel notion of coarse and fine schedules,\na generalisation of weak and strong fairness for specifying events' scheduling\nassumptions. Based on events schedules, we propose proof rules to reason about\nprogress properties and a refinement order preserving both liveness and safety\nproperties. We illustrate our approach by an example to show that systems\ndevelopment can be driven by not only safety but also liveness requirements.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we perform a detail analysis on the phenomenology of $Z'$\nportal scalar and Dirac fermion dark matter in $B-L$ scotogenic Dirac model.\nUnconventional $B-L$ charge $Q$ is assigned to the right-handed neutrino\n$\\nu_R$ in order to realise scotogenic Dirac neutrino mass at one-loop level,\nwhere three typical value $Q=-\\frac{1}{4},-4,\\frac{3}{2}$ are chosen to\nillustrate. Observational properties involving dilepton signature at LHC,\nrelativistic degrees of freedom $N_\\text{eff}$, dark matter relic density,\ndirect and indirect detections are comprehensively studied. Combined results of\nthese observables for the benchmark scenarios imply that the resonance region\n$M_\\text{DM}\\sim M_{Z'}/2$ is the viable parameter space. Focusing on the\nresonance region, a scanning for TeV-scale dark matter is also performed to\nobtain current allowed and future prospective parameter space.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $A\\in \\mathcal{B}(X)$ and $B\\in \\mathcal{B}(Y)$, where $X$ and $Y$ are\nBanach spaces, and let $M_{C}$ be an operator acting on $X\\oplus Y$ given by\n$M_C=\\begin{pmatrix} A & C \\\\ 0 & B \\\\ \\end{pmatrix}$. We investigate the limit\npoint set of the Browder spectrum of $M_{C}$. It is shown that\n  $$ acc \\sigma_{b}(M_C)\\cup W_{acc \\sigma_{b}}= acc \\sigma_{b}(A)\\cup acc\n\\sigma_{b}(B)$$ where $W_{acc \\sigma_{b}}$ is a subsets of $\nacc\\sigma_{*}(B)\\cap acc\\sigma_{*}(A)$ and a union of certain holes in $ acc\n\\sigma_{b}(M_C)$. Furthermore, several sufficient conditions for\n$acc\\sigma_{b}(M_C)=acc\\sigma_{b}(A)\\cup acc\\sigma_{b}(B)$ holds for every\n$C\\in \\mathcal{B}(Y,X)$ are given.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The computation of the diameter is one of the most central problems in\ndistributed computation. In the standard CONGEST model, in which two adjacent\nnodes can exchange $O(\\log n)$ bits per round (here $n$ denotes the number of\nnodes of the network), it is known that exact computation of the diameter\nrequires $\\tilde \\Omega(n)$ rounds, even in networks with constant diameter. In\nthis paper we investigate quantum distributed algorithms for this problem in\nthe quantum CONGEST model, where two adjacent nodes can exchange $O(\\log n)$\nquantum bits per round. Our main result is a $\\tilde O(\\sqrt{nD})$-round\nquantum distributed algorithm for exact diameter computation, where $D$ denotes\nthe diameter. This shows a separation between the computational power of\nquantum and classical algorithms in the CONGEST model. We also show an\nunconditional lower bound $\\tilde \\Omega(\\sqrt{n})$ on the round complexity of\nany quantum algorithm computing the diameter, and furthermore show a tight\nlower bound $\\tilde \\Omega(\\sqrt{nD})$ for any distributed quantum algorithm in\nwhich each node can use only $\\textrm{poly}(\\log n)$ quantum bits of memory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider approximation of vectors $\\mathbf{z}\\in\nF\\otimes\\mathbb{R}\\cong\\mathbb{R}^r\\times\\mathbb{C}^s$ by elements of a number\nfield $F$ and construct examples of badly approximable vectors. These examples\ncome from compact subspaces of $SL_2(\\mathcal{O}_F)\\backslash\nSL_2(F\\otimes\\mathbb{R})$ naturally associated to (totally indefinite,\nanisotropic) $F$-rational binary quadratic and Hermitian forms, a\ngeneralization of the well-known fact that quadratic irrationals are badly\napproximable over $\\mathbb{Q}$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We establish a stability result for elliptic and parabolic complex\nMonge-Amp{\\`e}re equations on compact K{\\\"a}hler manifolds, which applies in\nparticular to the K{\\\"a}hler-Ricci flow. Dedicated to Jean-Pierre Demailly on\nthe occasion of his 60th birthday.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Among the various geometries to study the fractional quantum Hall effect in\ntwo dimensional electron gas, the Corbino disc owns the advantage to probe the\nbulk properties directly. In this work we explore the influence of in-plane\nelectric fields on the stability of the 5/2 fractional quantum Hall state\nrealized in Corbino geometry. The effect of weak electric fields is\ninvestigated at ultra-low temperatures in order to compare with a theoretical\nproposal of enhanced Pfaffian state under weak electric fields.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Quantum error-correcting codes can be used to protect qubits involved in\nquantum computation. This requires that logical operators acting on protected\nqubits be translated to physical operators (circuits) acting on physical\nquantum states. We propose a mathematical framework for synthesizing physical\ncircuits that implement logical Clifford operators for stabilizer codes.\nCircuit synthesis is enabled by representing the desired physical Clifford\noperator in $\\mathbb{C}^{N \\times N}$ as a partial $2m \\times 2m$ binary\nsymplectic matrix, where $N = 2^m$. We state and prove two theorems that use\nsymplectic transvections to efficiently enumerate all symplectic matrices that\nsatisfy a system of linear equations. As an important corollary of these\nresults, we prove that for an $[\\![ m,m-k ]\\!]$ stabilizer code every logical\nClifford operator has $2^{k(k+1)/2}$ symplectic solutions. The desired physical\ncircuits are then obtained by decomposing each solution as a product of\nelementary symplectic matrices. Our assembly of the possible physical\nrealizations enables optimization over them with respect to a suitable metric.\nFurthermore, we show that any circuit that normalizes the stabilizer of the\ncode can be transformed into a circuit that centralizes the stabilizer, while\nrealizing the same logical operation. Our method of circuit synthesis can be\napplied to any stabilizer code, and this paper provides a proof of concept\nsynthesis of universal Clifford gates for the $[\\![ 6,4,2 ]\\!]$ CSS code. We\nconclude with a classical coding-theoretic perspective for constructing logical\nPauli operators for CSS codes. Since our circuit synthesis algorithm builds on\nthe logical Pauli operators for the code, this paper provides a complete\nframework for constructing all logical Clifford operators for CSS codes.\nPrograms implementing our algorithms can be found at\nhttps://github.com/nrenga/symplectic-arxiv18a\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Coding Opportunistically (COPE) is a simple but very effective data coding\nmechanism in the wireless network. However, COPE leaves risks for attackers\neasily getting the private information saved in the packets, when they move\nthrough the network to their destination nodes. Hence in our work, a\nlightweight cryptographic approach, namely SCOPE, is proposed to consolidate\nCOPE against the honest-but-curious and malicious attacks. Honest-but-curious\nattack serves adversaries who accurately obey the protocol but try to learn as\nmuch private information as possible for their curiosity. Additionally, this\nkind of attack is not destructive consequently. However, it may leave the\nbackdoor for the more dangerous attacks carrying catastrophes to the system.\nMalicious attack tries to learn not only the private information but also\nmodifies the packet on harmful purposes. In our work, the SCOPE protocol is\ndefensive to the both attacks. The private information in the COPE packet are\nencrypted by Elliptic Curve Cryptography (ECC), and an additional information\nis inserted into SCOPE packets served for the authentication process using the\nlightweight hash Elliptic Curve Digital Signature Algorithm (ECDSA). We then\nprove our new protocol is still guaranteed to be a secure method of data\ncoding, and to be light to effectively operate in the peer-to-peer wireless\nnetwork\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This article presents for the first time a global method for registering 3D\ncurves with 3D surfaces without requiring an initialization. The algorithm\nworks with 2-tuples point+vector that consist in pairs of points augmented with\nthe information of their tangents or normals. A closed-form solution for\ndetermining the alignment transformation from a pair of matching 2-tuples is\nproposed. In addition, the set of necessary conditions for two 2-tuples to\nmatch is derived. This allows fast search of correspondences that are used in\nan hypothesise-and-test framework for accomplishing global registration.\nComparative experiments demonstrate that the proposed algorithm is the first\neffective solution for curve vs surface registration, with the method achieving\naccurate alignment in situations of small overlap and large percentage of\noutliers in a fraction of a second. The proposed framework is extended to the\ncases of curve vs curve and surface vs surface registration, with the former\nbeing particularly relevant since it is also a largely unsolved problem.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Universal Dependencies (UD) and Universal Morphology (UniMorph) projects\neach present schemata for annotating the morphosyntactic details of language.\nEach project also provides corpora of annotated text in many languages - UD at\nthe token level and UniMorph at the type level. As each corpus is built by\ndifferent annotators, language-specific decisions hinder the goal of universal\nschemata. With compatibility of tags, each project's annotations could be used\nto validate the other's. Additionally, the availability of both type- and\ntoken-level resources would be a boon to tasks such as parsing and homograph\ndisambiguation. To ease this interoperability, we present a deterministic\nmapping from Universal Dependencies v2 features into the UniMorph schema. We\nvalidate our approach by lookup in the UniMorph corpora and find a\nmacro-average of 64.13% recall. We also note incompatibilities due to paucity\nof data on either side. Finally, we present a critical evaluation of the\nfoundations, strengths, and weaknesses of the two annotation projects.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Graphene is an excellent material for Hall sensors due to its atomically thin\nstructure, high carrier mobility and low carrier density. However, graphene\ndevices need to be protected from the environment for reliable and durable\nperformance in different environmental conditions. Here we present magnetic\nHall sensors fabricated on large area commercially available CVD graphene\nprotected by exfoliated hexagonal boron nitride (h-BN). To connect the graphene\nactive regions of Hall samples to the outputs the 1D edge contacts were\nutilized which show reliable and stable electrical properties. The operation of\nthe Hall sensors shows the current-related sensitivity up to 345 V/(AT). By\nchanging the carrier concentration and type in graphene by the application of\ngate voltage we are able to tune the Hall sensitivity.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We examine the efficacy of the halo mass function as a probe of $f(R)$,\nsymmetron and DGP gravity. We develop an excursion-set method to generalise a\nrange of popular HMF fitting functions from GR to screened MG, considering the\nHMF dependence on the critical density parameter $\\delta_{c}$. In particular,\nwe propose a variety of new methods to account for the environmental dependence\nof chameleon screening and compare their accuracy to existing ones via $N$-body\ndata. Finally, using the nested sampling routine MultiNest, we examine two\npossible interpretations of the MG $N$-body results: whether they can be\ninterpreted as $\\Lambda$CDM HMFs and whether the MG HMFs display any\nuniversality.\n  We find that the effects of MG can be interpreted as a change in best-fit\nparameters in the $\\Lambda$CDM HMF---i.e. can be mistaken for GR---for all of\nthe fitting functions. Alternatively, the relation can be inverted to judge the\nuniversality of the HMF---not in terms of its purported invariance to $z$,\n$H_{0}$, $\\Omega_{m}$, $\\Omega_{\\Lambda}$ as in GR, but its independence on the\nunderlying theory of gravity. Although we found no completely universal HMF,\nthe parameter values did cluster according to the type of screening mechanism.\nThe results suggest that a single, best-fit HMF might be used for each type of\nscreening, independent of the parameters in the MG model. This demonstrates\nthat the additional complexity of the gravitational collapse in screened MG\ntheories cannot always be accounted for using the techniques developed in GR.\nHowever, the variations are small enough that it is unnecessary to develop new\nfitting functions and calibrate them on a case-by-case basis.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigated the precursor wave emission efficiency in magnetized purely\nperpendicular relativistic shocks in pair plasmas. We extended our previous\nstudy to include the dependence of upstream magnetic field orientations. We\nperformed two-dimensional particle-in-cell simulations and focused on two\nmagnetic field orientations: the magnetic field to be in the simulation plane\n(i.e., in-plane configuration) and perpendicular to the simulation plane (i.e.,\nout-of-plane configuration). Our simulations in the in-plane configuration\ndemonstrated that not only extraordinary but also ordinary mode waves are\nexcited. We quantified the emission efficiency as a function of the\nmagnetization parameter $\\sigma_e$ and found that the large-amplitude precursor\nwaves are emitted for a wide range of $\\sigma_e$. We found that especially at\nlow $\\sigma_e$, the magnetic field generated by Weibel instability amplifies\nthe ordinary mode wave power. The amplitude is large enough to perturb the\nupstream plasma, and transverse density filaments are generated as in the case\nof the out-of-plane configuration investigated in the previous study. We\nconfirmed that our previous conclusion holds regardless of upstream magnetic\nfield orientations with respect to the two-dimensional simulation plane. We\ndiscuss the precursor wave emission in three dimensions and the feasibility of\nwakefield acceleration in relativistic shocks based on our results.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Shannon's entropy is a clear lower bound for statistical compression. The\nsituation is not so well understood for dictionary-based compression. A\nplausible lower bound is $b$, the least number of phrases of a general\nbidirectional parse of a text, where phrases can be copied from anywhere else\nin the text. Since computing $b$ is NP-complete, a popular gold standard is\n$z$, the number of phrases in the Lempel-Ziv parse of the text, which is the\noptimal one when phrases can be copied only from the left. While $z$ can be\ncomputed in linear time with a greedy algorithm, almost nothing has been known\nfor decades about its approximation ratio with respect to $b$. In this paper we\nprove that $z=O(b\\log(n/b))$, where $n$ is the text length. We also show that\nthe bound is tight as a function of $n$, by exhibiting a text family where $z =\n\\Omega(b\\log n)$. Our upper bound is obtained by building a run-length\ncontext-free grammar based on a locally consistent parsing of the text. Our\nlower bound is obtained by relating $b$ with $r$, the number of equal-letter\nruns in the Burrows-Wheeler transform of the text. We proceed by observing that\nLempel-Ziv is just one particular case of greedy parses, meaning that the\noptimal value of $z$ is obtained by scanning the text and maximizing the phrase\nlength at each step, and of ordered parses, meaning that there is an increasing\norder between phrases and their sources. As a new example of ordered greedy\nparses, we introduce {\\em lexicographical} parses, where phrases can only be\ncopied from lexicographically smaller text locations. We prove that the size\n$v$ of the optimal lexicographical parse is also obtained greedily in $O(n)$\ntime, that $v=O(b\\log(n/b))$, and that there exists a text family where $v =\n\\Omega(b\\log n)$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider nearly K\\\"ahler 6-manifolds with effective 2-torus symmetry. The\nmulti-moment map for the $T^2$-action becomes an eigenfunction of the Laplace\noperator. At regular values, we prove the $T^2$-action is necessarily free on\nthe level sets and determines the geometry of three-dimensional quotients. An\ninverse construction is given locally producing nearly K\\\"ahler six-manifolds\nfrom three-dimensional data. This is illustrated for structures on the\nHeisenberg group.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Environment-assisted quantum transport (ENAQT) is the possibility of an\nexternal environment to enhance transport efficiency of quantum particles. This\nidea has generated much excitement over recent years, especially due to the\nexperimentally-motivated possibility of ENAQT in photo-synthetic exciton\ntransfer complexes. Many theoretical calculations have shown ENAQT, but the\nexplanations for its origin differ, and a universal explanation has been\nelusive. Here we demonstrate a universal origin for ENAQT in quantum networks\nwith a dephasing environment, based on a relation between exciton current and\noccupation within a Markovian open quantum system approach. We show that ENAQT\nappears due to two competing processes, namely the tendency of dephasing to\nmake the exciton population uniform, and the formation of an exciton density\ngradient, defined by the source and the sink. Furthermore, we find a geometric\ncondition on the network for the appearance of ENAQT, relevant to natural and\nartificial systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study how quantum states are scrambled via braiding in systems of\nnon-Abelian anyons through the lens of entanglement spectrum statistics. In\nparticular, we focus on the degree of scrambling, defined as the randomness\nproduced by braiding, at the same amount of entanglement entropy. To quantify\nthe degree of randomness, we define a distance between the entanglement\nspectrum level spacing distribution of a state evolved under random braids and\nthat of a Haar-random state, using the Kullback-Leibler divergence\n$D_{\\mathrm{KL}}$. We study $D_{\\mathrm{KL}}$ numerically for random braids of\nMajorana fermions (supplemented with random local four-body interactions) and\nFibonacci anyons. For comparison, we also obtain $D_{\\mathrm{KL}}$ for the\nSachdev-Ye-Kitaev model of Majorana fermions with all-to-all interactions,\nrandom unitary circuits built out of (a) Hadamard (H), $\\pi/8$ (T), and CNOT\ngates, and (b) random unitary circuits built out of two-qubit Haar-random\nunitaries. To compare the degree of randomness that different systems produce\nbeyond entanglement entropy, we look at $D_{\\mathrm{KL}}$ as a function of the\nPage limit-normalized entanglement entropy $S/S_{\\mathrm{max}}$. Our results\nreveal a hierarchy of scrambling among various models --- even for the same\namount of entanglement entropy --- at intermediate times, whereas all models\nexhibit the same late-time behavior. In particular, we find that braiding of\nFibonacci anyons randomizes initial product states more efficiently than the\nuniversal H+T+CNOT set.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Accurate line lists for the carbon dimer, C$_2$, are presented. These line\nlists cover rovibronic transitions between the eight lowest electronic states:\n$X\\,{}^{1}\\Sigma_{g}^{+}$, $a\\,{}^{3}\\Pi_{u}$, $A\\,{}^{1}\\Pi_{u}$,\n$b\\,^{3}\\Sigma_{g}^{-}$, $b\\,^{3}\\Sigma_{g}^{-}$, $c\\,^{3}\\Sigma_{u}^{+}$,\n$d\\,{}^{3}\\Pi_{g}$, $B\\,{}^{1}\\Delta_{g}$, $B^\\prime\\,{}^{1}\\Sigma_{g}^{+}$.\nPotential energy curves (PECs) and transition dipole moment curves are computed\non a large grid of geometries using the aug-cc-pwCVQZ-DK/MRCI level of theory\nincluding core and core-valence correlations and scalar relativistic energy\ncorrections. The same level of theory is used to compute spin-orbit and\nelectronic angular momentum couplings. The PECs and couplings are refined by\nfitting to the empirical (MARVEL) energies of $^{12}$C$_2$ using the\nnuclear-motion program Duo. The transition dipole moment curves are represented\nas analytical functions to reduce the numerical noise when computing transition\nline strengths. Partition functions, full line lists, Land\\'{e}-factors and\nlifetimes for three main isotopologues of C$_2$ ($^{12}$C$_2$,$^{13}$C$_2$ and\n$^{12}$C$^{13}$C) are made available in electronic form from the CDS\n(http://cdsarc.u-strasbg.fr) and ExoMol (www.exomol.com) databases.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Fourier Transform Interferometry (FTI) is an interferometric procedure for\nacquiring HyperSpectral (HS) data. Recently, it has been observed that the\nlight source highlighting a (biologic) sample can be coded before the FTI\nacquisition in a procedure called Coded Illumination-FTI (CI-FTI). This turns\nHS data reconstruction into a Compressive Sensing (CS) problem regularized by\nthe sparsity of the HS data. CI-FTI combines the high spectral resolution of\nFTI with the advantages of reduced-light-exposure imaging in biology.\n  In this paper, we leverage multilevel sampling scheme recently developed in\nCS theory to adapt the coding strategy of CI-FTI to the spectral sparsity\nstructure of HS data in Fluorescence Spectroscopy (FS). This structure is\nactually extracted from the spectral signatures of actual fluorescent dyes used\nin FS. Accordingly, the optimum illumination coding as well as the theoretical\nrecovery guarantee are derived. We conduct numerous numerical experiments on\nsynthetic and experimental data that show the faithfulness of the proposed\ntheory to experimental observations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Detecting and localizing objects in the real 3D space, which plays a crucial\nrole in scene understanding, is particularly challenging given only a single\nRGB image due to the geometric information loss during imagery projection. We\npropose MonoGRNet for the amodal 3D object detection from a monocular RGB image\nvia geometric reasoning in both the observed 2D projection and the unobserved\ndepth dimension. MonoGRNet is a single, unified network composed of four\ntask-specific subnetworks, responsible for 2D object detection, instance depth\nestimation (IDE), 3D localization and local corner regression. Unlike the\npixel-level depth estimation that needs per-pixel annotations, we propose a\nnovel IDE method that directly predicts the depth of the targeting 3D bounding\nbox's center using sparse supervision. The 3D localization is further achieved\nby estimating the position in the horizontal and vertical dimensions. Finally,\nMonoGRNet is jointly learned by optimizing the locations and poses of the 3D\nbounding boxes in the global context. We demonstrate that MonoGRNet achieves\nstate-of-the-art performance on challenging datasets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In the design of materials with low lattice thermal conductivity, compounds\nwith high density, low speed of sound, and complexity at either the atomic,\nnano- or microstructural level are preferred. The layered compound Mg$_3$Sb$_2$\ndefies these prevailing paradigms, exhibiting lattice thermal conductivity\ncomparable to PbTe and Bi$_2$Te$_3$, despite its low density and simple\nstructure. The excellent thermoelectric performance ($zT$ $\\sim$ 1.5) in\n$n$-type Mg$_3$Sb$_2$ has thus far been attributed to its multi-valley\nconduction band, while its anomalous thermal properties have been largely\noverlooked. To explain the origin of the low lattice thermal conductivity of\nMg$_3$Sb$_2$, we have used both experimental methods and ab initio phonon\ncalculations to investigate trends in the elasticity, thermal expansion and\nanharmonicity of $A$Mg$_2Pn_2$ Zintl compounds with $A$ = Mg, Ca, Yb, and $Pn$\n= Sb and Bi. Phonon calculations within the quasi-harmonic approximation reveal\nlarge mode Gr\\\"uneisen parameters in Mg$_3$Sb$_2$ compared with isostructural\ncompounds, in particular in transverse acoustic modes involving shearing of\nadjacent anionic layers. Measurements of the elastic moduli and sound velocity\nas a function of temperature using resonant ultrasound spectroscopy provide a\nwindow into the softening of the acoustic branches at high temperature,\nconfirming their exceptionally high anharmonicity. We attribute the anomalous\nthermal behavior of Mg$_3$Sb$_2$ to the diminutive size of Mg, which may be too\nsmall for the octahedrally-coordinated site, leading to weak, unstable\ninterlayer Mg-Sb bonding. This suggests more broadly that soft shear modes\nresulting from undersized cations provide a potential route to achieving low\nlattice thermal conductivity low-density, earth-abundant materials.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we train independent linear decoder models to estimate the\nperceived quality of images. More specifically, we calculate the responses of\nindividual non-overlapping image patches to each of the decoders and scale\nthese responses based on the sharpness characteristics of filter set. We use\nmultiple linear decoders to capture different abstraction levels of the image\npatches. Training each model is carried out on 100,000 image patches from the\nImageNet database in an unsupervised fashion. Color space selection and ZCA\nWhitening are performed over these patches to enhance the descriptiveness of\nthe data. The proposed quality estimator is tested on the LIVE and the TID 2013\nimage quality assessment databases. Performance of the proposed method is\ncompared against eleven other state of the art methods in terms of accuracy,\nconsistency, linearity, and monotonic behavior. Based on experimental results,\nthe proposed method is generally among the top performing quality estimators in\nall categories.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we rederive an old upper bound on the number of halving edges\npresent in the halving graph of an arbitrary set of $n$ points in 2-dimensions\nwhich are placed in general position. We provide a different analysis of an\nidentity discovered by Andrejak et al, to rederive this upper bound of\n$O(n^{4/3})$. In the original paper of Andrejak et al. the proof is based on a\nnaive analysis whereas in this paper we obtain the same upper bound by\ntightening the analysis thereby opening a new door to derive these upper bounds\nusing the identity. Our analysis is based on a result of Cardano for finding\nthe roots of a cubic equation. We believe that our technique has the potential\nto derive improved bounds on the number of halving edges.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Results of a search for individual impulsive signals on the Large Scanning\nAntenna of the Lebedev Physical Institute at 111 MHz carried out from July 2012\nthrough May 2018 are presented. The data were convolved with a template of a\nspecified form and convolved with a test dispersion measure. A region of sky\nwith central coordinates $\\alpha = 05^h 32^m;$ $\\delta = +41.72^\\circ$ and also\na region of sky around the coordinates fixed earlier for FRB 121102 ($\\alpha =\n05^h 32^m;$ $\\delta = +33.1^\\circ$) were chosen for the analysis. In all, 355\nhours of observations were processed for each beam. Three radio bursts with\ndispersion measures of $247$ $pc \\cdot cm^{-3}$, $570$ $ pc \\cdot cm^{-3}$,\n$1767$ $ pc \\cdot cm^{-3}$ were detected in the course of reducing the data.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this article, we study microscopic properties of a two-dimensional\neigenvalue ensemble near a conical singularity arising from insertion of a\npoint charge in the bulk of the support of eigenvalues. In particular, we\ncharacterize all rotationally symmetric scaling limits ('Mittag-Leffler\nfields') and obtain universality of them when the underlying potential is\nalgebraic. Applications include a result on the asymptotic distribution of\n$\\log|p_n(\\zeta)|$ where $p_n$ is the characteristic polynomial of an $n$:th\norder random normal matrix.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Mobile phones can record individual's daily behavioral data as a time-series.\nIn this paper, we present an effective time-series segmentation technique that\nextracts optimal time segments of individual's similar behavioral\ncharacteristics utilizing their mobile phone data. One of the determinants of\nan individual's behavior is the various activities undertaken at various\ntimes-of-the-day and days-of-the-week. In many cases, such behavior will follow\ntemporal patterns. Currently, researchers use either equal or unequal\ninterval-based segmentation of time for mining mobile phone users' behavior.\nMost of them take into account static temporal coverage of 24-h-a-day and few\nof them take into account the number of incidences in time-series data.\nHowever, such segmentations do not necessarily map to the patterns of\nindividual user activity and subsequent behavior because of not taking into\naccount the diverse behaviors of individuals over time-of-the-week. Therefore,\nwe propose a behavior-oriented time segmentation (BOTS) technique that takes\ninto account not only the temporal coverage of the week but also the number of\nincidences of diverse behaviors dynamically for producing similar behavioral\ntime segments over the week utilizing time-series data. Experiments on the real\nmobile phone datasets show that our proposed segmentation technique better\ncaptures the user's dominant behavior at various times-of-the-day and\ndays-of-the-week enabling the generation of high confidence temporal rules in\norder to mine individual mobile phone users' behavior.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Automatic recognition of human activities from time-series sensor data\n(referred to as HAR) is a growing area of research in ubiquitous computing.\nMost recent research in the field adopts supervised deep learning paradigms to\nautomate extraction of intrinsic features from raw signal inputs and addresses\nHAR as a multi-class classification problem where detecting a single activity\nclass within the duration of a sensory data segment suffices. However, due to\nthe innate diversity of human activities and their corresponding duration, no\ndata segment is guaranteed to contain sensor recordings of a single activity\ntype. In this paper, we express HAR more naturally as a set prediction problem\nwhere the predictions are sets of ongoing activity elements with unfixed and\nunknown cardinality. For the first time, we address this problem by presenting\na novel HAR approach that learns to output activity sets using deep neural\nnetworks. Moreover, motivated by the limited availability of annotated HAR\ndatasets as well as the unfortunate immaturity of existing unsupervised\nsystems, we complement our supervised set learning scheme with a prior\nunsupervised feature learning process that adopts convolutional auto-encoders\nto exploit unlabeled data. The empirical experiments on two widely adopted HAR\ndatasets demonstrate the substantial improvement of our proposed methodology\nover the baseline models.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Memristors, resistors with memory whose outputs depend on the history of\ntheir inputs, have been used with success in neuromorphic architectures,\nparticularly as synapses and non-volatile memories. However, to the best of our\nknowledge, no model for a network in which both the synapses and the neurons\nare implemented using memristors has been proposed so far. In the present work\nwe introduce models for single and multilayer perceptrons based exclusively on\nmemristors. We adapt the delta rule to the memristor-based single-layer\nperceptron and the backpropagation algorithm to the memristor-based multilayer\nperceptron. Our results show that both perform as expected for perceptrons,\nincluding satisfying Minsky-Papert's theorem. As a consequence of the Universal\nApproximation Theorem, they also show that memristors are universal function\napproximators. By using memristors for both the neurons and the synapses, our\nmodels pave the way for novel memristor-based neural network architectures and\nalgorithms. A neural network based on memristors could show advantages in terms\nof energy conservation and open up possibilities for other learning systems to\nbe adapted to a memristor-based paradigm, both in the classical and quantum\nlearning realms.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper introduces the KineCluE code that implements the self-consistent\nmean-field theory for clusters of finite size. Transport coefficients are\nobtained as a sum over cluster contributions (in a cluster expansion\nformalism), each being individually computed with KineCluE. This method allows\nfor the calculation of these coefficients beyond the infinitely dilute limit,\nand is an important step in bridging the gap between dilute and concentrated\napproaches. Inside a finite volume of space containing the components of a\ngiven cluster, all kinetic trajectories are accounted for in an exact manner.\nThe code, written in Python, adapts to a wide variety of systems, with various\ncrystallographic structures (possibly under strain), defects and solute amount\nand types, and various jump mechanisms, including collective ones. The code\nalso features a set of useful tools, such as the sensitivity study routine that\nallows for the identification of the most important jump frequencies to get\naccurate transport coefficients with minimum computational cost.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Astronomical observations of extended sources, such as cubes of integral\nfield spectroscopy (IFS), encode auto-correlated spatial structures that cannot\nbe optimally exploited by standard methodologies. This work introduces a novel\ntechnique to model IFS datasets, which treats the observed galaxy properties as\nrealizations of an unobserved Gaussian Markov random field. The method is\ncomputationally efficient, resilient to the presence of low-signal-to-noise\nregions, and uses an alternative to Markov Chain Monte Carlo for fast Bayesian\ninference, the Integrated Nested Laplace Approximation (INLA). As a case study,\nwe analyse 721 IFS data cubes of nearby galaxies from the CALIFA and PISCO\nsurveys, for which we retrieve the maps of the following physical properties:\nage, metallicity, mass and extinction. The proposed Bayesian approach, built on\na generative representation of the galaxy properties, enables the creation of\nsynthetic images, recovery of areas with bad pixels, and an increased power to\ndetect structures in datasets subject to substantial noise and/or sparsity of\nsampling. A snippet code to reproduce the analysis of this paper is available\nin the COIN toolbox, together with the field reconstructions of the CALIFA and\nPISCO samples.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We construct a counterexample to a well-known extension theorem for slice\nregular functions, which motivates us to develop a theory of Riemann\nslice-domains by introducing a new topology on quaternions. By some paths\ndescribing axial symmetry in Riemann slice-domains, we rectify the classical\nextension formula in the theory of slice regular functions and prove a\nrepresentation formula over slice-domains of regularity. This proof involves an\nintertwining relation between imaginary units of quaternions and a fixed matrix\ncorresponding to a complex structure.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Based on high throughput density functional theory calculations, we performed\nsystematic screening for spin-gapless semiconductors (SGSs) in quaternary\nHeusler alloys XX 0 YZ (X, X 0 , and Y are transition metal elements without\nTc, and Z is one of B, Al, Ga, In, Si, Ge, Sn, Pb, P, As, Sb, and Bi).\nFollowing the empirical rule, we focused on compounds with 21, 26, or 28\nvalence electrons, resulting in 12, 000 possible chemical compositions. After\nsystematically evaluating the thermodynamic, mechanical, and dynamical\nstabilities, we successfully identified 70 stable SGSs, confirmed by explicit\nelectronic structure calculations with proper magnetic ground states. It is\ndemonstrated that all four types of SGSs can be realized, defined based on the\nspin characters of the bands around the Fermi energy, and the type-II SGSs show\npromising transport properties for spintronic applications. The effect of\nspin-orbit coupling is investigated, resulting in large anisotropic\nmagnetoresistance and anomalous Nernst effects.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Caching at base stations (BSs) is a promising approach for supporting the\ntremendous traffic growth of content delivery over future small-cell wireless\nnetworks with limited backhaul. This paper considers exploiting spatial caching\ndiversity (i.e., caching different subsets of popular content files at\nneighboring BSs) that can greatly improve the cache hit probability, thereby\nleading to a better overall system performance. A key issue in exploiting\nspatial caching diversity is that the cached content may not be located at the\nnearest BS, which means that to access such content, a user needs to overcome\nstrong interference from the nearby BSs; this significantly limits the gain of\nspatial caching diversity. In this paper, we consider a joint design of\nfrequency reuse and caching, such that the benefit of an improved cache hit\nprobability induced by spatial caching diversity and the benefit of\ninterference coordination induced by frequency reuse can be achieved\nsimultaneously. We obtain a closed-form characterization of the approximate\nsuccessful transmission probability for the proposed scheme and analyze the\nimpact of key operating parameters on the performance. We design a\nlow-complexity algorithm to optimize the frequency reuse factor and the cache\nstorage allocation. Simulations show that the proposed scheme achieves a higher\nsuccessful transmission probability than existing caching schemes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Technical systems have evolved over time into large and complex Interwoven\nSystems consisting of several to a huge number of (possibly heterogeneous)\nsubsystems that have interdependencies. The resultant mutual influences among\nsubsystems have made them so complex that they are no longer manageable by\nhumans and it is assumed to intensify rapidly. Identifying such mutual\ninfluences is the first step towards mastering the complexity of such systems.\nThis paper presents mutual influences in Interwoven Systems by describing\nreal-world examples and a methodology to detect them in the context of Organic\nComputing. The methodology is evaluated with the help of an example. Further, a\ntaxonomy of Organic Computing applications helpful for selecting suitable\nmethods for detecting hidden mutual influences is described briefly.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Esik and Maletti introduced the notion of a proper semiring and proved that\nsome important (classes of) semirings -- Noetherian semirings, natural numbers\n-- are proper. Properness matters as the equivalence problem for weighted\nautomata over a semiring which is proper and finitely and effectively presented\nis decidable. Milius generalised the notion of properness from a semiring to a\nfunctor. As a consequence, a semiring is proper if and only if its associated\n\"cubic functor\" is proper. Moreover, properness of a functor renders soundness\nand completeness proofs for axiomatizations of equivalent behaviour.\n  In this paper we provide a method for proving properness of functors, and\ninstantiate it to cover both the known cases and several novel ones: (1)\nproperness of the semirings of positive rationals and positive reals, via\nproperness of the corresponding cubic functors; and (2) properness of two\nfunctors on (positive) convex algebras. The latter functors are important for\naxiomatizing trace equivalence of probabilistic transition systems. Our proofs\nrely on results that stretch all the way back to Hilbert and Minkowski.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The electroweak fine-tuning measure Delta(EW) allows for correlated SUSY soft\nterms as are expected in any ultra-violet complete theory. Requiring no less\nthan 3% electroweak fine-tuning implies upper bounds of about 360~GeV on all\nhiggsinos, while top squarks are lighter than ~3 TeV and gluinos are bounded by\n~ 6-9 TeV. We examine the reach for SUSY of the planned high luminosity (HL: 3\nab^{-1} at 14 TeV) and the proposed high energy (HE: 15 ab^{-1} at 27 TeV)\nupgrades of the LHC via four LHC collider search channels relevant for natural\nSUSY: 1. gluino pair production followed by gluino decay to third generation\n(s)quarks, 2. top-squark pair production followed by decay to third generation\nquarks and light higgsinos, 3. neutral higgsino pair production with QCD jet\nradiation (resulting in monojet events with soft dileptons), and 4. wino pair\nproduction followed by decay to light higgsinos leading to same-sign diboson\nproduction. We confront our reach results with upper limits on superpartner\nmasses in four natural SUSY models: natural gravity-mediation via the 1. two-\nand 2. three-extra-parameter non-universal Higgs models, 3. natural\nmini-landscape models with generalized mirage mediation and 4. natural\nanomaly-mediation. We find that while the HL-LHC can probe considerable\nportions of natural SUSY parameter space in all these models, the HE-LHC will\ndecisively cover the entire natural SUSY parameter space with better than 3%\nfine-tuning.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  State-of-the-art methods for 3D reconstruction of faces from a single image\nrequire 2D-3D pairs of ground-truth data for supervision. Such data is costly\nto acquire, and most datasets available in the literature are restricted to\npairs for which the input 2D images depict faces in a near fronto-parallel\npose. Therefore, many data-driven methods for single-image 3D facial\nreconstruction perform poorly on profile and near-profile faces. We propose a\nmethod to improve the performance of single-image 3D facial reconstruction\nnetworks by utilizing the network to synthesize its own training data for\nfine-tuning, comprising: (i) single-image 3D reconstruction of faces in\nnear-frontal images without ground-truth 3D shape; (ii) application of a\nrigid-body transformation to the reconstructed face model; (iii) rendering of\nthe face model from new viewpoints; and (iv) use of the rendered image and\ncorresponding 3D reconstruction as additional data for supervised fine-tuning.\nThe new 2D-3D pairs thus produced have the same high-quality observed for near\nfronto-parallel reconstructions, thereby nudging the network towards more\nuniform performance as a function of the viewing angle of input faces.\nApplication of the proposed technique to the fine-tuning of a state-of-the-art\nsingle-image 3D-reconstruction network for faces demonstrates the usefulness of\nthe method, with particularly significant gains for profile or near-profile\nviews.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove the following theorem. Let $G$ be a finite group generated by\nunitary reflections in a complex Hermitian space $V=\\mathbb{C}^\\ell$ and let\n$G'$ be any reflection subgroup of $G$. Let $\\mathcal{H}(G)$ be the space of\n$G$-harmonic polynomials on $V$. There is a degree preserving isomorphism\n$\\xi:\\mathcal{H}(G')\\otimes\\mathcal{H}(G)^{G'}\\overset{\\sim}{\\longrightarrow}\\mathcal{H}$\nof graded $\\mathcal{N}$-modules, where $\\mathcal{N}:=N_{\\rm{GL}(V)}(G)\\cap\nN_{\\rm{GL}(V)}(G')$ and $\\mathcal{H}^{G'}$ is the space of $G'$-fixed points of\n$\\mathcal{H}$. This generalises a result of Douglass and Dyer for parabolic\nsubgroups of real reflection groups.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We analyze the Casimir effect for a flavor doublet of mixed scalar fields\ncon- fined inside a one-dimensional finite region. In the framework of the\nunitary inequivalence between mass and flavor representations in quantum field\ntheory, we employ two alternative approaches to derive the Casimir force: in\nthe first case, the zero-point energy is evaluated for the vacuum of fields\nwith definite mass, then similar calculations are performed for the vacuum of\nfields with defi- nite flavor. We find that signatures of mixing only appear in\nthe latter context, showing the result to be independent of the mixing\nparameters in the former.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $k$ be a field with a real embedding. We compare the motivic slice\nfiltration of a motivic spectrum over $Spec(k)$ with the $C_2$-equivariant\nslice filtration of its equivariant Betti realization, giving conditions under\nwhich realization induces an equivalence between the associated slice towers.\nIn particular, we show that, up to reindexing, the towers agree for all spectra\nobtained from localized quotients of $MGL$ and $MR$, and for motivic Landweber\nexact spectra and their realizations. As a consequence, we deduce that\nequivariant spectra obtained from localized quotients of $MR$ are even in the\nsense of Hill--Meier, and give a computation of the slice spectral sequence\nconverging to $\\pi_{*,*}BP\\langle n \\rangle/2$ for $1 \\le n \\le \\infty$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We improve upon a recent result of Culler and Dunfield on orderability of\ncertain Dehn fillings by removing a difficult condition they required.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The governance of data used for biomedical research and clinical trials is an\nimportant requirement for generating accurate results. To improve the\nvisibility of data quality and analysis, we developed TrialChain, a\nblockchain-based platform that can be used to validate data integrity from\nlarge, biomedical research studies. We implemented a private blockchain using\nthe MultiChain platform and integrated it with a data science platform deployed\nwithin a large research center. An administrative web application was built\nwith Python to manage the platform, which was built with a microservice\narchitecture using Docker. The TrialChain platform was integrated during data\nacquisition into our existing data science platform. Using NiFi, data were\nhashed and logged within the local blockchain infrastructure. To provide public\nvalidation, the local blockchain state was periodically synchronized to the\npublic Ethereum network. The use of a combined private/public blockchain\nplatform allows for both public validation of results while maintaining\nadditional security and lower cost for blockchain transactions. Original data\nand modifications due to downstream analysis can be logged within TrialChain\nand data assets or results can be rapidly validated when needed using API calls\nto the platform. The TrialChain platform provides a data governance solution to\naudit the acquisition and analysis of biomedical research data. The platform\nprovides cryptographic assurance of data authenticity and can also be used to\ndocument data analysis.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the Andreev reflection in the parallel double-quantum-dot\nstructure, by considering one metallic lead and one $s$-wave superconductor to\ncouple to the quantum dots simultaneously. It is found that the Fano lineshhape\nhas opportunities to appear in the linear conductance spectrum of the Andreev\nreflection, which can be reversed by tuning the dot level or local magnetic\nflux. However, the property of the Fano effect is very complicated, in\ncomparison with the normal electron tunnelling case. This is manifested as the\nspecial Fano form of the linear-conductance expression and the interference\nmanner among the Feynman paths. We believe that this work can be helpful for\nunderstanding the Fano interference in the Andreev reflection process.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Earth, Venus, Mars, and some extrasolar terrestrial planets have a mass\nand radius that is consistent with a mass fraction of about 30% metallic core\nand 70% silicate mantle. At the inner frontier of the solar system, Mercury has\na completely different composition, with a mass fraction of about 70% metallic\ncore and 30% silicate mantle. Several formation or evolution scenarios are\nproposed to explain this metal-rich composition, such as a giant impact, mantle\nevaporation, or the depletion of silicate at the inner-edge of the\nproto-planetary disk. These scenarios are still strongly debated. Here we\nreport the discovery of a multiple transiting planetary system (K2-229), in\nwhich the inner planet has a radius of 1.165+/-0.066 Rearth and a mass of\n2.59+/-0.43 Mearth. This Earth-sized planet thus has a core-mass fraction that\nis compatible with that of Mercury, while it was expected to be similar to that\nof the Earth based on host-star chemistry. This larger Mercury analogue either\nformed with a very peculiar composition or it has evolved since, e.g. by losing\npart of its mantle. Further characterisation of Mercury-like exoplanets like\nK2-229 b will help putting the detailed in-situ observations of Mercury (with\nMessenger and BepiColombo) into the global context of the formation and\nevolution of solar and extrasolar terrestrial planets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A revolution in elementary particle physics occurred during the period from\nthe ICHEP1968 to the ICHEP1982 with the advent of the parton model from\ndiscoveries in Deeply Inelastic electron-proton Scattering at SLAC, neutrino\nexperiments, hard-scattering observed in p$+$p collisions at the CERN ISR, the\ndevelopment of QCD, the discovery of the J/$\\Psi$ at BNL and SLAC and the clear\nobservation of high transverse momentum jets at the CERN SPS $\\bar{p}+p$\ncollider. These and other discoveries in this period led to the acceptance of\nQCD as the theory of the strong interactions. The desire to understand nuclear\nphysics at high density such as in neutron stars led to the application of QCD\nto this problem and to the prediction of a Quark-Gluon Plasma (QGP) in nuclei\nat high energy density and temperatures. This eventually led to the\nconstruction of the Relativistic Heavy Ion Collider (RHIC) at BNL to observe\nsuperdense nuclear matter in the laboratory. This article discusses how\nexperimental methods and results which confirmed QCD at the first hadron\ncollider, the CERN ISR, played an important role in experiments at the first\nheavy ion collider, RHIC, leading to the discovery of the QGP as a perfect\nliquid as well as discoveries at RHIC and the LHC which continue to the present\nday.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Observations of the 21 cm line from neutral hydrogen indicate that an Epoch\nof Heating (EoH) might have preceded the later Epoch of Reionization (EoR).\nHere we study the effects on the ionization state and the thermal history of\nthe Intergalactic Medium (IGM) during the EoH induced by different assumptions\non ionizing sources in the high redshift Universe: (i) stars, (ii) X-ray\nbinaries (XRBs), (iii) thermal bremsstrahlung of the hot Interstellar Medium\n(ISM), and (iv) accreting nuclear black holes (BHs). To this aim, we\npost-process outputs from the ($100 h^{-1}$ cMpc)$^3$ hydrodynamical simulation\nMassiveBlack-II with the cosmological 3D radiative transfer code CRASH, which\nfollows the propagation of UV and X-ray photons, computing the thermal and\nionization state of hydrogen and helium through the EoH. We find that stars\ndetermine the fully ionized morphology of the IGM, while the spectrally hard\nXRBs pave way for efficient subsequent heating and ionization by the spectrally\nsofter ISM. With the seeding prescription in MassiveBlack-II, BHs do not\ncontribute significantly to either ionization or heating. With only stars, most\nof the IGM remains in a cold state (with a median $T=11$ K at $z=10$), however,\nthe presence of more energetic sources raises the temperature of regions around\nthe brightest and more clustered sources above that of the CMB, opening the\npossibility to observing the 21 cm signal in emission.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate three combinatorial problems considered by Erd\\\"os, Rivat,\nSark\\\"ozy and Sch\\\"on regarding divisibility properties of sum sets and sets of\nshifted products of integers in the context of function fields. Our results in\nthis function field setting are better than those previously obtained for\nsubsets of the integers. These improvements depend on a version of the large\nsieve for sparse sets of moduli developed recently by the first and third-named\nauthors.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We adapt the interactive spline model of Wahba to growth curves with\ncovariates. The smoothing spline formulation permits a non-parametric\nrepresentation of the growth curves. In the limit when the discretization error\nis small relative to the estimation error, the resulting growth curve estimates\noften depend only weakly on the number and locations of the knots. The\nsmoothness parameter is determined from the data by minimizing an empirical\nestimate of the expected error. We show that the risk estimate of Craven and\nWahba is a weighted goodness of fit estimate. A modified loss estimate is\ngiven, where $\\sigma^2$ is replaced by its unbiased estimate.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We expand upon the standard quantum adiabatic theorem, examining the\ntime-dependence of quantum evolution in the near-adiabatic limit. We examine a\nHamiltonian that evolves along some fixed trajectory from $\\hat{H}_0$ to\n$\\hat{H}_1$ in a total evolution-time $\\tau$, and our goal is to determine how\nthe final state of the system depends on $\\tau$. If the system is initialized\nin a non-degenerate ground state, the adiabatic theorem says that in the limit\nof large $\\tau$, the system will stay in the ground state. We examine the\nnear-adiabatic limit where the system evolves slowly enough that most but not\nall of the final state is in the ground state, and we find that the probability\nof leaving the ground state oscillates in $\\tau$ with a frequency determined by\nthe integral of the spectral gap along the trajectory of the Hamiltonian, so\nlong as the gap is big. If the gap becomes exceedingly small, the final\nprobability is the sum of oscillatory behavior determined by the integrals of\nthe gap before and after the small gap. We confirm these analytic predictions\nwith numerical evidence from barrier tunneling problems in the context of\nquantum adiabatic optimization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this note, we propose a new approach to solving the Calabi problem on\nmanifolds with edge-cone singularities of prescribed angles along complex\nhypersurfaces. It is shown how the classical approach of Aubin-Yau in derving\n{\\it a priori} estimates for the complex hessian can be made to work via\nadopting a \\emph{good reference metric} and studying equivalent equations with\ndifferent referrence metrics. This further allows extending much of the methods\nused in the smooth setting to the edge setting. These results generalise to the\ncase of multiple hypersufaces with possibly normal crossing.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The L1 regularization (Lasso) has proven to be a versatile tool to select\nrelevant features and estimate the model coefficients simultaneously and has\nbeen widely used in many research areas such as genomes studies, finance, and\nbiomedical imaging. Despite its popularity, it is very challenging to guarantee\nthe feature selection consistency of Lasso especially when the dimension of the\ndata is huge. One way to improve the feature selection consistency is to select\nan ideal tuning parameter. Traditional tuning criteria mainly focus on\nminimizing the estimated prediction error or maximizing the posterior model\nprobability, such as cross-validation and BIC, which may either be\ntime-consuming or fail to control the false discovery rate (FDR) when the\nnumber of features is extremely large. The other way is to introduce\npseudo-features to learn the importance of the original ones. Recently, the\nKnockoff filter is proposed to control the FDR when performing feature\nselection. However, its performance is sensitive to the choice of the expected\nFDR threshold. Motivated by these ideas, we propose a new method using\npseudo-features to obtain an ideal tuning parameter. In particular, we present\nthe Efficient Tuning of Lasso (ET-Lasso) to separate active and inactive\nfeatures by adding permuted features as pseudo-features in linear models. The\npseudo-features are constructed to be inactive by nature, which can be used to\nobtain a cutoff to select the tuning parameter that separates active and\ninactive features. Experimental studies on both simulations and real-world data\napplications are provided to show that ET-Lasso can effectively and efficiently\nselect active features under a wide range of scenarios\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Unlicensed spectrum has been viewed as a way to increase competition in\nwireless access and promote innovation in new technologies and business models.\nHowever, several recent papers have shown that the openness of such spectrum\ncan also lead to it becoming over congested when used by competing wireless\nservice providers (SPs). This in turn can result in the SPs making no profit\nand may deter them from entering the market. However, this prior work assumes\nthat unlicensed access is a separate service from any service offered using\nlicensed spectrum. Here, we instead consider the more common case were service\nproviders bundle both licensed and unlicensed spectrum as a single service and\noffer this with a single price. We analyze a model for such a market and show\nthat in this case SPs are able to gain higher profit than the case without\nbundling. It is also possible to get higher social welfare with bundling.\nMoreover, we explore the case where SPs are allowed to manage the customers'\naverage percentage of time they receive service on unlicensed spectrum and\ncharacterize the social welfare gap between the profit maximizing and social\nwelfare maximizing setting.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In requirements engineering (RE), knowledge is mainly communicated via\nwritten specifications. This practice is cumbersome due to its low\ncommunication richness and effectiveness. In contrast, videos can transfer\nknowledge more richly and effectively. However, video is still a neglected\nmedium in RE. We investigate if software professionals perceive video as a\nmedium that can contribute to RE. We focus on their attitudes towards video as\na medium in RE including its strengths, weaknesses, opportunities, and threats.\nWe conducted a survey to explore these attitudes with a questionnaire. 64 out\nof 106 software professionals completed the survey. The respondents' overall\nattitude towards video is positive. 59 of them stated that video has the\npotential to improve RE. However, 34 respondents also mentioned threats of\nvideos for RE. We identified the strengths, weaknesses, opportunities, and\nthreats of videos for RE from the point of view of software professionals.\nVideo is a medium with a neglected potential. Software professionals do not\nfundamentally reject videos in RE. Despite the strengths and opportunities of\nvideo, the stated weaknesses and threats impede its application. Based on our\nfindings, we conclude that software professionals need guidance on how to\nproduce and use videos for visual communication to take full advantage of the\ncurrently neglected potential.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We apply the event-chain algorithm proposed by Bernard, Krauth and Wilson in\n2009 to toy models of lattice QCD. We give a formal prove of stability of the\nalgorithm. We study its performance at the example of the massive Gaussian\nmodel on the square and the simple cubic lattice, the $O(3)$-invariant\nnon-linear $\\sigma$-model and the $SU(3) \\times SU(3)$ principle chiral model\non the square lattice. In all these cases we find that critical slowing down is\nessentially eliminated.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a texture template approach, consisting of a set of virtual\nminutiae, to improve the overall latent fingerprint recognition accuracy. To\ncompensate for the lack of sufficient number of minutiae in poor quality latent\nprints, we generate a set of virtual minutiae. However, due to a large number\nof these regularly placed virtual minutiae, texture based template matching has\na large computational requirement compared to matching true minutiae templates.\nTo improve both the accuracy and efficiency of the texture template matching,\nwe investigate: i) both original and enhanced fingerprint patches for training\nconvolutional neural networks (ConvNets) to improve the distinctiveness of\ndescriptors associated with each virtual minutiae, ii) smaller patches around\nvirtual minutiae and a fast ConvNet architecture to speed up descriptor\nextraction, iii) reduce the descriptor length, iv) a modified hierarchical\ngraph matching strategy to improve the matching speed, and v) extraction of\nmultiple texture templates to boost the performance. Experiments on NIST SD27\nlatent database show that the above strategies can improve the matching speed\nfrom 11 ms (24 threads) per comparison (between a latent and a reference print)\nto only 7.7 ms (single thread) per comparison while improving the rank-1\naccuracy by 8.9% against 10K gallery.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Detecting the presence of a random wireless source with minimum latency\nutilizing an array of radio sensors is considered. The problem is studied under\nthe constraint that the analog-to-digital conversion at each sensor is\nrestricted to reading the sign of the analog received signal. We formulate the\nresulting digital signal processing task as a sequential hypothesis test in\nsimple form. To circumvent the intractable probabilistic model of the\nmultivariate binary array data, a reduced model representation within the\nexponential family in conjunction with a log-likelihood ratio approximation is\nemployed. This approach allows us to design a likelihood-based sequential test\nand to analyze its analytic performance along Wald's classical arguments. In\nthe context of wireless spectrum monitoring for satellite-based navigation and\nsynchronization systems, we study the achievable processing latency,\ncharacterized by the average sample number, as a function of the binary sensors\nin use. The practical feasibility and potential of the discussed low-complexity\nsensing and decision-making technology is demonstrated via simulations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we prove the uniqueness of the saddle-shaped solution to the\nsemilinear nonlocal elliptic equation $(-\\Delta)^\\gamma u = f(u)$ in $\\mathbb\nR^{2m}$, where $\\gamma \\in (0,1)$ and $f$ is of Allen-Cahn type. Moreover, we\nprove that this solution is stable whenever $2m\\geq 14$. As a consequence of\nthis result and the connection of the problem with nonlocal minimal surfaces,\nwe show that the Simons cone $\\{(x', x'') \\in \\mathbb R^{m}\\times \\mathbb R^m \\\n: \\ |x'| = |x''|\\}$ is a stable nonlocal $(2\\gamma)$-minimal surface in\ndimensions $2m\\geq 14$.\n  Saddle-shaped solutions of the fractional Allen-Cahn equation are doubly\nradial, odd with respect to the Simons cone, and vanish only in this set. It\nwas known that these solutions exist in all even dimensions and are unstable in\ndimensions $2$, $4$ and $6$. Thus, after our result, the stability remains an\nopen problem only in dimensions $8$, $10$, and $12$.\n  The importance of studying this type of solution is due to its relation with\nthe fractional version of a conjecture by De Giorgi. Saddle-shaped solutions\nare the simplest non 1D candidates to be global minimizers in high dimensions,\na property not yet established in any dimension.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The aim of this work is to develop a formal semi-analytical model using the\nmodal expansion method in cylindrical coordinates to calculate the\noptical/electromagnetic (EM) radiation force-per-length experienced by an\ninfinitely long electrically-conducting elliptical cylinder having a smooth or\nwavy/corrugated surface in EM plane progressive waves with different\npolarizations. One of the semi-axes of the elliptical cylinder coincides with\nthe direction of the incident field. The modal matching method is used to\ndetermine the scattering coefficients by matrix inversion. Standard cylindrical\n(Bessel and Hankel) wave functions are used. Simplified expressions leading to\nexact series expansions for the optical/EM radiation forces assuming either\nelectric (TM) of magnetic (TE) plane wave incidences are provided without any\napproximations, in addition to integral equations demonstrating the direct\nrelationship of the radiation force with the square of the scattered field\nmagnitude. Numerical computations for the non-dimensional radiation force\nfunction are performed for electrically conducting elliptic and circular\ncylinders having a smooth or ribbed/corrugated surface. Adequate convergence\nplots confirm the validity and correctness of the method to evaluate the\nradiation force with no limitation to a particular frequency range (i.e.\nRayleigh, Mie or geometrical optics regimes). Emphases are given on the aspect\nratio, the non-dimensional size of the cylinder, the corrugation characteristic\nof its surface, and the polarization of the incident field. The results are\nparticularly relevant in optical tweezers and other related applications in\nfluid dynamics, where the shape and stability of a cylindrical drop stressed by\na uniform external electric/magnetic field are altered. Furthermore, a direct\nanalogy with the acoustical counterpart is discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Advanced oxidation processes that utilize highly oxidative radicals are\nwidely used in water reuse treatment. In recent years, the application of\nsulfate radical (SO$_4\\cdot^-$) as a promising oxidant for water treatment has\ngained increasing attention. To understand the efficiency of SO$_4\\cdot^-$ in\nthe degradation of organic contaminants in wastewater effluent, it is important\nto be able to predict the reaction kinetics of various SO$_4\\cdot^-$-driven\noxidation reactions. In this study, we utilize density functional theory (DFT)\nand high-level wavefunction-based methods (including computationally-intensive\ncoupled cluster methods), to explore the activation energies and kinetic rates\nof SO$_4\\cdot^-$-driven oxidation reactions on a series of benzene-derived\ncontaminants. These high-level calculations encompassed a wide set of reactions\nincluding 110 forward/reverse reactions and 5 different computational methods\nin total. Based on the high-level coupled-cluster quantum calculations, we find\nthat the popular M06-2X DFT functional is significantly more accurate for\nHO-additions than for SO$_4\\cdot^-$ reactions. Most importantly, we highlight\nsome of the limitations and deficiencies of other computational methods, and we\nrecommend the use of high-level quantum calculations to spot-check\nenvironmental chemistry reactions that may lie outside the training set of the\nM06-2X functional, particularly for water oxidation reactions that involve\nSO$_4\\cdot^-$ and other inorganic species.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work we examine how the updates addressing Meltdown and Spectre\nvulnerabilities impact the performance of HPC applications. To study this we\nuse the application kernel module of XDMoD to test the performance before and\nafter the application of the vulnerability patches. We tested the performance\ndifference for multiple application and benchmarks including: NWChem, NAMD,\nHPCC, IOR, MDTest and IMB. The results show that although some specific\nfunctions can have performance decreased by as much as 74%, the majority of\nindividual metrics indicates little to no decrease in performance. The\nreal-world applications show a 2-3% decrease in performance for single node\njobs and a 5-11% decrease for parallel multi node jobs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider partial words with a unique position starting a power. We show\nthat over a $k$ letter alphabet, a partial word with a unique position starting\na square can contain at most $k$ squares. This is in contrast to full words\nwhich can contain at most one power if a unique position starts a power. For\ncertain higher powers we exhibit binary partial words containing three powers\nall of which start at the same position.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We formulate the conditions defining the irreducible continuous spin\nrepresentation of the four-dimensional Poincar\\'e group based on spin-tensor\nfields with dotted and undotted indices. Such a formulation simplifies analysis\nof the Bargmann-Wigner equations and reduces the number of equations from four\nto three. Using this formulation we develop the BRST approach and derive the\ncovariant Lagrangian for the continuous spin fields.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Over the past decade, our knowledge of the \\gamma-ray sky has been\nrevolutionized by ground- and space-based observatories by detecting photons up\nto several hundreds of tera-electron volt (TeV) energies. A major population of\nthe $\\gamma$-ray bright objects are active galactic nuclei (AGN) with their\nrelativistic jets pointed along our line-of-sight. Gamma-ray emission is also\ndetected from nearby mis-aligned AGN such as radio galaxies. While the\nTeV-detected radio galaxies (TeVRad) only form a small fraction of the\n\\gamma-ray detected AGN, their multi-wavelength study offers a unique\nopportunity to probe and pinpoint the high-energy emission processes and sites.\nEven in the absence of substantial Doppler beaming TeVRad are extremely bright\nobjects in the TeV sky (luminosities detected up to 10^{45} erg/s), and exhibit\nflux variations on timescales shorter than the event-horizon scales (flux\ndoubling timescale less than 5 minutes). Thanks to the recent advancement in\nthe imaging capabilities of high-resolution radio interferometry (millimeter\nvery long baseline interferometry, mm-VLBI), one can probe the scales down to\nless than 10 gravitational radii in TeVRad, making it possible not only to test\njet launching models but also to pinpoint the high-energy emission sites and to\nunravel the emission mechanisms. This review provides an overview of the\nhigh-energy observations of TeVRad with a focus on the emitting sites and\nradiation processes. Some recent approaches in simulations are also sketched.\nObservations by the near-future facilities like Cherenkov Telescope Array,\nshort millimeter-VLBI, and high-energy polarimetry instruments will be crucial\nfor discriminating the competing high-energy emission models.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we introduce an attribute-based interactive image search which\ncan leverage human-in-the-loop feedback to iteratively refine image search\nresults. We study active image search where human feedback is solicited\nexclusively in visual form, without using relative attribute annotations used\nby prior work which are not typically found in many datasets. In order to\noptimize the image selection strategy, a deep reinforcement model is trained to\nlearn what images are informative rather than rely on hand-crafted measures\ntypically leveraged in prior work. Additionally, we extend the recently\nintroduced Conditional Similarity Network to incorporate global similarity in\ntraining visual embeddings, which results in more natural transitions as the\nuser explores the learned similarity embeddings. Our experiments demonstrate\nthe effectiveness of our approach, producing compelling results on both active\nimage search and image attribute representation tasks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work we study a multi-step scheme on time-space grids proposed by W.\nZhao et al. [28] for solving backward stochastic differential equations, where\nLagrange interpolating polynomials are used to approximate the time-integrands\nwith given values of these integrands at chosen multiple time levels. For a\nbetter stability and the admission of more time levels we investigate the\napplication of spline instead of Lagrange interpolating polynomials to\napproximate the time-integrands. The resulting scheme is a semi-discretization\nin the time direction involving conditional expectations, which can be\nnumerically solved by using the Gaussian quadrature rules and polynomial\ninterpolations on the spatial grids. Several numerical examples including\napplications in finance are presented to demonstrate the high accuracy and\nstability of our new multi-step scheme.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Two results from the PIENU Experiment are presented reporting a test of\nlepton universality in pion decay and improved limits on heavy neutrinos\ncoupling to positrons. The status of the full analysis for the $\\pi^+\n\\rightarrow \\mbox{e}^+ \\nu$ branching ratio measurement is summarized.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The practice of transforming raw data to a feature space so that inference\ncan be performed in that space has been popular for many years. Recently, rapid\nprogress in deep neural networks has given both researchers and practitioners\nenhanced methods that increase the richness of feature representations, be it\nfrom images, text or speech. In this work we show how a constructed latent\nspace can be explored in a controlled manner and argue that this complements\nwell founded inference methods. For constructing the latent space a Variational\nAutoencoder is used. We present a novel controller module that allows for\nsmooth traversal in the latent space and construct an end-to-end trainable\nframework. We explore the applicability of our method for performing spatial\ntransformations as well as kinematics for predicting future latent vectors of a\nvideo sequence.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Consider the Dirichlet problem with respect to an elliptic operator \\[ A = -\n\\sum_{k,l=1}^d \\partial_k \\, a_{kl} \\, \\partial_l\n  - \\sum_{k=1}^d \\partial_k \\, b_k\n  + \\sum_{k=1}^d c_k \\, \\partial_k\n  + c_0 \\] on a bounded Wiener regular open set $\\Omega \\subset R^d$, where\n$a_{kl}, c_k \\in L_\\infty(\\Omega,R)$ and $b_k,c_0 \\in L_\\infty(\\Omega,C)$.\nSuppose that the associated operator on $L_2(\\Omega)$ with Dirichlet boundary\nconditions is invertible. Then we show that for all $\\varphi \\in C(\\partial\n\\Omega)$ there exists a unique $u \\in C(\\overline \\Omega) \\cap H^1_{\\rm\nloc}(\\Omega)$ such that $u|_{\\partial \\Omega} = \\varphi$ and $A u = 0$.\n  In the case when $\\Omega$ has a Lipschitz boundary and $\\varphi \\in\nC(\\overline \\Omega) \\cap H^{1/2}(\\overline \\Omega)$, then we show that $u$\ncoincides with the variational solution in $H^1(\\Omega)$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Coherently splitting a one-dimensional Bose gas provides an attractive,\nexperimentally estab- lished platform to investigate many-body quantum\ndynamics. At short enough times, the dynamics is dominated by the dephasing of\nsingle quasi-particles, and well described by the relaxation to- wards a\ngeneralized Gibbs ensemble corresponding to the free Luttinger theory. At later\ntimes on the other hand, the approach to a thermal Gibbs ensemble is expected\nfor a generic, interacting quantum system. Here, we go one step beyond the\nquadratic Luttinger theory and include the lead- ing phonon-phonon\ninteractions. By applying kinetic theory and non-equilibrium Dyson-Schwinger\nequations, we analyze the full relaxation dynamics beyond dephasing and\ndetermine the asymptotic thermalization process in the two-wire system for a\nsymmetric splitting protocol. The major ob- servables are the different phonon\noccupation functions and the experimentally accessible coherence factor, as\nwell as the phase correlations between the two wires. We demonstrate that,\ndepending on the splitting protocol, the presence of phonon collisions can have\nsignificant influence on the asymptotic evolution of these observables, which\nmakes the corresponding thermalization dynamics experimentally accessible.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we present a new approach to visualize directed graphs and\ntheir hierarchies that completely departs from the classical four-phase\nframework of Sugiyama and computes readable hierarchical visualizations that\ncontain the complete reachability information of a graph. Additionally, our\napproach has the advantage that only the necessary edges are drawn in the\ndrawing, thus reducing the visual complexity of the resulting drawing.\nFurthermore, most problems involved in our framework require only polynomial\ntime. Our framework offers a suite of solutions depending upon the\nrequirements, and it consists of only two steps: (a) the cycle removal step (if\nthe graph contains cycles) and (b) the channel decomposition and hierarchical\ndrawing step. Our framework does not introduce any dummy vertices and it keeps\nthe vertices of a channel vertically aligned. The time complexity of the main\ndrawing algorithms of our framework is $O(kn)$, where $k$ is the number of\nchannels, typically much smaller than $n$ (the number of vertices).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A fast and automated scheme for general polarization transformations holds\ngreat value in adaptive optics, quantum information, and virtually all\napplications involving light-matter and light-light interactions. We present an\nexperiment that uses a liquid crystal on silicon spatial light modulator\n(LCOS-SLM) to perform polarization transformations on a light field. We\nexperimentally demonstrate the point-by-point conversion of uniformly polarized\nlight fields across the wave front to realize arbitrary, spatially varying\npolarization states. Additionally, we demonstrate that a light field with an\narbitrary spatially varying polarization can be transformed to a spatially\ninvariant (i.e., uniform) polarization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Consider the following Stochastic Score Classification Problem. A doctor is\nassessing a patient's risk of developing a certain disease, and can perform $n$\ntests on the patient. Each test has a binary outcome, positive or negative. A\npositive test result is an indication of risk, and a patient's score is the\ntotal number of positive test results. The doctor needs to classify the patient\ninto one of $B$ risk classes, depending on the score (e.g., LOW, MEDIUM, and\nHIGH risk). Each of these classes corresponds to a contiguous range of scores.\nTest $i$ has probability $p_i$ of being positive, and it costs $c_i$ to perform\nthe test. To reduce costs, instead of performing all tests, the doctor will\nperform them sequentially and stop testing when it is possible to determine the\nrisk category for the patient. The problem is to determine the order in which\nthe doctor should perform the tests, so as to minimize the expected testing\ncost. We provide approximation algorithms for adaptive and non-adaptive\nversions of this problem, and pose a number of open questions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Bindlib library for OCaml provides a set of tools for the manipulation of\ndata structures with variable binding. It is very well suited for the\nrepresentation of abstract syntax trees, and has already been used for the\nimplementation of half a dozen languages and proof assistants (including a new\nversion of the logical framework Dedukti). Bindlib is optimised for fast\nsubstitution, and it supports variable renaming. Since the representation of\nbinders is based on higher-order abstract syntax, variable capture cannot arise\nduring substitution. As a consequence, variable names are not updated at\nsubstitution time. They can however be explicitly recomputed to avoid \"visual\ncapture\" (i.e., distinct variables with the same apparent name) when a data\nstructure is displayed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $G$ be a graph and $\\tau$ be an assignment of nonnegative integer\nthresholds to the vertices of $G$. Denote the average of thresholds in $\\tau$\nby $\\bar{\\tau}$. A subset of vertices $D$ is said to be a $\\tau$-dynamic\nmonopoly, if $V(G)$ can be partitioned into subsets $D_0, D_1, \\ldots, D_k$\nsuch that $D_0=D$ and for any $i\\in \\{0, \\ldots, k-1\\}$, each vertex $v$ in\n$D_{i+1}$ has at least $\\tau(v)$ neighbors in $D_0\\cup \\ldots \\cup D_i$. Denote\nthe size of smallest $\\tau$-dynamic monopoly by $dyn_{\\tau}(G)$. Also a subset\nof vertices $M$ is said to be a $\\tau$-static monopoly (or simply\n$\\tau$-monopoly) if any vertex $v\\in V(G)\\setminus M$ has at least $\\tau(v)$\nneighbors in $M$. Denote the size of smallest $\\tau$-monopoly by\n$mon_{\\tau}(G)$. For a given positive number $t$, denote by $Sdyn_t(G)$ (resp.\n$Smon_t(G)$), the minimum $dyn_{\\tau}(G)$ (resp. $mon_{\\tau}(G)$) among all\nthreshold assignments $\\tau$ with $\\overline{\\tau}\\geq t$. In this paper we\nconsider the concept of partial vertex cover as follows. Let $G=(V, E)$ be a\ngraph and $t$ be any positive integer. A subset $S\\subseteq V$ is said to be a\n$t$-partial vertex cover of $G$, if $S$ covers at least $t$ edges of $G$.\nDenote the smallest size of a $t$-partial vertex cover of $G$ by $P\\beta_t(G)$.\nLet $\\rho$, $0<\\rho<1$ be any fixed number and $G$ be a given bipartite graph\nwith $m$ edges. We first prove that to determine the smallest cardinality of a\nset $S\\subseteq V(G)$ such that $S$ covers at least $\\rho m$ edges of $G$, is\nan NP-hard problem. Then we prove that for any constant $t$,\n$Sdyn_{t}(G)=P\\beta_{nt-m}(G)$ and $Smon_t(G)=P\\beta_{nt/2}(G)$, where $n$ and\n$m$ are the order and size of $G$, respectively.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We outline the important role that ground-based, Doppler monitoring of\nexoplanetary systems will play in advancing our theories of planet formation\nand dynamical evolution. A census of planetary systems requires a well designed\nsurvey to be executed over the course of a decade or longer. A coordinated\nsurvey to monitor several thousand targets each at ~1000 epochs (~3-5 million\nnew observations) will require roughly 40 dedicated spectrographs. We advocate\nfor improvements in data management, data sharing, analysis techniques, and\nsoftware testing, as well as possible changes to the funding structures for\nexoplanet science.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the behavior of negatively charged colloids with two positively\ncharged polar caps close to a planar patterned surface. The competition between\nthe different anisotropic components of the particle-particle interaction\npatterns is able by itself to give rise to a rich assembly scenario: colloids\nwith charged surface patterns form different crystalline domains when adsorbed\nto a homogeneously charged substrate. Here we consider substrates composed of\nalternating (negative/neutral, positive/neutral and positive/negative) parallel\nstripes and, by means of Monte Carlo simulations, we investigate the ordering\nof the colloids on changing the number of the stripes. We show that the\nadditional competition between the two different lengths scales characterizing\nthe system ($i.e.,$ the particle interaction range and the size of the stripes)\ngives rise to a plethora of distinct particle arrangements, where some\nwell-defined trends can be observed. By accurately tuning the substrate charged\nmotif it is possible to, $e. g.,$ promote specific particles arrangements,\ndisfavor crystalline domains or induce the formation of extended, open\nclusters.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Progress in nuclear physics is driven by the experimental observation that\nrequires state of the art detectors to measure various kinematic properties,\nsuch as energy, momentum, position etc. of the particles produced in a nuclear\nreaction. Advances in detector technology has enabled nuclear physicists to\nmeasure these quantities with better precision, and the reduced cost of the\ndetection system has helped to have larger detection systems (array of\ndetectors) to measure the rare processes with greater sensitivity. Several\ndetection systems have been designed, developed and built in India over last\nfew decades and are being used by the physicists. In this article, I will focus\non such developments of detection systems at Variable Energy Cyclotron Centre\n(VECC), Kolkata.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In G dwarfs, the surface distribution, coverage and lifetimes of starspots\ndeviate from solar-like patterns as the rotation rate increases. We set up a\nnumerical platform which includes the large-scale rotational and surface flow\neffects, aiming to simulate evolving surface patterns over an activity cycle\nfor up to 8 times the solar rotation and flux emergence rates. At the base of\nthe convection zone, we assume a solar projected butterfly diagram. We then\nfollow the rotationally distorted trajectories of rising thin flux tubes to\nobtain latitudes and tilt angles. Using them as source distributions, we run a\nsurface flux transport model with solar parameters. Our model predicts surface\ndistributions of the signed radial fields and the starspots that qualitatively\nagree with observations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Microreversibility rules the fluctuations of the currents flowing across open\nsystems in nonequilibrium (or equilibrium) steady states. As a consequence, the\nstatistical cumulants of the currents and their response coefficients at\narbitrary orders in the deviations from equilibrium obey time-reversal symmetry\nrelations. It is shown that these relations allow us to systematically reduce\nthe amount of independent quantities that need to be measured experimentally or\ncomputed theoretically in order to fully characterize the linear and nonlinear\ntransport properties of general open systems. This reduction is shown to\napproach one half for quantities of arbitrarily high orders.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Two-dimensional magnetic insulators exhibit a plethora of competing ground\nstates, such as ordered (anti)ferromagnets, exotic quantum spin liquid states\nwith topological order and anyonic excitations, and random singlet phases\nemerging in highly disordered frustrated magnets. Here we show how single spin\nqubits, which interact directly with the low-energy excitations of magnetic\ninsulators, can be used as a diagnostic of magnetic ground states.\nExperimentally tunable parameters, such as qubit level splitting, sample\ntemperature, and qubit-sample distance, can be used to measure spin\ncorrelations with energy and wavevector resolution. Such resolution can be\nexploited, for instance, to distinguish between fractionalized excitations in\nspin liquids and spin waves in magnetically ordered states, or to detect\nanyonic statistics in gapped systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Named Entity Recognition (NER) is an important subtask of information\nextraction that seeks to locate and recognise named entities. Despite recent\nachievements, we still face limitations in correctly detecting and classifying\nentities, prominently in short and noisy text, such as Twitter. An important\nnegative aspect in most of NER approaches is the high dependency on\nhand-crafted features and domain-specific knowledge, necessary to achieve\nstate-of-the-art results. Thus, devising models to deal with such\nlinguistically complex contexts is still challenging. In this paper, we propose\na novel multi-level architecture that does not rely on any specific linguistic\nresource or encoded rule. Unlike traditional approaches, we use features\nextracted from images and text to classify named entities. Experimental tests\nagainst state-of-the-art NER for Twitter on the Ritter dataset present\ncompetitive results (0.59 F-measure), indicating that this approach may lead\ntowards better NER models.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Hales-Jewett theorem states that for any $m$ and $r$ there exists an $n$\nsuch that any $r$-colouring of the elements of $[m]^n$ contains a monochromatic\ncombinatorial line. We study the structure of the wildcard set $S \\subseteq\n[n]$ which determines this monochromatic line, showing that when $r$ is odd\nthere are $r$-colourings of $[3]^n$ where the wildcard set of a monochromatic\nline cannot be the union of fewer than $r$ intervals. This is tight, as for $n$\nsufficiently large there are always monochromatic lines whose wildcard set is\nthe union of at most $r$ intervals.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  IIn this paper we show that some HJB equations arising from both finite and\ninfinite horizon stochastic optimal control problems have a regular singular\npoint at the origin. This makes them amenable to solution by power series\ntechniques. This extends the work of Al'brecht who showed that the HJB\nequations of an infinite horizon deterministic optimal control problem can have\na regular singular point at the origin, Al'brekht solved the HJB equations by\npower series, degree by degree. In particular, we show that the infinite\nhorizon stochastic optimal control problem with linear dynamics, quadratic cost\nand bilinear noise leads to a new type of algebraic Riccati equation which we\ncall the Stochastic Algebraic Riccati Equation (SARE). If SARE can be solved\nthen one has a complete solution to this infinite horizon stochastic optimal\ncontrol problem. We also show that a finite horizon stochastic optimal control\nproblem with linear dynamics, quadratic cost and bilinear noise leads to a\nStochastic Differential Riccati Equation (SDRE) that is well known. If these\nproblems are the linear-quadratic-bilinear part of a nonlinear finite horizon\nstochastic optimal control problem then we show how the higher degree terms of\nthe solutions can be computed degree by degree. To our knowledge this\ncomputation is new.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The 3D video quality metric (3VQM) was proposed to evaluate the temporal and\nspatial variation of the depth errors for the depth values that would lead to\ninconsistencies between left and right views, fast changing disparities, and\ngeometric distortions. Previously, we evaluated 3VQM against subjective scores.\nIn this paper, we show the effectiveness of 3VQM in capturing errors and\ninconsistencies that exist in the rendered depth-based 3D videos. We further\ninvestigate how 3VQM could measure excessive disparities, fast changing\ndisparities, geometric distortions, temporal flickering and/or spatial noise in\nthe form of depth cues inconsistency. Results show that 3VQM best captures the\ndepth inconsistencies based on errors in the reference views. However, the\nmetric is not sensitive to depth map mild errors such as those resulting from\nblur. We also performed a subjective quality test and showed that 3VQM performs\nbetter than PSNR, weighted PSNR and SSIM in terms of accuracy, coherency and\nconsistency.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We calculate the deflection angle of light from a distant source by a galaxy\ncluster in Weyl's conformal gravity. The general method of calculation is first\napplied to calculate the deflection angle in Schwarzschild-de Sitter (Kottler)\nspacetime. The deflection angle calculated in Kottler spacetime includes the\ncontribution of the cosmological constant, which quantitatively agrees with one\nwork and disagrees with many works in the literature. We then calculate the\ndeflection angle in Mannheim-Kazanas spacetime in two conformally related\ncoordinate systems and find that the result includes contributions from both\nthe cosmological constant and the Mannheim-Kazanas parameter. There are\nconflicting results on the deflection angle for light in Weyl gravity in the\nliterature. We point out a possible reason for the discrepancy between our work\nand the others.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Mass and specific angular momentum are two fundamental physical parameters of\ngalaxies. We present measurements of the baryonic mass and specific angular\nmomentum of 11 void dwarf galaxies derived from neutral hydrogen (H{\\sc i})\nsynthesis data. Rotation curves were measured using 3D and 2D tilted ring\nfitting routines, and the derived curves generally overlap within the error\nbars, except in the central regions where, as expected, the 3D routines give\nsteeper curves. The specific angular momentum of void dwarfs is found to be\nhigh compared to an extrapolation of the trends seen for higher mass bulge-less\nspirals, but comparable to that of other dwarf irregular galaxies that lie\noutside of voids. As such, our data show no evidence for a dependence of the\nspecific angular momentum on the large scale environment. Combining our data\nwith the data from the literature, we find a baryonic threshold of $\\sim\n10^{9.1}~M_{\\odot}$ for this increase in specific angular momentum.\nInterestingly, this threshold is very similar to the mass threshold below which\nthe galaxy discs start to become systematically thicker. This provides\nqualitative support to the suggestion that the thickening of the discs, as well\nas the increase in specific angular momentum, are both results of a common\nphysical mechanism, such as feedback from star formation. Quantitatively,\nhowever, the amount of star formation observed in our dwarfs appears\ninsufficient to produce the observed increase in specific angular momentum. It\nis hence likely that other processes, such as cold accretion of high angular\nmomentum gas, also play a role in increasing the specific angular momentum.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Orthogonal matching pursuit (OMP) is a widely used algorithm for recovering\nsparse high dimensional vectors in linear regression models. The optimal\nperformance of OMP requires \\textit{a priori} knowledge of either the sparsity\nof regression vector or noise statistics. Both these statistics are rarely\nknown \\textit{a priori} and are very difficult to estimate. In this paper, we\npresent a novel technique called residual ratio thresholding (RRT) to operate\nOMP without any \\textit{a priori} knowledge of sparsity and noise statistics\nand establish finite sample and large sample support recovery guarantees for\nthe same. Both analytical results and numerical simulations in real and\nsynthetic data sets indicate that RRT has a performance comparable to OMP with\n\\textit{a priori} knowledge of sparsity and noise statistics.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Exploration is a difficult challenge in reinforcement learning and is of\nprime importance in sparse reward environments. However, many of the state of\nthe art deep reinforcement learning algorithms, that rely on epsilon-greedy,\nfail on these environments. In such cases, empowerment can serve as an\nintrinsic reward signal to enable the agent to maximize the influence it has\nover the near future. We formulate empowerment as the channel capacity between\nstates and actions and is calculated by estimating the mutual information\nbetween the actions and the following states. The mutual information is\nestimated using Mutual Information Neural Estimator and a forward dynamics\nmodel. We demonstrate that an empowerment driven agent is able to improve\nsignificantly the score of a baseline DQN agent on the game of Montezuma's\nRevenge.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Frame theory has a great revolution in recent years. This new Theory have\nbeen extended from Hilbert spaces to Hilbert C*-modules. In this paper, we\nintroduce the notion of dual *-K-g-frames in Hilbert A-modules. Lastly we study\n*-K-g-frames in tensor product of Hilbert C*-Modules and we establish some new\nresults.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the multi-agent reinforcement learning setting with imperfect\ninformation in which each agent is trying to maximize its own utility. The\nreward function depends on the hidden state (or goal) of both agents, so the\nagents must infer the other players' hidden goals from their observed behavior\nin order to solve the tasks. We propose a new approach for learning in these\ndomains: Self Other-Modeling (SOM), in which an agent uses its own policy to\npredict the other agent's actions and update its belief of their hidden state\nin an online manner. We evaluate this approach on three different tasks and\nshow that the agents are able to learn better policies using their estimate of\nthe other players' hidden states, in both cooperative and adversarial settings.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  For decades it has been established that the amount of energy released by\nsolar flares excites the acoustic oscillations propagating on the surface of\nthe Sun (Wolff 1972). It is believed that these flares can excite velocity\noscillations in active regions, especially those regions where a higher class\nsolar flare has taken place (Kumar 2006). However, questions arise as to how\nthe behaviors of acoustic oscillations within such a chaotic environment can\nbirth other waves of the MHD type. Can we observe such events?\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove that finite lamplighter groups\n$\\{\\mathbb{Z}_2\\wr\\mathbb{Z}_n\\}_{n\\ge 2}$ with a standard set of generators\n  embed with uniformly bounded distortions into any non-superreflexive Banach\nspace, and therefore form a set of test-spaces for superreflexivity. Our proof\nis inspired by the well known identification of Cayley graphs of infinite\nlamplighter groups with the horocyclic product of trees. We cover\n$\\mathbb{Z}_2\\wr\\mathbb{Z}_n$ by three sets with a structure similar to a\nhorocyclic product of trees, which enables us to construct well-controlled\nembeddings.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In recent years, it has been widely argued that the duality transformations\nof string and M-theory naturally imply the existence of so-called `exotic\nbranes'---low codimension objects with highly non-perturbative tensions,\nscaling as $g_s^{\\alpha}$ for $\\alpha \\leq -3$. We argue that their intimate\nlink with these duality transformations make them an ideal object of study\nusing the general framework of Double Field Theory (DFT) and Exceptional Field\nTheory (EFT)---collectively referred to as ExFT. Parallel to the theme of\ndualities, we also stress that these theories unify known solutions in string-\nand M-theory into a single solution under ExFT. We argue that not only is there\na natural unifying description of the lowest codimension objects, many of these\nexotic states require this formalism as a consistent supergravity description\ndoes not exist.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Metric functions for phoneme perception capture the similarity structure\namong phonemes in a given language and therefore play a central role in\nphonology and psycho-linguistics. Various phenomena depend on phoneme\nsimilarity, such as spoken word recognition or serial recall from verbal\nworking memory. This study presents a new framework for learning a metric\nfunction for perceptual distances among pairs of phonemes. Previous studies\nhave proposed various metric functions, from simple measures counting the\nnumber of phonetic dimensions that two phonemes share (place-,\nmanner-of-articulation and voicing), to more sophisticated ones such as\nderiving perceptual distances based on the number of natural classes that both\nphonemes belong to. However, previous studies have manually constructed the\nmetric function, which may lead to unsatisfactory account of the empirical\ndata. This study presents a framework to derive the metric function from\nbehavioral data on phoneme perception using learning algorithms. We first show\nthat this approach outperforms previous metrics suggested in the literature in\npredicting perceptual distances among phoneme pairs. We then study several\nmetric functions derived by the learning algorithms and show how perceptual\nsaliencies of phonological features can be derived from them. For English, we\nshow that the derived perceptual saliencies are in accordance with a previously\ndescribed order among phonological features and show how the framework extends\nthe results to more features. Finally, we explore how the metric function and\nperceptual saliencies of phonological features may vary across languages. To\nthis end, we compare results based on two English datasets and a new dataset\nthat we have collected for Hebrew.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the conformal invariant Lagrangian of the self-gravitating\nU(1) scalar-gauge field and find new features of the model on the\ntime-dependent axially symmetric Bondi-Marder spacetime. By considering the\nconformal symmetry as exact at the level of the Lagrangian and broken in the\nvacuum, a consistent model is found with an exact solution of the vacuum\nBondi-Marder spacetime $g_{\\mu\\nu}=\\omega^2 \\bar g_{\\mu\\nu}$, where $\\omega$ is\nthe conformal factor and $\\bar g_{\\mu\\nu}$ the `un-physical` spacetime. If we\ntry to match this vacuum solution onto the interior vortex solution of the\ncoupled Einstein-scalar-gauge field, we need, besides the matching conditions,\nconstraint equations in order to obtain a topological regular description of\nthe small-scale behaviour of the model. Probably, one needs the\nfive-dimensional warped counterpart model, where the 5D dilaton field act as a\nwarp factor. Moreover, the tracelessness of the energy-momentum tensor could\nthen be maintained by a contribution from the bulk.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This thesis concerns embeddings and self-embeddings of foundational\nstructures in both set theory and category theory.\n  The first part of the work on models of set theory consists in establishing a\nrefined version of Friedman's theorem on the existence of embeddings between\ncountable non-standard models of a fragment of ZF, and an analogue of a theorem\nof Gaifman to the effect that certain countable models of set theory can be\nelementarily end-extended to a model with many automorphisms whose sets of\nfixed points equal the original model. The second part of the work on set\ntheory consists in combining these two results into a technical machinery,\nyielding several results about non-standard models of set theory relating such\nnotions as self-embeddings, their sets of fixed points, strong rank-cuts, and\nset theories of different strengths.\n  The work in foundational category theory consists in the formulation of a\nnovel algebraic set theory which is proved to be equiconsistent to New\nFoundations (NF), and which can be modulated to correspond to intuitionistic or\nclassical NF, with or without atoms. A key axiom of this theory expresses that\nits structures have an endofunctor with natural properties.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We describe a method for generating graphs that provide difficult examples\nfor practical Graph Isomorphism testers. We first give the theoretical\nconstruction, showing that we can have a family of graphs without any\nnon-trivial automorphisms which also have high Weisfeiler-Leman dimension. The\nconstruction is based on properties of random 3XOR-formulas. We describe how to\nconvert such a formula into a graph which has the desired properties with high\nprobability. We validate the method by an experimental implementation. We\nconstruct random formulas and validate them with a SAT solver to filter through\nsuitable ones, and then convert them into graphs. Experimental results\ndemonstrate that the resulting graphs do provide hard examples that match the\nhardest known benchmarks for graph isomorphism.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A recommender system based on ranks is proposed, where an expert's ranking of\na set of objects and a user's ranking of a subset of those objects are combined\nto make a prediction of the user's ranking of all objects. The rankings are\nassumed to be induced by latent continuous variables corresponding to the\ngrades assigned by the expert and the user to the objects. The dependence\nbetween the expert and user grades is modelled by a copula in some parametric\nfamily. Given a prior distribution on the copula parameter, the user's complete\nranking is predicted by the mode of the posterior predictive distribution of\nthe user's complete ranking conditional on the expert's complete and the user's\nincomplete rankings. Various Markov chain Monte-Carlo algorithms are proposed\nto approximate the predictive distribution or only its mode. The predictive\ndistribution can be obtained exactly for the Farlie-Gumbel-Morgenstern copula\nfamily, providing a benchmark for the approximation accuracy of the algorithms.\nThe method is applied to the MovieLens 100k dataset with a Gaussian copula\nmodelling dependence between the expert's and user's grades.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Quasi-elliptic cohomology is a variant of elliptic cohomology theories. It is\nthe orbifold K-theory of a space of constant loops. For global quotient\norbifolds, it can be expressed in terms of equivariant K-theories. Thus, the\nconstructions on it can be made in a neat way. This theory reflects the\ngeometric nature of the Tate curve. In this paper we provide a systematic\nintroduction of its construction and definition.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This thesis is devoted to various questions connected with duality. It is\ncomposed of two parts. The first part discusses some aspects of timelike\nT-duality. We explore the possibility of compactification of supergravity\ntheories with various signatures (low energy limit of $M$-theories which are\ndual under timelike T-dualities) on parallelizable internal seven dimensional\n(pseudo-)spheres. We show that, beside the standard theory, only one of the\ndual theories known as $M'$-theory can admit such a solution. The effective\nfour dimensional theory is non-supersymmetric and due to the presence of\ntorsion the symmetry of seven dimensional (pseudo-)sphere breaks down to\n$Spin(3,4)$. In the second part, in an attempt to have a systematic discussion\nof gaugings in supergravity, we show the isomorphism between the space of local\ndeformations of the appropriate zero coupling limit of the embedding tensor\nLagrangian and that of the second-order scalar-vector Lagrangian, describing\nthe bosonic sector of supergravity ignoring gravity, in a chosen duality frame\ndetermined by embedding tensors. We analyze the BV-BRST deformation of a class\nof scalar-vector coupled Lagrangians, which contains supergravity Lagrangians\nas examples, and find a set of constraints that guarantee the consistency of\nthe deformations of the Lagrangians. We show in principle that for a large\nclass of theories considered in this thesis, the only deformations are those of\nthe Yang-Mills type associated with a subgroup of the rigid symmetries.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In recent years an increasing number of researchers and practitioners have\nbeen suggesting algorithms for large-scale neural network architecture search:\ngenetic algorithms, reinforcement learning, learning curve extrapolation, and\naccuracy predictors. None of them, however, demonstrated high-performance\nwithout training new experiments in the presence of unseen datasets. We propose\na new deep neural network accuracy predictor, that estimates in fractions of a\nsecond classification performance for unseen input datasets, without training.\nIn contrast to previously proposed approaches, our prediction is not only\ncalibrated on the topological network information, but also on the\ncharacterization of the dataset-difficulty which allows us to re-tune the\nprediction without any training. Our predictor achieves a performance which\nexceeds 100 networks per second on a single GPU, thus creating the opportunity\nto perform large-scale architecture search within a few minutes. We present\nresults of two searches performed in 400 seconds on a single GPU. Our best\ndiscovered networks reach 93.67% accuracy for CIFAR-10 and 81.01% for\nCIFAR-100, verified by training. These networks are performance competitive\nwith other automatically discovered state-of-the-art networks however we only\nneeded a small fraction of the time to solution and computational resources.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The origin of the so-called $p$-isotopes $^{92,94}\\mathrm{Mo}$ and\n$^{96,98}\\mathrm{Ru}$ in the solar system remains a mystery as several\nastrophysical scenarios fail to account for them. In addition, data on presolar\nsilicon carbide grains of type X (SiC X) exhibit peculiar Mo patterns,\nespecially for $^{95,97}\\mathrm{Mo}$. We examine production of Mo and Ru\nisotopes in neutrino-driven winds associated with core-collapse supernovae\n(CCSNe) over a wide range of conditions. We find that proton-rich winds can\nmake dominant contributions to the solar abundance of $^{98}\\mathrm{Ru}$,\nsignificant contributions to those of $^{96}$Ru ($\\lesssim 40\\%$) and $^{92}$Mo\n($\\lesssim 27\\%$), and relatively minor contributions to that of $^{94}$Mo\n($\\lesssim 14\\%$). In contrast, neutron-rich winds make negligible\ncontributions to the solar abundances of $^{92,94}$Mo and cannot produce\n$^{96,98}$Ru. However, we show that some neutron-rich winds can account for the\npeculiar Mo patterns in SiC X grains. Our results can be generalized if\nconditions similar to those studied here are also obtained for other types of\nejecta in either CCSNe or neutron star mergers.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We suggest a Hamiltonian formulation for the spin Ruijsenaars-Schneider\nsystem in the trigonometric case. Within this interpretation, the phase space\nis obtained by a quasi-Hamiltonian reduction performed on (the cotangent bundle\nto) a representation space of a framed Jordan quiver. For arbitrary quivers,\nanalogous varieties were introduced by Crawley-Boevey and Shaw, and their\ninterpretation as quasi-Hamiltonian quotients was given by Van den Bergh. Using\nVan den Bergh's formalism, we construct commuting Hamiltonian functions on the\nphase space and identify one of the flows with the spin Ruijsenaars-Schneider\nsystem. We then calculate all the Poisson brackets between local coordinates,\nthus answering an old question of Arutyunov and Frolov. We also construct a\ncomplete set of commuting Hamiltonians and integrate all the flows explicitly.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Thermal radiation from bulk disorderly placed nonresonant emitters is\nincoherent, broadband and isotropic. In an external magnetic field the thermal\nradiation from any source is circularly polarized. Here we propose a thermal\nradiation source which emits circularly polarized radiation and which is not\nplaced in a magnetic field. The thermal source consists of a slab waveguide\nwith etched chiral metasurface. Due to the absence of a mirror symmetry of the\nmetasurface, the thermally generated electromagnetic waves become circularly\npolarized. In this letter we discuss the origin of this phenomenon in details.\nUsing the Fourier modal method we analyze the eigenmodes of the structure and\nthe emissivity spectra. We demonstrate that the degree of circular polarization\nin an optimized structure can be as high as 0.87.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we propose an end-to-end trainable deep neural network model\nfor egocentric activity recognition. Our model is built on the observation that\negocentric activities are highly characterized by the objects and their\nlocations in the video. Based on this, we develop a spatial attention mechanism\nthat enables the network to attend to regions containing objects that are\ncorrelated with the activity under consideration. We learn highly specialized\nattention maps for each frame using class-specific activations from a CNN\npre-trained for generic image recognition, and use them for spatio-temporal\nencoding of the video with a convolutional LSTM. Our model is trained in a\nweakly supervised setting using raw video-level activity-class labels.\nNonetheless, on standard egocentric activity benchmarks our model surpasses by\nup to +6% points recognition accuracy the currently best performing method that\nleverages hand segmentation and object location strong supervision for\ntraining. We visually analyze attention maps generated by the network,\nrevealing that the network successfully identifies the relevant objects present\nin the video frames which may explain the strong recognition performance. We\nalso discuss an extensive ablation analysis regarding the design choices.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Magnetic skyrmions are vortex-like topological spin textures often observed\nto form a triangular-lattice skyrmion crystal in structurally chiral magnets\nwith Dzyaloshinskii-Moriya interaction. Recently $\\beta$-Mn structure-type\nCo-Zn-Mn alloys were identified as a new class of chiral magnet to host such\nskyrmion crystal phases, while $\\beta$-Mn itself is known as hosting an\nelemental geometrically frustrated spin liquid. Here we report the intermediate\ncomposition system Co$_7$Zn$_7$Mn$_6$ to be a unique host of two disconnected,\nthermal-equilibrium topological skyrmion phases; one is a conventional skyrmion\ncrystal phase stabilized by thermal fluctuations and restricted to exist just\nbelow the magnetic transition temperature $T_\\mathrm{c}$, and the other is a\nnovel three-dimensionally disordered skyrmion phase that is stable well below\n$T_\\mathrm{c}$. The stability of this new disordered skyrmion phase is due to a\ncooperative interplay between the chiral magnetism with Dzyaloshinskii-Moriya\ninteraction and the frustrated magnetism inherent to $\\beta$-Mn.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper describes a method for achieving continuous deterministic\n360$^{\\circ} $ magnetic moment rotations in single domain magnetoelastic discs,\nand examines the performance bounds for a mechanically lossless multiferroic\nbead-on-a-disc motor based on dipole coupling these discs to small magnetic\nnanobeads. The continuous magnetic rotations are attained by controlling the\nrelative orientation of a four-fold anisotropy (e.g., cubic magnetocrystalline\nanisotropy) with respect to the two-fold magnetoelastic anisotropy. This\napproach produces continuous rotations from the quasi-static regime up through\noperational frequencies of several GHz. Driving strains of only $\\approx$90 to\n180 ppm are required for operation of motors using existing materials. The\nlarge operational frequencies and small sizes, with lateral dimensions of\n$\\approx$100s of nanometers, produce large power densities for the rotary\nbead-on-a-disc motor, and a newly proposed linear variant, in a size range\nwhere power dense alternative technologies do not currently exist.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Future generations of communications systems will target a very wide range of\napplications. Each application comes with its own set of requirements in terms\nof data rate, latency, user density, reliability... Accommodating this large\nvariety of specifications implies the need for a novel physical layer\ntechnology. In this regard, the most popular modulation nowadays, namely, the\northogonal frequency division multiplexing modulation, is characterized by a\npoor time-frequency localization, implying strong limitations. In the light of\nthese limitations, communications using new waveforms, relying on more\nsophisticated signal processing techniques and providing improved\ntime-frequency localization, have attracted a lot of attention for the last\ndecade. At the same time, the higher complexity of these new waveforms, not\nonly in terms of implementation but also conceptually, creates an entrance\nbarrier that slows down their adoption by industries, standardization bodies\nand more generally in the telecommunication community. The WaveComBox toolbox,\nfreely available at www.wavecombox.com, is a user-friendly, open-source and\nwell documented piece of software aiming at considerably lowering the entrance\nbarrier of recently proposed waveforms. This article first describes the\ngeneral abstract structure of the toolbox. Secondly, examples are given to\nillustrate how to use the toolbox and to show some more advanced\nfunctionalities.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The goal of this paper is to study the subspace of stability condition\n$\\Sigma_{\\mathcal{E}}\\subset \\mathrm{Stab}(X)$ associated to an exceptional\ncollection $\\mathcal{E}$ on a projective variety $X$. Following Emanuele\nMacr\\`{i}'s approach, we show a certain correspondence between the homotopy\nclass of continuous loops in $\\Sigma_{\\mathcal{E}}$ and words of the braid\ngroup. In particular, we prove that in the case $X=\\mathbb{P}^3$ and\n$\\mathcal{E}=\\{\\mathcal{O},\\mathcal{O}(1),\\mathcal{O}(2),\\mathcal{O}(3)\\}$, the\nspace $\\Sigma_{\\mathcal{E}}$ is a connected and simply connected 4-dimensional\nmanifold.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper proposes a novel approach for designing channel estimation,\nbeamforming and scheduling jointly for wideband massive multiple input multiple\noutput (MIMO) systems. With the proposed approach, we first quantify the\nmaximum number of user equipments (UEs) that can send pilots which may or may\nnot be orthogonal. Specifically, when the channel has a maximum of $L$\nmultipath taps, and we allocate $\\tilde{M}$ sub-carriers for the channel state\ninformation (CSI) estimation, a maximum of $\\tilde{M}$ UEs CSI can be estimated\n($L$ times compared to the conventional CSI estimation approach) in a massive\nMIMO regime. Then, we propose to schedule a subset of these UEs using greedy\nbased scheduling to transmit their data on each sub-carrier with the proposed\njoint beamforming and scheduling design. We employ the well known maximum ratio\ncombiner (MRC) beamforming approach in the uplink channel data transmission.\nAll the analytical expressions are validated via numerical results, and the\nsuperiority of the proposed design over the conventional orthogonal frequency\ndivision multiplexing (OFDM) transmission approach is demonstrated using\nextensive numerical simulations in the long term evolution (LTE) channel\nenvironment. The proposed channel estimation and beamforming design is linear\nand simple to implement.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The $\\Lambda$CDM model is the current standard model in cosmology thanks to\nits ability to reproduce the observations. Its first observational evidence\nappeared from the type Ia supernovae (SNIa) Hubble diagram. However, there has\nbeen some debate in the literature concerning the statistical treatment of\nSNIa. In this paper we relax the standard assumption that SNIa intrinsic\nluminosity is independent of the redshift, and we examine whether it may have\nan impact on the accelerated nature of the expansion of the Universe. In order\nto be as general as possible, we reconstruct the expansion rate of the Universe\nthrough a cubic spline interpolation fitting observations of different probes:\nSNIa, baryon acoustic oscillations (BAO), and the high-redshift information\nfrom the cosmic microwave background (CMB). We show that when SNIa intrinsic\nluminosity is not allowed to vary as a function of the redshift, cosmic\nacceleration is definitely proven in a model-independent approach. However,\nallowing for a redshift dependence, a non-accelerated reconstruction of the\nexpansion rate is able to fit, as well as $\\Lambda$CDM, the combination of SNIa\nand BAO data, both treating the BAO standard ruler $r_d$ as a free parameter,\nor adding the recently published prior from CMB observations. We further extend\nthe analysis by including the CMB data, and we show that a non-accelerated\nreconstruction is able to nicely fit this combination of low and high-redshift\ndata. In this work we present a model-independent reconstruction of a\nnon-accelerated expansion rate of the Universe that is able to nicely fit all\nthe main background cosmological probes. However, the predicted value of $H_0$\nis in tension with recent direct measurements. Our analysis points out that a\nfinal, reliable, and consensual value for $H_0$ would be critical to\ndefinitively prove the cosmic acceleration in a model-independent way.\n[Abridged]\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Our aim is for Wibson to be a blockchain-based, decentralized data\nmarketplace that provides individuals a way to securely and anonymously sell\ninformation in a trusted environment. The combination of the Wibson token and\nblockchain-enabled smart contracts hopes to allow Data Sellers and Data Buyers\nto transact with each other directly while providing individuals the ability to\nmaintain anonymity as desired.\n  Wibson intends that its data marketplace will provide infrastructure and\nfinancial incentives for individuals to securely sell personal information\nwithout sacrificing personal privacy. Data Buyers receive information from\nwilling and actively participating individuals with the benefit of knowing that\nthe personal information should be accurate and current.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Han Chinese experienced substantial population migrations and admixture in\nhistory, yet little is known about the evolutionary process of Chinese\ndialects. Here, we used phylogenetic approaches and admixture inference to\nexplicitly decompose the underlying structure of the diversity of Chinese\ndialects, based on the total phoneme inventories of 140 dialect samples from\nseven traditional dialect groups: Mandarin, Wu, Xiang, Gan, Hakka, Min and Yue.\nWe found a north-south gradient of phonemic differences in Chinese dialects\ninduced from historical population migrations. We also quantified extensive\nhorizontal language transfers among these dialects, corresponding to the\ncomplicated socio-genetic history in China. We finally identified that the\nmiddle latitude dialects of Xiang, Gan and Hakka were formed by admixture with\nother four dialects. Accordingly, the middle-latitude areas in China were a\nlinguistic melting pot of northern and southern Han populations. Our study\nprovides a detailed phylogenetic and historical context against family-tree\nmodel in China.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the stochastically perturbed cubic difference equation with\nvariable coefficients \\[ x_{n+1}=x_n(1-h_nx_n^2)+\\rho_{n+1}\\xi_{n+1}, \\quad\nn\\in \\mathbb N,\\quad x_0\\in \\mathbb R. \\] Here $(\\xi_n)_{n\\in \\mathbb N}$ is a\nsequence of independent random variables, and $(\\rho_n)_{n\\in \\mathbb N}$ and\n$(h_n)_{n\\in \\mathbb N}$ are sequences of nonnegative real numbers. We can stop\nthe sequence $(h_n)_{n\\in \\mathbb N}$ after some random time $\\mathcal N$ so it\nbecomes a constant sequence, where the common value is an\n$\\mathcal{F}_\\mathcal{N}$-measurable random variable. We derive conditions on\nthe sequences $(h_n)_{n\\in \\mathbb N}$, $(\\rho_n)_{n\\in \\mathbb N}$ and\n$(\\xi_n)_{n\\in \\mathbb N}$, which guarantee that $\\lim_{n\\to \\infty} x_n$\nexists almost surely (a.s.), and that the limit is equal to zero a.s. for any\ninitial value $ x_0\\in \\mathbb R$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In dense starless and protostellar cores, the relative abundance of\ndeuterated species to their non-deuterated counterparts can become orders of\nmagnitude greater than in the local interstellar medium. This enhancement\nproceeds through multiple pathways in the gas phase and on dust grains, where\nthe chemistry is strongly dependent on the physical conditions. In this\nChapter, we discuss how sensitive, high resolution observations with the ngVLA\nof emission from deuterated molecules will trace both the dense gas structure\nand kinematics on the compact physical scales required to track the\ngravitational collapse of star-forming cores and the subsequent formation of\nyoung protostars and circumstellar accretion regions. Simultaneously, such\nobservations will play a critical role in tracing the chemical history\nthroughout the various phases of star and planet formation. Many low-J\ntransitions of key deuterated species, along with their undeuterated\ncounterparts, lie within the 60-110 GHz frequency window, the lower end of\nwhich is largely unavailable with current facilities and instrumentation. The\ncombination of sensitivity and angular resolution provided only by the ngVLA\nwill enable unparalleled detailed studies of the physics and chemistry of the\nearliest stages of star formation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a 69 arcmin$^2$ ALMA survey at 1.1mm, GOODS-ALMA, matching the\ndeepest HST-WFC3 H-band part of the GOODS-South field. We taper the 0\"24\noriginal image with a homogeneous and circular synthesized beam of 0\"60 to\nreduce the number of independent beams - thus reducing the number of purely\nstatistical spurious detections - and optimize the sensitivity to point\nsources. We extract a catalogue of galaxies purely selected by ALMA and\nidentify sources with and without HST counterparts down to a 5$\\sigma$ limiting\ndepth of H=28.2 AB (HST/WFC3 F160W). ALMA detects 20 sources brighter than 0.7\nmJy in the 0\"60 tapered mosaic (rms sensitivity =0.18 mJy/beam) with a purity\ngreater than 80%. Among these detections, we identify three sources with no HST\nnor Spitzer-IRAC counterpart, consistent with the expected number of spurious\ngalaxies from the analysis of the inverted image; their definitive status will\nrequire additional investigation. An additional three sources with HST\ncounterparts are detected either at high significance in the higher resolution\nmap, or with different detection-algorithm parameters ensuring a purity greater\nthan 80%. Hence we identify in total 20 robust detections. Our wide contiguous\nsurvey allows us to push further in redshift the blind detection of massive\ngalaxies with ALMA with a median redshift of $z$=2.92 and a median stellar mass\nof M$_{\\star}$ = 1.1 $\\times 10^{11}$M$_\\odot$. Our sample includes 20%\nHST-dark galaxies (4 out of 20), all detected in the mid-infrared with IRAC.\nThe near-infrared based photometric redshifts of two of them $z\\sim$4.3 and\n4.8) suggest that these sources have redshifts $z$>4. At least 40% of the ALMA\nsources host an X-ray AGN, compared to 14% for other galaxies of similar mass\nand redshift. The wide area of our ALMA survey provides lower values at the\nbright end of number counts than single-dish telescopes\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Inspired by a theorem of Bhatt-Morrow-Scholze, we develop a stacky approach\nto crystals and isocrystals on \"Frobenius-smooth\" schemes over F_p . This class\nof schemes goes back to Berthelot-Messing and contains all smooth schemes over\nperfect fields of characteristic p.\n  To treat isocrystals, we prove some descent theorems for sheaves of Banachian\nmodules, which could be interesting in their own right.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Digitization provides a sound and complete method to reduce the problem of\nverifying whether a real-time system satisfies a property under dense-time\nsemantics to whether the same real-time system satisfies the property over\ndiscrete-time. This is a brief overview of digitization of real-time models and\nlogics covering known results, value, limitations, and alternatives.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The safety, mobility, environmental, energy, and economic benefits of\ntransportation systems, which are the focus of recent connected vehicle (CV)\nprograms, are potentially dramatic. However, realization of these benefits\nlargely hinges on the timely integration of digital technology into upcoming as\nwell as existing transportation infrastructure. CVs must be enabled to\nbroadcast and receive data to and from other CVs [vehicle-to-vehicle (V2V)\ncommunication], to and from infrastructure [vehicle-to-infrastructure (V2I)\ncommunication], and to and from other road users, such as bicyclists or\npedestrians (vehicle-to-other road users communication). Further, the\ninfrastructure and transportation agencies that manage V2I-focused applications\nmust be able to collect, process, distribute, and archive these data quickly,\nreliably, and securely. This paper focuses on V2I applications and investigates\ncurrent digital roadway infrastructure initiatives. It highlights the\nimportance of including digital infrastructure investment alongside investment\nin more traditional transportation infrastructure to keep up with the auto\nindustry push toward increasing intervehicular communication. By studying\ncurrent CV testbeds and smart-city initiatives, this paper identifies digital\ninfrastructure being used by public agencies. It also examines public agencies\nlimited budgeting for digital infrastructure and finds that current expenditure\nis inadequate for realizing the potential benefits of V2I applications.\nFinally, the paper presents a set of recommendations, based on a review of\ncurrent practices and future needs, designed to guide agencies responsible for\ntransportation infrastructure. It stresses the importance of collaboration for\nestablishing national and international platforms for the planning, deployment,\nand management of digital infrastructure to support connected transportation\nsystems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate $\\mathcal F$-Borel topological spaces. We focus on finding out\nhow a~complexity of a~space depends on where the~space is embedded. Of\na~particular interest is the~problem of determining whether a~complexity of\ngiven space $X$ is absolute (that is, the~same in every compactification of\n$X$). We show that the~complexity of metrizable spaces is absolute and provide\na~sufficient condition for a~topological space to be absolutely $\\mathcal\nF_{\\sigma\\delta}$. We then investigate the~relation between local and global\ncomplexity. To improve our understanding of $\\mathcal F$-Borel spaces, we\nintroduce different ways of representing an~$\\mathcal F$-Borel set. We use\nthese tools to construct a~hierarchy of $\\mathcal F$-Borel spaces with\nnon-absolute complexity, and to prove several other results.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In the appropriate limit, a type IIB string theory setup involving D3 branes,\nwrapped D5 branes, and fluxes on a conifold generally leads to a supergravity\nbackground involving a warped version of the conifold with fluxes. We study the\nsupergravity dual of the baryonic branch of the Klebanov Strassler theory by\nwriting down a very general conifold metric--the non-K\\\"ahler resolved\nwarped-deformed conifold--and a general set of fluxes that satisfy the\nsupergravity equations of motion, and derive the necessary constraints that\nallow the geometry to be dual to an $\\mathcal{N}=1$ supersymmetric gauge theory\nin $3+1$ dimensions. These backgrounds encompass known solutions, such as the\nKS, MN and Butti et al. models, but the added layer of generality can lead to a\nlarger class of gauge-gravity dualities. We also present many consistency\nchecks that validate our background matches known cases for certain values in\nour parameter space. This is a companion paper to arXiv:1805.03676 [hep-th]\ncovering the section 'IR physics, dualities, and supersymmetry'.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the long-wavelength excitations of the inner crust of neutron stars,\nconsidering three phases: cubic crystal at low densities, rods and plates near\nthe core-crust transition. To describe the phonons, we write an effective\nLagrangian density in terms of the coarse-grained phase of the neutron\nsuperfluid gap and of the average displacement field of the clusters. The\nkinetic energy, including the entrainment of the neutron gas by the clusters,\nis obtained within a superfluid hydrodynamics approach. The potential energy is\ndetermined from a model where clusters and neutron gas are considered in phase\ncoexistence, augmented by the elasticity of the lattice due to Coulomb and\nsurface effects. All three phases show strong anisotropy, i.e., angle\ndependence of the phonon velocities. Consequences for the specific heat at low\ntemperature are discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Inspired by the success of Convolutional Neural Networks (CNNs) for\nsupervised prediction in images, we design the Deconvolutional Generative Model\n(DGM), a new probabilistic generative model whose inference calculations\ncorrespond to those in a given CNN architecture. The DGM uses a CNN to design\nthe prior distribution in the probabilistic model. Furthermore, the DGM\ngenerates images from coarse to finer scales. It introduces a small set of\nlatent variables at each scale, and enforces dependencies among all the latent\nvariables via a conjugate prior distribution. This conjugate prior yields a new\nregularizer based on paths rendered in the generative model for training\nCNNs-the Rendering Path Normalization (RPN). We demonstrate that this\nregularizer improves generalization, both in theory and in practice. In\naddition, likelihood estimation in the DGM yields training losses for CNNs, and\ninspired by this, we design a new loss termed as the Max-Min cross entropy\nwhich outperforms the traditional cross-entropy loss for object classification.\nThe Max-Min cross entropy suggests a new deep network architecture, namely the\nMax-Min network, which can learn from less labeled data while maintaining good\nprediction performance. Our experiments demonstrate that the DGM with the RPN\nand the Max-Min architecture exceeds or matches the-state-of-art on benchmarks\nincluding SVHN, CIFAR10, and CIFAR100 for semi-supervised and supervised\nlearning tasks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report on the experience of developing Merlin, a language server for the\nOCaml programming language in development since 2013. Merlin is a daemon that\nconnects to your favourite text editor and provides services that require a\nfine-grained understanding of the programming language syntax and static\nsemantics: instant feedback on warnings and errors, autocompletion, `type of\nthe code under the cursor', `go to definition', etc.\n  Language servers need to handle incomplete and partially-incorrect programs,\nand try to be incremental to minimize recomputation after small editing\nactions. Merlin was built by carefully adapting the existing tools (the\nOCamllex lexer and Menhir parser generators) to better support incrementality,\nincompleteness and error handling. These extensions are elegant and general, as\ndemonstrated by the interesting, unplanned uses that the OCaml community found\nfor them. They could be adapted to other frontends -- in any language.\n  Besides incrementality, we discuss the way Merlin communicates with editors,\ndescribe the design decisions that went into some demanding features and report\non some of the non-apparent difficulties in building good editor support,\nemerging from expressive programming languages or frustrating tooling\necosystems.\n  We expect this experience report to be of interest to authors of interactive\nlanguage tooling for any programming language; many design choices may be\nreused, and some hard-won lessons can serve as warnings.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The collective excitation spectrum of two-dimensional (2D) antimonene is\ncalculated beyond the low energy continuum approximation. The dynamical\npolarizability is computed using a 6-orbitals tight-binding model that properly\naccounts for the band structure of antimonene in a broad energy range.\nElectron-electron interaction is considered within the random phase\napproximation. The obtained spectrum is rich, containing the standard\nintra-band 2D plasmon and a set of single inter-band modes. We find that\nspin-orbit interaction plays a fundamental role in the reconstruction of the\nexcitation spectrum, with the emergence of novel inter-band branches in the\ncontinuum that interact with the plasmon.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  With the development of real-time networks such as reactive embedded systems,\nthere is a need to compute deterministic performance bounds. This paper focuses\non the performance guarantees and stability conditions in networks with cyclic\ndependencies in the network calculus framework. We first propose an algorithm\nthat computes tight backlog bounds in tree networks for any set of flows\ncrossing a server. Then, we show how this algorithm can be applied to improve\nbounds from the literature fir any topology, including cyclic networks. In\nparticular, we show that the ring is stable in the network calculus framework.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the Cauchy problem of the semilinear wave equation with a damping\nterm \\begin{align*}\n  u_{tt} - \\Delta u + c(t,x) u_t = |u|^p, \\quad (t,x)\\in (0,\\infty)\\times\n\\mathbb{R}^N,\\quad\n  u(0,x) = \\varepsilon u_0(x), \\ u_t(0,x) = \\varepsilon u_1(x), \\quad x\\in\n\\mathbb{R}^N, \\end{align*} where $p>1$ and the coefficient of the damping term\nhas the form \\begin{align*}\n  c(t,x) = a_0 (1+|x|^2)^{-\\alpha/2} (1+t)^{-\\beta} \\end{align*} with some $a_0\n> 0$, $\\alpha < 0$, $\\beta \\in (-1, 1]$. In particular, we mainly consider the\ncases $ \\alpha < 0, \\beta =0$ or $\\alpha < 0, \\beta = 1$, which imply $\\alpha +\n\\beta < 1$, namely, the damping is spatially increasing and effective. Our aim\nis to prove that the critical exponent is given by $ p = 1+\n\\frac{2}{N-\\alpha}$. This shows that the critical exponent is the same as that\nof the corresponding parabolic equation $c(t,x) v_t - \\Delta v = |v|^p$. The\nglobal existence part is proved by a weighted energy estimates with an\nexponential-type weight function and a special case of the\nCaffarelli-Kohn-Nirenberg inequality. The blow-up part is proved by a\ntest-function method introduced by Ikeda and Sobajima (arXiv:1710.06780v1). We\nalso give an upper estimate of the lifespan.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Control of complex systems involves both system identification and controller\ndesign. Deep neural networks have proven to be successful in many\nidentification tasks, however, from model-based control perspective, these\nnetworks are difficult to work with because they are typically nonlinear and\nnonconvex. Therefore many systems are still identified and controlled based on\nsimple linear models despite their poor representation capability. In this\npaper we bridge the gap between model accuracy and control tractability faced\nby neural networks, by explicitly constructing networks that are convex with\nrespect to their inputs. We show that these input convex networks can be\ntrained to obtain accurate models of complex physical systems. In particular,\nwe design input convex recurrent neural networks to capture temporal behavior\nof dynamical systems. Then optimal controllers can be achieved via solving a\nconvex model predictive control problem. Experiment results demonstrate the\ngood potential of the proposed input convex neural network based approach in a\nvariety of control applications. In particular we show that in the MuJoCo\nlocomotion tasks, we could achieve over 10% higher performance using 5* less\ntime compared with state-of-the-art model-based reinforcement learning method;\nand in the building HVAC control example, our method achieved up to 20% energy\nreduction compared with classic linear models.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present an analytic description of tides raised on a star by a small\norbiting body. In particular, we highlight the disproportionate effect of\neccentricity and thus the scope for using these tides to detect and\ncharacterise the orbits of exoplanets and brown dwarfs. The tidal distortions\nof the star produced by an eccentric orbit are, in comparison to a circular\norbit, much richer in detail, and potentially visible from any viewing angle.\nThe magnitude of these variations is much larger than that in a circular orbit\nof the same semi-major axis. These variations are visible in both photometric\nand spectroscopic data, and dominate other regular sources of phase variability\n(e.g reflection and Doppler beaming) over a particularly interesting portion of\nparameter space. These tidal signatures will be a useful tool for planet\ndetection on their own, and used in concert with other methods provide powerful\nconstraints on planetary and stellar properties.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the highest spatial resolution ALMA observations to date of the\nClass I protostar GY 91 in the $\\rho$ Ophiuchus L1688 molecular cloud complex.\nOur 870 $\\mu$m and 3 mm dust continuum maps show that the GY 91 disk has a\nradius of $\\sim$80 AU, and an inclination of $\\sim$40$^{\\circ}$, but most\ninterestingly that the disk has three dark lanes located at 10 AU, 40 AU, and\n70 AU. We model these features assuming they are gaps in the disk surface\ndensity profile and find that their widths are 7 AU, 30 AU, and 10 AU. These\ngaps bear a striking resemblance to the gaps seen in the HL Tau disk,\nsuggesting that there may be Saturn-mass planets hiding in the disk. To\nconstrain the relative ages of GY 91 and HL Tau, we also model the disk and\nenvelope of HL Tau and find that they are of similar ages, although GY 91 may\nbe younger. Although snow lines and magnetic dead zones can also produce dark\nlanes, if planets are indeed carving these gaps then Saturn-mass planets must\nform within the first $\\sim$0.5 Myr of the lifetime of protoplanetary disks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Applying linear response and the magnetic force theorem in correlated density\nfunctional theory, the inter-sublattice exchange constants of antiferromagnetic\nEu are calculated and found to vanish near the pressure of P$_c$=82 GPa, just\nwhere magnetic order is observed experimentally to be lost. The Eu $4f^7$\nmoment remains unchanged at high pressure, again in agreement with\nspectroscopic measurements, leaving the picture of perfect frustration of\ninteratomic Ruderman-Kittel-Kasuya-Yoshida couplings in a broad metallic\nbackground, leaving a state of electrons strongly exchange coupled to\narbitrarily oriented, possibly quasistatic local moments. This strongly\nfrustrated state gives way to superconductivity at T$_c$=1.7K, observed\nexperimentally. These phenomena, and free energy considerations related to\ncorrelations, suggest an unusual phase of matter that is discussed within the\nscenarios of the Doniach Kondo lattice phase diagram, the metallic spin glass\nclass, and itinerant spin liquid or spin gas systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we propose a new SVRG-style acceleated stochastic algorithm\nfor solving a family of non-convex optimization problems whose objective\nconsists of a sum of $n$ smooth functions and a non-smooth convex function. Our\nmajor goal is to improve the convergence of SVRG-style stochastic algorithms to\nstationary points under a setting with a large condition number $c$ - the ratio\nbetween the smoothness constant and the negative curvature constant. The\nproposed algorithm achieves the best known gradient complexity when $c\\geq\n\\Omega(n)$, which was achieved previously by a SAGA-style accelerated\nstochastic algorithm. Compared with the SAGA-style accelerated stochastic\nalgorithm, the proposed algorithm is more practical due to its low memory cost\nthat is inherited from previous SVRG-style algorithms. Compared with previous\nstudies on SVRG-style stochastic algorithms, our theory provides much stronger\nresults in terms of (i) reduced gradient complexity under a large condition\nnumber; and (ii) that the convergence is proved for a sampled stagewise\naveraged solution that is selected from all stagewise averaged solutions with\nincreasing sampling probabilities instead of for a uniformly sampled solutions\nacross all iterations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Chemically resolved electrical measurements (CREM) of zinc oxysulfide (ZnOS)\nover-layers on gold show very poor conductance under either electrical or\noptical input signals, whereas simultaneous application of the two yields\nextremely high sample currents. The effect and its dependence on wavelength and\nelectrical parameters is explained by the in-situ derived band diagram, in\nwhich a buffer level of charge traps cannot contribute directly to conductance,\nhowever amplifies the photoconductance by orders of magnitudes under\nsub-bandgap illumination. This AND-type doubly-triggered response proposes\ninteresting applications and an answer to problems encountered in related\noptoelectronic devices.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The use of special quantum states to achieve sensitivities below the limits\nestablished by classically behaving states has enjoyed immense success since\nits inception. In bosonic interferometers, squeezed states, number states and\ncat states have been implemented on various platforms and have demonstrated\nimproved measurement precision over interferometers based on coherent states.\nAnother metrologically useful state is an equal superposition of two\neigenstates with maximally different energies; this state ideally reaches the\nfull interferometric sensitivity allowed by quantum mechanics. By leveraging\nimprovements to our apparatus made primarily to reach higher operation\nfidelities in quantum information processing, we extend a technique to create\nnumber states up to $n=100$ and to generate superpositions of a harmonic\noscillator ground state and a number state of the form\n$\\textstyle{\\frac{1}{\\sqrt{2}}}(\\lvert 0\\rangle+\\lvert n\\rangle)$ with $n$ up\nto 18 in the motion of a single trapped ion. While experimental imperfections\nprevent us from reaching the ideal Heisenberg limit, we observe enhanced\nsensitivity to changes in the oscillator frequency that initially increases\nlinearly with $n$, with maximal value at $n=12$ where we observe 3.2(2) dB\nhigher sensitivity compared to an ideal measurement on a coherent state with\nthe same average occupation number. The quantum advantage from using\nnumber-state superpositions can be leveraged towards precision measurements on\nany harmonic oscillator system; here it enables us to track the average\nfractional frequency of oscillation of a single trapped ion to approximately\n2.6 $\\times$ 10$^{-6}$ in 5 s. Such measurements should provide improved\ncharacterization of imperfections and noise on trapping potentials, which can\nlead to motional decoherence, a leading source of error in quantum information\nprocessing with trapped ions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In the present work we introduce a computational approach to the absolute\nrovibrational quantum partition function using the path-integral formalism of\nquantum mechanics in combination with the nested sampling technique. The\nnumerical applicability of path-integral nested sampling is demonstrated for\nsmall molecules of spectroscopic interest. The computational cost of the method\nis determined by the evaluation time of a point on the potential-energy surface\n(PES). For efficient PES implementations, the path-integral nested-sampling\nmethod can be a viable alternative to the direct Boltzmann summation technique\nof variationally computed rovibrational energies, especially for medium-sized\nmolecules and at elevated temperatures.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper concerns space-sphere point processes, that is, point processes on\nthe product space of $\\mathbb R^d$ (the $d$-dimensional Euclidean space) and\n$\\mathbb S^k$ (the $k$-dimen\\-sional sphere). We consider specific classes of\nmodels for space-sphere point processes, which are adaptations of existing\nmodels for either spherical or spatial point processes. For model checking or\nfitting, we present the space-sphere $K$-function which is a natural extension\nof the inhomogeneous $K$-function for point processes on $\\mathbb R^d$ to the\ncase of space-sphere point processes. Under the assumption that the intensity\nand pair correlation function both have a certain separable structure, the\nspace-sphere $K$-function is shown to be proportional to the product of the\ninhomogeneous spatial and spherical $K$-functions. For the presented\nspace-sphere point process models, we discuss cases where such a separable\nstructure can be obtained. The usefulness of the space-sphere $K$-function is\nillustrated for real and simulated datasets with varying dimensions $d$ and\n$k$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It has recently been shown that vacuum expectation values and Feynman path\nintegrals can be regularized using Fourier integral operator $\\zeta$-function,\nyet the physical meaning of these $\\zeta$-regularized objects was unknown.\n  Here we show that $\\zeta$-regularized vacuum expectations appear as continuum\nlimits using a certain discretization scheme. Furthermore, we study the rate of\nconvergence for the discretization scheme using the example of a\none-dimensional hydrogen atom in $(-\\pi,\\pi)$ which we evaluate classically,\nusing the Rigetti Quantum Virtual Machine, and on the Rigetti 8Q quantum chip\n\"Agave\" device. We also provide the free radiation field as an example for the\ncomputation of $\\zeta$-regularized vacuum expectation values in a gauge theory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Two dwarf irregular galaxies DDO 187 and NGC 3738 exhibit a striking pattern\nof star formation: intense star formation is taking place in a large region\noccupying roughly half of the inner part of the optical galaxy. We use data on\nthe HI distribution and kinematics and stellar images and colors to examine the\nproperties of the environment in the high star formation rate (HSF) halves of\nthe galaxies in comparison with the low star formation rate (LSF) halves. We\nfind that the pressure and gas density are higher on the HSF sides by 30-70%.\nIn addition we find in both galaxies that the HI velocity fields exhibit\nsignificant deviations from ordered rotation and there are large regions of\nhigh velocity dispersion and multiple velocity components in the gas beyond the\ninner regions of the galaxies. The conditions in the HSF regions are likely the\nresult of large-scale external processes affecting the internal environment of\nthe galaxies and enabling the current star formation there.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Wasserstein distances are metrics on probability distributions inspired by\nthe problem of optimal mass transportation. Roughly speaking, they measure the\nminimal effort required to reconfigure the probability mass of one distribution\nin order to recover the other distribution. They are ubiquitous in mathematics,\nwith a long history that has seen them catalyse core developments in analysis,\noptimization, and probability. Beyond their intrinsic mathematical richness,\nthey possess attractive features that make them a versatile tool for the\nstatistician: they can be used to derive weak convergence and convergence of\nmoments, and can be easily bounded; they are well-adapted to quantify a natural\nnotion of perturbation of a probability distribution; and they seamlessly\nincorporate the geometry of the domain of the distributions in question, thus\nbeing useful for contrasting complex objects. Consequently, they frequently\nappear in the development of statistical theory and inferential methodology,\nand have recently become an object of inference in themselves. In this review,\nwe provide a snapshot of the main concepts involved in Wasserstein distances\nand optimal transportation, and a succinct overview of some of their many\nstatistical aspects.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A transform that is universally polarizing over a set of channels with memory\nis presented. Memory may be present in both the input to the channel and the\nchannel itself. Both the encoder and the decoder are aware of the input\ndistribution, which is fixed. However, only the decoder is aware of the actual\nchannel being used. The transform can be used to design a universal code for\nthis scenario. The code is to have vanishing error probability when used over\nany channel in the set, and achieve the infimal information rate over the set.\nThe setting considered is, in fact, more general: we consider a set of\nprocesses with memory. Universal polarization is established for the case where\neach process in the set: (a) has memory in the form of an underlying hidden\nMarkov state sequence that is aperiodic and irreducible, and (b) satisfies a\n`forgetfulness' property. Forgetfulness, which we believe to be of independent\ninterest, occurs when two hidden Markov states become approximately independent\nof each other given a sufficiently long sequence of observations between them.\nWe show that aperiodicity and irreducibility of the underlying Markov chain is\nnot sufficient for forgetfulness, and develop a sufficient condition for a\nhidden Markov process to be forgetful.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper derives sparse recurrence relations between orthogonal polynomials\non a triangle and their partial derivatives, which are analogous to recurrence\nrelations for Jacobi polynomials. We derive these recurrences in a systematic\nfashion by introducing ladder operators that map an orthogonal polynomial to\nanother by incrementing or decrementing its associated parameters by one.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In $\\mathcal{N}$=1 supersymmetric Yang-Mills theory the superpartner of the\ngluon is the gluino, which is a spin 1/2 Majorana particle in the adjoint\nrepresentation of the gauge group. Combining three gluinos, it is possible to\nform colour neutral bound states, analogous to baryons in QCD. The correlation\nfunctions of the corresponding baryonic operators contain a contribution\nrepresented by a `sunset diagram', and in addition, unlike in QCD, another\ncontribution represented by a `spectacle diagram'. We present first results\nfrom an implementation and calculation of these objects, obtained from\nnumerical simulations of supersymmetric Yang-Mills theory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the structural ordering and the associated physical behavior of a\nNi-Mn-Si Laves phase, Mn(Ni$_{0.6}$Si$_{0.4})_2$. The high-resolution\ntransmission electron microscopy and electron energy loss spectroscopy analysis\nwere performed to resolve a distinct atomic ordering of the system. The study\ndetermined the origin of the short-range ordering to be the unique arrangement\nbetween Ni and Si atoms. The study also presents the atomic resolution mapping\nof the Si atoms which has never been reported by any previous studies. With\nfurther electrical conductivity measurement, we find one of the consequences of\nthe unique ordering reflected in a semiconducting like temperature dependence\nof the compound.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In previous publications [arXiv:1608.08430, arXiv:1704.06502], the authors\nhave proposed Debye-H\\\"uckel-approximate free-energy functionals of the pair\ndistribution functions for one-component fluid and two-component plasmas. These\nfunctionals yield the corresponding Debye-H\\\"uckel integral equations when they\nare minimized with respect to the pair distribution functions, lead to correct\nthermodynamic relations and fulfill the virial theorem. In the present\naddendum, we update our results by providing simpler functionals that have the\nsame properties. We relate these functionals to the approaches of Lado [Phys.\nRev. A 8:2548, 1973] and of Olivares and McQuarrie [J. Chem. Phys. 65:3604,\n1976]. We also discuss briefly the non-uniqueness issue that is raised by these\nresults.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The possibility of using Infrared Lock-In Thermography (LIT) to estimate the\nthickness of a sample was assessed and shown to be accurate up to 1.8mm. LIT is\na technique involving heating samples with halogen lamps with varying intensity\nover time. The intensity is defined by sinusoidal functions. LIT was conducted\non samples of varying thickness, gradient, and shape. The Lock-In phase signals\nwere calculated, and a database was then created with the data obtained and was\nused to estimate the thickness based on the original phase signal. A\nrelationship between gradient and phase signal was also shown based on our\ndata, contrary to current findings in existing literature.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  An issue of the parameter selection in various branches of a multi-antenna\nreceiver system determines its effectiveness. A significant effect on these\nparameters are correlation properties of received signals. In this paper, the\nassessment of the signal correlation properties for different environmental\nconditions is presented. The obtained results showed that depending on the\nreceiver speed, the adaptive selection of the delays in the different RAKE\nreceiver branches provide minimization of the correlation between the signals.\nParticularly low levels of the signal correlation could be obtained in complex\npropagation environments such as urban and bad urban.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study networks of human decision-makers who independently decide how to\nprotect themselves against Susceptible-Infected-Susceptible (SIS) epidemics.\nMotivated by studies in behavioral economics showing that humans perceive\nprobabilities in a nonlinear fashion, we examine the impacts of such\nmisperceptions on the equilibrium protection strategies. In our setting, nodes\nchoose their curing rates to minimize the infection probability under the\ndegree-based mean-field approximation of the SIS epidemic plus the cost of\ntheir selected curing rate. We establish the existence of a degree based\nequilibrium under both true and nonlinear perceptions of infection\nprobabilities (under suitable assumptions). When the per-unit cost of curing\nrate is sufficiently high, we show that true expectation minimizers choose the\ncuring rate to be zero at the equilibrium, while curing rate is nonzero under\nnonlinear probability weighting.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The infrared asymptotics of probability of radiation of twisted photons in an\narbitrary scattering process of quantum electrodynamics (QED) in a vacuum is\ninvestigated. This asymptotics is universal and corresponds to the radiation\nproduced by a classical current. Such a radiation is known as the edge\nradiation. We represent it in terms of the twisted photons: the exact\nanalytical formulas for the average number of radiated twisted photons are\nderived. We find the average projection of the total angular momentum of the\nedge radiation and the angular momentum per photon. It is shown that the edge\nradiation can be used as a source of twisted photons with large angular\nmomentum. Moreover, this radiation can be employed as a superradiant coherent\nsource of twisted photons in the infrared domain, in particular, in the THz\npart of the electromagnetic spectrum. Several general selection rules for the\nradiation and absorbtion of twisted photons are proved. These selection rules\nallow one, in particular, to modulate the one-particle radiation probability by\nmeans of scattering of charged particles on symmetrically arranged crystals.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This survey is an introduction to the geometry of co-Minkowksi space, the\nspace of unoriented spacelike hyperplanes of the Minkowski space. Affine\ndeformations of cocompact lattices of hyperbolic isometries act on it, in a way\nsimilar to the way that quasi-Fuchsian groups act on hyperbolic space. In\nparticular, there is a convex core. There is also a unique \"mean\" hypersurface,\ni.e. with traceless second fundamental form. The mean distance between the mean\nhypersurface and the lower boundary of the convex core endows the space of\naffine deformations of a given lattice with an asymmetric norm. The\nsymmetrization of the asymmetric norm is simply the volume of the convex core.\n  In dimension 2+1, the asymmetric norm is the total length of the bending\nlamination of the lower boundary component of the convex core. We obtain an\nextrinsic proof of a theorem of Thurston saying that, on the tangent space of\nTeichm\\\"{u}ller space, the total length of measured geodesic laminations is an\nasymmetric norm.\n  We also exhibit and comment the Anosov-like character of these deformations,\nsimilar to the Anosov character of the quasi-Fuchsians representations pointed\nout in Guichard--Wienhard.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Despite their great success in practical applications, there is still a lack\nof theoretical and systematic methods to analyze deep neural networks. In this\npaper, we illustrate an advanced information theoretic methodology to\nunderstand the dynamics of learning and the design of autoencoders, a special\ntype of deep learning architectures that resembles a communication channel. By\ngeneralizing the information plane to any cost function, and inspecting the\nroles and dynamics of different layers using layer-wise information quantities,\nwe emphasize the role that mutual information plays in quantifying learning\nfrom data. We further suggest and also experimentally validate, for mean square\nerror training, three fundamental properties regarding the layer-wise flow of\ninformation and intrinsic dimensionality of the bottleneck layer, using\nrespectively the data processing inequality and the identification of a\nbifurcation point in the information plane that is controlled by the given\ndata. Our observations have a direct impact on the optimal design of\nautoencoders, the design of alternative feedforward training methods, and even\nin the problem of generalization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  When an ice crystal is born from liquid water two key changes occur: (i) the\nmolecules order; and (ii) the mobility of the molecules drops as they adopt\ntheir lattice positions. Most research on ice nucleation (and crystallization\nin general) has focused on understanding the former with less attention paid to\nthe latter. However, supercooled water exhibits fascinating and complex\ndynamical behavior, most notably dynamical heterogeneity (DH), a phenomenon\nwhere spatially separated domains of relatively mobile and immobile particles\ncoexist. Strikingly, the microscopic connection between the DH of water and the\nnucleation of ice has yet to be unraveled directly at the molecular level. Here\nwe tackle this issue via computer simulations which reveal that: (i) ice\nnucleation occurs in low-mobility regions of the liquid; (ii) there is a\ndynamical incubation period in which the mobility of the molecules drops prior\nto any ice-like ordering; and (iii) ice-like clusters cause arrested dynamics\nin surrounding water molecules. With this we establish a clear connection\nbetween dynamics and nucleation. We anticipate that our findings will pave the\nway for the examination of the role of dynamical heterogeneities in\nheterogeneous and solution-based nucleation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We generalize $f(R)$-theory of anti-evaporation/evaporation for a\nReissner-Nordstr\\\"om black hole in $n$-dimensional space-time. We consider\nnon-linear conformally invariant Maxwell field. By perturbing the fields over\nNariai-like space-time associated with degenerate horizon, we describe\ndynamical behavior of horizon. We show that $f(R)$-gravity can offer both\nanti-evaporation and evaporation in $n$-dimensional Reissner-Nordstr\\\"om black\nhole depending on the dimension $n$ and the functional form of $f(R)$.\nFurthermore, we argue that, in one class of non-oscillatory solution, stable\nand unstable anti-evaporation/evaporation exist. In the other class of\noscillatory solution anti-evaporation/evaporation exists only with instability.\nThe first class of solution may explain a long-lived black hole.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We apply reverse-engineering to find electromagnetic pulses that allow for\nthe control of populations in quantum systems under dephasing and thermal\nnoises. In particular, we discuss two-level systems given their importance in\nthe description of several molecular systems as well as quantum computing. Such\nan investigation naturally finds applications in a multitude of physical\nsituations involving the control of quantum systems. We present an analytical\ndescription of the pulse which solves a constrained dynamics where the initial\nand final populations are fixed a priori. This constrained dynamics is\nsometimes impossible and we precisely spot the conditions for that. One of our\nmain results is the presentation of analytical conditions for the establishment\nof steady states for finite coherence in the presence of noise. This might\nnaturally find applications in quantum memories.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The ratio set of a set of positive integers $A$ is defined as $R(A) := \\{a /\nb : a, b \\in A\\}$. The study of the denseness of $R(A)$ in the set of positive\nreal numbers is a classical topic and, more recently, the denseness in the set\nof $p$-adic numbers $\\mathbb{Q}_p$ has also been investigated. Let $A_1,\n\\ldots, A_k$ be a partition of $\\mathbb{N}$ into $k$ sets. We prove that for\nall prime numbers $p$ but at most $\\lfloor \\log_2 k \\rfloor$ exceptions at\nleast one of $R(A_1), \\ldots, R(A_k)$ is dense in $\\mathbb{Q}_p$. Moreover, we\nshow that for all prime numbers $p$ but at most $k - 1$ exceptions at least one\nof $A_1, \\ldots, A_k$ is dense in $\\mathbb{Z}_p$. Both these results are\noptimal in the sense that there exist partitions $A_1, \\ldots, A_k$ having\nexactly $\\lfloor \\log_2 k \\rfloor$, respectively $k - 1$, exceptional prime\nnumbers; and we give explicit constructions for them. Furthermore, as a\ncorollary, we answer negatively a question raised by Garcia et al.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In recent times, many of the breakthroughs in various vision-related tasks\nhave revolved around improving learning of deep models; these methods have\nranged from network architectural improvements such as Residual Networks, to\nvarious forms of regularisation such as Batch Normalisation. In essence, many\nof these techniques revolve around better conditioning, allowing for deeper and\ndeeper models to be successfully learned. In this paper, we look towards better\nconditioning Generative Adversarial Networks (GANs) in an unsupervised learning\nsetting. Our method embeds the powerful discriminating capabilities of a\ndecision forest into the discriminator of a GAN. This results in a better\nconditioned model which learns in an extremely stable way. We demonstrate\nempirical results which show both clear qualitative and quantitative evidence\nof the effectiveness of our approach, gaining significant performance\nimprovements over several popular GAN-based approaches on the Oxford Flowers\nand Aligned Celebrity Faces datasets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Student course feedback is generated daily in both classrooms and online\ncourse discussion forums. Traditionally, instructors manually analyze these\nresponses in a costly manner. In this work, we propose a new approach to\nsummarizing student course feedback based on the integer linear programming\n(ILP) framework. Our approach allows different student responses to share\nco-occurrence statistics and alleviates sparsity issues. Experimental results\non a student feedback corpus show that our approach outperforms a range of\nbaselines in terms of both ROUGE scores and human evaluation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider perturbations of nonlinear eigenvalue problems driven by a\nnonhomogeneous differential operator plus an indefinite potential. We consider\nboth sublinear and superlinear perturbations and we determine how the set of\npositive solutions changes as the real parameter $\\lambda$ varies. We also show\nthat there exists a minimal positive solution $\\overline{u}_\\lambda$ and\ndetermine the monotonicity and continuity properties of the map\n$\\lambda\\mapsto\\overline{u}_\\lambda$. Special attention is given to the\nparticular case of the $p$-Laplacian.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Attached to a vertex algebra $\\mathcal{V}$ are two geometric objects. The\nassociated scheme of $\\mathcal{V}$ is the spectrum of Zhu's Poisson algebra\n$R_{\\mathcal{V}}$. The singular support of $\\mathcal{V}$ is the spectrum of the\nassociated graded algebra $\\text{gr}(\\mathcal{V})$ with respect to Li's\ncanonical decreasing filtration. There is a closed embedding from the singular\nsupport to the arc space of the associated scheme, which is an isomorphism in\nmany interesting cases. In this note we give an example of a non-quasi-lisse\nvertex algebra whose associated scheme is reduced, for which the isomorphism is\nnot true as schemes but true as varieties.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the problem of determining the geometric parameters of a Galactic\nspiral arm from its segment by including the distance to the spiral pole, i.e.,\nthe distance to the Galactic center ($R_0$). The question about the number of\npoints belonging to one turn of a logarithmic spiral and defining this spiral\nas a geometric figure has been investigated numerically and analytically by\nassuming the direction to the spiral pole (to the Galactic center) to be known.\nBased on the results obtained, in an effort to test the new approach, we have\nconstructed a simplified method of solving the problem that consists in finding\nthe median of the values for each parameter from all possible triplets of\nobjects in the spiral arm segment satisfying the condition for the angular\ndistance between objects. Applying the method to the data on the spatial\ndistribution of masers in the Perseus and Scutum arms (the catalogue by Reid et\nal. (2014)) has led to an estimate of $R_0 = 8.8 \\pm 0.5$ kpc. The parameters\nof five spiral arm segments have been determined from masers of the same\ncatalogue. We have confirmed the difference between the spiral arms in pitch\nangle. The pitch angles of the arms revealed by masers are shown to generally\ncorrelate with $R_0$ in the sense that an increase in $R_0$ leads to a growth\nin the absolute values of the pitch angles.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Hilbert's 17th problem asks that whether every nonnegative polynomial can be\na sum of squares of rational functions. It has been answered affirmatively by\nArtin. However, the question as to whether a given nonnegative polynomial is a\nsum of squares of polynomials is still a central question in real algebraic\ngeometry. In this paper, we solve this question completely for the nonnegative\npolynomials associated with isoparametric polynomials, initiated by E. Cartan,\nwhich define the focal submanifolds of the corresponding isoparametric\nhypersurfaces.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The present work continues a series of the KEDR measurements of the $R$ value\nthat started in 2010 at the VEPP-4M $e^+e^-$ collider. By combining new data\nwith our previous results in this energy range we measured the values of\n$R_{\\text{uds}}$ and $R$ at nine center-of-mass energies between 3.08 and 3.72\nGeV. The total accuracy is about or better than $2.6\\%$ at most of energy\npoints with a systematic uncertainty of about $1.9\\%$. Together with the\nprevious precise $R$ measurement at KEDR in the energy range 1.84-3.05 GeV, it\nconstitutes the most detailed high-precision $R$ measurement near the\ncharmonium production threshold.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we introduce a novel method to interpret recurrent neural\nnetworks (RNNs), particularly long short-term memory networks (LSTMs) at the\ncellular level. We propose a systematic pipeline for interpreting individual\nhidden state dynamics within the network using response characterization\nmethods. The ranked contribution of individual cells to the network's output is\ncomputed by analyzing a set of interpretable metrics of their decoupled step\nand sinusoidal responses. As a result, our method is able to uniquely identify\nneurons with insightful dynamics, quantify relationships between dynamical\nproperties and test accuracy through ablation analysis, and interpret the\nimpact of network capacity on a network's dynamical distribution. Finally, we\ndemonstrate generalizability and scalability of our method by evaluating a\nseries of different benchmark sequential datasets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We have studied the compact phase conformations of semi-flexible polymer\nchains confined in two dimensional nonhomogeneous media, modelled by fractals\nthat belong to the family of modified rectangular (MR) lattices. Members of the\nMR family are enumerated by an integer $p$ $(2\\leq p<\\infty)$, and fractal\ndimension of each member of the family is equal to 2. The polymer flexibility\nis described by the stiffness parameter $s$, while the polymer conformations\nare modelled by weighted Hamiltonian walks (HWs). Applying an exact method of\nrecurrence equations we have found the asymptotic behavior of partition\nfunction $Z_N$ for closed HWs consisting of $N$ steps. We have established that\n$Z_N$ scales as $\\omega^N \\mu^{N^\\sigma}$, where the critical exponent $\\sigma$\nin the stretched exponential term does not depend on $s$, and takes the value\n1/2 for each fractal from the family. The constants $\\omega$ and $\\mu$ depend\non both $p$ and $s$, and, in addition, $\\mu$ depends on the parity of MR\ngenerator. Besides, we have calculated numerically the stiffness dependence of\nthe polymer persistence length and various thermodynamic quantities (such as\nfree and internal energy, specific heat and entropy), for a large set of\nmembers of MR family. We have found that semi-flexible compact polymers, on MR\nlattices, can exist only in the liquid-like (disordered) phase, whereas the\ncrystal (ordered) phase has not appeared. Finally, the behavior of examined\nsystem at zero temperature has been discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Wireless communications are vulnerable against radio frequency (RF) jamming\nwhich might be caused either intentionally or unintentionally. A particular\nsubset of wireless networks, vehicular ad-hoc networks (VANET) which\nincorporate a series of safety-critical applications, may be a potential target\nof RF jamming with detrimental safety effects. To ensure secure communication\nand defend it against this type of attacks, an accurate detection scheme must\nbe adopted. In this paper we introduce a detection scheme that is based on\nsupervised learning. The machine-learning algorithms, KNearest Neighbors (KNN)\nand Random Forests (RF), utilize a series of features among which is the metric\nof the variations of relative speed (VRS) between the jammer and the receiver\nthat is passively estimated from the combined value of the useful and the\njamming signal at the receiver. To the best of our knowledge, this metric has\nnever been utilized before in a machine-learning detection scheme in the\nliterature. Through offline training and the proposed KNN-VRS, RF-VRS\nclassification algorithms, we are able to efficiently detect various cases of\nDenial of Service Attacks (DoS) jamming attacks, differentiate them from cases\nof interference as well as foresee a potential danger successfully and act\naccordingly.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The human eye contains millions of rod photoreceptor cells, and each one is a\nsingle-photon detector. Whether people can actually see a single photon, which\nrequires the rod signal to propagate through the rest of the noisy visual\nsystem and be perceived in the brain, has been the subject of research for\nnearly 100 years. Early experiments hinted that people could see just a few\nphotons, but classical light sources are poor tools for answering these\nquestions. Single-photon sources have opened up a new area of vision research,\nproviding the best evidence yet that humans can indeed see single photons, and\ncould even be used to test quantum effects through the visual system. We\ndiscuss our program to study the lower limits of human vision with a heralded\nsingle-photon source based on spontaneous parametric downconversion, and\npresent two proposed experiments to explore quantum effects through the visual\nsystem: testing the perception of superposition states, and using a human\nobserver as a detector in a Bell test.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The passage of a magnetosonic (MS) soliton in a cold plasma leads to the\ndisplacement of charged particles in the direction of a compressive pulse and\nin the opposite direction of a rarefaction pulse. In the overdense plasma\nlimit, the displacement induced by a weakly nonlinear MS soliton is derived\nanalytically. This result is then used to derive an asymptotic expansion for\nthe displacement resulting from the bouncing motion of a MS soliton reflected\nback and forth in a vacuum-bounded cold plasma slab. Particles' displacement\nafter the pulse energy has been lost to the vacuum region is shown to scale as\nthe ratio of light speed to Alfv\\'en velocity. Results for the displacement\nafter a few MS soliton reflections are corroborated by particle-in-cell\nsimulations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Cell membranes separate the cell interior from the external environment. They\nare constituted by a variety of lipids; their composition determines the\ndynamics of membrane proteins and affects the ability of the cells to adapt.\nEven though the study of model membranes allows to understand the interactions\namong lipids and the overall mechanics, little is known about these properties\nin native membranes. To combine topology and nanomechanics analysis of native\nmembranes, I designed a method to investigate the plasma membranes isolated\nfrom a variety of single cells. Five cell types were chosen and tested,\nrevealing 20\\% variation in membrane thickness. I probed the resistance of the\nisolated membranes to indent, finding their line tension and spreading\npressure. These results show that membranes isolated from neurons are stiffer\nand less diffusive than brain cancer cell membranes. This method gives direct\nquantitative insights on the mechanics of native cell membranes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show that large subsets of vector spaces over finite fields determine\ncertain point configurations with prescribed distance structure. More\nspecifically, we consider the complete graph with vertices as the points of $A\n\\subseteq \\mathbf{F}_q^d$ and edges assigned the algebraic distance between\npairs of vertices. We prove nontrivial results on locating specified subgraphs\nof maximum vertex degree at most $t$ in dimensions $d \\geq 2t$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the singular Liouville equation and the Henon-Lane-Emden problem\non simply connected planar domains. We show that any solution to each problem\nmust satisfy a uniform bound on the mass. The same results applies to some\nsystems and more general non-linearities. The proofs are based on the Riemann\nmapping theorem and a Pohozaev-type identity.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The effects of radiation damage in silicon photomultipliers (SiPMs) from\ngamma rays have been measured and compared with the damage produced by\nneutrons. Several types of MPPCs from Hamamatsu were exposed to gamma rays and\nneutrons at the Solid State Gamma Ray Irradiation Facility (SSGRIF) at\nBrookhaven National Lab and the Institute for Nuclear Research (Atomki) in\nDebrecen, Hungary. The gamma ray exposures ranged from 1 krad to 1 Mrad and the\nneutron exposures ranged from 10$^8$ n/cm$^2$ to 10$^{12}$ n/cm$^2$. The main\neffect of gamma ray damage is an increase in the noise and leakage current in\nthe irradiated devices, similar to what is seen from neutron damage, but the\nlevel of damage is considerably less at comparable high levels of exposure. In\naddition, the damage from gamma rays saturates after a few hundred krad, while\nthe damage from neutrons shows no sign of saturation, suggestive of different\ndamage mechanisms in the two cases. The change in optical absorption in the\nwindow material of the SiPMs due to radiation was also measured. This study was\ncarried out in order to evaluate the use of SiPMs for particle physics\napplications with moderate levels of radiation exposures.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, with the parametric symmetric coercive elliptic boundary value\nproblem as an example of the primal-dual variational problems satisfying the\nstrong duality, we develop primal-dual reduced basis methods (PD-RBM) with\nrobust true error certifications and discuss three versions of greedy\nalgorithms to balance the finite element error, the exact reduced basis error,\nand the adaptive mesh refinements.\n  For a class of convex minimization variational problems which has\ncorresponding dual problems satisfying the strong duality, the primal-dual gap\nbetween the primal and dual functionals can be used as a posteriori error\nestimator. This primal-dual gap error estimator is robust with respect to the\nparameters of the problem, and it can be used for both mesh refinements of\nfinite element methods and the true RB error certification.\n  With the help of integrations by parts formula, the primal-dual variational\ntheory is developed for the symmetric coercive elliptic boundary value problems\nwith non-homogeneous boundary conditions by both the conjugate function and\nLagrangian theories. A generalized Prager-Synge identity, which is the\nprimal-dual gap error representation for this specific problem, is developed.\nRBMs for both the primal and dual problems with robust error estimates are\ndeveloped. The dual variational problem often can be viewed as a constraint\noptimization problem. In the paper, different from the standard saddle-point\nfinite element approximation, the dual RBM is treated as a Galerkin projection\nby constructing RB spaces satisfying the homogeneous constraint.\n  Inspired by the greedy algorithm with spatio-parameter adaptivity of\n\\cite{Yano:18}, adaptive balanced greedy algorithms with primal-dual finite\nelement and reduced basis error estimators are discussed. Numerical tests are\npresented to test the PD-RBM with adaptive balanced greedy algorithms.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Genome-wide eQTL mapping explores the relationship between gene expression\nvalues and DNA variants to understand genetic causes of human disease. Due to\nthe large number of genes and DNA variants that need to be assessed\nsimultaneously, current methods for eQTL mapping often suffer from low\ndetection power, especially for identifying trans-eQTLs. In this paper, we\npropose a new method that utilizes advanced techniques in large-scale signal\ndetection to pursue the structure of eQTL data and improve the power for eQTL\nmapping. The new method greatly reduces the burden of joint modeling by\ndeveloping a new ranking and screening strategy based on the higher criticism\nstatistic. Numerical results in simulation studies demonstrate the superior\nperformance of our method in detecting true eQTLs with reduced computational\nexpense. The proposed method is also evaluated in HapMap eQTL data analysis and\nthe results are compared to a database of known eQTLs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we discuss centroaffine geometry of polygons in $3$-space. For\na polygon $X$ that is locally convex with respect to an origin together with a\ntransversal vector field $U$, we define the centroaffine dual pair $(Y,V)$\nsimilarly to [6]. We prove that vertices of $(X,U)$ correspond to flattening\npoints for $(Y,V)$ and also that constant curvature polygons are dual to planar\npolygons. As an application, we give a new proof of a known $4$ flattening\npoints theorem for spatial polygons.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Training set bugs are flaws in the data that adversely affect machine\nlearning. The training set is usually too large for man- ual inspection, but\none may have the resources to verify a few trusted items. The set of trusted\nitems may not by itself be adequate for learning, so we propose an algorithm\nthat uses these items to identify bugs in the training set and thus im- proves\nlearning. Specifically, our approach seeks the smallest set of changes to the\ntraining set labels such that the model learned from this corrected training\nset predicts labels of the trusted items correctly. We flag the items whose\nlabels are changed as potential bugs, whose labels can be checked for veracity\nby human experts. To find the bugs in this way is a challenging combinatorial\nbilevel optimization problem, but it can be relaxed into a continuous\noptimization problem. Ex- periments on toy and real data demonstrate that our\napproach can identify training set bugs effectively and suggest appro- priate\nchanges to the labels. Our algorithm is a step toward trustworthy machine\nlearning.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A distinctive feature observed in lattice simulations of confining nonabelian\ngauge theories, such as Quantum Chromodynamics, is the presence of a dynamical\nmass for the gauge field in the low energy regime of the theory. In the\nGribov-Zwanziger framework in the Landau gauge, such mass is a consequence of\nthe generation of the dimension two condensates $\\langle A_\\mu^aA_\\mu^a\\rangle$\nand $\\langle\n\\bar\\varphi_\\mu^{ab}\\varphi_\\mu^{ab}-\\bar\\omega_\\mu^{ab}\\omega_\\mu^{ab}\\rangle$,\nwhere $A$ is the gluon field and the fields $\\bar\\varphi$, $\\varphi$,\n$\\bar\\omega$, and $\\omega$ are Zwanziger's auxiliary fields. In this work, we\nshow that, in the recently developed BRST-invariant version of the Refined\nGribov-Zwanziger theory, these condensates can be introduced in a\nBRST-invariant way for a family of $R_\\xi$ gauges. Their values are explicitly\ncomputed to first order and turn out to be independent of the gauge parameters\ncontained in the gauge-fixing condition, as expected from the BRST invariance\nof the formulation. This fact supports the possibility of a gauge-parameter\nindependent nonzero infrared gluon mass, whose value is the same as the one in\nthe Landau gauge.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The intersection $L$ of two different non-opposite hemispheres of the unit\nsphere $S^2$ is called a lune. By $\\Delta (L)$ we denote the distance of the\ncenters of the semicircles bounding $L$. By the thickness $\\Delta (C)$ of a\nconvex body $C \\subset S^2$ we mean the minimal value of $\\Delta (L)$ over all\nlunes $L \\supset C$. We call a convex body $R\\subset S^2$ reduced provided\n$\\Delta (Z) < \\Delta (R)$ for every convex body $Z$ being a proper subset of\n$R$. Our aim is to estimate the diameter of $R$, where $\\Delta (R) <\n\\frac{\\pi}{2}$, in terms of its thickness.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Internet of Things (IoT) applications have seen a phenomenal growth with\nestimates of growing to a 25 Billion dollar industry by 2020. With the scale of\nIoT applications growing and stricter requirements on latency, edge computing\nhas piqued the interest for such environments. However, the industry is still\nin its infancy with no proper support for applications running across the\nentire edge-cloud environment, and an array of manual tedious per-application\noptimizations. In this work, we propose Steel, a unified framework for\ndeveloping, deploying, and monitoring applications in the edge-cloud. Steel\nsupports dynamically adapting and easily moving services back and forth between\nthe edge and the cloud. Steel is extensible where common optimizations (but\ncrucial for the edge) can be built as pluggable and configurable modules. We\nhave added two very common optimizations: placement and adaptive communication,\nto cope with both short and long-term changes in the workload and environment.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The ability of a classifier to recognize unknown inputs is important for many\nclassification-based systems. We discuss the problem of simultaneous\nclassification and novelty detection, i.e. determining whether an input is from\nthe known set of classes and from which specific class, or from an unknown\ndomain and does not belong to any of the known classes. We propose a method\nbased on the Generative Adversarial Networks (GAN) framework. We show that a\nmulti-class discriminator trained with a generator that generates samples from\na mixture of nominal and novel data distributions is the optimal novelty\ndetector. We approximate that generator with a mixture generator trained with\nthe Feature Matching loss and empirically show that the proposed method\noutperforms conventional methods for novelty detection. Our findings\ndemonstrate a simple, yet powerful new application of the GAN framework for the\ntask of novelty detection.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Ammonia, if present in the ice shells of icy satellites, could lower the\ntemperature for the onset of melting to 176 K and create a large temperature\nrange where partial melt is thermally stable. The evolution of regions of\nammonia-rich partial melt could strongly influence the geological and thermal\nevolution of icy bodies. For melt to be extracted from partially molten\nregions, the surrounding solid matrix must deform and compact. Whether\nammonia-rich melts sink to the subsurface ocean or become frozen into the ice\nshell depends on the compaction rate and thermal evolution. Here we construct a\nmodel for the compaction and thermal evolution of a partially molten,\nammonia-rich ice shell in a one-dimensional geometry. We model the thickening\nof an initially thin ice shell above an ocean with $10\\%$ ammonia. We find that\nammonia-rich melts can freeze into the upper $5$ to $10$ kilometers of the ice\nshell, when ice shell thickening is rapid compared to the compaction rate. The\ntrapping of near-surface volatiles suggests that, upon reheating of the ice\nshell, eutectic melting events are possible. However, as the ice shell\nthickening rate decreases, ammonia-rich melt is efficiently excluded from the\nice shell and the bulk of the ice shell is pure water ice. We apply our results\nto the thermal evolution of Neptune's moon Triton. As Triton's ice shell\nthickens, the gradual increase of ammonia concentration in Triton's subsurface\nocean helps to prevent freezing and increases the predicted final ocean\nthickness by up to $50$ km.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The unpredictability of chaotic nonlinear dynamics leads naturally to\nstatistical descriptions, including probabilistic limit laws such as the\ncentral limit theorem and large deviation principle. A key tool in the\nNagaev-Guivarc'h spectral method for establishing statistical limit theorems is\na \"twisted\" transfer operator. In the abstract setting of Keller-Liverani we\nprove that derivatives of all orders of the leading eigenvalues and\neigenprojections of the twisted transfer operators with respect to the twist\nparameter are stable when subjected to a broad class of perturbations. As a\nresult, we demonstrate stability of the variance in the central limit theorem\nand the rate function from a large deviation principle with respect to\ndeterministic and stochastic perturbations of the dynamics and perturbations\ninduced by numerical schemes. We apply these results to piecewise expanding\nmaps in one and multiple dimensions, including new convergence results for Ulam\nprojections on quasi-H\\\"older spaces.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Two opposite parity dipole bandlike structures DB I and DB II of $^{142}$Eu\nare investigated by the Indian National Gamma Array (INGA), using the fusion\nevaporation reaction $^{31}$P + $^{116}$Cd @ 148 MeV. The decreasing trend as\nwell as magnitude of the measured $B(M1)$ and $B(E2)$ transition rates of the\nband DB II has been reproduced well within the shears mechanism with the\nprincipal axis cranking model calculations. This calculation reflects the fact\nthat the maximum contribution of the angular momentum of the states in DB II\nhas been generated from the magnetic rotation (MR) phenomenon. The enhanced\n$B(E1)$ rates of the connecting $E1$ transitions from the states of DB II to DB\nI are demanding the octupole correlation due to the involvement of the octupole\ndriving pair of orbitals $\\pi{h_{11/2}}$ and $\\pi{d_{5/2}}$ as evident from the\nquasiparticle alignment ($i_{x}$), the experimental routhians (e$^{'}$) and the\ncalculated neutron and proton quasiparticle energies against the rotational\nfrequency ($\\omega$).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Ultrafast terahertz (THz) pump{probe spectroscopy reveals unusual\nout-of-equilibrium Cooper pair dynamics driven by femtosecond (fs) optical\nquench of superconductivity (SC) in iron pnictides. We observe a two{step\nquench of the SC gap, where an abnormally slow (many 100's of ps) quench\nprocess is clearly distinguished from the usual fast (sub-ps)\nhot{phonon{mediated scattering channel. This pair breaking dynamics depends\nstrongly on doping, pump uence, and temperature. The above observations,\ntogether with quantum kinetic modeling of non-equilibrium SC and magnetic\ncorrelations, provide evidence for photogeneration of a transient state where\nSC competes with build{up of spin-density-wave (SDW) excitonic correlation\nbetween quasi-particles (QP).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The financial services industry has unique explainability and fairness\nchallenges arising from compliance and ethical considerations in credit\ndecisioning. These challenges complicate the use of model machine learning and\nartificial intelligence methods in business decision processes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Searches for millisecond-duration, dispersed single pulses have become a\nstandard tool used during radio pulsar surveys in the last decade. They have\nenabled the discovery of two new classes of sources: rotating radio transients\nand fast radio bursts. However, we are now in a regime where the sensitivity to\nsingle pulses in radio surveys is often limited more by the strong background\nof radio frequency interference (RFI, which can greatly increase the\nfalse-positive rate) than by the sensitivity of the telescope itself. To\nmitigate this problem, we introduce the Single-pulse Searcher (SpS). This is a\nnew machine-learning classifier designed to identify astrophysical signals in a\nstrong RFI environment, and optimized to process the large data volumes\nproduced by the new generation of aperture array telescopes. It has been\nspecifically developed for the LOFAR Tied-Array All-Sky Survey (LOTAAS), an\nongoing survey for pulsars and fast radio transients in the northern\nhemisphere. During its development, SpS discovered 7 new pulsars and blindly\nidentified ~80 known sources. The modular design of the software offers the\npossibility to easily adapt it to other studies with different instruments and\ncharacteristics. Indeed, SpS has already been used in other projects, e.g. to\nidentify pulses from the fast radio burst source FRB 121102. The software\ndevelopment is complete and SpS is now being used to re-process all LOTAAS data\ncollected to date.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Highly efficient information processing in brain is based on processing and\nmemory components called synapses, whose output is dependent on the history of\nthe signals passed through them. Here we have developed an artificial synapse\nwith both electrical and optical memory effects using reactive tunnel junctions\nbased on plasmonic nanorods. In an electronic realization, the electrons\ntunneled into plasmonic nanorods under low bias voltage are harvested to write\ninformation into the tunnel junctions via hot-electron-mediated chemical\nreactions with the environment. In an optical realization, the information can\nalso be written optically by external light illumination to excite hot\nelectrons in plasmonic nanorods. The stored information is non-volatile and can\nbe read in both realizations either electrically or optically by measuring the\nresistance or inelastic-tunnelling-induced light emission, respectively. These\nmemristive light-emitting plasmonic tunnel junctions can be used as memory,\nlogic units or artificial synapses in future optoelectronic or neuromorphic\ninformation systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  To a braid $\\beta\\in Br_n$ we associate a complex of sheaves $S_\\beta$ on\n$Hilb_n(C^2)$ such that the previously defined triply graded link homology of\nthe closure $L(\\beta)$ is isomorphic to the homology of $S_\\beta$.\n  The construction of $S_\\beta$ relies on the Chern functor\n  $CH: MF_n^{st}\\to D^{per}_{C^*\\times C^*}(Hilb_n(C^2))$ defined in the paper\ntogether with its adjoint functor\n  $HC$. The properties of these functors lead us to a conjecture that $HC$\nsends\n  $D^{per}_{C^*\\times C^*}(Hilb_n(C^2))$\n  to the Drinfeld center of $MF_n^{st}$. Modulo an explicit parity conjecture\nfor $CH$, we prove a\n  formula for the closure of sufficiently positive elements of the Jucys-Murphy\nalgebra previously conjectured\n  by Gorsky, Negut and Rasmussen.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we consider the (global and sum) energy efficiency\noptimization problem in downlink multi-input multi-output multi-cell systems,\nwhere all users suffer from multi-user interference. This is a challenging\nproblem due to several reasons: 1) it is a nonconvex fractional programming\nproblem, 2) the transmission rate functions are characterized by\n(complex-valued) transmit covariance matrices, and 3) the processing-related\npower consumption may depend on the transmission rate. We tackle this problem\nby the successive pseudoconvex approximation approach, and we argue that\npseudoconvex optimization plays a fundamental role in designing novel iterative\nalgorithms, not only because every locally optimal point of a pseudoconvex\noptimization problem is also globally optimal, but also because a descent\ndirection is easily obtained from every optimal point of a pseudoconvex\noptimization problem. The proposed algorithms have the following advantages: 1)\nfast convergence as the structure of the original optimization problem is\npreserved as much as possible in the approximate problem solved in each\niteration, 2) easy implementation as each approximate problem is suitable for\nparallel computation and its solution has a closed-form expression, and 3)\nguaranteed convergence to a stationary point or a Karush-Kuhn-Tucker point. The\nadvantages of the proposed algorithm are also illustrated numerically.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A conceptual model of the Plio-Pleistocene glacial cycles is developed based\non the Budyko-Sellers type energy balance model. The model is shown to admit a\nphenomenon like the Mid-Pleistocene transition, capturing the essence of the\nalbedo and the temperature precipitation feedbacks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider the problem of energy balancing in a clustered wireless sensor\nnetwork (WSN) deployed randomly in a large field and aided by a mobile robot\n(MR). The sensor nodes (SNs) are tasked to monitor a region of interest (ROI)\nand report their test statistics to the cluster heads (CHs), which subsequently\nreport to the fusion center (FC) over a wireless fading channel. To maximize\nthe lifetime of the WSN, the MR is deployed to act as an adaptive relay between\na subset of the CHs and the FC. To achieve this we develop a multiple-link\nmobility diversity algorithm (MDA) executed by the MR that will allow to\ncompensate simultaneously for the small-scale fading at the established\nwireless links (i.e., the MR-to-FC as well as various CH-to-MR communication\nlinks). Simulation results show that the proposed MR aided technique is able to\nsignificantly reduce the transmission power required and thus extend the\noperational lifetime of the WSN. We also show how the effect of small-scale\nfading at various wireless links is mitigated by using the proposed\nmultiple-link MDA executed by a MR equipped with a single antenna.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Cross-lingual semantic textual similarity systems estimate the degree of the\nmeaning similarity between two sentences, each in a different language.\nState-of-the-art algorithms usually employ machine translation and combine vast\namount of features, making the approach strongly supervised, resource rich, and\ndifficult to use for poorly-resourced languages.\n  In this paper, we study linear transformations, which project monolingual\nsemantic spaces into a shared space using bilingual dictionaries. We propose a\nnovel transformation, which builds on the best ideas from prior works. We\nexperiment with unsupervised techniques for sentence similarity based only on\nsemantic spaces and we show they can be significantly improved by the word\nweighting. Our transformation outperforms other methods and together with word\nweighting leads to very promising results on several datasets in different\nlanguages.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, the wavelet analysis is used to study the ECG signal. We show\nthat the high-frequency wavelet components of the ECG signal contain\ninformation on the functioning of the heart and can be used in diagnosis. We\ndescribe the automated classification system that separates the ECG of sick and\nhealthy persons using only a high-frequency ECG component.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Manin transformations are maps of the plane that preserve a pencil of cubic\ncurves. They are the composition of two involutions. Each involution is\nconstructed in terms of an involution point that is required to be one of the\nbase points of the pencil. We generalise this construction to explicit\nbirational maps of the plane that preserve quadratic resp. certain quartic\npencils, and show that they are measure-preserving and hence integrable. In the\nquartic construction the two involution points are required to be base points\nof the pencil of multiplicity 2. On the other hand, for the quadratic pencils\nthe involution points can be any two distinct points in the plane (except for\nbase points). We employ Pascal's theorem to show that the maps that preserve a\nquadratic pencil admit infinitely many symmetries. The full 18-parameter QRT\nmap is obtained as a special instance of the quartic case in a limit where the\ntwo involution points go to infinity. We show by construction that each\ngeneralised Manin transformation can be brought to QRT form by a fractional\naffine transformation. We also specify classes of generalised Manin\ntransformations which admit a root.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Applying the method of light-cone sum rules with photon distribution\namplitudes, we compute the subleading-power correction to the radiative\nleptonic $B \\to \\gamma \\ell \\nu$ decay, at next-to-leading order in QCD for the\ntwist-two contribution and at leading order in $\\alpha_s$ for the higher-twist\ncontributions, induced by the hadronic component of the collinear photon. The\nleading-twist hadronic photon effect turns out to preserve the symmetry\nrelation between the two $B \\to \\gamma$ form factors due to the helicity\nconservation, however, the higher-twist hadronic photon corrections can yield\nsymmetry-breaking effect already at tree level in QCD. Using the conformal\nexpansion of photon distribution amplitudes with the non-perturbative\nparameters estimated from QCD sum rules, the twist-two hadronic photon\ncontribution can give rise to approximately 30\\% correction to the\nleading-power \"direct photon\" effect computed from the perturbative QCD\nfactorization approach. In contrast, the subleading-power corrections from the\nhigher-twist two-particle and three-particle photon distribution amplitudes are\nestimated to be of ${\\cal O} (3 \\sim 5\\%)$ with the light-cone sum rule\napproach. We further predict the partial branching fractions of $B \\to \\gamma\n\\ell \\nu $ with a photon-energy cut $E_{\\gamma} \\geq E_{\\rm cut}$, which are of\ninterest for determining the inverse moment of the leading-twist $B$-meson\ndistribution amplitude thanks to the forthcoming high-luminosity Belle II\nexperiment at KEK.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The theory of the post-Newtonian (PN) planar circular restricted three-body\nproblem is used for numerically investigating the orbital dynamics of a test\nparticle (e.g., a comet, asteroid, meteor or spacecraft) in the planar\nSun-Jupiter system with a scattering region around Jupiter. For determining the\norbital properties of the test particle, we classify large sets of initial\nconditions of orbits for several values of the Jacobi constant in all possible\nHill region configurations. The initial conditions are classified into three\nmain categories: (i) bounded, (ii) escaping and (iii) collisional. Using the\nsmaller alignment index chaos indicator (SALI), we further classify bounded\norbits into regular, sticky or chaotic. In order to get a spherical view of the\ndynamics of the system, the grids of the initial conditions of the orbits are\ndefined on different types of two-dimensional planes. We locate the different\ntypes of basins and we also relate them with the corresponding spatial\ndistributions of the escape and collision time. Our thorough analysis exposes\nthe high complexity of the orbital dynamics and exhibits an appreciable\ndifference between the final states of the orbits in the classical and PN\napproaches. Furthermore, our numerical results reveal a strong dependence of\nthe properties of the considered basins with the Jacobi constant, along with a\nremarkable presence of fractal basin boundaries. Our outcomes are compared with\nearlier ones, regarding other planetary systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the distribution of additive functionals of reset Brownian motion, a\nvariation of normal Brownian motion in which the path is interrupted at a given\nrate and placed back to a given reset position. Our goal is two-fold: (1) For\ngeneral functionals, we derive a large deviation principle in the presence of\nresetting and identify the large deviation rate function in terms of a\nvariational formula involving large deviation rate functions without resetting.\n(2) For three examples of functionals (positive occupation time, area and\nabsolute area), we investigate the effect of resetting by computing\ndistributions and moments, using a formula that links the generating function\nwith resetting to the generating function without resetting.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, we exploit the capability of virtual element methods in\naccommodating approximation spaces featuring high-order continuity to\nnumerically approximate differential problems of the form $\\Delta^p u =f$,\n$p\\ge1$. More specifically, we develop and analyze the conforming virtual\nelement method for the numerical approximation of polyharmonic boundary value\nproblems, and prove an abstract result that states the convergence of the\nmethod in the energy norm.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this article, we present a distance estimation formula that can be used to\nray trace 3D slices of the filled-in Julia sets and the Multibrot sets\ngenerated by the tricomplex polynomials of the form $\\eta^p+c$ where $p$ is any\ninteger greater than $1$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We determine the net-baryon multiplicity distribution which reproduces all\ncumulants measured so far by lattice QCD. We present the dependence on the\nvolume and temperature of this distribution. We find that for temperatures and\nvolumes encountered in heavy ion reactions, the multiplicity distribution is\nvery close to the Skellam distribution, making the experimental determination\nof it rather challenging. We further provide estimates for the statistics\nrequired to measure cumulants of the net-baryon and net-proton distributions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  As shown in recent research, deep neural networks can perfectly fit randomly\nlabeled data, but with very poor accuracy on held out data. This phenomenon\nindicates that loss functions such as cross-entropy are not a reliable\nindicator of generalization. This leads to the crucial question of how\ngeneralization gap should be predicted from the training data and network\nparameters. In this paper, we propose such a measure, and conduct extensive\nempirical studies on how well it can predict the generalization gap. Our\nmeasure is based on the concept of margin distribution, which are the distances\nof training points to the decision boundary. We find that it is necessary to\nuse margin distributions at multiple layers of a deep network. On the CIFAR-10\nand the CIFAR-100 datasets, our proposed measure correlates very strongly with\nthe generalization gap. In addition, we find the following other factors to be\nof importance: normalizing margin values for scale independence, using\ncharacterizations of margin distribution rather than just the margin (closest\ndistance to decision boundary), and working in log space instead of linear\nspace (effectively using a product of margins rather than a sum). Our measure\ncan be easily applied to feedforward deep networks with any architecture and\nmay point towards new training loss functions that could enable better\ngeneralization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper considers node localization in static sensor networks using\nrange-only measurements. Similar to state- of-the-art algorithms, such as ECHO\nand DILOC, we rely on barycentric coordinates of the nodes to transform the\nnon-convex node localization problem into a linear system of equations. The\nmain contribution of this paper is a simple closed-form expression for\ngeneralized barycentric coordinates, which extends existing algorithms from two\nto n dimensions and allows arbitrary anchor-node configurations. The result\nrelies on a connection between the Cayley-Menger bi-determinants of subsets of\nn+1 neighbor nodes and the signed volume of the simplices defined by these\nneighbor nodes. Hence, for noise-free measurements, the proposed method\ncomputes the optimal sensor network embedding as the solution of a linear\nsystem with coefficients obtained from the generalized barycentric node\ncoordinates. Using simulations, we provide comparisons with DILOC and Matlab's\nMDS implementation. We also show that it is possible to improve our algorithm\nrun time using fewer subsets of neighbor nodes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a link between parametrizations of alternative theories of gravity\non large and small scales in cosmology. This relationship is established using\ntheoretical consistency conditions only. We find that in both limits the \"slip\"\nand \"effective Newton's constant\" can be written in terms of a set of four\nfunctions of time, two of which are direct generalizations of the $\\alpha$ and\n$\\gamma$ parameters from post-Newtonian physics. This generalizes previous work\nthat has constructed frameworks for testing gravity on small scales, and is to\nthe best of our knowledge the first time that a link between parametrizations\nof gravity on such very different scales has been established. We expect our\nresult to facilitate the imposition of observational constraints, by\ndrastically reducing the number of functional degrees of freedom required to\nconsistently test gravity on multiple scales in cosmology.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It was at the dawn of the historical developments of quantum mechanics when\nSchr\\\"odinger, Kennard and Darwin proposed an interesting type of Gaussian wave\npackets, which do not spread out while evolving in time. Originally, these wave\npackets are the prototypes of the renowned discovery, which are familiar as\ncoherent states today. Coherent states are inevitable in the study of almost\nall areas of modern science, and the rate of progress of the subject is\nastonishing nowadays. Nonclassical states constitute one of the distinguished\nbranches of coherent states having applications in various subjects including\nquantum information processing, quantum optics, quantum superselection\nprinciples and mathematical physics. On the other hand, the compelling\nadvancements of non-Hermitian systems and related areas have been appealing,\nwhich became popular with the seminal paper by Bender and Boettcher in 1998.\nThe subject of non-Hermitian Hamiltonian systems possessing real eigenvalues\nare exploding day by day and combining with almost all other subjects rapidly,\nin particular, in the areas of quantum optics, lasers and condensed matter\nsystems, where one finds ample successful experiments for the proposed theory.\nFor this reason, the study of coherent states for non-Hermitian systems have\nbeen very important. In this article, we review the recent developments of\ncoherent and nonclassical states for such systems and discuss their\napplications and usefulness in different contexts of physics. In addition,\nsince the systems considered here originate from the broader context of the\nstudy of minimal uncertainty relations, our review is also of interest to the\nmathematical physics community.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the most probable trajectories of the concentration evolution for\nthe transcription factor activator in a genetic regulation system, with\nnon-Gaussian stable L\\'evy noise in the synthesis reaction rate taking into\naccount. We calculate the most probable trajectory by spatially maximizing the\nprobability density of the system path, i.e., the solution of the associated\nnonlocal Fokker-Planck equation. We especially examine those most probable\ntrajectories from low concentration state to high concentration state (i.e.,\nthe likely transcription regime) for certain parameters, in order to gain\ninsights into the transcription processes and the tipping time for the\ntranscription likely to occur. This enables us: (i) to visualize the progress\nof concentration evolution (i.e., observe whether the system enters the\ntranscription regime within a given time period); (ii) to predict or avoid\ncertain transcriptions via selecting specific noise parameters in particular\nregions in the parameter space. Moreover, we have found some peculiar or\ncounter-intuitive phenomena in this gene model system, including (a) a smaller\nnoise intensity may trigger the transcription process, while a larger noise\nintensity can not, under the same asymmetric L\\'evy noise. This phenomenon does\nnot occur in the case of symmetric L\\'evy noise; (b) the symmetric L\\'evy\nmotion always induces transition to high concentration, but certain asymmetric\nL\\'evy motions do not trigger the switch to transcription. These findings\nprovide insights for further experimental research, in order to achieve or to\navoid specific gene transcriptions, with possible relevance for medical\nadvances.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Health professionals can use natural language processing (NLP) technologies\nwhen reviewing electronic health records (EHR). Machine learning free-text\nclassifiers can help them identify problems and make critical decisions. We aim\nto develop deep learning neural network algorithms that identify EHR progress\nnotes pertaining to diabetes and validate the algorithms at two institutions.\nThe data used are 2,000 EHR progress notes retrieved from patients with\ndiabetes and all notes were annotated manually as diabetic or non-diabetic.\nSeveral deep learning classifiers were developed, and their performances were\nevaluated with the area under the ROC curve (AUC). The convolutional neural\nnetwork (CNN) model with a separable convolution layer accurately identified\ndiabetes-related notes in the Brigham and Womens Hospital testing set with the\nhighest AUC of 0.975. Deep learning classifiers can be used to identify EHR\nprogress notes pertaining to diabetes. In particular, the CNN-based classifier\ncan achieve a higher AUC than an SVM-based classifier.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The \\textit{axial} electromagnetic (EM) perturbations of the black hole (BH)\nsolutions in general relativity coupled to nonlinear electrodynamics (NED) were\nstudied for both electrically and magnetically charged BHs, assuming that the\nEM perturbations do not alter the spacetime geometry in our preceding paper\n[Phys. Rev. D 97, 084058 (2018)]. Here, as a continuation of that work, the\nformalism for the \\textit{polar} EM perturbations of the BHs in general\nrelativity coupled to the NED is presented. We show that the quasinormal modes\n(QNMs) spectra of polar EM perturbations of the electrically and magnetically\ncharged BHs in the NED are not isospectral, contrary to the case of the\nstandard Reissner-Nordstr\\\"{o}m BHs in the classical linear electrodynamics. It\nis shown by the detailed study of QNMs properties in the eikonal approximation\nthat the EM perturbations can be a powerful tool to confirm that in the NED\nlight ray does not follow the null geodesics of the spacetime. By specifying\nthe NED model and comparing axial and polar EM perturbations of the\nelectrically and magnetically charged BHs, it is shown that QNM spectra of the\naxial EM perturbations of magnetically (electrically) charged BH and polar EM\nperturbations of the electrically (magnetically) charged BH are isospectral,\ni.e., $\\omega_{mag}^{ax}\\approx\\omega_{el}^{pol}$\n($\\omega_{mag}^{pol}\\approx\\omega_{el}^{ax}$).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Neural networks have been used to solve different types of large data related\nproblems in many different fields.This project takes a novel approach to\nsolving the Navier-Stokes Equations for turbulence by training a neural network\nusing Bayesian Cluster and SOM neighbor weighting to map ionospheric velocity\nfields based on 3-dimensional inputs. Parameters used in this problem included\nthe velocity, Reynolds number, Prandtl number, and temperature. In this project\ndata was obtained from Johns-Hopkins University to train the neural network\nusing MATLAB. The neural network was able to map the velocity fields within a\nsixty-seven percent accuracy of the validation data used. Further studies will\nfocus on higher accuracy and solving further non-linear differential equations\nusing convolutional neural networks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a one-class neural network (OC-NN) model to detect anomalies in\ncomplex data sets. OC-NN combines the ability of deep networks to extract a\nprogressively rich representation of data with the one-class objective of\ncreating a tight envelope around normal data. The OC-NN approach breaks new\nground for the following crucial reason: data representation in the hidden\nlayer is driven by the OC-NN objective and is thus customized for anomaly\ndetection. This is a departure from other approaches which use a hybrid\napproach of learning deep features using an autoencoder and then feeding the\nfeatures into a separate anomaly detection method like one-class SVM (OC-SVM).\nThe hybrid OC-SVM approach is sub-optimal because it is unable to influence\nrepresentational learning in the hidden layers. A comprehensive set of\nexperiments demonstrate that on complex data sets (like CIFAR and GTSRB), OC-NN\nperforms on par with state-of-the-art methods and outperformed conventional\nshallow methods in some scenarios.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Using element-specific X-ray magnetic circular dichroism (XMCD) technique we\nhave studied different magnetic sublattices in a multiferroic\nHo$_{0.5}$Nd$_{0.5}$Fe$_{3}$(BO$_{3}$)$_{4}$ single crystal. The XMCD\nmeasurements at the \\emph{L}$_{2,3}$-edges of Ho and Nd, and at the Fe\n\\emph{K}-edge have been performed at \\emph{T}=2~K under a magnetic field up to\n17~T applied along the trigonal \\emph{c}-axis as well as in the basal\n\\emph{ab}-plane. All three magnetic sublattices are shown to undergo a\nspin-reorientation transition under magnetic field applied along the\n\\emph{c}-axis. On the contrary, when magnetic field is applied in the\n\\emph{ab}-plane only the holmium atoms exhibit a magnetization jump. Thus, the\nelement-specific magnetization curves revealed the Ho sublattice to be much\nstronger coupled to the Fe one than the Nd sublattice. The results demonstrate\nthat the Ho$^{3+}$ subsystem plays even more dominant role in magnetic behavior\nof Ho$_{0.5}$Nd$_{0.5}$Fe$_{3}$(BO$_{3}$)$_{4}$ crystal than in pure\nHoFe$_{3}$(BO$_{3}$)$_{4}$ crystal.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Flexible manipulation of terahertz-wave polarization during the generation\nprocess is very important for terahertz applications, especially for the\nnext-generation on-chip functional terahertz sources. However, current\nterahertz emitters could not satisfy such demand, hence calling for new\nmechanism and conceptually new terahertz source. Here we demonstrate a\nmagnetic-field-controlled, highly-efficient, cost-effective, and broadband\nterahertz source with flexible switch of terahertz polarization states in\nferromagnetic heterostructures driven by femtosecond laser pulses. We verify\nthat the chirality, azimuthal angle, and ellipticity of the generated\nelliptical terahertz waves can be independently manipulated by delicately\nengineering of the external applied magnetic fields via effectively\nmanipulating the photo-induced spin currents. Such an ultrafast photomagnetic\ninteraction-based, magnetic-field-controlled, and broadband tunable solid-state\nterahertz source integrated with terahertz polarization tunability function not\nonly has the capability to reveal physical mechanisms of femtosecond spin\ndynamics, but also demonstrates the feasibility to realize novel on-chip\nterahertz functional devices, boosting the potential applications for\ncontrolling elementary molecular rotations, phonon vibrations, spin\nprecessions, high-speed terahertz communication, and accelerating the\ndevelopment of ultrafast terahertz opto-spintronics.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we generalize an elementary real-analysis result to a class of\ntopological vector spaces. We also give an example of a topological vector\nspace to which the result cannot be generalized.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  An abelian 4D, $\\mathcal{N}$ = 4 vector supermultiplet allows for a duality\ntransformation to be applied to one of its spin-0 states. The resulting theory\ncan be described as an abelian 4D, $\\mathcal{N}$ = 4 vector-tensor\nsupermultiplet. It is seen to decompose into a direct sum of an off-shell 4D,\n$\\mathcal{N}$ = 2 vector supermultiplet and an off-shell 4D, $\\mathcal{N}$ = 2\ntensor supermultiplet. The commutator algebra of the other two supersymmetries\nare still found to be on-shell. However, the central charge structure in the\nresulting 4D, $\\mathcal{N}$ = 4 vector-tensor supermultiplet is considerably\nsimpler that that of the parent abelian 4D, $\\mathcal{N}$ = 4 vector\nsupermultiplet. This appears to be due to the replacement of the usual SO(4)\nsymmetry associated with the abelian 4D, $\\mathcal{N}$ = 4 vector\nsupermultiplet being replaced by a\nGL(2,$\\mathbb{R}$)$\\otimes$GL(2,$\\mathbb{R}$) symmetry in the 4D, $\\mathcal{N}$\n= 4 vector-tensor supermultiplet. The $Mathematica$ code detailing the\ncalculations is available open-source at the HEPTHools Data Repository on\nGitHub.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove the existence and uniqueness of solutions of SDEs with Lipschitz\ncoefficients, driven by continuous, model-free martingales. The main tool in\nour reasoning is Picard's iterative procedure and a model-free version of the\nBurkholder-Davis-Gundy inequality for integrals driven by model-free,\ncontinuous martingales. We work with a new outer measure which assigns zero\nvalue exactly to those properties which are instantly blockable.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The cosmological principle is one of the cornerstones in modern cosmology. It\nassumes that the universe is homogeneous and isotropic on cosmic scales. Both\nthe homogeneity and the isotropy of the universe should be tested carefully. In\nthe present work, we are interested in probing the possible preferred direction\nin the distribution of type Ia supernovae (SNIa). To our best knowledge, two\nmain methods have been used in almost all of the relevant works in the\nliterature, namely the hemisphere comparison (HC) method and the dipole fitting\n(DF) method. However, the results from these two methods are not always\napproximately coincident with each other. In this work, we test the cosmic\nanisotropy by using these two methods with the Joint Light-Curve Analysis (JLA)\nand simulated SNIa datasets. In many cases, both methods work well, and their\nresults are consistent with each other. However, in the cases with two (or even\nmore) preferred directions, the DF method fails while the HC method still works\nwell. This might shed new light on our understanding of these two methods.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show that the special values at tuples of positive integers of the\n$p$-adic multiple $L$-function introduced by the first-named author et al. can\nbe expressed in terms of the cyclotomic multiple harmonic values introduced by\nthe second-named author.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we consider the inverse problem of determining a rigid\ninclusion inside a thin plate by applying a couple field at the boundary and by\nmeasuring the induced transversal displacement and its normal derivative at the\nboundary of the plate. The plate is made by non-homogeneous, linearly elastic\nand isotropic material. Under suitable a priori regularity assumptions on the\nboundary of the inclusion, we prove a constructive stability estimate of log\ntype. Key mathematical tool is a recently proved optimal three spheres\ninequality at the boundary for solutions to the Kirchhoff-Love plate's\nequation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The number of isolating integrals of motion of the Trappist-1 system - a late\nM-dwarf orbited by seven Earth-sized planets - was determined numerically,\nusing an adapted version of the correlation dimension method. It was found that\nover the investigated time-scales of up to 20 000 years the number of isolating\nintegrals of motion is the same as one would find for a system of seven\nnon-interacting planets - despite the fact that the planets in the Trappist-1\nsystem are strongly interacting. Considering perturbed versions of the\nTrappist-1 system shows that the system may occupy an atypical part of\nphase-space with high stability. These findings are consistent with earlier\nstudies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Internet provides students with a unique opportunity to connect and\nmaintain social ties with peers from other schools, irrespective of how far\nthey are from each other. However, little is known about the real structure of\nsuch online relationships. In this paper, we investigate the structure of\ninterschool friendship on a popular social networking site. We use data from\n36,951 students from 590 schools of a large European city. We find that the\nprobability of a friendship tie between students from neighboring schools is\nhigh and that it decreases with the distance between schools following the\npower law. We also find that students are more likely to be connected if the\neducational outcomes of their schools are similar. We show that this fact is\nnot a consequence of residential segregation. While high- and low-performing\nschools are evenly distributed across the city, this is not the case for the\ndigital space, where schools turn out to be segregated by educational outcomes.\nThere is no significant correlation between the educational outcomes of a\nschool and its geographical neighbors; however, there is a strong correlation\nbetween the educational outcomes of a school and its digital neighbors. These\nresults challenge the common assumption that the Internet is a borderless\nspace, and may have important implications for the understanding of educational\ninequality in the digital age.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We analyze high-quality stellar catalogs for 24 young and nearby (within 1\nkpc) embedded clusters and present a catalogue of 32 groups which have a high\nconcentration of protostars. The median effective radius of these groups is\n0.17 pc. The median protostellar and pre-main sequence star surface densities\nare 46 M_{\\odot} pc^{-2} and 11 M_{\\odot} pc^{-2}, respectively. We estimate\nthe age of these groups using a model of constant birthrate and random\naccretion stopping and find a median value of 0.25 Myr. Some groups in Aquila\nand Serpens, Corona Australia and Ophichus L1688 show high protostellar surface\ndensity and high molecular gas surface density, which seem to be undergoing\nvigorous star formation. These groups provide an excellent opportunity to study\ninitial conditions of clustered star formation. Comparison of protostellar and\npre-main-sequence stellar surface densities reveal continuous low-mass star\nformation of these groups over several Myr in some clouds. For groups with\ntypical protostellar separations of less than 0.4 pc, we find that these\nseparations agree well with the thermal Jeans fragmentation scale. On the other\nhand, for groups with typical protostellar separations larger than 0.4 pc,\nthese separations are always larger than the associated Jeans length.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Topological phases of Hermitian systems are known to exhibit intriguing\nproperties such as the presence of robust boundary states and the famed\nbulk-boundary correspondence. These features can change drastically for their\nnon-Hermitian generalizations, as exemplified by a general breakdown of\nbulk-boundary correspondence and a localization of all states at the boundary,\ntermed the non-Hermitian skin effect. In this article, we present a completely\nanalytical unifying framework for studying these systems using generalized\ntransfer matrices -- a real-space approach suitable for systems with periodic\nas well as open boundary conditions. We show that various qualitative\nproperties of these systems can be easily deduced from the transfer matrix. For\ninstance, the connection between the breakdown of the conventional\nbulk-boundary correspondence and the existence of a non-Hermitian skin effect,\npreviously observed numerically, is traced back to the transfer matrix having a\ndeterminant not equal to unity. The vanishing of this determinant signals\nreal-space exceptional points, whose order scales with the system size. We also\nderive previously proposed topological invariants such as the biorthogonal\npolarization and the Chern number computed on a complexified Brillouin zone.\nFinally, we define an invariant for and thereby clarify the meaning of\ntopologically protected boundary modes for non-Hermitian systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Deep learning algorithms achieve high classification accuracy at the expense\nof significant computation cost. To address this cost, a number of quantization\nschemes have been proposed - but most of these techniques focused on quantizing\nweights, which are relatively smaller in size compared to activations. This\npaper proposes a novel quantization scheme for activations during training -\nthat enables neural networks to work well with ultra low precision weights and\nactivations without any significant accuracy degradation. This technique,\nPArameterized Clipping acTivation (PACT), uses an activation clipping parameter\n$\\alpha$ that is optimized during training to find the right quantization\nscale. PACT allows quantizing activations to arbitrary bit precisions, while\nachieving much better accuracy relative to published state-of-the-art\nquantization schemes. We show, for the first time, that both weights and\nactivations can be quantized to 4-bits of precision while still achieving\naccuracy comparable to full precision networks across a range of popular models\nand datasets. We also show that exploiting these reduced-precision\ncomputational units in hardware can enable a super-linear improvement in\ninferencing performance due to a significant reduction in the area of\naccelerator compute engines coupled with the ability to retain the quantized\nmodel and activation data in on-chip memories.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The aim of this paper is to point out that the classic seismological problem\nusing observations and theoretical expressions for the periods and damping\ntimes of transverse standing magnetohydrodynamic (MHD) waves in coronal loops\nis better referred to as a reduced seismological problem. Reduced emphasises\nthe fact that only a small number of characteristic quantities of the\nequilibrium profiles can be determined. Reduced also implies that there is no\nunique solution to the full seismological problem. Even the reduced\nseismological problem does not allow a unique solution. Bayesian inference\nresults support our mathematical arguments and offer insight into the\nrelationship between the algebraic and the probabilistic inversions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This two-part paper is concerned with the problem of minimizing a linear\nobjective function subject to a bilinear matrix inequality (BMI) constraint. In\nthis part, we first consider a family of convex relaxations which transform BMI\noptimization problems into polynomial-time solvable surrogates. As an\nalternative to the state-of-the-art semidefinite programming (SDP) and\nsecond-order cone programming (SOCP) relaxations, a computationally efficient\nparabolic relaxation is developed, which relies on convex quadratic constraints\nonly. Next, we developed a family of penalty functions, which can be\nincorporated into the objective of SDP, SOCP, and parabolic relaxations to\nfacilitate the recovery of feasible points for the original non-convex BMI\noptimization. Penalty terms can be constructed using any arbitrary initial\npoint. We prove that if the initial point is sufficiently close to the feasible\nset, then the penalized relaxations are guaranteed to produce feasible points\nfor the original BMI. In Part II of the paper, the efficacy of the proposed\npenalized convex relaxations is demonstrated on benchmark instances of H2 and\nHinf optimal control synthesis problems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a thorough analysis of symmetry breaking observed in Hartree-Fock\n(HF) solutions of fullerenes C$_{60}$, C$_{36}$, and C$_{20}$ in order to\ncharacterize the nature of electron correlation in them. Our analysis is based\non (1) the critical regularization strength to restore symmetry breaking in the\nrecently developed regularized orbital optimized second-order M{\\o}ller-Plesset\nperturbation theory ($\\kappa$-OOMP2), (2) singlet-triplet gaps from various MP2\nmethods, and (3) natural orbital occupation numbers from restricted\ncoupled-cluster with singles and doubles (RCCSD) and coupled-cluster valence\nbond with singles and doubles (CCVB-SD). Based on these three independent\nprobes, we conclude that C$_{36}$ (D$_\\text{6h}$) exhibits genuine strong\ncorrelation and symmetry breaking whereas C$_{60}$ exhibits {\\it artificial} HF\nsymmetry breaking and is not strongly correlated. Investigating the critical\nregularization strength, we discuss strong correlation in C$_{20}$ at the\nJahn-Teller distorted geometries (C$_\\text{2h}$, D$_\\text{2h}$, C$_\\text{i}$,\nand D$_\\text{3h}$) and the I$_\\text{h}$ geometry. Only C$_{20}$ (I$_\\text{h}$)\nwas found to be strongly correlated while others exhibit {\\it artificial} HF\nsymmetry breaking. This analysis highlights a useful feature of the recommended\n$\\kappa$-OOMP2 method. It is an electronic structure method that describes\ndynamic correlation, and attenuates strong correlation in MP2 towards zero by\nregularization. Therefore, $\\kappa$-OOMP2 will exhibit symmetry breaking in its\nreference determinant only when correlation is strong (i.e., essential symmetry\nbreaking). Artificial symmetry breaking (arising in HF due to neglect of\ndynamic correlation) is thus removed in $\\kappa$-OOMP2.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present one of the most precise emission spectra of an exoplanet observed\nso far. We combine five secondary eclipses of the hot Jupiter WASP-18 b\n(Tday=2900K) that we secured between 1.1 and 1.7 micron with the WFC3\ninstrument aboard the Hubble Space Telescope. Our extracted spectrum (S/N=50,\nR=40) does not exhibit clearly identifiable molecular features but is poorly\nmatched by a blackbody spectrum. We complement this data with previously\npublished Spitzer/IRAC observations of this target and interpret the combined\nspectrum by computing a grid of self-consistent, 1D forward models, varying the\ncomposition and energy budget. At these high temperatures, we find there are\nimportant contributions to the overall opacity from H- ions, as well as the\nremoval of major molecules by thermal dissociation (including water), and\nthermal ionization of metals. These effects were omitted in previous spectral\nretrievals for very hot gas giants, and we argue that they must be included to\nproperly interpret the spectra of these objects. We infer a new metallicity and\nC/O ratio for WASP-18 b, and find them well constrained to be solar\n([M/H]=-0.01 (0.35), C/O<0.85 at 3 sigma confidence level), unlike previous\nwork but in line with expectations for giant planets. The best fitting\nself-consistent temperature-pressure profiles are inverted, resulting in an\nemission feature at 4.5 micron seen in the Spitzer photometry. These results\nfurther strengthen the evidence that the family of very hot gas giant\nexoplanets commonly exhibit thermal inversions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we address the estimation of a time-varying spatial field of\nreceived signal strength (RSS) by relying on measurements from randomly placed\nand not very accurate sensors. We employ a radio propagation model where the\npath loss exponent and the transmitted power are unknown with Gaussian priors\nwhose hyper-parameters are estimated by applying the empirical Bayes method. We\nconsider the locations of the sensors to be imperfectly known, which entails\nthat they represent another source of error in the model. The propagation model\nincludes shadowing which is considered to be a zero-mean Gaussian process where\nthe correlation of attenuation between two spatial points is quantified by an\nexponential function of the distance between the points. The location of the\ntransmitter is also unknown and estimated from the data with a weighted\ncentroid approach. We propose to estimate time-varying RSS fields by a\nrecursive Bayesian method and crowdsourcing. The method is based on Gaussian\nprocesses (GP), and it produces the joint distribution of the spatial field.\nFurther, it summarizes all the acquired information by keeping the size of the\nneeded memory bounded. We also present the Bayesian Cram\\'er-Rao bound (BCRB)\nof the estimated parameters. Finally, we illustrate the performance of our\nmethod with experimental results on synthetic data sets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this review, we highlight the role of halogenated compounds in the\ncolloidal synthesis of nanostructured semiconductors. Halogen-containing\nmetallic salts used as precursors and halogenated hydrocarbons used as ligands\nallow stabilizing different shapes and crystal phases, and enable the formation\nof colloidal systems with different dimensionality. We summarize recent reports\non the tremendous influence of these compounds on the physical properties of\nnanocrystals, like field-effect mobility and solar cell performance and outline\nmain analytical methods for the nanocrystal surface control.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  For prostate cancer patients, the Gleason score is one of the most important\nprognostic factors, potentially determining treatment independent of the stage.\nHowever, Gleason scoring is based on subjective microscopic examination of\ntumor morphology and suffers from poor reproducibility. Here we present a deep\nlearning system (DLS) for Gleason scoring whole-slide images of\nprostatectomies. Our system was developed using 112 million\npathologist-annotated image patches from 1,226 slides, and evaluated on an\nindependent validation dataset of 331 slides, where the reference standard was\nestablished by genitourinary specialist pathologists. On the validation\ndataset, the mean accuracy among 29 general pathologists was 0.61. The DLS\nachieved a significantly higher diagnostic accuracy of 0.70 (p=0.002) and\ntrended towards better patient risk stratification in correlations to clinical\nfollow-up data. Our approach could improve the accuracy of Gleason scoring and\nsubsequent therapy decisions, particularly where specialist expertise is\nunavailable. The DLS also goes beyond the current Gleason system to more finely\ncharacterize and quantitate tumor morphology, providing opportunities for\nrefinement of the Gleason system itself.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present two new NuSTAR observations of the narrow line Seyfert 1 (NLS1)\ngalaxy Mrk 766 and give constraints on the two scenarios previously proposed to\nexplain its spectrum and that of other NLS1s: relativistic reflection and\npartial covering. The NuSTAR spectra show a strong hard (>15 keV) X-ray excess,\nwhile simultaneous soft X-ray coverage of one of the observations provided by\nXMM-Newton constrains the ionised absorption in the source. The pure reflection\nmodel requires a black hole of high spin ($a>0.92$) viewed at a moderate\ninclination ($i=46^{+1}_{-4}$ degrees). The pure partial covering model\nrequires extreme parameters: the cut-off of the primary continuum is very low\n($22^{+7}_{-5}$ keV) in one observation and the intrinsic X-ray emission must\nprovide a large fraction (75%) of the bolometric luminosity. Allowing a hybrid\nmodel with both partial covering and reflection provides more reasonable\nabsorption parameters and relaxes the constraints on reflection parameters. The\nfractional variability reduces around the iron K band and at high energies\nincluding the Compton hump, suggesting that the reflected emission is less\nvariable than the continuum.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Electronic structure methods for accurate calculation of molecular properties\nhave a high cost that grows steeply with the problem size, therefore, it is\nhelpful to have the underlying atomic basis functions that are less in number\nbut of higher quality. Following our earlier work [Chem. Phys. Lett. 416, 116\n(2005)] where general correlation-consistent basis sets are defined, for any\natom, as solutions of purely atomic functional minimization problems, and which\nare shown to work well for chemical bonding in molecules, we take a further\nstep here and define a new kind of atomic polarization functionals, the\nminimization of which yields additional sets of diffuse functions that help to\ncalculate better molecular electron affinities, polarizabilities, and\nintermolecular dispersion interactions. Analytical representations by\ngenerally-contracted Gaussian functions of up to microhartree numerical\naccuracy grades are developed for atoms Hydrogen through Nobelium within the\nfour-component Dirac-Coulomb theory and its scalar-relativistic approximation,\nand also for Hydrogen through Krypton in the two-component nonrelativistic\ncase. The convergence of correlation energy with the basis set size is studied,\nand complete-basis-set extrapolation formulas are developed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Image slicing is a powerful technique in astronomy. It allows the instrument\ndesigner to reduce the slit width of the spectrograph, increasing spectral\nresolving power whilst retaining throughput. Conventionally this is done using\nbulk optics, such as mirrors and prisms, however more recently astrophotonic\ncomponents known as photonic lanterns (PLs) and photonic reformatters have also\nbeen used. These devices reformat the multi-mode (MM) input light from a\ntelescope into single-mode (SM) outputs, which can then be re-arranged to suit\nthe spectrograph. The photonic dicer (PD) is one such device, designed to\nreduce the dependence of spectrograph size on telescope aperture and eliminate\nmodal noise. We simulate the PD, by optimising the throughput and geometrical\ndesign using Soapy and BeamProp. The simulated device shows a transmission\nbetween 8 and 20 %, depending upon the type of adaptive optics (AO) correction\napplied, matching the experimental results well. We also investigate our\nidealised model of the PD and show that the barycentre of the slit varies only\nslightly with time, meaning that the modal noise contribution is very low when\ncompared to conventional fibre systems. We further optimise our model device\nfor both higher throughput and reduced modal noise. This device improves\nthroughput by 6.4 % and reduces the movement of the slit output by 50%, further\nimproving stability. This shows the importance of properly simulating such\ndevices, including atmospheric effects. Our work complements recent work in the\nfield and is essential for optimising future photonic reformatters.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The notions of knowledge and its management have been at the core of the\ninformation systems (IS) field almost since its inception. Knowledge has been\nviewed in several ways in the prior literature, including as a state of mind,\nan object, a process, access to information, and a capability. A commonly-used\ndefinition characterizes knowledge as a justified belief that increases an\nentity's capacity for effective action (Alavi and Leidner 2001, p. 109).\nRelatedly, knowledge management (KM) has been defined as a systemic process to\nacquire, organize, and communicate individual knowledge so that others may make\nuse of it (Beck et al. 2014). Knowledge-management systems (KMSs) support these\nprocesses for creating, exchanging, and storing knowledge (Beck et al. 2014),\nand have been viewed as being either repository- based or network-based\n(Kankanhalli et al. 2005). In an attempt to provide a useful resource for\nscholars interested in KM, we take stock of the pertinent research published in\nMISQ. More specifically, the goal of this curation is to serve as a living\ndocument that will offer a starting point for future KM research. This curation\nhighlights the 44 articles with a primary focus on KM (Table 1). The articles\naddress theoretical and conceptual issues, provide methodological guidance, and\nuse a wide range of quantitative and qualitative research methods. To define\nthe scope of this curation, we excluded: (1) articles in which KM is used as\npart of another construct; (2) some early articles that were practice- oriented\nwith limited scholarly orientation; and (3) articles that focus on knowledge\n(such as the knowledge requirements of IS professionals) but not on KM.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Transiting exoplanets provide detailed access to their atmospheres, as the\nplanet's signal can be effectively separated from that of its host star. For\ntransiting exoplanets three fundamental atmospheric measurements are possible:\ntransmission spectra - where atmospheric absorption features are detected\nacross an exoplanets limb during transit, emission spectra - where the day-side\naverage emission of the planet is detected during secondary eclipse events, and\nphase curves - where the spectral emission of the planet is mapped globally\nfollowing the planet around its orbit. All of these techniques have been well\nproven to provide detailed characterisation information about planets ranging\nfrom super-Earth to Jupiter size. In this chapter, I present the overall\nbackground, history and methodology of these measurements. A few of the major\nscience related questions are also discussed, which range from broad questions\nabout planet formation and migration, to detailed atmospheric physics questions\nabout how a planet's atmosphere responds under extreme conditions. I also\ndiscuss the analysis methods and light-curve fitting techniques that have been\ndeveloped to help reach the extreme spectrophotometric accuracies needed, and\nhow to derive reliable error estimates despite limiting systematic errors. As a\ntransmission spectra derived from primary transit is a unique measurement\noutside of our solar system, I discuss its physical interpretation and the\nunderlying degeneracies associated with the measurement.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Evolutionary Biologists have long struggled with the challenge of developing\nanalysis workflows in a flexible manner, thus facilitating the reuse of\nphylogenetic knowledge. An evolutionary biology workflow can be viewed as a\nplan which composes web services that can retrieve, manipulate, and produce\nphylogenetic trees. The Phylotastic project was launched two years ago as a\ncollaboration between evolutionary biologists and computer scientists, with the\ngoal of developing an open architecture to facilitate the creation of such\nanalysis workflows. While composition of web services is a problem that has\nbeen extensively explored in the literature, including within the logic\nprogramming domain, the incarnation of the problem in Phylotastic provides a\nnumber of additional challenges. Along with the need to integrate preferences\nand formal ontologies in the description of the desired workflow, evolutionary\nbiologists tend to construct workflows in an incremental manner, by\nsuccessively refining the workflow, by indicating desired changes (e.g.,\nexclusion of certain services, modifications of the desired output). This leads\nto the need of successive iterations of incremental replanning, to develop a\nnew workflow that integrates the requested changes while minimizing the changes\nto the original workflow. This paper illustrates how Phylotastic has addressed\nthe challenges of creating and refining phylogenetic analysis workflows using\nlogic programming technology and how such solutions have been used within the\ngeneral framework of the Phylotastic project. Under consideration in Theory and\nPractice of Logic Programming (TPLP).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Ambient backscatter communication (AmBC) enables wireless-powered backscatter\ndevices (BDs) to transmit information over ambient radio-frequency (RF)\ncarriers without using an RF transmitter, and thus has emerged as a promising\ntechnology for green Internet-of-Things. This paper considers an AmBC network\nin which a full-duplex access point (FAP) simultaneously transmits downlink\northogonal frequency division multiplexing (OFDM) signals to its legacy user\n(LU) and receives uplink signals backscattered from multiple BDs in a\ntime-division-multiple-access manner. To enhance the system performance from\nmultiple design dimensions and ensure fairness, we maximize the minimum\nthroughput among all BDs by jointly optimizing the BDs' backscatter time\nportions, the BDs' power reflection coefficients, and the FAP's subcarrier\npower allocation, subject to the LU's throughput constraint, the BDs'\nharvested-energy constraints, and other practical constraints. As such, we\npropose an efficient iterative algorithm for solving the formulated non-convex\nproblem by leveraging the block coordinated decent and successive convex\noptimization techniques. We further show the convergence of the proposed\nalgorithm, and analyze its complexity. Finally, extensive simulation results\nshow that the proposed joint design achieves significant throughput gains as\ncompared to the benchmark scheme with equal resource allocation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a sample of 54 disk galaxies which have well developed extraplanar\nstructures. We selected them using visual inspections from the color images of\nthe Sloan Digital Sky Survey. Since the sizes of the extraplanar structures are\ncomparable to the disks, they are considered as prominent stellar halos rather\nthan large bulges. A single S\\'ersic profile fitted to the surface brightness\nalong the minor-axis of the disk shows a luminosity excess in the central\nregions for the majority of sample galaxies. This central excess is considered\nto be caused by the central bulge component. The mean S\\'ersic index of the\nsingle component model is $1.1\\pm0.9$. A double S\\'ersic profile model that\nemploys $n=1$ for the inner region, and varying $n$ for the outer region,\nprovides a better fit than the single S\\'ersic profile model. For a small\nfraction of galaxies, a S\\'ersic profile fitted with $n=4$ for the inner region\ngives similar results. There is a weak tendency of increasing $n$ with\nincreasing luminosity and central velocity dispersion, but there is no\ndependence on the local background density.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We describe the effect of Feigin's flat degeneration of the type $\\textrm{A}$\nflag variety on its Schubert varieties. In particular, we study when they stay\nirreducible and in several cases we are able to encode reducibility of the\ndegenerations in terms of symmetric group combinatorics. As a side result, we\nobtain an identification of some Schubert varieties with Richardson varieties\nin higher rank partial flag varieties.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Advances in machine learning have led to broad deployment of systems with\nimpressive performance on important problems. Nonetheless, these systems can be\ninduced to make errors on data that are surprisingly similar to examples the\nlearned system handles correctly. The existence of these errors raises a\nvariety of questions about out-of-sample generalization and whether bad actors\nmight use such examples to abuse deployed systems. As a result of these\nsecurity concerns, there has been a flurry of recent papers proposing\nalgorithms to defend against such malicious perturbations of correctly handled\nexamples. It is unclear how such misclassifications represent a different kind\nof security problem than other errors, or even other attacker-produced examples\nthat have no specific relationship to an uncorrupted input. In this paper, we\nargue that adversarial example defense papers have, to date, mostly considered\nabstract, toy games that do not relate to any specific security concern.\nFurthermore, defense papers have not yet precisely described all the abilities\nand limitations of attackers that would be relevant in practical security.\nTowards this end, we establish a taxonomy of motivations, constraints, and\nabilities for more plausible adversaries. Finally, we provide a series of\nrecommendations outlining a path forward for future work to more clearly\narticulate the threat model and perform more meaningful evaluation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $(G,+)$ be an abelian group and consider a subset $A \\subseteq G$ with\n$|A|=k$. Given an ordering $(a_1, \\ldots, a_k)$ of the elements of $A$, define\nits {\\em partial sums} by $s_0 = 0$ and $s_j = \\sum_{i=1}^j a_i$ for $1 \\leq j\n\\leq k$. We consider the following conjecture of Alspach: For any cyclic group\n$\\Z_n$ and any subset $A \\subseteq \\Z_n \\setminus \\{0\\}$ with $s_k \\neq 0$, it\nis possible to find an ordering of the elements of $A$ such that no two of its\npartial sums $s_i$ and $s_j$ are equal for $0 \\leq i < j \\leq k$. We show that\nAlspach's Conjecture holds for prime $n$ when $k \\geq n-3$ and when $k \\leq\n10$. The former result is by direct construction, the latter is\nnon-constructive and uses the polynomial method. We also use the polynomial\nmethod to show that for prime $n$ a sequence of length $k$ having distinct\npartial sums exists in any subset of $\\Z_n \\setminus \\{0\\}$ of size at least\n$2k- \\sqrt{8k}$ in all but at most a bounded number of cases.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show that, within the framework of $SU(5)$ Grand Unified Theories (GUTs),\nmultiple vector-like families at the GUT scale which transform under a gauged\n$U(1)'$ (under which the three chiral families are neutral) can result in a\nsingle vector-like family at low energies which can induce non-universal and\nflavourful $Z'$ couplings, which can account for the B physics anomalies in\n$R_{K^{(*)}}$. In such theories, we show that the same muon couplings which\nexplain $R_{K^{(*)}}$ also correct the Yukawa relation $Y_e=Y_d^T$ in the muon\nsector without the need for higher Higgs representations. To illustrate the\nmechanism, we construct a concrete a model based on $SU(5)\\times A_4 \\times\nZ_3\\times Z_7$ with two vector-like families at the GUT scale, and two\nright-handed neutrinos, leading to a successful fit to quark and lepton\n(including neutrino) masses, mixing angles and CP phases, where the constraints\nfrom lepton flavour violation require $Y_e$ to be diagonal.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  When modeling concurrent or cyber-physical systems, non-functional\nrequirements such as time are important to consider. In order to improve the\ntiming aspects of a model, it is necessary to have some notion of what it means\nfor a process to be faster than another, which can guide the stepwise\nrefinement of the model. To this end we study a faster-than relation for\nsemi-Markov decision processes and compare it to standard notions for relating\nsystems. We consider the compositional aspects of this relation, and show that\nthe faster-than relation is not a precongruence with respect to parallel\ncomposition, hence giving rise to so-called parallel timing anomalies. We take\nthe first steps toward understanding this problem by identifying decidable\nconditions sufficient to avoid parallel timing anomalies in the absence of\nnon-determinism.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  With the rapid growth of fashion-focused social networks and online shopping,\nintelligent fashion recommendation is now in great need. We design algorithms\nwhich automatically suggest users outfits (e.g. a shirt, together with a skirt\nand a pair of high-heel shoes), that fit their personal fashion preferences.\nRecommending sets, each of which is composed of multiple interacted items, is\nrelatively new to recommender systems, which usually recommend individual items\nto users. We explore the use of deep networks for this challenging task. Our\nsystem, dubbed FashionNet, consists of two components, a feature network for\nfeature extraction and a matching network for compatibility computation. The\nformer is achieved through a deep convolutional network. And for the latter, we\nadopt a multi-layer fully-connected network structure. We design and compare\nthree alternative architectures for FashionNet. To achieve personalized\nrecommendation, we develop a two-stage training strategy, which uses the\nfine-tuning technique to transfer a general compatibility model to a model that\nembeds personal preference. Experiments on a large scale data set collected\nfrom a popular fashion-focused social network validate the effectiveness of the\nproposed networks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate, in the framework of the linearized quantum gravity and the\nleading-order perturbation theory, the quantum correction to the classical\nNewtonian interaction between a pair of gravitationally polarizable objects in\nthe presence of both Neumann and Dirichlet boundaries. We obtain general\nresults for the interaction potential and find that the presence of a boundary\nalways strengthens in the leading-order the interaction as compared with the\ncase in absence of boundaries. But different boundaries yield a different\ndegree of strengthening. In the limit when one partner of the pair is placed\nvery close to the Neumann boundary, the interaction potential is larger when\nthe pair is parallel with the boundary than when it is perpendicular to, which\nis just opposite to the case when the boundary is Dirichlet where the latter is\nlarger than the former. In addition, we find that the pair-boundary separation\ndependence of the higher-order correction term is determined by the orientation\nof the pair with respect to boundary, with the parallel case giving a quadratic\nbehavior and the perpendicular case a linear one.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study scalar perturbations and quasinormal modes of a nonlinear magnetic\ncharged black hole surrounded by quintessence. Time evolution of scalar\nperturbations is studied for different parameters associated with the black\nhole solution. We also study the reflection and transmission coefficients along\nwith absorption cross-section for the considered black hole spacetime. It was\nshown that the real part of quasinormal frequency increases with increase in\nnonlinear magnetic charge while the module of the imaginary part of the\nfrequency decreases. The analysis of the perturbations with changing\nquintessential parameter $c$ showed that perturbations with high values of $c$\nbecome unstable.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we explore how network centrality and network entropy can be\nused to identify a bifurcation network event. A bifurcation often occurs when a\nnetwork undergoes a qualitative change in its structure as a response to\ninternal changes or external signals. In this paper, we show that network\ncentrality allows us to capture important topological properties of dynamic\nnetworks. By extracting multiple centrality features from a network for\ndimensionality reduction, we are able to track the network dynamics underlying\nan intrinsic low-dimensional manifold. Moreover, we employ von Neumann graph\nentropy (VNGE) to measure the information divergence between networks over\ntime. In particular, we propose an asymptotically consistent estimator of VNGE\nso that the cubic complexity of VNGE is reduced to quadratic complexity that\nscales more gracefully with network size. Finally, the effectiveness of our\napproaches is demonstrated through a real-life application of cyber intrusion\ndetection.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Metallic nanoparticles (NPs) support localized surface plasmon resonances\n(LSPRs), which enable to concentrate sunlight at the active layer of solar\ncells. However, full-wave modeling of the plasmonic solar cells faces great\nchallenges in terms of huge computational workload and bad matrix condition. It\nis tremendously difficult to accurately and efficiently simulate near-field\nmultiple scattering effects from plasmonic NPs embedded into solar cells. In\nthis work, a preconditioned volume integral equation (VIE) is proposed to model\nplasmonic organic solar cells (OSCs). The diagonal block preconditioner is\napplied to different material domains of the device structure. As a result,\nbetter convergence and higher computing efficiency are achieved. Moreover, the\ncalculation is further accelerated by two-dimensional periodic Green's\nfunctions. Using the proposed method, the dependences of optical absorption on\nthe wavelengths and incident angles are investigated. Angular responses of the\nplasmonic OSCs show the super-Lambertian absorption on the plasmon resonance\nbut near-Lambertian absorption off the plasmon resonance. The volumetric method\nof moments and explored physical understanding are of great help to investigate\nthe optical responses of OSCs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a legitimate and easily computable measure of nonclassicality for\nthe states of electromagnetic field based on the standard deviation in the\nmeasurement of the homodyne rotated quadrature operator. The proposed measure\nis the nonclassical area projected by the optical tomogram of the quantum state\nof light on the optical tomographic plane. If the nonclassical area projected\nby the optical tomogram of a quantum state is greater than zero, the state is\nstrictly nonclassical, and the area is zero for the classical state. It is also\nnoted that the nonclassical area of a quantum state increases with an increase\nin the strength of nonclassicality inducing operations on the state such as the\nsqueezing, photon addition, etc. We have tested the validity of the\nnonclassical area measure by calculating the same for certain well-known\nnonclassical states and found that essential features of the nonclassicality\nshown by the states are captured in the nonclassical area measure. We have also\nshown that the nonclassical area measure is robust against environment-induced\ndecoherence of the states. Nonclassical area projected by the optical tomogram\nof a quantum state of light is experimentally tractable using the balanced\nhomodyne detection of the quadrature operator of the field, avoiding the\nreconstruction of the density matrix or the quasiprobability distribution of\nthe state.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the implementation and the first results of cosmic ray (CR)\nfeedback in the Feedback In Realistic Environments (FIRE) simulations. We\ninvestigate CR feedback in non-cosmological simulations of dwarf, sub-$L\\star$\nstarburst, and $L\\star$ galaxies with different propagation models, including\nadvection, isotropic and anisotropic diffusion, and streaming along field lines\nwith different transport coefficients. We simulate CR diffusion and streaming\nsimultaneously in galaxies with high resolution, using a two moment method. We\nforward-model and compare to observations of $\\gamma$-ray emission from nearby\nand starburst galaxies. We reproduce the $\\gamma$-ray observations of dwarf and\n$L\\star$ galaxies with constant isotropic diffusion coefficient $\\kappa \\sim\n3\\times 10^{29}\\,{\\rm cm^{2}\\,s^{-1}}$. Advection-only and streaming-only\nmodels produce order-of-magnitude too large $\\gamma$-ray luminosities in dwarf\nand $L\\star$ galaxies. We show that in models that match the $\\gamma$-ray\nobservations, most CRs escape low-gas-density galaxies (e.g.\\ dwarfs) before\nsignificant collisional losses, while starburst galaxies are CR proton\ncalorimeters. While adiabatic losses can be significant, they occur only after\nCRs escape galaxies, so they are only of secondary importance for $\\gamma$-ray\nemissivities. Models where CRs are ``trapped'' in the star-forming disk have\nlower star formation efficiency, but these models are ruled out by $\\gamma$-ray\nobservations. For models with constant $\\kappa$ that match the $\\gamma$-ray\nobservations, CRs form extended halos with scale heights of several kpc to\nseveral tens of kpc.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The object of study is almost paracomplex pseudo-Riemannian manifolds with a\npair of metrics associated each other by the almost paracomplex structure. A\ntorsion-free connection and tensors with geometric interpretation are found\nwhich are invariant under the twin interchange, i.e. the swap of the\ncounterparts of the pair of associated metrics and the corresponding\nLevi-Civita connections. A Lie group depending on two real parameters is\nconstructed as an example of a 4-dimensional manifold of the studied type and\nthe mentioned invariant objects are found in an explicit form.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We explore the interplay between random and deterministic phenomena using a\nrepresentation of uncertainty based on the measure-theoretic concept of outer\nmeasure. The meaning of the analogues of different probabilistic concepts is\ninvestigated and examples of application are given. The novelty of this article\nlies mainly in the suitability of the tools introduced for jointly representing\nrandom and deterministic uncertainty. These tools are shown to yield intuitive\nresults in simple situations and to generalise easily to more complex cases.\nConnections with Dempster-Shafer theory, the empirical Bayes methods and\ngeneralised Bayesian inference are also highlighted.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work we propose a parton state as a candidate state to describe the\nfractional quantum Hall effect in the half-filled second Landau level. The wave\nfunction for this parton state is $\\mathcal{P}_{\\rm LLL}\n\\Phi_{1}^3[\\Phi_{2}^{*}]^{2}\\sim\\Psi^{2}_{2/3}/\\Phi_{1}$ and in the spherical\ngeometry it occurs at the same flux as the anti-Pfaffian state. This state has\na good overlap with the anti-Pfaffian state and with the ground state obtained\nby exact diagonalization, using the second Landau level Coulomb interaction\npseudopotentials for an ordinary semiconductor such as GaAs. By calculating the\nentanglement spectrum we show that this state lies in the same phase as the\nanti-Pfaffian state. A major advantage of this parton state is that its wave\nfunction can be evaluated for large systems, which makes it amenable to\nvariational calculations. In the appendix of this work we have numerically\nassessed the validity of another candidate state at filling factor $\\nu=5/2$,\nnamely the particle-hole-symmetric Pfaffian (PH-Pfaffian) state. We find that\nthe proposed candidate wave function for the PH-Pfaffian state is particle-hole\nsymmetric to a high degree but it does not appear to arise as the ground state\nof any simple Hamiltonian with two-body interactions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Deep learning has recently demonstrated state-of-the art performance on key\ntasks related to the maintenance of computer systems, such as intrusion\ndetection, denial of service attack detection, hardware and software system\nfailures, and malware detection. In these contexts, model interpretability is\nvital for administrator and analyst to trust and act on the automated analysis\nof machine learning models. Deep learning methods have been criticized as black\nbox oracles which allow limited insight into decision factors. In this work we\nseek to \"bridge the gap\" between the impressive performance of deep learning\nmodels and the need for interpretable model introspection. To this end we\npresent recurrent neural network (RNN) language models augmented with attention\nfor anomaly detection in system logs. Our methods are generally applicable to\nany computer system and logging source.\n  By incorporating attention variants into our RNN language models we create\nopportunities for model introspection and analysis without sacrificing\nstate-of-the art performance.\n  We demonstrate model performance and illustrate model interpretability on an\nintrusion detection task using the Los Alamos National Laboratory (LANL) cyber\nsecurity dataset, reporting upward of 0.99 area under the receiver operator\ncharacteristic curve despite being trained only on a single day's worth of\ndata.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Under certain assumptions (such as weak exacteness or monotonicity) we show\nthat splitting Lagrangians through cobordism has an energy cost and, from this\ncost being smaller than certain explicit bounds, we deduce some strong forms of\nrigidity of Lagrangian intersections. As a consequence, we construct some new\npseudo-metrics and metrics on certain classes of Lagrangian submanifolds. We\nalso fit these constructions in a more general setting, independent of\nLagrangian cobordism. As a main technical tool, we develop aspects of the\ntheory of (weakly) filtered A-infinity categories.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We characterize rational series over the free group by using an operator\nintroduced by A. Connes. We prove that rational Malcev--Neumann series posses\nrational expressions without simplifications. Finally, we develop an effective\nalgorithm for solving the word problem in the free skew field.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce a fundamental lemma called the Poisson matching lemma, and apply\nit to prove one-shot achievability results for various settings, namely\nchannels with state information at the encoder, lossy source coding with side\ninformation at the decoder, joint source-channel coding, broadcast channels,\ndistributed lossy source coding, multiple access channels, channel\nresolvability and wiretap channels. Our one-shot bounds improve upon the best\nknown one-shot bounds in most of the aforementioned settings (except multiple\naccess channels, channel resolvability and wiretap channels, where we recover\nbounds comparable to the best known bounds), with shorter proofs in some\nsettings even when compared to the conventional asymptotic approach using\ntypicality. The Poisson matching lemma replaces both the packing and covering\nlemmas, greatly simplifying the error analysis. This paper extends the work of\nLi and El Gamal on Poisson functional representation, which mainly considered\nvariable-length source coding settings, whereas this paper studies fixed-length\nsettings, and is not limited to source coding, showing that the Poisson\nfunctional representation is a viable alternative to typicality for most\nproblems in network information theory.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We compute the superconformal partial waves of the four-point correlator\n$\\langle JJJJ\\rangle$, in which the external operator $J$ is the superconformal\nprimary of the $4D$ $\\mathcal{N}=2$ stress-tensor multiplet $\\mathcal{J}$. We\ndevelop the superembedding formalism for the superconformal field theories\n(SCFTs) with extended supersymmetry. In $\\mathcal{N}=2$ SCFTs, the three-point\nfunctions $\\langle \\mathcal{J}\\mathcal{J}\\mathcal{O}\\rangle$ with general\nmultiplet $\\mathcal{O}$ contain two independent nilpotent superconformal\ninvariants and new superconformal tensor structures, which can be nicely\nconstructed from variables in superembedding space, and the three-point\nfunctions can be solved in compact forms. We compute the superconformal partial\nwaves corresponding to the exchange of long multiplets using supershadow\napproach. The results are consistent with the non-trivial constraints by\ndecomposing the $\\mathcal{N}=2$ superconformal blocks into $\\mathcal{N}=1$\nsuperconformal blocks. Our results provide the necessary ingredient to study\nthe fascinating $4D$ $\\mathcal{N}=2$ SCFTs using conformal bootstrap.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose that the $\\gamma + E \\hspace{-.5em}/\\;\\:$ signal at the Belle-II\nwill be a smoking gun for supersymmetry (SUSY) in the presence of a gauged\n$U(1)_{L_{\\mu}-L_{\\tau}}$ symmetry. A striking consequence of breaking the\nenhanced symmetry in the limit of degenerate (s)leptons is the nondecoupling of\nthe radiative contribution of heavy charged sleptons, appearing in SUSY, to the\n$\\gamma - Z^\\prime$ kinetic mixing. The signal process, $e^+ e^- \\rightarrow\n\\gamma Z^\\prime \\rightarrow \\gamma + E \\hspace{-.5em}/\\;\\:$, is an outcome of\nthis ubiquitous feature. We take into account the severe constraints on gauged\n$U(1)_{L_{\\mu}-L_{\\tau}}$ models by several low-energy observables and show\nthat any significant excess in all but the highest photon energy bin would be\nan undeniable signature of such heavy scalar fields in SUSY coupling to\n$Z^\\prime$. The number of signal events depends crucially on the logarithm of\nthe ratio of stau to smuon mass in the presence of SUSY. In addition, the\nnumber is also inversely proportional to the $e^+-e^-$ collision energy, making\na low-energy, high-luminosity collider like Belle-II an ideal testing ground\nfor this channel. This process can probe large swathes of the slepton mass\nratio vs the additional gauge coupling ($g_X$) parameter space. More\nimportantly, it can explore the narrow slice of $M_{Z^{\\prime}}-g_X$ parameter\nspace still allowed in gauged $U(1)_{L_{\\mu}-L_{\\tau}}$ models for superheavy\nsparticles.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We provide an intrinsic description of the notion of modular class for an\neven symplectic manifold and study its properties in this coordinate free\nsetting.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We derive a degenerate quasilinear Schr\\\"odinger equation that describes the\nresonant reflection of very weak, nonlinear sound waves off a weak sawtooth\nentropy wave.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We perform a detailed analysis of the properties of stationary observers\nlocated on the equatorial plane of the ergosphere in a Kerr spacetime,\nincluding light-surfaces. This study highlights crucial differences between\nblack hole and the super-spinner sources. In the case of Kerr naked\nsingularities, the results allow us to distinguish between \"weak\" and \"strong\"\nsingularities, corresponding to spin values close to or distant from the\nlimiting case of extreme black holes, respectively. We derive important\nlimiting angular frequencies for naked singularities. We especially study very\nweak singularities as resulting from the spin variation of black holes. We also\nexplore the main properties of zero angular momentum observers for different\nclasses of black hole and naked singularity spacetimes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  For several decades, the no-arbitrage (NA) condition and the martingale\nmeasures have played a major role in the financial asset's pricing theory. We\npropose a new approach for estimating the super-replication cost based on\nconvex duality instead of martingale measures duality: Our prices will be\nexpressed using Fenchel conjugate and bi-conjugate. The super-hedging problem\nleads endogenously to a weak condition of NA called Absence of Immediate Profit\n(AIP). We propose several characterizations of AIP and study the relation with\nthe classical notions of no-arbitrage. We also give some promising numerical\nillustrations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Shocked POststarburst Galaxy Survey (SPOGS) aims to identify galaxies in\nthe transitional phase between actively star-forming and quiescence with\nnebular lines that are excited from shocks rather than star formation\nprocesses. We explored the ultraviolet (UV) properties of objects with\nnear-ultraviolet (NUV) and far-ultraviolet (FUV) photometry from archival GALEX\ndata; 444 objects were detected in both bands, 365 in only NUV, and 24 in only\nFUV, for a total of 833 observed objects. We compared SPOGs to samples of\nStar-forming galaxies (SFs), Quiescent galaxies (Qs), classical E+A\npost-starburst galaxies, active galactic nuclei (AGN) host galaxies, and\ninteracting galaxies. We found that SPOGs have a larger range in their FUV-NUV\nand NUV-r colors compared to most of the other samples, although all of our\ncomparison samples occupied color space inside of the SPOGs region. Based on\ntheir UV colors, SPOGs are a heterogeneous group, possibly made up of a mixture\nof SFs, Qs, and/or AGN. Using Gaussian mixture models, we are able to recreate\nthe distribution of FUV-NUV colors of SPOGs and E+A galaxies with different\ncombinations of SFs, Qs, and AGN. We find that the UV colors of SPOGs require a\n>60% contribution from SFs, with either Qs or AGN representing the remaining\ncontribution, while UV colors of E+A galaxies required a significantly lower\nfraction of SFs, supporting the idea that SPOGs are at an earlier point in\ntheir transition from quiescent to star-forming than E+A galaxies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we introduce Iterative Text Summarization (ITS), an\niteration-based model for supervised extractive text summarization, inspired by\nthe observation that it is often necessary for a human to read an article\nmultiple times in order to fully understand and summarize its contents. Current\nsummarization approaches read through a document only once to generate a\ndocument representation, resulting in a sub-optimal representation. To address\nthis issue we introduce a model which iteratively polishes the document\nrepresentation on many passes through the document. As part of our model, we\nalso introduce a selective reading mechanism that decides more accurately the\nextent to which each sentence in the model should be updated. Experimental\nresults on the CNN/DailyMail and DUC2002 datasets demonstrate that our model\nsignificantly outperforms state-of-the-art extractive systems when evaluated by\nmachines and by humans.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Here we present a fundamental comprehension of the microscopic mechanisms\nleading to the emergence of inverse melting transitions by considering a\nthorough mean-field analysis of a variety of minimal models with different\ncompeting interactions. Through analytical and numerical tools we identify the\nspecific connections between the characteristic energy of the homogeneous and\nmodulated phases and the observed reentrant behaviors. In particular, we find\nthat reentrance is appreciable when the characteristic energy cost of the\nhomogeneous and modulated phases are comparable to each other, and for systems\nin which the local order parameter is limited. In the asymptotic limit of high\nenergy cost of the homogeneous phase we obtain analytically that the degree of\nreentrance of the phase diagram decreases exponentially with the ratio of the\ncharacteristic energy cost of homogeneous and modulated phases. We are also\nable to establish theoretical (upper and lower) bounds for the degree of the\nreentrance, according to the nature of the competing interactions. Finally, we\nconfront our mean-field results with Langevin simulations of an effective\ncoarse grained model, confirming the main results regarding the degree of the\nreentrance in the phase diagram. These results shed new light on the many\nsystems undergoing inverse melting transitions, from magnets to colloids and\nvortex matter, by qualitatively improving the understanding of the interplay of\nentropy and energy around the inverse melting points.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we analyze several neural network designs (and their\nvariations) for sentence pair modeling and compare their performance\nextensively across eight datasets, including paraphrase identification,\nsemantic textual similarity, natural language inference, and question answering\ntasks. Although most of these models have claimed state-of-the-art performance,\nthe original papers often reported on only one or two selected datasets. We\nprovide a systematic study and show that (i) encoding contextual information by\nLSTM and inter-sentence interactions are critical, (ii) Tree-LSTM does not help\nas much as previously claimed but surprisingly improves performance on Twitter\ndatasets, (iii) the Enhanced Sequential Inference Model is the best so far for\nlarger datasets, while the Pairwise Word Interaction Model achieves the best\nperformance when less data is available. We release our implementations as an\nopen-source toolkit.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce a new iterative rounding technique to round a point in a matroid\npolytope subject to further matroid constraints. This technique returns an\nindependent set in one matroid with limited violations of the other ones. On\ntop of the classical steps of iterative relaxation approaches, we iteratively\nrefine/split involved matroid constraints to obtain a more restrictive\nconstraint system, that is amenable to iterative relaxation techniques. Hence,\nthroughout the iterations, we both tighten constraints and later relax them by\ndropping constrains under certain conditions. Due to the refinement step, we\ncan deal with considerably more general constraint classes than existing\niterative relaxation/rounding methods, which typically round on one matroid\npolytope with additional simple cardinality constraints that do not overlap too\nmuch.\n  We show how our rounding method, combined with an application of a matroid\nintersection algorithm, yields the first $2$-approximation for finding a\nmaximum-weight common independent set in $3$ matroids. Moreover, our\n$2$-approximation is LP-based, and settles the integrality gap for the natural\nrelaxation of the problem. Prior to our work, no better upper bound than $3$\nwas known for the integrality gap, which followed from the greedy algorithm. We\nalso discuss various other applications of our techniques, including an\nextension that allows us to handle a mixture of matroid and knapsack\nconstraints.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Jupiter's radio emission has been linked to its planetary-scale magnetic\nfield, and spacecraft investigations have revealed that most planets, and some\nmoons, have or had a global magnetic field. Generated by internal dynamos,\nmagnetic fields are one of the few remote sensing means of constraining the\nproperties of planetary interiors. For the Earth, its magnetic field has been\nspeculated to be partially responsible for its habitability, and knowledge of\nan extrasolar planet's magnetic field may be necessary to assess its\nhabitability. The radio emission from Jupiter and other solar system planets is\nproduced by an electron cyclotron maser, and detections of extrasolar planetary\nelectron cyclotron masers will enable measurements of extrasolar planetary\nmagnetic fields.\n  This white paper draws heavily on the W. M. Keck Institute for Space Studies\nreport Planetary Magnetic Fields: Planetary Interiors and Habitability (Lazio,\nShkolnik, Hallinan, et al.), it incorporates topics discussed at the American\nAstronomical Society Topical Conference \"Radio Exploration of Planetary\nHabitability,\" it complements the Astrobiology Science Strategy white paper\n\"Life Beyond the Solar System: Space Weather and Its Impact on Habitable\nWorlds\" (Airapetian et al.), and it addresses aspects of planetary magnetic\nfields discussed in the NASA Astrobiology Strategy.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the following generalization of the well-known model of broadcasting\non trees. Consider an infinite directed acyclic graph (DAG) with a unique\nsource node $X$. Let the collection of nodes at distance $k$ from $X$ be called\nthe $k$th layer. At time zero, the source node is given a bit. At time $k\\geq\n1$, each node in the $(k-1)$th layer inspects its inputs and sends a bit to its\ndescendants in the $k$th layer. Each bit is flipped with a probability of error\n$\\delta \\in \\left(0,\\frac{1}{2}\\right)$ in the process of transmission. The\ngoal is to be able to recover the original bit with probability of error better\nthan $\\frac{1}{2}$ from the values of all nodes at an arbitrarily deep layer\n$k$.\n  Besides its natural broadcast interpretation, the DAG broadcast is a natural\nmodel of noisy computation. Some special cases of the model represent\ninformation flow in biological networks, and other cases represent noisy finite\nautomata models.\n  We show that there exist DAGs with bounded degree and layers of size\n$\\omega(\\log(k))$ that permit recovery provided $\\delta$ is sufficiently small\nand find the critical $\\delta$ for the DAGs constructed. Our result\ndemonstrates a doubly-exponential advantage for storing a bit in bounded degree\nDAGs compared to trees. On the negative side, we show that if the DAG is a\ntwo-dimensional regular grid, then recovery is impossible for any $\\delta \\in\n\\left(0,\\frac{1}{2}\\right)$ provided all nodes use either AND or XOR for their\nprocessing functions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Minijets provide useful information on parton interactions in the low\ntransverse-momentum (low-$p_T$) region. Because minijets produce clusters, we\nstudy the clustering properties of produced particles in high-energy $pp$\ncollisions as a first step to identify minijets. We develop an algorithm to\nfind clusters by using the k-means clustering method, in conjunction with a\nk-number (cluster number) selection principle in the space of pseudorapidity\nand azimuthal angles. We test the clustering algorithm using events generated\nby PYTHIA 8.1, for $pp$ collision at $\\sqrt{s}=200$ GeV. We find that\nclustering of low-$p_T$ hadrons occurs in high multiplicity events. However\nsimilar clustering properties are also present for particles produced randomly\nin a finite pseudorapidity and azimuthal angle space. To distinguish the\ndynamics from random generations of events, it is necessary to examine the\ncorrelation between particles and between clusters. We find that the\ncorrelations between clusters may provide a useful tool to distinguish the\nunderlying dynamics of the reaction mechanism.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Charged colloidal monolayers at the interface between water and air (or oil)\nare used in a large number of chemical, physical and biological applications.\nAlthough a considerable experimental and theoretical effort has been devoted in\nthe past few decades to investigate such monolayers, some of their fundamental\nproperties are not yet fully understood. In this paper, we model charged\ncolloidal monolayers as a continuum layer of finite thickness, with separate\ncharge distribution on the water and air sides. The electrostatic surface\nfree-energy and surface pressure are calculated via the charging method and\nwithin the Debye-H{\\\"u}ckel approximation. We obtain the dependence of surface\npressure on several system parameters: the monolayer thickness, its distinct\ndielectric permittivity, and the ionic strength of the aqueous subphase. The\nsurface pressure scaling with the area per particle, ${a}$, is found to be\nbetween ${a}^{-2}$ in the close-packing limit, and ${a}^{-5/2}$ in the\nloose-packing limit. In general, it is found that the surface-pressure is\nstrongly influenced by charges on the air-side of the colloids. However, when\nthe larger charge resides on the water-side, a more subtle dependence on salt\nconcentration emerges. This corrects a common assumption that the charges on\nthe water-side can \\textit{always} be neglected due to screening. Finally,\nusing a single fit parameter, our theory is found to fit well the experimental\ndata for strong to intermediate strength electrolytes. We postulate that an\nanomalous scaling of $a^{-3/2}$, recently observed in low ionic concentrations,\ncannot be accounted for within a linear theory, and its explanation requires a\nfully-nonlinear analysis.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Given a complex connected reductive Lie group $G$ with a maximal torus\n$H\\subset G$, Tits defined an extension $W_G^T$ of the corresponding Weyl group\n$W_G$. The extended group is supplied with an embedding into the normalizer\n$N_G(H)$, such that $W_G^T$ together with $H$ generate $N_G(H)$. In this paper\nwe propose an interpretation of the Tits classical construction in terms of the\nmaximal split real form $G(\\mathbb{R})\\subset G$, which leads to the simple\ntopological description of $W^T_G$. We also consider a variation of the Tits\nconstruction associated with compact real form $U$ of $G$. In this case we\ndefine an extension $W_G^U$ of the Weyl group $W_G$, naturally embedded into\nthe group extension $\\widetilde{U}:=U\\rtimes\\Gamma$ of the compact real form\n$U$ by the Galois group $\\Gamma={\\rm\n  Gal}(\\mathbb{C}/\\mathbb{R})$. Generators of $W^U_G$ are squared to identity\nas in the Weyl group $W_G$. However, the non-trivial action of $\\Gamma$ by\nouter automorphisms requires $W^U_G$ to be a non-trivial extension of $W_G$.\nThis gives a specific presentation of the maximal torus normalizer of the group\nextension $\\widetilde{U}$. Finally, we describe explicitly the adjoint action\nof $W_G^T$ and $W^U_G$ on the Lie algebra of $G$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The fixed-target NA61/SHINE experiment (SPS CERN) looks for the critical\npoint of strongly interacting matter and the properties of the onset of\ndeconfinement. It is a two dimensional scan of measurements of particle spectra\nand fluctuations in proton-proton, proton-nucleus and nucleus-nucleus\ninteractions as a function of collision energy and system size, corresponding\nto a two dimensional phase diagram (temperature T - baryonic chemical potential\n$\\mu_B$). New NA61/SHINE results are presented here, such as transverse\nmomentum and multiplicity fluctuations in Ar+Sc collisions compared to\nNA61/SHINE p+p and Be+Be data, as well as to earlier NA49 A+A results.\nRecently, a preliminary signature for the new size dependent effect - rapid\nchanges in system size dependence was observed in NA61-SHINE data, labeled as\npercolation threshold or onset of fireball. This would be closely related to\nthe vicinity of the hadronic phase transition region.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce a new model of preferential attachment with fitness, and\nestablish a time reversed duality between the model and a system of\nbranching-coalescing particles. Using this duality, we give a clear and concise\nexplanation for the condensation phenomenon, in which unusually fit vertices\nmay obtain abnormally high degree: it arises from a growth-extinction dichotomy\nwithin the branching part of the dual. We show further that the condensation is\nextensive. As the graph grows, unusually fit vertices become, each only for a\nlimited time, neighbouring to a non-vanishing proportion of the current graph.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We develop a description of the equation of state of QCD matter with restored\nchiral symmetry, which is in thermal and chemical equilibrium with the hadronic\nphase. The hadron gas is described with self-consistent volume corrections. The\nchiral phase is composed of a group of few quark condensates, each of which\ncorresponds to a family of hadrons with specific quark content. Between the two\nphases and along the chemical freeze-out curve we apply the requirement of\nconservation of particle numbers per family. We use lattice calculations for\ntemperatures lower than the critical one to determine hadronic volumes. We find\nthat the pion system plays decisive role in the shift of the transition from\nhigher order (crossover) to first order. For three volume models we calculate\nthe position of the critical point as function of critical temperature $T_c$ at\nvanishing baryon density. Particularly, in a model with different radii for\nmesons and baryons --if we additionally impose the equality between the\ndensities of quarks contained in mesons and baryons-- we find a critical point\nresiding at $\\mu_B \\simeq$ 266 MeV and $T \\simeq$ 152 MeV which corresponds to\n$T_c \\simeq$ 161 MeV.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a generalization of the best arm identification problem in\nstochastic multi-armed bandits (MAB) to the setting where every pull of an arm\nis associated with delayed feedback. The delay in feedback increases the\neffective sample complexity of standard algorithms, but can be offset if we\nhave access to partial feedback received before a pull is completed. We propose\na general framework to model the relationship between partial and delayed\nfeedback, and as a special case we introduce efficient algorithms for settings\nwhere the partial feedback are biased or unbiased estimators of the delayed\nfeedback. Additionally, we propose a novel extension of the algorithms to the\nparallel MAB setting where an agent can control a batch of arms. Our\nexperiments in real-world settings, involving policy search and hyperparameter\noptimization in computational sustainability domains for fast charging of\nbatteries and wildlife corridor construction, demonstrate that exploiting the\nstructure of partial feedback can lead to significant improvements over\nbaselines in both sequential and parallel MAB.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Not all people are equally easy to identify: color statistics might be enough\nfor some cases while others might require careful reasoning about high- and\nlow-level details. However, prevailing person re-identification(re-ID) methods\nuse one-size-fits-all high-level embeddings from deep convolutional networks\nfor all cases. This might limit their accuracy on difficult examples or makes\nthem needlessly expensive for the easy ones. To remedy this, we present a new\nperson re-ID model that combines effective embeddings built on multiple\nconvolutional network layers, trained with deep-supervision. On traditional\nre-ID benchmarks, our method improves substantially over the previous\nstate-of-the-art results on all five datasets that we evaluate on. We then\npropose two new formulations of the person re-ID problem under\nresource-constraints, and show how our model can be used to effectively trade\noff accuracy and computation in the presence of resource constraints. Code and\npre-trained models are available at https://github.com/mileyan/DARENet.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Uncertain information on input parameters of reliability models is usually\nmodeled by considering these parameters as random, and described by marginal\ndistributions and a dependence structure of these variables. In numerous\nreal-world applications, while information is mainly provided by marginal\ndistributions, typically from samples , little is really known on the\ndependence structure itself. Faced with this problem of incomplete or missing\ninformation, risk studies are often conducted by considering independence of\ninput variables, at the risk of including irrelevant situations. This approach\nis especially used when reliability functions are considered as black-box\ncomputational models. Such analyses remain weakened in absence of in-depth\nmodel exploration, at the possible price of a strong risk misestimation.\nConsidering the frequent case where the reliability output is a quantile, this\narticle provides a methodology to improve risk assessment, by exploring a set\nof pessimistic dependencies using a copula-based strategy. In dimension greater\nthan two, a greedy algorithm is provided to build input regular vine copulas\nreaching a minimum quantile to which a reliability admissible limit value can\nbe compared, by selecting pairwise components of sensitive influence on the\nresult. The strategy is tested over toy models and a real industrial\ncase-study. The results highlight that current approaches can provide\nnon-conservative results, and that a nontrivial dependence structure can be\nexhibited to define a worst-case scenario.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Motivated by symmetry-protected topological phases (SPTs) with both spatial\nsymmetry (e.g., lattice rotation) and internal symmetry (e.g., spin rotation),\nwe propose a class of exotic topological terms, which generalize the well-known\nWen-Zee topological terms of quantum Hall systems [X.-G. Wen and A. Zee, Phys.\nRev. Lett. 69, 953 (1992)]. These generalized Wen-Zee terms are expressed as\nwedge product of spin connection and usual gauge fields (1-form or higher) in\nvarious dimensions. In order to probe SPT orders, we externally insert\n\"symmetry twists\" like domain walls of discrete internal symmetry and\ndisclinations that are geometric defects with nontrivial Riemann curvature.\nThen, generalized Wen-Zee terms simply tells us how SPTs respond to those\nsymmetry twists. Classifying these exotic topological terms thus leads to a\ncomplete classification and characterization of SPTs within the present\nframework. We also propose SPT low-energy field theories, from which\ngeneralized Wen-Zee terms are deduced as topological response actions.\nFollowing the Abstract of Wen-Zee paper, our work enriches alternative\npossibilities of condensed-matter realization of unification of\nelectromagnetism and \"gravity\".\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Star-Planet Activity Research CubeSat (SPARCS) is a NASA-funded\nastrophysics mission, devoted to the study of the ultraviolet (UV) time-domain\nbehavior in low-mass stars. Given their abundance and size, low-mass stars are\nimportant targets in the search for habitable-zone, exoplanets. However, not\nenough is known about the stars flare and quiescent emission, which powers\nphotochemical reactions on the atmospheres of possible planets. Over its\ninitial 1-year mission, SPARCS will stare at ~10 stars in order to measure\nshort- (minutes) and long- (months) term variability simultaneously in the\nnear-UV (NUV - lam = 280 nm) and far-UV (FUV - lam = 162 nm). The SPARCS\npayload consists of a 9-cm reflector telescope paired with two high-sensitivity\n2D-doped CCDs. The detectors are kept passively cooled at 238K, in order to\nreduce dark-current contribution. The filters have been selected to provide\nstrong rejection of longer wavelengths, where most of the starlight is emitted.\nThe payload will be integrated within a 6U CubeSat to be placed on a\nSun-synchronous terminator orbit, allowing for long observing stares for all\ntargets. Launch is expected to occur not earlier than October 2021.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  During the last years, the new science of municipalities has been established\nas a fertile quantitative approach to systematically understand the urban\nphenomena. One of its main pillars is the proposition that urban systems\ndisplay universal scaling behavior regarding socioeconomic, infrastructural and\nindividual basic services variables. This paper discusses the extension of the\nuniversality proposition by testing it against a broad range of urban metrics\nin a developing country urban system. We present an exploration of the scaling\nexponents for over 6$ variables for the Brazilian urban system. As Brazilian\nmunicipalities can deviate significantly from urban settlements, urban-like\nmunicipalities were selected based on a systematic density cut-off procedure\nand the scaling exponents were estimated for this new subset of municipalities.\nTo validate our findings we compared the results for overlaying variables with\nother studies based on alternative methods. It was found that the analyzed\nsocioeconomic variables follow a superlinear scaling relationship with the\npopulation size, and most of the infrastructure and individual basic services\nvariables follow expected sublinear and linear scaling, respectively. However,\nsome infrastructural and individual basic services variables deviated from\ntheir expected regimes, challenging the universality hypothesis of urban\nscaling. We propose that these deviations are a product of top-down\ndecisions/policies. Our analysis spreads over a time-range of 10 years, what is\nnot enough to draw conclusive observations, nevertheless we found hints that\nthe scaling exponent of these variables are evolving towards the expected\nscaling regime, indicating that the deviations might be temporally constrained\nand that the urban systems might eventually reach the expected scaling regime.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Though deep neural networks have achieved state-of-the-art performance in\nvisual classification, recent studies have shown that they are all vulnerable\nto the attack of adversarial examples. Small and often imperceptible\nperturbations to the input images are sufficient to fool the most powerful deep\nneural networks. Various defense methods have been proposed to address this\nissue. However, they either require knowledge on the process of generating\nadversarial examples, or are not robust against new attacks specifically\ndesigned to penetrate the existing defense. In this work, we introduce\nkey-based network, a new detection-based defense mechanism to distinguish\nadversarial examples from normal ones based on error correcting output codes,\nusing the binary code vectors produced by multiple binary classifiers applied\nto randomly chosen label-sets as signatures to match normal images and reject\nadversarial examples. In contrast to existing defense methods, the proposed\nmethod does not require knowledge of the process for generating adversarial\nexamples and can be applied to defend against different types of attacks. For\nthe practical black-box and gray-box scenarios, where the attacker does not\nknow the encoding scheme, we show empirically that key-based network can\neffectively detect adversarial examples generated by several state-of-the-art\nattacks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present nearly simultaneous NuSTAR and XMM-Newton observations of the\nnearby (832 kpc) ultraluminous X-ray source (ULX) M33 X-8. M33 X-8 has a 0.3-10\nkeV luminosity of LX ~ 1.4 x 10^39 erg/s, near the boundary of the\n\"ultraluminous\" classification, making it an important source for understanding\nthe link between typical Galactic X-ray binaries and ULXs. Past studies have\nshown that the 0.3-10 keV spectrum of X-8 can be characterized using an\nadvection-dominated accretion disk model. We find that when fitting to our\nNuSTAR and XMM-Newton observations, an additional high-energy (>10 keV)\nComptonization component is required, which allows us to rule out single\nadvection-dominated disk and classical sub-Eddington models. With our new\nconstraints, we analyze XMM-Newton data taken over the last 17 years to show\nthat small (~30%) variations in the 0.3-10 keV flux of M33 X-8 result in\nspectral changes similar to those observed for other ULXs. The two most likely\nphenomenological scenarios suggested by the data are degenerate in terms of\nconstraining the nature of the accreting compact object (i.e., black hole\nversus neutron star). We further present a search for pulsations using our\nsuite of data; however, no clear pulsations are detected. Future observations\ndesigned to observe M33 X-8 at different flux levels across the full 0.3-30 keV\nrange would significantly improve our constraints on the nature of this\nimportant source.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the first steps of a procedure which discretises surface theory in\nclassical projective differential geometry in such a manner that underlying\nintegrable structure is preserved. We propose a canonical frame in terms of\nwhich the associated projective Gauss-Weingarten and Gauss-Mainardi-Codazzi\nequations adopt compact forms. Based on a scaling symmetry which injects a\nparameter into the linear Gauss-Weingarten equations, we set down an algebraic\nclassification scheme of discrete projective minimal surfaces which turns out\nto admit a geometric counterpart formulated in terms of discrete notions of Lie\nquadrics and their envelopes. In the case of discrete Demoulin surfaces, we\nderive a Backlund transformation for the underlying discrete Demoulin system\nand show how the latter may be formulated as a two-component generalisation of\nthe integrable discrete Tzitzeica equation which has originally been derived in\na different context. At the geometric level, this connection leads to the\nretrieval of the standard discretisation of affine spheres in affine\ndifferential geometry.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider a wave packet of a spin-1/2 particle in a gravitational field,\nthe effect of which can be described in terms of a succession of local inertial\nframes. It is shown that integrating out of the momentum yields a spin mixed\nstate, with the entropy dependent on the deviation of metric from the flat\nspacetime. The decoherence occurs even if the particle is static in the\ngravitational field.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A two-dimensional (2D) hydrogen-like atom with a relativistic Dirac electron,\nplaced in a weak, static, uniform magnetic field perpendicular to the atomic\nplane, is considered. Closed forms of the first- and second-order Zeeman\ncorrections to energy levels are calculated analytically, within the framework\nof the Rayleigh-Schr\\\"odinger perturbation theory, for an arbitrary electronic\nbound state. The second-order calculations are carried out with the use of the\nSturmian expansion of the two-dimensional generalized radial Dirac-Coulomb\nGreen function derived in the paper. It is found that, in contrast to the case\nof the three-dimensional atom [P. Stefa\\'nska, Phys. Rev. A 92 (2015) 032504],\nin two spatial dimensions atomic magnetizabilities (magnetic susceptibilities)\nare expressible in terms of elementary algebraic functions of a nuclear charge\nand electron quantum numbers. The problem considered here is related to the\nCoulomb impurity problem for graphene in a weak magnetic field.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Phase retrieval (PR) is an ill-conditioned inverse problem which can be found\nin various science and engineering applications. Assuming sparse priority over\nthe signal of interest, recent algorithms have been developed to solve the\nphase retrieval problem. Some examples include SparseAltMinPhase (SAMP), Sparse\nWirtinger flow (SWF) and Sparse Truncated Amplitude flow (SPARTA). However, the\noptimization cost functions of the mentioned algorithms are non-convex and\nnon-smooth. In order to fix the non-smoothness of the cost function, the SPARTA\nmethod uses truncation thresholds to calculate a truncated step update\ndirection. In practice, the truncation procedure requires calculating more\nparameters to obtain a desired performance in the phase recovery. Therefore,\nthis paper proposes an algorithm called SPRSF (Sparse Phase retrieval via\nSmoothing Function) to solve the sparse PR problem by introducing a smoothing\nfunction. SPRSF is an iterative algorithm where the update step is obtained by\na hard thresholding over a gradient descent direction. Theoretical analyses\nshow that the smoothing function uniformly approximates the non-convex and\nnon-smooth sparse PR optimization problem. Moreover, SPRSF does not require the\ntruncation procedure used in SPARTA. Numerical tests demonstrate that SPRSF\nperforms better than state-of-the-art methods, especially when there is no\nknowledge about the sparsity $k$. In particular, SPRSF attains a higher mean\nrecovery rate in comparison with SPARTA, SAMP and SWF methods, when the\nsparsity varies for the real and complex cases. Further, in terms of the\nsampling complexity, the SPRSF method outperforms its competitive alternatives.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The realization of high fidelity quantum gates in a multi-qubit system, with\na typical target set at 99.9%, is a critical requirement for the implementation\nof fault-tolerant quantum computation. To reach this level of fidelity, one\nneeds to carefully analyze the noises and imperfections in the experimental\nsystem and optimize the gate operations to mitigate their effects. Here, we\nconsider one of the leading experimental systems for the fault-tolerant quantum\ncomputation, ions in an anharmonic linear Paul trap, and optimize entangling\nquantum gates using segmented laser pulses with the assistance of all the\ncollective transverse phonon modes of the ion crystal. We present detailed\nanalyses of the effects of various kinds of intrinsic experimental noises as\nwell as errors from imperfect experimental controls. Through explicit\ncalculations, we find the requirements on these relevant noise levels and\ncontrol precisions to achieve the targeted high fidelity of 99.9% for the\nentangling quantum gates in a multi-ion crystal.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, we studied amorphous carbon ($a$-C) thin films deposited using\ndirect current (dc) and high power impulse magnetron sputtering (HiPIMS)\ntechniques. The microstructure and electronic properties reveal subtle\ndifferences in $a$-C thin films deposited by two techniques. While, films\ndeposited with dcMS have a smooth texture typically found in $a$-C thin films,\nthose deposited with HiPIMS consist of dense hillocks surrounded by a porous\nmicrostructure. The density of $a$-C thin films is a decisive parameter to\njudge their quality. Often, x-ray reflectivity (XRR) has been used to measure\nthe density of carbon thin films. From the present work, we find that\ndetermination of density of carbon thin films, specially those with a thickness\nof few tens of nm, may not be accurate with XRR due to a poor scattering\ncontrast between the film and substrate. By utilizing neutron reflectivity (NR)\nin the time of flight mode, a technique not commonly used for carbon thin\nfilms, we could accurately measure differences in the densities of $a$-C thin\nfilms deposited using dcMS and HiPIMS.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we present the results of our investigation relating particle\ndynamics and non-commutativity of space-time by using Dirac's constraint\nanalysis. In this study, we re-parameterise the time $t=t(\\tau)$ along with\n$x=x(\\tau)$ and treat both as configuration space variables. Here, $\\tau$ is a\nmonotonic increasing parameter and the system evolves with this parameter.\nAfter constraint analysis, we find the deformed Dirac brackets similar to the\n$\\kappa$-deformed space-time and also, get the deformed Hamilton's equations of\nmotion. Moreover, we study the effect of non-commutativity on the generators of\nGalilean group and Poincare group and find undeformed form of the algebra.\nAlso, we work on the extended space analysis in the Lagrangian formalism. We\nfind the primary as well as the secondary constraints. Strikingly on\ncalculating the Dirac brackets among the phase space variables, we obtain the\nclassical version of $\\kappa$-Minkowski algebra.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we present a fast streamline-based numerical method for the\ntwo-phase flow equations in high-rate flooding scenarios for incompressible\nfluids in heterogeneous and anisotropic porous media. A fractional flow\nformulation is adopted and a discontinuous Galerkin method (DG) is employed to\nsolve the pressure equation. Capillary effects can be neglected in high-rate\nflooding scenarios. This allows us to present an improved streamline approach\nin combination with the one-dimensional front tracking method to solve the\ntransport equation. To handle the high computational costs of the DG\napproximation, domain decomposition is applied combined with an algebraic\nmultigrid preconditioner to solve the linear system. Special care at the\ninterior interfaces is required and the streamline tracer has to include a\ndynamic communication strategy. The method is validated in various two- and\nthree-dimensional tests, where comparisons of the solutions in terms of\napproximation of flow front propagation with standard fully-implicit finite\nvolume methods are provided.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the quantum criticality of the phase transition between the Dirac\nsemimetal and the excitonic insulator in two dimensions. Even though the system\nhas a semimetallic ground state, there are observable effects of excitonic\npairing at finite temperatures and/or finite energies, provided that the system\nis in proximity to the excitonic insulating transition. To determine the\nquantum critical behavior, we consider three potentially important\ninteractions, including the Yukawa coupling between Dirac fermions and the\nexcitonic order parameter fluctuation, the long-range Coulomb interaction, and\nthe disorder scattering. We employ the renormalization group technique to study\nhow these interactions affect quantum criticality and also how they influence\neach other. We first investigate the Yukawa coupling in the clean limit, and\nshow that it gives rise to typical non-Fermi liquid behavior. Adding random\nscalar potential to the system always turns such a non-Fermi liquid into a\ncompressible diffusive metal. In comparison, the non-Fermi liquid behavior is\nfurther enhanced by random vector potential, but is nearly unaffected by random\nmass. Incorporating the Coulomb interaction may change the results\nqualitatively. In particular, the non-Fermi liquid state is protected by the\nCoulomb interaction for weak random scalar potential, and it becomes a\ndiffusive metal only when random scalar potential becomes sufficiently strong.\nWhen random vector potential or random mass coexists with Yukawa coupling and\nCoulomb interaction, the system is a stable non-Fermi liquid state, with\nfermion velocities flowing to constants in the former case and being singularly\nrenormalized in the latter case. These quantum critical phenomena can be probed\nby measuring observable quantities.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We have previously established that $\\Pi^1_1$-comprehension is equivalent to\nthe statement that every dilator has a well-founded Bachmann-Howard fixed\npoint, over $\\mathbf{ATR_0}$. In the present paper we show that the base theory\ncan be lowered to $\\mathbf{RCA_0}$. We also show that the minimal\nBachmann-Howard fixed point of a dilator $T$ can be represented by a notation\nsystem $\\vartheta(T)$, which is computable relative to $T$. The statement that\n$\\vartheta(T)$ is well-founded for any dilator $T$ will still be equivalent to\n$\\Pi^1_1$-comprehension. Thus the latter is split into the computable\ntransformation $T\\mapsto\\vartheta(T)$ and a statement about the preservation of\nwell-foundedness, over a system of computable mathematics.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  X-ray reflection is a very powerful method to assess the spin of supermassive\nblack holes (SMBHs) in active galactic nuclei (AGN), yet this technique is not\nuniversally accepted. Indeed, complex reprocessing (absorption, scattering) of\nthe intrinsic spectra along the line of sight can mimic the relativistic\neffects on which the spin measure is based. In this work, we test the\nreliability of SMBH spin measurements that can currently be achieved through\nthe simulations of high-quality XMM-Newton and NuSTAR spectra. Each member of\nour group simulated ten spectra with multiple components that are typically\nseen in AGN, such as warm and (partial-covering) neutral absorbers,\nrelativistic and distant reflection, and thermal emission. The resulting\nspectra were blindly analysed by the other two members. Out of the 60 fits, 42\nturn out to be physically accurate when compared to the input model. The SMBH\nspin is retrieved with success in 31 cases, some of which (9) are even found\namong formally inaccurate fits (although with looser constraints). We show\nthat, at the high signal-to-noise ratio assumed in our simulations, neither the\ncomplexity of the multi-layer, partial-covering absorber nor the input value of\nthe spin are the major drivers of our results. The height of the X-ray source\n(in a lamp-post geometry) instead plays a crucial role in recovering the spin.\nIn particular, a success rate of 16 out of 16 is found among the accurate fits\nfor a dimensionless spin parameter larger than 0.8 and a lamp-post height lower\nthan five gravitational radii.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Object-oriented programming (OOP) has long been regarded as too inefficient\nfor SIMD high-performance computing, despite the fact that many important HPC\napplications have an inherent object structure. We discovered a broad subset of\nOOP that can be implemented efficiently on massively parallel SIMD\naccelerators. We call it Single-Method Multiple-Objects (SMMO), because\nparallelism is expressed by running a method on all objects of a type.\n  To make fast GPU programming available to domain experts who are less\nexperienced in GPU programming, we developed DynaSOAr, a CUDA framework for\nSMMO applications. DynaSOAr improves the usage of allocated memory with an SOA\ndata layout and achieves low memory fragmentation through efficient management\nof free and allocated memory blocks with lock-free, hierarchical bitmaps.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recent studies have investigated siamese network architectures for learning\ninvariant speech representations using same-different side information at the\nword level. Here we investigate systematically an often ignored component of\nsiamese networks: the sampling procedure (how pairs of same vs. different\ntokens are selected). We show that sampling strategies taking into account\nZipf's Law, the distribution of speakers and the proportions of same and\ndifferent pairs of words significantly impact the performance of the network.\nIn particular, we show that word frequency compression improves learning across\na large range of variations in number of training pairs. This effect does not\napply to the same extent to the fully unsupervised setting, where the pairs of\nsame-different words are obtained by spoken term discovery. We apply these\nresults to pairs of words discovered using an unsupervised algorithm and show\nan improvement on state-of-the-art in unsupervised representation learning\nusing siamese networks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The aim of this paper is to prove $\\Gamma^{1,\\alpha}$ Schauder estimates near\na $C^{1,\\alpha}$ non-characteristic portion of the boundary for $\\Gamma^{0,\n\\alpha}$ perturbations of horizontal Laplaceans in Carnot groups. This\nsituation of minimally smooth domains presents itself naturally in the study of\nsubelliptic free boundary problems of obstacle type, see [15].\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We will present solutions to the constant Yang-Baxter equation, in any\ndimension $n$. More precisely, for any $n$, we will create an infinite family\nof $n^2$ by $n^2$ matrices which are solutions to the constant Yang-Baxter\nequation. The total number of non-vanishing entries of such a matrix is $4n^2$\nfor $n$ even, and $4(n-1)(n)+1$ for $n$ odd. We will also present the unitary\nconditions for those matrices. Moreover, we discuss the entangling property of\nthose matrices.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Stable basis algebras were introduced by Fountain and Gould and developed in\na series of articles. They form a class of universal algebras, extending that\nof independence algebras. If a stable basis algebra $\\mathbb{B}$ of finite rank\nsatisfies the distributivity condition (a condition satisfied by all the\npreviously known examples), it is a reduct of an independence algebra\n$\\mathbb{A}$. Our first aim is to give an example of an independence algebra\nnot satisfying the distributivity condition.\n  Gould showed that if a stable basis algebra $\\mathbb{B}$ with the\ndistributivity condition has finite rank, then so does the independence algebra\n$\\mathbb{A}$ of which it is a reduct, and in this case the endomorphism monoid\nEnd$(\\mathbb{B})$ of $\\mathbb{B}$ is a left order in the endomorphism monoid\nEnd$(\\mathbb{A})$ of $\\mathbb{A}$. We complete the picture by determining when\nEnd$(\\mathbb{B})$ is a right, and hence a two-sided, order in\nEnd$(\\mathbb{A})$. In fact (for rank at least 2), this happens precisely when\nevery element of End$(\\mathbb{A})$ can be written as $\\alpha^\\sharp\\beta$ where\n$\\alpha,\\beta\\in$ End$(\\mathbb{B})$, $\\alpha^\\sharp$ is the inverse of $\\alpha$\nin a subgroup of End$(\\mathbb{A})$ and $\\alpha$ and $\\beta$ have the same\nkernel. This is equivalent to End$(\\mathbb{B})$ being a special kind of left\norder in End$(\\mathbb{A})$ known as straight.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Context. The presence of dust in the neutral interstellar medium (ISM)\ndramatically changes the metal abundances that we measure. Understanding the\nmetal content in the neutral ISM, and a direct comparison between different\nenvironments, has been hampered to date because of the degeneracy to the\nobserved ISM abundances caused by the effects of metallicity, the presence of\ndust, and nucleosynthesis. Aims. We study the metal and dust content in the\nneutral ISM consistently in different environments, and assess the universality\nof recently discovered sequences of relative abundances. We also intend to\nassess the validity of [Zn/Fe] as a tracer of dust in the ISM. This has\nrecently been cast into doubt based on observations of stellar abundances, and\nneeds to be addressed before we can safely use it to study the ISM. Methods. In\nthis letter we present a simple comparison of relative abundances observed in\nthe neutral ISM in the Galaxy, the Magellanic Clouds, and damped Lyman-{\\alpha}\nAbsorbers (DLAs). The main novelty in this comparison is the inclusion of the\nMagellanic Clouds. Results. The same sequences of relative abundances are valid\nfor the Galaxy, Magellanic Clouds, and DLAs. These sequences are driven by the\npresence of dust in the ISM and seem 'universal'. Conclusions. The metal and\ndust properties in the neutral ISM appear to follow a similar behaviour in\ndifferent environments. This suggests that a dominant fraction of the dust\nbudget is built up from grain growth in the ISM depending of the physical\nconditions and regardless of the star formation history of the system. In\naddition, the DLA gas behaves like the neutral ISM, at least from a chemical\npoint of view. Finally, despite the deviations in [Zn/Fe] observed in stellar\nabundances, [Zn/Fe] is a robust dust tracer in the ISM of different\nenvironments, from the Galaxy to DLAs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The spanning tree heuristic is a commonly adopted procedure in network\ninference and estimation. It allows one to generalize an inference method\ndeveloped for trees, which is usually based on a statistically rigorous\napproach, to a heuristic procedure for general graphs by (usually randomly)\nchoosing a spanning tree in the graph to apply the approach developed for\ntrees. However, there are an intractable number of spanning trees in a dense\ngraph. In this paper, we represent a weighted tree with a matrix, which we call\na Gromov matrix. We propose a method that constructs a family of Gromov\nmatrices using convex combinations, which can be used for inference and\nestimation instead of a randomly selected spanning tree. This procedure\nincreases the size of the candidate set and hence enhances the performance of\nthe classical spanning tree heuristic. On the other hand, our new scheme is\nbased on simple algebraic constructions using matrices, and hence is still\ncomputationally tractable. We discuss some applications on network inference\nand estimation to demonstrate the usefulness of the proposed method.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Inter-core crosstalk is one of the most serious impairments for signal\ntransmission in a multi-core fiber (MCF) optical network. On the other hand,\nbecause of wide deployment of data centers (DCs), we are seeing an increasing\nbidirectional traffic demand asymmetry, which leads to significant capacity\nwastage in designing and operating an optical transport network. To alleviate\nthese effects, for an MCF optical network, we propose to assign fiber cores in\nan MCF in an asymmetric and counter-propagating manner. This can not only\nsignificantly reduce inter-core crosstalk between counter-propagating fiber\ncores but also flexibly assign different numbers of fiber cores in the opposite\ndirections of a fiber link, thereby overcoming network capacity wastage due to\nthe bidirectional traffic demand asymmetry. To evaluate the benefits of the\nproposed strategy, we consider the routing, spectrum, and core assignment\n(RSCA) problem for the MCF optical network. An integer linear programming (ILP)\nmodel and an auxiliary graph (AG) based heuristic algorithm are developed to\noptimize network spectrum resource utilization. Simulation studies show the\neffectiveness of the proposed core counter-propagation strategy, which can\nsignificantly outperform its counterpart, i.e., the co-propagation scheme, in\nterms of the total number of MCFs used and average inter-core crosstalk. In\naddition, the proposed RSCA heuristic algorithm is efficient to perform close\nto the ILP model, which can minimize the number of MCFs used and crosstalk\nbetween neighboring cores.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Given a rooted point set $P$, the rooted $y-$Monotone Minimum Spanning Tree\n(rooted $y-$MMST) of $P$ is the spanning geometric graph of $P$ in which all\nthe vertices are connected to the root by some $y-$monotone path and the sum of\nthe Euclidean lengths of its edges is the minimum. We show that the maximum\ndegree of a rooted $y-$MMST is not bounded by a constant number. We give a\nlinear time algorithm that draws any rooted tree as a rooted $y-$MMST and also\nshow that there exist rooted trees that can be drawn as rooted $y-$MMSTs only\nin a grid of exponential area.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we propose a protocol for angular displacement estimation\nbased upon orbital angular momentum coherent state and a SU(1,1)-SU(2) hybrid\ninterferometer. This interferometer consists of an optical parametric\namplifier, a beam splitter and reflection mirrors, hereon we use a quantum\ndetection strategy $\\---$ balanced homodyne detection. The results indicate\nthat super-resolution and super-sensitivity can be realized with ideal\ncondition. Additionally, we study the impact of photon loss on the resolution\nand the sensitivity, and the robustness of our protocol is also discussed.\nFinally, we demonstrate the advantage of our protocol over SU(1,1) and\nsummarize the merits of orbital angular momentum-enhanced protocol.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the growth behaviour of rational linear recurrence sequences. We\nshow that for low-order sequences, divergence is decidable in polynomial time.\nWe also exhibit a polynomial-time algorithm which takes as input a divergent\nrational linear recurrence sequence and computes effective fine-grained lower\nbounds on the growth rate of the sequence.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In 2008, Muneta found explicit evaluation of the multiple zeta star value\n$\\zeta^\\star(\\{3, 1\\}^d)$, and in 2013, Yamamoto proved a sum formula for\nmultiple zeta star values on 3-2-1 indices. In this paper, we provide another\nway of deriving the formulas mentioned above. It is based on our previous work\non generating functions for multiple zeta star values and also on constructions\nof generating functions for restricted sums of alternating Euler sums. As a\nresult, the formulas obtained are simpler and computationally more effective\nthan the known ones. Moreover, we give explicit evaluations of\n$\\zeta^\\star(\\{\\{2\\}^m, 3, \\{2\\}^m, 1\\bigr\\}^d)$ and $\\zeta^\\star(\\{\\{2\\}^m, 3,\n\\{2\\}^m, 1\\}^d, \\{2\\}^{m+1})$ in two ways. The first is based on computation of\nproduct of generating functions, while the second uses properties of Bell\npolynomials.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The t-distributed Stochastic Neighbor Embedding (t-SNE) is a powerful and\npopular method for visualizing high-dimensional data. It minimizes the\nKullback-Leibler (KL) divergence between the original and embedded data\ndistributions. In this work, we propose extending this method to other\nf-divergences. We analytically and empirically evaluate the types of latent\nstructure-manifold, cluster, and hierarchical-that are well-captured using both\nthe original KL-divergence as well as the proposed f-divergence generalization,\nand find that different divergences perform better for different types of\nstructure.\n  A common concern with $t$-SNE criterion is that it is optimized using\ngradient descent, and can become stuck in poor local minima. We propose\noptimizing the f-divergence based loss criteria by minimizing a variational\nbound. This typically performs better than optimizing the primal form, and our\nexperiments show that it can improve upon the embedding results obtained from\nthe original $t$-SNE criterion as well.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recent research has widely explored the problem of aesthetics assessment of\nimages with generic content. However, few approaches have been specifically\ndesigned to predict the aesthetic quality of images containing human faces,\nwhich make up a massive portion of photos in the web. This paper introduces a\nmethod for aesthetic quality assessment of images with faces. We exploit three\ndifferent Convolutional Neural Networks to encode information regarding\nperceptual quality, global image aesthetics, and facial attributes; then, a\nmodel is trained to combine these features to explicitly predict the aesthetics\nof images containing faces. Experimental results show that our approach\noutperforms existing methods for both binary, i.e. low/high, and continuous\naesthetic score prediction on four different databases in the state-of-the-art.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, the composite control-variate stratified sampling (CCSS) method\nis presented for calculation of MO integrals without transformation of AO\nintegrals. The central idea of this approach is to obtain the 2-electron MO\nintegrals by direct integration of 2-electron coordinates. This method does not\nrequire or use pre-computed AO integrals and the value of the MOs at any point\nin space is obtained directly from the linear combination of AOs. The\nintegration over the electronic coordinates was performed using stratified\nsampling Monte Carlo method. This approach was implemented by dividing the\nintegration region into a set of non-overlapping segments and performing Monte\nCarlo calculations on each segment. The Monte Carlo sampling points for each\nsegment were optimized to minimize the total variance of the sample mean.\nAdditional variance reduction of the overall calculations was achieved by\nintroducing control-variate in the stratified sampling scheme. The composite\naspect of the CCSS allows for simultaneous computation of multiple MO integrals\nduring the stratified sampling evaluation. The main advantage of the CCSS\nmethod is that unlike rejection sampling Monte Carlo methods such as Metropolis\nalgorithm, the stratified sampling uses all instances of the calculated\nfunctions for the evaluation of the sample mean. The CCSS method is designed to\nbe used for large systems where AO-to-MO transformation is computationally\nprohibitive. Because it is based on numerical integration, the CCSS method can\nbe applied to a wide variety of integration kernels and does not require\n\\textit{a priori} knowledge of analytical integrals. In this work, the\ndeveloped CCSS method was applied for calculation of excitonic properties in\nCdSe quantum dots using electron-hole explicitly correlated Hartree-Fock\n(eh-XCHF) and geminal-screened electron-hole interaction kernel (GSIK) methods.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Semantic segmentation for aerial imagery is a challenging and important\nproblem in remotely sensed imagery analysis. In recent years, with the success\nof deep learning, various convolutional neural network (CNN) based models have\nbeen developed. However, due to the varying sizes of the objects and imbalanced\nclass labels, it can be challenging to obtain accurate pixel-wise semantic\nsegmentation results. To address those challenges, we develop a novel semantic\nsegmentation method and call it Contextual Hourglass Network. In our method, in\norder to improve the robustness of the prediction, we design a new contextual\nhourglass module which incorporates attention mechanism on processed\nlow-resolution featuremaps to exploit the contextual semantics. We further\nexploit the stacked encoder-decoder structure by connecting multiple contextual\nhourglass modules from end to end. This architecture can effectively extract\nrich multi-scale features and add more feedback loops for better learning\ncontextual semantics through intermediate supervision. To demonstrate the\nefficacy of our semantic segmentation method, we test it on Potsdam and\nVaihingen datasets. Through the comparisons to other baseline methods, our\nmethod yields the best results on overall performance.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Photonic materials are an emerging platform to explore quantum matter and\nquantum dynamics. The development of Rydberg electromagnetically induced\ntransparency provided a clear route to strong interactions between individual\noptical photons. In conjunction with carefully designed optical resonators, it\nis now possible to achieve extraordinary control of the properties of\nindividual photons, introducing tunable gauge fields whilst imbuing the photons\nwith mass and embedding them on curved spatial manifolds. Building on work\nformalizing Rydberg-mediated interactions between propagating photons, we\ndevelop a theory of interacting Rydberg polaritons in multimode optical\nresonators, where the strong interactions are married with tunable\nsingle-particle properties to build and probe exotic matter. In the presence of\nstrong coupling between the resonator field and a Rydberg-dressed atomic\nensemble, a quasiparticle called the \"cavity Rydberg polariton\" emerges. We\ninvestigate its properties, finding that it inherits both the fast dynamics of\nits photonic constituents and the strong interactions of its atomic\nconstituents. We develop tools to properly renormalize the interactions when\npolaritons approach each other, and investigate the impact of atomic motion on\nthe coherence of multi-mode polaritons, showing that most channels for\natom-polariton cross-thermalization are strongly suppressed. Finally, we\npropose to harness the repeated diffraction and refocusing of the optical\nresonator to realize interactions which are local in momentum space. This work\npoints the way to efficient modeling of polaritonic quantum materials in\nproperly renormalized strongly interacting effective theories, thereby enabling\nexperimental studies of photonic fractional quantum Hall fluids and crystals,\nplus photonic quantum information processors and repeaters.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Due to the good performance of current SAT (satisfiability) and Max-SAT\n(maximum ssatisfiability) solvers, many real-life optimization problems such as\nscheduling can be solved by encoding them into Max-SAT. In this paper we tackle\nthe course timetabling problem of the department of mathematics, Cairo\nUniversity by encoding it into Max-SAT. Generating timetables for the\ndepartment by hand has proven to be cumbersome and the generated timetable\nalmost always contains conflicts. We show how the constraints can be modelled\nas a Max-SAT instance.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate how to simulate anisotropic heat conduction in a stable manner\nin Smoothed Particle Hydrodynamics. We show that the requirement for stability\nis that entropy must increase. From this, we deduce that methods involving\ndirect second derivatives in SPH are unstable, as found by previous authors. We\nshow that the only stable method is to use two first derivatives with\nalternating differenced and symmetric SPH derivative operators, with the\ncaveat, that one may need to apply smoothing or use an artificial conductivity\nterm if the initial temperature jump is discontinuous. Furthermore, we find\nthat with two first derivatives the stable timestep can be 3--8 times larger\neven for isotropic diffusion.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We initiate the study of the capacity constrained facility location problem\nfrom a mechanism design perspective. The capacity constrained setting leads to\na new strategic environment where a facility serves a subset of the population,\nwhich is endogenously determined by the ex-post Nash equilibrium of an induced\nsubgame and is not directly controlled by the mechanism designer. Our focus is\non mechanisms that are ex-post dominant-strategy incentive compatible (DIC) at\nthe reporting stage. We provide a complete characterization of DIC mechanisms\nvia the family of Generalized Median Mechanisms (GMMs). In general, the social\nwelfare optimal mechanism is not DIC. Adopting the worst-case approximation\nmeasure, we attain tight lower bounds on the approximation ratio of any DIC\nmechanism. The well-known median mechanism is shown to be optimal among the\nfamily of DIC mechanisms for certain capacity ranges. Surprisingly, the\nframework we introduce provides a new characterization for the family of GMMs,\nand is responsive to gaps in the current social choice literature highlighted\nby Border and Jordan (1983) and Barbar{\\`a}, Mass{\\'o} and Serizawa (1998).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Deep learning models for survival analysis have gained significant attention\nin the literature, but they suffer from severe performance deficits when the\ndataset contains many irrelevant features. We give empirical evidence for this\nproblem in real-world medical settings using the state-of-the-art model\nDeepHit. Furthermore, we develop methods to improve the deep learning model\nthrough novel approaches to feature selection in survival analysis. We propose\nfilter methods for hard feature selection and a neural network architecture\nthat weights features for soft feature selection. Our experiments on two\nreal-world medical datasets demonstrate that substantial performance\nimprovements against the original models are achievable.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Materials with extreme photonic properties such as maximum diffuse\nreflectance, high albedo, or tunable band gaps are essential in many current\nand future photonic devices and coatings. While photonic crystals, periodic\nanisotropic structures, are well established, their disordered counterparts,\nphotonic glasses (PGs), are less understood despite their most interesting\nisotropic photonic properties. Here, we introduce a controlled high index model\nPG system. It is made of monodisperse spherical TiO$_2$ colloids to exploit\nstrongly resonant Mie scattering for optimal turbidity. We report spectrally\nresolved combined measurements of turbidity and light energy velocity from\nlarge monolithic crack-free samples. This material class reveals pronounced\nresonances enabled by the possibility to tune both the refractive index of the\nextremely low polydisperse constituents and their radius. All our results are\nrationalized by a model based on the energy coherent potential approximation,\nwhich is free of any fitting parameter. Surprisingly good quantitative\nagreement is found even at high index and elevated packing fraction. This class\nof PGs may be the key to optimized tunable photonic materials and also central\nto understand fundamental questions such as isotropic structural colors, random\nlasing or strong light localization in 3D.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Effective resource allocation plays a pivotal role for performance\noptimization in wireless networks. Unfortunately, typical resource allocation\nproblems are mixed-integer nonlinear programming (MINLP) problems, which are\nNP-hard. Machine learning based methods recently emerge as a disruptive way to\nobtain near-optimal performance for MINLP problems with affordable\ncomputational complexity. However, they suffer from severe performance\ndeterioration when the network parameters change, which commonly happens in\npractice and can be characterized as the task mismatch issue. In this paper, we\npropose a transfer learning method via self-imitation, to address this issue\nfor effective resource allocation in wireless networks. It is based on a\ngeneral \"learning to optimize\" framework for solving MINLP problems. A unique\nadvantage of the proposed method is that it can tackle the task mismatch issue\nwith a few additional unlabeled training samples, which is especially important\nwhen transferring to large-size problems. Numerical experiments demonstrate\nthat with much less training time, the proposed method achieves comparable\nperformance with the model trained from scratch with sufficient amount of\nlabeled samples. To the best of our knowledge, this is the first work that\napplies transfer learning for resource allocation in wireless networks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Representation stability in the sense of Church-Farb is concerned with stable\nproperties of representations of sequences of algebraic structures, in\nparticular of groups. We study this notion on objects arising in toric\ntopology. With a simplicial $G$-complex $K$ and a topological pair $(X, A)$, a\n$G$-polyhedral product $(X, A)^K$ is associated. We show that the homotopy\ndecomposition [2] of $\\Sigma (X, A)^K$ is then $G$-equivariant after\nsuspension. In the case of $\\Sigma_m$-polyhedral products, we give criteria on\nsimplicial $\\Sigma_m$-complexes which imply representation stability of\n$\\Sigma_m$-representations $\\{H_i((X, A)^{K_m})\\}$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We used the Atacama Large Millimeter/Submillimeter Array (ALMA) to map the\nCO(3-2) and [CI](1-0) lines, as well as their underlying continuum emission,\nfrom the central $\\sim 200$ pc region of the Circinus galaxy that hosts the\nnearest type 2 Seyfert-class active galactic nucleus (AGN), with a spatial\nresolution of $\\sim 6-15$ pc. The lines and continuum-emitting regions consist\nof a circumnuclear disk (CND; 74 pc $\\times$ 34 pc) and spiral arms. The\ndistribution of the continuum emission revealed a temperature-dependent dust\ngeometry and possibly polar dust elongation in the torus region. The molecular\nmass of the CND is $M_{\\rm H2} \\sim 3 \\times 10^6~M_\\odot$ with a beam-averaged\nH$_2$ column density of $\\sim 5 \\times 10^{23}$ cm$^{-2}$ toward the AGN\nposition, which contributes significantly to the nuclear obscuration. The\n[CI](1-0)/CO(3-2) ratio at the AGN position is unusually high, suggesting an\nX-ray dominated region-type chemistry. We decomposed the observed velocity\nfields into rotational and dispersion components, and revealed multi-phase\ndynamic nature in the $r \\lesssim 10$ pc torus region, i.e., the diffuse atomic\ngas is more spatially extended along the vertical direction of the disk than\nthe dense molecular gas. Through comparisons with our model predictions based\non the radiation-driven fountain scheme, we indicate that atomic outflows are\nthe driver of the geometrical thickness of the atomic disk. This supports the\nvalidity of the radiation-driven fountain scheme in the vicinity of this AGN,\nwhich would explain the long-lasting mystery, the physical origin of the AGN\ntorus.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A major obstacle in reinforcement learning-based sentence generation is the\nlarge action space whose size is equal to the vocabulary size of the\ntarget-side language. To improve the efficiency of reinforcement learning, we\npresent a novel approach for reducing the action space based on dynamic\nvocabulary prediction. Our method first predicts a fixed-size small vocabulary\nfor each input to generate its target sentence. The input-specific vocabularies\nare then used at supervised and reinforcement learning steps, and also at test\ntime. In our experiments on six machine translation and two image captioning\ndatasets, our method achieves faster reinforcement learning ($\\sim$2.7x faster)\nwith less GPU memory ($\\sim$2.3x less) than the full-vocabulary counterpart.\nThe reinforcement learning with our method consistently leads to significant\nimprovement of BLEU scores, and the scores are equal to or better than those of\nbaselines using the full vocabularies, with faster decoding time ($\\sim$3x\nfaster) on CPUs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The pairwise maximum entropy model, also known as the Ising model, has been\nwidely used to analyze the collective activity of neurons. However, controversy\npersists in the literature about seemingly inconsistent findings, whose\nsignificance is unclear due to lack of reliable error estimates. We therefore\ndevelop a method for accurately estimating parameter uncertainty based on\nrandom walks in parameter space using adaptive Markov Chain Monte Carlo after\nthe convergence of the main optimization algorithm. We apply our method to the\nspiking patterns of excitatory and inhibitory neurons recorded with\nmultielectrode arrays in the human temporal cortex during the wake-sleep cycle.\nOur analysis shows that the Ising model captures neuronal collective behavior\nmuch better than the independent model during wakefulness, light sleep, and\ndeep sleep when both excitatory (E) and inhibitory (I) neurons are modeled;\nignoring the inhibitory effects of I-neurons dramatically overestimates\nsynchrony among E-neurons. Furthermore, information-theoretic measures reveal\nthat the Ising model explains about 80%-95% of the correlations, depending on\nsleep state and neuron type. Thermodynamic measures show signatures of\ncriticality, although we take this with a grain of salt as it may be merely a\nreflection of long-range neural correlations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Distracted pedestrians, like distracted drivers, are an increasingly\ndangerous threat and precursors to pedestrian accidents in urban communities,\noften resulting in grave injuries and fatalities. Mitigating such hazards to\npedestrian safety requires employment of pedestrian safety systems and\napplications that are effective in detecting them. Designing such frameworks is\npossible with the availability of sophisticated mobile and wearable devices\nequipped with high-precision on-board sensors capable of capturing fine-grained\nuser movements and context, especially distracted activities. However, the key\ntechnical challenge is accurate recognition of distractions with minimal\nresources in real-time given the computation and communication limitations of\nthese devices. Several recently published works improve distracted pedestrian\nsafety by leveraging on complex activity recognition frameworks using mobile\nand wearable sensors to detect pedestrian distractions. Their primary focus,\nhowever, was to achieve high detection accuracy, and therefore most designs are\neither resource intensive and unsuitable for implementation on mainstream\nmobile devices, or computationally slow and not useful for real-time pedestrian\nsafety applications, or require specialized hardware and less likely to be\nadopted by most users. In the quest for a pedestrian safety system, we design\nan efficient and real-time pedestrian distraction detection technique that\novercomes some of these shortcomings. We demonstrate its practicality by\nimplementing prototypes on commercially-available mobile and wearable devices\nand evaluating them using data collected from participants in realistic\npedestrian experiments. Using these evaluations, we show that our technique\nachieves a favorable balance between computational efficiency, detection\naccuracy and energy consumption compared to some other techniques in the\nliterature.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A new mathematical method for elucidating neutrino mass from beta decay is\nstudied. It is based upon the solutions of transformed Fredholm and Volterra\nintegral equations. In principle, theoretical beta-particle spectra can consist\nof several neutrino-mass eigenvalues. Integration of the theoretical beta\nspectrum with a normalized instrumental response function results in the\nFredholm integral equation of the first kind. This equation is transformed in\nsuch a way that the solution of it is a superposition of the Heaviside\nstep-functions, one for each neutrino mass eigenvalue. A series expansion\nleading to matrix linear equations is then derived to solve the transformed\nFredholm equation. Another approach is derived when the theoretical beta\nspectrum is obtained by a separate deconvolution of the observed spectrum. It\nis then proven that the transformed Fredholm equation reduces to the Abel\nintegral equation. The Abel equation has a general integral solution, which is\nproven in this work by using a specific function for the beta spectrum. As an\nexample, a numerical solution of the Abel integral equation is also provided,\nwhich has a fractional sensitivity of about 0.001 for subtle neutrino\neigenvalue searches, and can distinguish from experimental beta-spectrum\ndiscrepancies, such as shape and energy nonlinearities.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A special type of Gagliardo-Nirenberg-Sobolev (GNS) inequalities in\n$\\mathbb{R}^d$ has played a key role in several proofs of Lieb-Thirring\ninequalities. Recently, a need for GNS inequalities in convex domains of\n$\\mathbb{R}^d$, in particular for cubes, has arised. The purpose of this\nmanuscript is two-fold. First we prove a GNS inequality for convex domains,\nwith explicit constants which depend on the geometry of the domain. Later,\nusing the discrete version of Rumin's method, we prove GNS inequalities on\ncubes with improved constants.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The innermost stable circular orbits (ISCOs) around rapidly rotating neutron\nstars are studied in dilatonic Einstein-Gauss-Bonnet theory. Universal\nrelations for properly scaled ISCO properties are extended from General\nRelativity to dilatonic Einstein-Gauss-Bonnet theory and additional relations\nare obtained.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present recent BESIII results about the study of mesons which contain at\nleast one charm quark. We determined the D(s)+ decay constants, the form\nfactors of D semi-leptonic decays, the CKM matrix elements |Vcs(d)|.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The main result of this paper is, that if we suppose that a function is\nabsolutely continuous and uniformly H\\\"older continuous and that it's finite\ndifference function does not oscillate infinitely often on a bounded interval,\nthen the decay rate of its Fourier coefficients can be estimated exactly. This\nrate of decay predicts the same uniform H\\\"older continuity but the two other\nconditions are not necessary. Several examples from literature and by the\nauthor show that none of the assumptions can be relaxed without weakening the\ndecay for some functions. The uniform H\\\"older continuity of chirps and the\ndecay of their Fourier coefficients are studied. The main result is then\napplied in the estimation of the error of numerical Weyl fractional derivatives\ncalculated using the discrete Fourier transform. The main result is also\nextended to Fourier transforms.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we introduce a new approach to the concept of multipolynomials\nand generalize several results of the homogeneous polynomials and symmetric\nmultilinear applications. We also present an abstract approach to the concept\nof absolutely summing multipolynomials\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A Huff curve over a field $K$ is an elliptic curve defined by the equation\n$ax(y^2-1)=by(x^2-1)$ where $a,b\\in K$ are such that $a^2\\ne b^2$. In a similar\nfashion, a general Huff curve over $K$ is described by the equation\n$x(ay^2-1)=y(bx^2-1)$ where $a,b\\in K$ are such that $ab(a-b)\\ne 0$. In this\nnote we express the number of rational points on these curves over a finite\nfield $\\mathbb{F}_q$ of odd characteristic in terms of Gaussian hypergeometric\nseries $\\displaystyle {_2F_1}(\\lambda):={_2F_1}\\left(\\begin{matrix} \\phi&\\phi &\n\\epsilon \\end{matrix}\\Big| \\lambda \\right)$ where $\\phi$ and $\\epsilon$ are the\nquadratic and trivial characters over $\\mathbb{F}_q$, respectively.\nConsequently, we exhibit the number of rational points on the elliptic curves\n$y^2=x(x+a)(x+b)$ over $\\mathbb{F}_q$ in terms of ${_2F_1}(\\lambda)$. This\ngeneralizes earlier known formulas for Legendre, Clausen and Edwards curves.\nFurthermore, using these expressions we display several transformations of\n${_2F_1}$. Finally, we present the exact value of $_2F_1(\\lambda)$ for\ndifferent $\\lambda$'s over a prime field $\\mathbb{F}_p$ extending previous\nresults of Greene and Ono.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the entanglement spectrum of topological systems hosting non-Abelian\nanyons. Akin to energy levels of a Hamiltonian, the entanglement spectrum is\ncomposed of symmetry multiplets. We find that the ratio between different\neigenvalues within one multiplet is universal and is determined by the anyonic\nquantum dimensions. This result is a consequence of the conservation of the\ntotal topological charge. For systems with non-Abelian topological order, this\ngeneralizes known degeneracies of the entanglement spectrum, which are\nhallmarks of topological states. Experimental detection of these entanglement\nspectrum signatures may become possible in Majorana wires using multicopy\nschemes, allowing the measurement of quantum entanglement and its symmetry\nresolution.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper presents approximate confidence intervals for each function of\nparameters in a Banach space based on a bootstrap algorithm. We apply kernel\ndensity approach to estimate the persistence landscape. In addition, we\nevaluate the quality distribution function estimator of random variables using\nintegrated mean square error (IMSE). The results of simulation studies show a\nsignificant improvement achieved by our approach compared to the standard\nversion of confidence intervals algorithm. In the next step, we provide several\nalgorithms to solve our model. Finally, real data analysis shows that the\naccuracy of our method compared to that of previous works for computing the\nconfidence interval.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Manipulation of spin states at the single-atom scale underlies spin-based\nquantum information processing and spintronic devices. Such applications\nrequire protection of the spin states against quantum decoherence due to\ninteractions with the environment. While a single spin is easily disrupted, a\ncoupled-spin system can resist decoherence by employing a subspace of states\nthat is immune to magnetic field fluctuations. Here, we engineered the magnetic\ninteractions between the electron spins of two spin-1/2 atoms to create a clock\ntransition and thus enhance their spin coherence. To construct and electrically\naccess the desired spin structures, we use atom manipulation combined with\nelectron spin resonance (ESR) in a scanning tunneling microscope (STM). We show\nthat a two-level system composed of a singlet state and a triplet state is\ninsensitive to local and global magnetic field noise, resulting in much longer\nspin coherence times compared with individual atoms. Moreover, the spin\ndecoherence resulting from the interaction with tunneling electrons is markedly\nreduced by a homodyne readout of ESR. These results demonstrate that\natomically-precise spin structures can be designed and assembled to yield\nenhanced quantum coherence.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Container technique is gaining increasing attention in recent years and has\nbecome an alternative to traditional virtual machines. Some of the primary\nmotivations for the enterprise to adopt the container technology include its\nconvenience to encapsulate and deploy applications, lightweight operations, as\nwell as efficiency and flexibility in resources sharing. However, there still\nlacks an in-depth and systematic comparison study on how big data applications,\nsuch as Spark jobs, perform between a container environment and a virtual\nmachine environment. In this paper, by running various Spark applications with\ndifferent configurations, we evaluate the two environments from many\ninteresting aspects, such as how convenient the execution environment can be\nset up, what are makespans of different workloads running in each setup, how\nefficient the hardware resources, such as CPU and memory, are utilized, and how\nwell each environment can scale. The results show that compared with virtual\nmachines, containers provide a more easy-to-deploy and scalable environment for\nbig data workloads. The research work in this paper can help practitioners and\nresearchers to make more informed decisions on tuning their cloud environment\nand configuring the big data applications, so as to achieve better performance\nand higher resources utilization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work we include black hole (BH) seeding, growth and feedback into our\nsemi-analytic galaxy formation model, Delphi. Our model now fully tracks the,\naccretion- and merger-driven, hierarchical assembly of the dark matter halo,\nbaryonic and BH masses of high-redshift ($z>5$) galaxies. We use a minimal set\nof mass- and $z$-independent free parameters associated with star formation and\nBH growth (and feedback) and include suppressed BH growth in low-mass galaxies\nto explore a number of physical scenarios including: (i) two types of BH seeds\n(stellar and those from Direct Collapse BH; DCBH); (ii) the impact of\nreionization feedback; and (iii) the impact of instantaneous versus delayed\ngalaxy mergers on the baryonic growth. While both reionization feedback and\ndelayed galaxy mergers have no sensible impact on the evolving ultra-violet\nluminosity function, the latter limits the maximum BH masses achieved at these\nhigh-$z$. We then use this model, baselined against all available high-$z$\ngalaxy and BH data-sets, to predict the LISA detectability of merger events at\n$z > 5$. As expected, the merger rate is dominated by stellar BH mergers for\nall scenarios and our model predicts an expected upper limit of about 20\nmergers in the case of instantaneous merging and no reionization feedback over\nthe 4-year mission duration. Including the impact of delayed mergers and\nreionization feedback reduces this to about 12 events over the same\nobservational time-scale.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Estimating the correspondences between pixels in sequences of images is a\ncritical first step for a myriad of tasks including vision-aided navigation\n(e.g., visual odometry (VO), visual-inertial odometry (VIO), and visual\nsimultaneous localization and mapping (VSLAM)) and anomaly detection. We\nintroduce a new unsupervised deep neural network architecture called the Visual\nInertial Flow (VIFlow) network and demonstrate image correspondence and optical\nflow estimation by an unsupervised multi-hypothesis deep neural network\nreceiving grayscale imagery and extra-visual inertial measurements. VIFlow\nlearns to combine heterogeneous sensor streams and sample from an unknown,\nun-parametrized noise distribution to generate several (4 or 8 in this work)\nprobable hypotheses on the pixel-level correspondence mappings between a source\nimage and a target image . We quantitatively benchmark VIFlow against several\nleading vision-only dense correspondence and flow methods and show a\nsubstantial decrease in runtime and increase in efficiency compared to all\nmethods with similar performance to state-of-the-art (SOA) dense correspondence\nmatching approaches. We also present qualitative results showing how VIFlow can\nbe used for detecting anomalous independent motion.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Mumford and Newstead generalized the classical Torelli theorem to higher rank\ni.e., a smooth, projective curve $X$ is uniquely determined by the second\nintermediate Jacobian of the moduli space of stable rank $2$ bundles on $X$,\nwith fixed odd degree determinant. In this article we prove the analogous\nresult in the case $X$ is an irreducible nodal curve with one node. As a\nbyproduct, we obtain the degeneration of the second intermediate Jacobians and\nthe associated N\\'{e}ron model of a family of such moduli spaces.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce and study a class of models of free fermions hopping between\nneighbouring sites with random Brownian amplitudes. These simple models\ndescribe stochastic, diffusive, quantum, unitary dynamics. We focus on periodic\nboundary conditions and derive the complete stationary distribution of the\nsystem. It is proven that the generating function of the latter is provided by\nthe Harish-Chandra-Itzykson-Zuber integral which allows us to access all\nfluctuations of the system state. The steady state is characterized by non\ntrivial correlations which have a topological nature. Diagrammatic tools\nappropriate for the study of these correlations are presented. In the\nthermodynamic large system size limit, the system approaches a non random\nequilibrium state plus occupancy and coherence fluctuations of magnitude\nscaling proportionally with the inverse of the square root of the volume. The\nlarge deviation function for those fluctuations is determined. Although\ndecoherence is effective on the mean steady state, we observe that sub-leading\nfluctuating coherences are dynamically produced from the inhomogeneities of the\ninitial occupancy profile.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We use room temperature ion beam assisted sputtering (IBAS) to deposit\nniobium nitride thin films. Electrical and structural characterizations were\nperformed by electric transport and magnetization measurements at variable\ntemperatures, X-ray diffraction and atomic force microscopy. Compared to\nreactive sputtering of NbN, films sputtered in presence of an ion beam show\nremarkable increase in the superconducting critical temperature T$_{\\rm{c}}$,\nwhile exhibiting lower sensitivity to nitrogen concentration during deposition.\nThickness dependence of the superconducting critical temperature is comparable\nto films prepared by conventional methods at high substrate temperatures and is\nconsistent with behavior driven by quantum size effects or weak localization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The general ability to analyze and classify the 3D kinematics of the human\nform is an essential step in the development of socially adept humanoid robots.\nA variety of different types of signals can be used by machines to represent\nand characterize actions such as RGB videos, infrared maps, and optical flow.\nIn particular, skeleton sequences provide a natural 3D kinematic description of\nhuman motions and can be acquired in real time using RGB+D cameras. Moreover,\nskeleton sequences are generalizable to characterize the motions of both humans\nand humanoid robots. The Globally Optimal Reparameterization Algorithm (GORA)\nis a novel, recently proposed algorithm for signal alignment in which signals\nare reparameterized to a globally optimal universal standard timescale (UST).\nHere, we introduce a variant of GORA for humanoid action recognition with\nskeleton sequences, which we call GORA-S. We briefly review the algorithm's\nmathematical foundations and contextualize them in the problem of action\nrecognition with skeleton sequences. Subsequently, we introduce GORA-S and\ndiscuss parameters and numerical techniques for its effective implementation.\nWe then compare its performance with that of the DTW and FastDTW algorithms, in\nterms of computational efficiency and accuracy in matching skeletons. Our\nresults show that GORA-S attains a complexity that is significantly less than\nthat of any tested DTW method. In addition, it displays a favorable balance\nbetween speed and accuracy that remains invariant under changes in skeleton\nsampling frequency, lending it a degree of versatility that could make it\nwell-suited for a variety of action recognition tasks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Gait has been proposed as a feature for mobile device pairing across\narbitrary positions on the human body. Results indicate that the correlation in\ngait-based features across different body locations is sufficient to establish\nsecure device pairing. However, the population size of the studies is limited\nand powerful attackers with e.g. capability of video recording are not\nconsidered. We present a concise discussion of security properties of\ngait-based pairing schemes including a discussion of popular quantization\nschemes, classification and analysis of attack surfaces, discussion of\nstatistical properties of generated sequences, an entropy analysis, as well as\npossible threats and security weaknesses of gait-based pairing systems. For one\nof the schemes considered, we present modifications to fix an identified\nsecurity flaw. As a general limitation of gait-based authentication or pairing\nsystems, we further demonstrate that an adversary with video support can create\nkey sequences that are sufficiently close to on-body generated acceleration\nsequences to breach gait-based security mechanisms.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Building detection from satellite multispectral imagery data is being a\nfundamental but a challenging problem mainly because it requires correct\nrecovery of building footprints from high-resolution images. In this work, we\npropose a deep learning approach for building detection by applying numerous\nenhancements throughout the process. Initial dataset is preprocessed by 2-sigma\npercentile normalization. Then data preparation includes ensemble modelling\nwhere 3 models were created while incorporating OpenStreetMap data. Binary\nDistance Transformation (BDT) is used for improving data labeling process and\nthe U-Net (Convolutional Networks for Biomedical Image Segmentation) is\nmodified by adding batch normalization wrappers. Afterwards, it is explained\nhow each component of our approach is correlated with the final detection\naccuracy. Finally, we compare our results with winning solutions of SpaceNet 2\ncompetition for real satellite multispectral images of Vegas, Paris, Shanghai\nand Khartoum, demonstrating the importance of our solution for achieving higher\nbuilding detection accuracy.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We use a machine learning approach to identify the importance of\nmicrostructure characteristics in causing magnetization reversal in ideally\nstructured large-grained Nd$_2$Fe$_{14}$B permanent magnets. The embedded\nStoner-Wohlfarth method is used as a reduced order model for determining local\nswitching field maps which guide the data-driven learning procedure. The\npredictor model is a random forest classifier which we validate by comparing\nwith full micromagnetic simulations in the case of small granular test\nstructures. In the course of the machine learning microstructure analysis the\nmost important features explaining magnetization reversal were found to be the\nmisorientation and the position of the grain within the magnet. The lowest\nswitching fields occur near the top and bottom edges of the magnet. While the\ndependence of the local switching field on the grain orientation is known from\ntheory, the influence of the position of the grain on the local coercive field\nstrength is less obvious. As a direct result of our findings of the machine\nlearning analysis we show that edge hardening via Dy-diffusion leads to higher\ncoercive fields.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The effects of dimension-eight operators giving rise to anomalous neutral\ntriple gauge boson interactions of $Z\\gamma\\gamma$ and $Z\\gamma Z$ vertices in\n$pp\\to l^-l^+\\gamma$ and $pp\\to \\nu\\bar \\nu \\gamma$ are investigated at 100 TeV\ncentre of mass energy of future circular hadron collider (FCC-hh). The\ntransverse momentum of photon, invariant mass of $l^-l^+\\gamma$ and angular\ndistribution of charged lepton in the rest frame of $l^-l^+$ and Missing Energy\nTransverse (MET) are considered in the analysis. The realistic detector effects\nare also included with Delphes simulation. Sensitivity limits obtained at 95\\%\nC.L. for $C_{\\widetilde B W}/\\Lambda^4$ and $C_{B B}/\\Lambda^4$ couplings are\n$[-0.52;0.52] ([-0.40;0.40])$ TeV$^{-4}$, $[-0.43;0.43] ([-0.33;0.33])$\nTeV$^{-4}$ in the dilepton+photon channel and $[-0.11;0.11] ([-0.084;0.084])$\nTeV$^{-4}$, $[-0.092;0.092] ([-0.072;0.072])$ TeV$^{-4}$ in the MET+photon\nchannel with $L_{int}$=1 (3) ab$^{-1}$, respectively.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $F$ be a finitely generated regular field extension of transcendence\ndegree $\\geq 2$ over a perfect field $k$. We show that the multiplicative group\n$F^\\times/k^\\times$ endowed with the equivalence relation induced by algebraic\ndependence on $k$ determines the isomorphism class of $F$ in a functorial way.\nAs a special case of this result, we obtain that the isomorphism class of the\ngraded Milnor $K$-ring $K^M_*(F)$ determines the isomorphism class of $F$, when\n$k$ is algebraically closed or finite.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Applying Robert Boltje's theory of canonical induction, we give a\nrestriction-preserving formula expressing any $p$-permutation module as a\n$\\mathbb{Z}[1/p]$-linear combination of modules induced and inflated from\nprojective modules associated with subquotient groups. The underlying\nconstructions include, for any given finite group, a ring with a\n$\\mathbb{Z}$-basis indexed by conjugacy classes of triples $(U, K, E)$ where\n$U$ is a subgroup, $K$ is a $p'$-residue-free normal subgroup of $U$ and $E$ is\nan indecomposable projective module of the group algebra of $U/K$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The design and implementation of decision procedures for checking path\nfeasibility in string-manipulating programs is an important problem, whose\napplications include symbolic execution and automated detection of cross-site\nscripting (XSS) vulnerabilities. A (symbolic) path is a finite sequence of\nassignments and assertions (i.e. without loops), and checking its feasibility\namounts to determining the existence of inputs that yield a successful\nexecution.\n  We give two general semantic conditions which together ensure the\ndecidability of path feasibility: (1) each assertion admits regular monadic\ndecomposition, and (2) each assignment uses a (possibly nondeterministic)\nfunction whose inverse relation preserves regularity. We show these conditions\nare expressive since they are satisfied by a multitude of string operations.\nThey also strictly subsume existing decidable string theories, and most\nexisting benchmarks (e.g. most of Kaluza's, and all of SLOG's, Stranger's, and\nSLOTH's). We give a simple decision procedure and an extensible architecture of\na string solver in that a user may easily incorporate his/her own string\nfunctions. We show the general fragment has a tight, but high complexity. To\naddress this, we propose to allow only partial string functions (i.e., prohibit\nnondeterminism) in condition (2). When nondeterministic functions are needed,\nwe also provide a syntactic fragment that provides a support of\nnondeterministic functions but can be reduced to an existing solver SLOTH.\n  We provide an efficient implementation of our decision procedure for\ndeterministic partial string functions in a new string solver OSTRICH. It\nprovides built-in support for concatenation, reverse, functional transducers,\nand replaceall and provides a framework for extensibility to support further\nstring functions. We demonstrate the efficacy of our new solver against other\ncompetitive solvers.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Electric dipole moments are sensitive probes of new phases in the Higgs\nYukawa couplings. We calculate the complete two-loop QCD anomalous dimension\nmatrix for the mixing of CP-odd scalar and tensor operators and apply our\nresults for a phenomenological study of CP violation in the bottom and charm\nYukawa couplings. We find large shifts of the induced Wilson coefficients at\nnext-to-leading-logarithmic order. Using the experimental bound on the electric\ndipole moment of the neutron, we update the constraints on CP-violating phases\nin the bottom and charm quark Yukawas.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We have initiated a dedicated project to follow-up with ground-based\nphotometry the transiting planets discovered by CoRoT in order to refine the\norbital elements, constrain their physical parameters and search for additional\nbodies in the system. From 2012 September to 2016 December we carried out 16\ntransit observations of six CoRoT planets (CoRoT-5b, CoRoT-8b, CoRoT-12b,\nCoRoT-18b, CoRoT-20b, and CoRoT-27b) at three observatories located in Germany\nand Spain. These observations took place between 5 and 9 yr after the planet's\ndiscovery, which has allowed us to place stringent constraints on the planetary\nephemeris. In five cases we obtained light curves with a deviation of the\nmid-transit time of up to ~115min from the predictions. We refined the\nephemeris in all these cases and reduced the uncertainties of the orbital\nperiods by factors between 1.2 and 33. In most cases our determined physical\nproperties for individual systems are in agreement with values reported in\nprevious studies. In one case, CoRoT-27b, we could not detect any transit event\nin the predicted transit window.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Datasets that boosted state-of-the-art solutions for Question Answering (QA)\nsystems prove that it is possible to ask questions in natural language manner.\nHowever, users are still used to query-like systems where they type in keywords\nto search for answer. In this study we validate which parts of questions are\nessential for obtaining valid answer. In order to conclude that, we take\nadvantage of LIME - a framework that explains prediction by local\napproximation. We find that grammar and natural language is disregarded by QA.\nState-of-the-art model can answer properly even if 'asked' only with a few\nwords with high coefficients calculated with LIME. According to our knowledge,\nit is the first time that QA model is being explained by LIME.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In order to reduce the latency of data delivery, one of techniques is to\ncache the popular contents at the base stations (BSs) i.e. edge caching.\nHowever, the technique of caching at edge can only reduce the backhaul delay,\nother techniques such as BS densification will also need to be considered to\nreduce the fronthaul delay. In this work, we study the trade-offs between BS\ndensification and cache size under delay constraint at a typical user (UE). For\nthis, we use the downlink SINR coverage probability and throughput obtained\nbased on stochastic geometrical analysis. The network deployment of BS and\ncache storage is introduced as a minimization problem of the product of the BS\nintensity and cache size which we refer to the product of \\tit{cache\nintensity}' under probabilistic delay constraint. We examine the cases when (i)\neither BS intensity or the cache size is held fixed, and (ii) when both BS\nintensity and the cache size are vary. For the case when both BS intensity and\nthe cache size are variable, the problem become nonconvex and we convert into a\ngeometric programing which we solve it analytically.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a randomized first order optimization method--SEGA (SkEtched\nGrAdient method)-- which progressively throughout its iterations builds a\nvariance-reduced estimate of the gradient from random linear measurements\n(sketches) of the gradient obtained from an oracle. In each iteration, SEGA\nupdates the current estimate of the gradient through a sketch-and-project\noperation using the information provided by the latest sketch, and this is\nsubsequently used to compute an unbiased estimate of the true gradient through\na random relaxation procedure. This unbiased estimate is then used to perform a\ngradient step. Unlike standard subspace descent methods, such as coordinate\ndescent, SEGA can be used for optimization problems with a non-separable\nproximal term. We provide a general convergence analysis and prove linear\nconvergence for strongly convex objectives. In the special case of coordinate\nsketches, SEGA can be enhanced with various techniques such as importance\nsampling, minibatching and acceleration, and its rate is up to a small constant\nfactor identical to the best-known rate of coordinate descent.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The low-x gluon density in the proton and, in particular, in nuclei is only\nvery poorly constrained, while a better understanding of the low-x structure is\ncrucial for measurements at the LHC and also for the planning of experiments at\nfuture hadron colliders. In addition, deviations from linear QCD evolution are\nexpected to appear at low x, potentially leading to gluon saturation and a\nuniversal state of hadronic matter, the color-glass condensate. However, these\neffects have not been unambiguously proven to date. Fortunately, data from the\nLHC can be used directly to provide better constraints of the parton\ndistribution functions (PDFs). In this context, a Forward Calorimeter (FoCal)\nis proposed as an addition to the ALICE experiment, to be installed in the Long\nShutdown 3.\n  The main goal of the FoCal proposal is to measure forward direct photons in\npp and p-Pb collisions to obtain experimental constraints on proton and nuclear\nPDFs in a new region of low x. Based on the current knowledge from DIS\nexperiments and first results from LHC, we will discuss the physics case for\nthis proposed detector. While open charm measurements do provide important\nconstraints, a photon measurement would provide additional unique information.\nThe direct photon measurement requires a new electromagnetic calorimeter with\nextremely high granularity. The corresponding innovative design principle of a\nhigh-resolution Si-W sandwich calorimeter is discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Einstein's theory of gravity, General Relativity, has been precisely tested\non Solar System scales, but the long-range nature of gravity is still poorly\nconstrained. The nearby strong gravitational lens, ESO 325-G004, provides a\nlaboratory to probe the weak-field regime of gravity and measure the spatial\ncurvature generated per unit mass, $\\gamma$. By reconstructing the observed\nlight profile of the lensed arcs and the observed spatially resolved stellar\nkinematics with a single self-consistent model, we conclude that $\\gamma = 0.97\n\\pm 0.09$ at 68% confidence. Our result is consistent with the prediction of 1\nfrom General Relativity and provides a strong extragalactic constraint on the\nweak-field metric of gravity.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It is often said that quantum and classical randomness are of different\nnature, the former being ontological and the latter epistemological. However,\nso far the question of \"What is quantum in quantum randomness\", i.e. what is\nthe impact of quantization and discreteness on the nature of randomness,\nremains to answer. In a first part, we explicit the differences between quantum\nand classical randomness within a recently proposed ontology for quantum\nmechanics based on contextual objectivity. In this view, quantum randomness is\nthe result of contextuality and quantization. We show that this approach\nstrongly impacts the purposes of quantum theory as well as its areas of\napplication. In particular, it challenges current programs inspired by\nclassical reductionism, aiming at the emergence of the classical world from a\nlarge number of quantum systems. In a second part, we analyze quantum physics\nand thermodynamics as theories of randomness, unveiling their mutual\ninfluences. We finally consider new technological applications of quantum\nrandomness opened in the emerging field of quantum thermodynamics.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce Kalman Gradient Descent, a stochastic optimization algorithm\nthat uses Kalman filtering to adaptively reduce gradient variance in stochastic\ngradient descent by filtering the gradient estimates. We present both a\ntheoretical analysis of convergence in a non-convex setting and experimental\nresults which demonstrate improved performance on a variety of machine learning\nareas including neural networks and black box variational inference. We also\npresent a distributed version of our algorithm that enables large-dimensional\noptimization, and we extend our algorithm to SGD with momentum and RMSProp.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In compressed sensing, a small number of linear measurements can be used to\nreconstruct an unknown signal. Existing approaches leverage assumptions on the\nstructure of these signals, such as sparsity or the availability of a\ngenerative model. A domain-specific generative model can provide a stronger\nprior and thus allow for recovery with far fewer measurements. However, unlike\nsparsity-based approaches, existing methods based on generative models\nguarantee exact recovery only over their support, which is typically only a\nsmall subset of the space on which the signals are defined. We propose\nSparse-Gen, a framework that allows for sparse deviations from the support set,\nthereby achieving the best of both worlds by using a domain specific prior and\nallowing reconstruction over the full space of signals. Theoretically, our\nframework provides a new class of signals that can be acquired using compressed\nsensing, reducing classic sparse vector recovery to a special case and avoiding\nthe restrictive support due to a generative model prior. Empirically, we\nobserve consistent improvements in reconstruction accuracy over competing\napproaches, especially in the more practical setting of transfer compressed\nsensing where a generative model for a data-rich, source domain aids sensing on\na data-scarce, target domain.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this letter we will study the cosmological dynamical system of an $f(R)$\ngravity in the presence of a canonical scalar field $\\phi$ with an exponential\npotential, by constructing the dynamical system in a way that it is render\nautonomous. This feature is controlled by a single variable $m$, which when it\nis constant, the dynamical system is autonomous. We focus on the $m=0$ case\nwhich, as we demonstrate by using a numerical analysis approach, leads to an\nunstable de Sitter attractor, which occurs after $N\\sim 60$ $e$-foldings. This\ninstability can be viewed as a graceful exit from inflation, which is inherent\nto the dynamics of de Sitter attractors.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show global uniqueness in the fractional Calder\\'on problem with a single\nmeasurement and with data on arbitrary, possibly disjoint subsets of the\nexterior. The previous work \\cite{GhoshSaloUhlmann} considered the case of\ninfinitely many measurements. The method is again based on the strong\nuniqueness properties for the fractional equation, this time combined with a\nunique continuation principle from sets of measure zero. We also give a\nconstructive procedure for determining an unknown potential from a single\nexterior measurement, based on constructive versions of the unique continuation\nresult that involve different regularization schemes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study quantum phase transitions (QPTs) associated with splitting nodal\nFermi points, motivated by topological phase transitions between Dirac and Weyl\nsemi-metals. A Dirac point in Dirac semi-metals may be split into two Weyl\npoints by breaking a lattice symmetry or time reversal symmetry, and the\nLifshitz transition is commonly used to describe the phase transitions. Here,\nwe show that the Lifshitz description is fundamentally incorrect in QPTs with\nsplitting nodal Fermi points. We argue that correlations between fermions,\norder parameter, and the long range Coulomb interaction { must} be incorporated\nfrom the beginning. One of the most striking correlation effects we find is\n{\\it infinite anisotropy} of physical quantities, which cannot appear in a\nLifshitz transition. By using the standard renormalization group (RG) method,\ntwo types of infinitely anisotropic quantum criticalities are found in three\nspatial dimensions varying with the number of the Dirac points ($N_f$). For\n$N_f = 1$, the ratio of the fermion velocity to the velocity of order parameter\nexcitations becomes universal ($\\sqrt{2}-1$) along the Dirac point splitting\ndirection . For $N_f >1$, we find that fermions are parametrically faster than\norder parameter excitations in all directions. Our RG analysis is fully\ncontrolled by the fact that order parameter and fermion fluctuations are at the\nupper critical dimension, and thus our stable fixed points demonstrate the\npresence of weakly coupled quantum criticalities with infinite anisotropy.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Milnor's fibration theorem is about the geometry and topology of real and\ncomplex analytic maps near their critical points, a ubiquitous theme in\nmathematics. As such, after 50 years, this has become a whole area of research\non its own, with a vast literature, plenty of different viewpoints, a large\nprogeny and connections with many other branches of mathematics. In this work\nwe revisit the classical theory in both the real and complex settings, and we\nglance at some areas of current research and connections with other important\ntopics. The purpose of this article is two-fold. On the one hand, it should\nserve as an introduction to the topic for non-experts, and on the other hand,\nit gives a wide perspective of some of the work on the subject that has been\nand is being done. It includes a vast literature for further reading.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Future galaxy surveys hope to realize significantly tighter constraints on\nvarious cosmological parameters. The higher number densities achieved by these\nsurveys will allow them to probe the smaller scales affected by non-linear\nclustering. However, in these regimes, the standard power spectrum can extract\nonly a portion of such surveys' cosmological information. In contrast, the\nalternate statistic $A^*$ has the potential to double these surveys'\ninformation return, provided one can predict the $A^*$-power spectrum for a\ngiven cosmology. Thus, in this work we provide a prescription for this power\nspectrum $P_{A^*}(k)$, finding that the prescription is typically accurate to\nabout 5 per cent for near-concordance cosmologies. This prescription will thus\nallow us to multiply the information gained from surveys such as Euclid and\nWFIRST.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Weighted model integration (WMI) extends weighted model counting (WMC) in\nproviding a computational abstraction for probabilistic inference in mixed\ndiscrete-continuous domains. WMC has emerged as an assembly language for\nstate-of-the-art reasoning in Bayesian networks, factor graphs, probabilistic\nprograms and probabilistic databases. In this regard, WMI shows immense promise\nto be much more widely applicable, especially as many real-world applications\ninvolve attribute and feature spaces that are continuous and mixed.\nNonetheless, state-of-the-art tools for WMI are limited and less mature than\ntheir propositional counterparts. In this work, we propose a new implementation\nregime that leverages propositional knowledge compilation for scaling up\ninference. In particular, we use sentential decision diagrams, a tractable\nrepresentation of Boolean functions, as the underlying model counting and model\nenumeration scheme. Our regime performs competitively to state-of-the-art WMI\nsystems but is also shown to handle a specific class of non-linear constraints\nover non-linear potentials.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  High-speed high-resolution Analog-to-Digital Conversion is the key part for\nwaveform digitization in physics experiments and many other domains. This paper\npresents a new fully digital correction of mismatch errors among the channels\nin Time Interleaved Analog-to-Digital Converter (TIADC) systems. We focus on\ncorrection with wide-band input signal, which means that we can correct the\nmismatch errors for any frequency point in a broad band with only one set of\nfilter coefficients. Studies were also made to show how to apply the correction\nalgorithm beyond the base band, i.e. other Nyquist zones in the under-sampling\nsituation. Structure of the correction algorithm is presented in this paper, as\nwell as simulation results. To evaluate the correction performance, we actually\nconducted a series of tests with two TIADC systems. The results indicate that\nthe performance of both two TIADC systems can be greatly improved by\ncorrection, and the Effective Number Of Bits (ENOB) is successfully improved to\nbe better than 9.5 bits and 5.5 bits for an input signal up to the bandwidth\n(-3dB) range in the 1.6-Gsps 14-bit and the 10-Gsps 8-bit TIADC systems,\nrespectively. Tests were also conducted for input signal frequencies in the\nsecond Nyquist zone, which shows that the correction algorithms also work well\nas expected.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, an approach to generate radial interfaces is presented. A\nradial network recursively obtained is used to implement discrete model rules\ndesigned originally for the investigation in flat substrates. In order to test\nthe proposed scheme, we have used the restricted solid-on-solid and etching\nmodels. The results indicate the KPZ conjecture is fully verified. Besides, a\nvery good agreement between the interface radius fluctuation distribution and\nthe GUE one was observed. The evolution of the radius agrees very well with the\ngeneralized conjecture, and the two-point correlation function exhibits a very\ngood agreement with the covariance of Airy$_2$ process. So, this approach can\nbe used to investigate radial interfaces evolution for others universality\nclasses.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The 4th generation light source has achieved tremendous success and leveraged\nscientific research in material science, biology and chemistry fundamentally.\nThis paper discussed progress in LCLS as introduction and the possibility of\naccelerating driver beam with plasma wakefield in following section. Several\npotential applications of next generation light source are listed at the end.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Frangi Filters are one of the widely used filters for enhancing vessels in\nmedical images. Since they were first proposed, the threshold of the vesselness\nfunction of Frangi Filters is to be arranged for each individual application.\nThese thresholds are changed manually for individual fluoroscope, for enhancing\ncoronary angiogram images. Hence it is felt, there is a need of mitigating the\ntuning procedure of threshold values for every fluoroscope. The current papers\napproach has been devised in order to treat the coronary angiogram images\nuniformly, irrespective of the fluoroscopes through which they were obtained\nand the patient demographics for further stenosis detection. This problem to\nthe best of our knowledge has not been addressed yet. In the approach, before\nfeeding the image to Frangi Filters, non uniform illumination of the input\nimage is removed using homomorphic filters and the image is enhanced using Non\nSubsampled Contourlet Transform (NSCT). The experiment was conducted on the\ndata that has been accumulated from various hospitals in India and the results\nobtained verifies dependency removal of parameters without compromising the\nresults obtained by Frangi filters.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The derivation of spherical harmonics is the same in nearly every quantum\nmechanics textbook and classroom. It is found to be difficult to follow, hard\nto understand, and challenging to reproduce by most students. In this work, we\nshow how one can determine spherical harmonics in a more natural way based on\noperators and a powerful identity called the exponential disentangling operator\nidentity (known in quantum optics, but little used elsewhere). This new\nstrategy follows naturally after one has introduced Dirac notation, computed\nthe angular momentum algebra, and determined the action of the angular momentum\nraising and lowering operators on the simultaneous angular momentum eigenstates\n(under $\\hat L^2$ and $\\hat L_z$).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Bilayer graphene twisted by a small angle shows a significant charge\nmodulation away from neutrality, as the charge in the narrow bands near the\nDirac point is mostly localized in the regions of the Moir\\'e pattern with $AA$\nstacking. The resulting electrostatic potential gives rise to the dominant\ncontribution to the electron-electron interaction within this low energy band,\nwhich becomes significantly distorted. The changes in the band structure are\ndescribed by new local interactions, and lead to an assisted electron-hopping\nprocess. These couplings favor superconductivity at certain fillings.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Spatially embedded networks have attracted increasing attention in the last\ndecade. In this context, new types of network characteristics have been\nintroduced which explicitly take spatial information into account. Among\nothers, edge directionality properties have recently gained particular\ninterest. In this work, we investigate the applicability of mean edge\ndirection, anisotropy and local mean angle as geometric characteristics in\ncomplex spherical networks. By studying these measures, both analytically and\nnumerically, we demonstrate the existence of a systematic bias in spatial\nnetworks where individual nodes represent different shares on a spherical\nsurface, and describe a strategy for correcting for this effect. Moreover, we\nillustrate the application of the mentioned edge directionality properties to\ndifferent examples of real-world spatial networks in spherical geometry (with\nor without the geometric correction depending on each specific case), including\nfunctional climate networks, transportation and trade networks. In climate\nnetworks, our approach highlights relevant patterns like large-scale\ncirculation cells, the El Ni\\~{n}o--Southern Oscillation and the Atlantic\nNi\\~{n}o. In an air transportation network, we are able to characterize\ndistinct air transportation zones, while we confirm the important role of the\nEuropean Union for the global economy by identifying convergent edge\ndirectionality patterns in the world trade network.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we consider unitary highest weight irreducible representations\nof the `Large' $\\mathcal{N}=4$ superconformal algebra $A_\\gamma$ in the Ramond\nsector as infinite-dimensional graded modules of its zero mode subalgebra,\n$\\mathfrak{su}(2|2)$. We describe how representations of $\\mathfrak{su}(2|2)$\nmay be classified using Young supertableaux, and use the decomposition of\n$A_\\gamma$ as an $\\mathfrak{su}(2|2)$ module to discuss the states which\ncontribute to the supersymmetric index $I_1$, previously proposed in the\nliterature by Gukov, Martinec, Moore and Strominger.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We develop an improved phase calibration method of a reflective spatial light\nmodulator (SLM) using interferometry by employing novel phase masks. We\ngenerate the optimised phase masks by using Iterative Fourier Transform\nAlgorithm (IFTA) and demonstrate that they perform with 18$\\%$ better\nefficiency over global linear corrections in the look-up table (LUT). In\naddition, we also implement global linear corrections in the LUT and\ncorrespondingly modify the phase encoding of blazed gratings to improve the\nefficiency of our phase-limited SLM. In the process, we definitively determine\nthe actual maximum phase throw of our SLM which provides a recipe for users to\nverify supplier specifications.Besides obtaining array of 1D/2D spots having\nhigh uniformity (~90$\\%$) using IFTA, our result exemplifies the use of\niterative algorithms for improving efficiency of phase limited SLMs. Finally,\nour method enables threefold faster phase measurements, and to the best of our\nknowledge, is the first endeavour directed towards enabling rapid phase\ncharacterisation of an SLM using interferometric measurements and can have very\nuseful applications in settings which often require faster phase calibrations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Autonomous path planning algorithms are significant to planetary exploration\nrovers, since relying on commands from Earth will heavily reduce their\nefficiency of executing exploration missions. This paper proposes a novel\nlearning-based algorithm to deal with global path planning problem for\nplanetary exploration rovers. Specifically, a novel deep convolutional neural\nnetwork with double branches (DB-CNN) is designed and trained, which can plan\npath directly from orbital images of planetary surfaces without implementing\nenvironment mapping. Moreover, the planning procedure requires no prior\nknowledge about planetary surface terrains. Finally, experimental results\ndemonstrate that DB-CNN achieves better performance on global path planning and\nfaster convergence during training compared with the existing Value Iteration\nNetwork (VIN).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the values of the M\\\"obius function $\\mu$ of intervals in the\ncontainment poset of permutations. We construct a sequence of permutations\n$\\pi_n$ of size $2n-2$ for which $\\mu(1,\\pi_n)$ is given by a polynomial in $n$\nof degree 7. This construction provides the fastest known growth of\n$|\\mu(1,\\pi)|$ in terms of $|\\pi|$, improving a previous quadratic bound by\nSmith.\n  Our approach is based on a formula expressing the M\\\"obius function of an\narbitrary permutation interval $[\\alpha,\\beta]$ in terms of the number of\nembeddings of the elements of the interval into $\\beta$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove that any countable non-amenable group G admits a free minimal\namenable purely infinite action on the non-compact Cantor set. This answers a\nquestion of Kellerhals, Monod and R{\\o}rdam.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The impossibility of undoing a mixing process is analysed in the context of\nquantum information theory. The optimal machine to undo the mixing process is\nstudied in the case of pure states, focusing on qubit systems. Exploiting the\nsymmetry of the problem we parametrise the optimal machine in such a way that\nthe number of parameters grows polynomially in the size of the problem. This\nsimplification makes the numerical methods feasible. For simple but non-trivial\ncases we computed the analytical solution, comparing the performance of the\noptimal machine with other protocols.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Atomic force microscopy (AFM) is an analytical surface characterization tool\nwhich can reveal a sample's topography with high spatial resolution while\nsimultaneously probing tip-sample interactions. Local measurement of chemical\nproperties with high-resolution has gained much popularity in recent years with\nadvances in dynamic AFM methodologies. A calibration factor is required to\nconvert the electrical readout to a mechanical oscillation amplitude in order\nto extract quantitative information about the surface. We propose a new\ncalibration technique for the oscillation amplitude of electrically driven\nprobes, which is based on measuring the electrical energy input to maintain the\noscillation amplitude constant. We demonstrate the application of the new\ntechnique with quartz tuning fork including the qPlus configuration, while the\nsame principle can be applied to other piezoelectric resonators such as length\nextension resonators, or piezoelectric cantilevers. The calibration factor\nobtained by this technique is found to be in agreement with using thermal noise\nspectrum method for capsulated, decapsulated tuning forks and tuning forks in\nthe qPlus configuration.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a method to construct reduced-order models for duct flows of\nBingham media. Our method is based on proper orthogonal decomposition (POD) to\nfind a low-dimensional approximation to the velocity and artificial neural\nnetwork to approximate the coefficients of a given solution in the constructed\nPOD basis. We use well-established augmented Lagrangian method and\nfinite-element discretization in the \"offline\" stage. We show that the\nresulting approximation has a reasonable accuracy, but the evaluation of the\napproximate solution several orders of magnitude times faster.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recent neural machine translation (NMT) systems have been greatly improved by\nencoder-decoder models with attention mechanisms and sub-word units. However,\nimportant differences between languages with logographic and alphabetic writing\nsystems have long been overlooked. This study focuses on these differences and\nuses a simple approach to improve the performance of NMT systems utilizing\ndecomposed sub-character level information for logographic languages. Our\nresults indicate that our approach not only improves the translation\ncapabilities of NMT systems between Chinese and English, but also further\nimproves NMT systems between Chinese and Japanese, because it utilizes the\nshared information brought by similar sub-character units.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Smart contracts are programs running on cryptocurrency (e.g., Ethereum)\nblockchains, whose popularity stem from the possibility to perform financial\ntransactions, such as payments and auctions, in a distributed environment\nwithout need for any trusted third party. Given their financial nature, bugs or\nvulnerabilities in these programs may lead to catastrophic consequences, as\nwitnessed by recent attacks. Unfortunately, programming smart contracts is a\ndelicate task that requires strong expertise: Ethereum smart contracts are\nwritten in Solidity, a dedicated language resembling JavaScript, and shipped\nover the blockchain in the EVM bytecode format. In order to rigorously verify\nthe security of smart contracts, it is of paramount importance to formalize\ntheir semantics as well as the security properties of interest, in particular\nat the level of the bytecode being executed.\n  In this paper, we present the first complete small-step semantics of EVM\nbytecode, which we formalize in the F* proof assistant, obtaining executable\ncode that we successfully validate against the official Ethereum test suite.\nFurthermore, we formally define for the first time a number of central security\nproperties for smart contracts, such as call integrity, atomicity, and\nindependence from miner controlled parameters. This formalization relies on a\ncombination of hyper- and safety properties. Along this work, we identified\nvarious mistakes and imprecisions in existing semantics and verification tools\nfor Ethereum smart contracts, thereby demonstrating once more the importance of\nrigorous semantic foundations for the design of security verification\ntechniques.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A brief review of the Stefan problem of solidification from a mixture, and\nits main numerical solution methods is given. Simulation of this problem in 2D\nor 3D is most practically done on a regular grid, where a sharp solid-liquid\ninterface moves relative to the grid. For this problem, a new simulation method\nis developed that manifestly conserves mass, and that simulates the motion of\nthe interface to second order in the grid size. When applied to an isothermal\nsimulation of solidification from solution in 1D at 50% supersaturation for\nonly 5 grid points, the motion of the interface is accurate to 5.5%; and for 10\npoints the result is accurate to 1.5%. The method should be applicable to 2D or\n3D with relative ease. This opens the door to large scale simulations with\nmodest computer power.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Using proper motion measurements from Gaia DR2, we probe the origin of 26\npreviously known hypervelocity stars (HVSs) around the Milky Way. We find that\na significant fraction of these stars have a high probability of originating\nclose to the Milky Way centre, but there is one obvious outlier. HVS3 is highly\nlikely to be coming almost from the centre of the Large Magellanic Cloud (LMC).\nDuring its closest approach, $21.1^{+6.1}_{-4.6}$ Myr ago, it had a relative\nvelocity of $870^{+69}_{-66}$ kms$^{-1}$ with respect to the LMC. This large\nkick velocity is only consistent with the Hills mechanism, requiring a massive\nblack hole at the centre of the LMC. This provides strong direct evidence that\nthe LMC itself harbours a massive black hole of at least $4\\times 10^3 -10^4\nM_\\odot$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Classical convolutional neural networks (cCNNs) are very good at categorizing\nobjects in images. But, unlike human vision which is relatively robust to noise\nin images, the performance of cCNNs declines quickly as image quality worsens.\nHere we propose to use recurrent connections within the convolutional layers to\nmake networks robust against pixel noise such as could arise from imaging at\nlow light levels, and thereby significantly increase their performance when\ntested with simulated noisy video sequences. We show that cCNNs classify images\nwith high signal to noise ratios (SNRs) well, but are easily outperformed when\ntested with low SNR images (high noise levels) by convolutional neural networks\nthat have recurrency added to convolutional layers, henceforth referred to as\ngruCNNs. Addition of Bayes-optimal temporal integration to allow the cCNN to\nintegrate multiple image frames still does not match gruCNN performance.\nAdditionally, we show that at low SNRs, the probabilities predicted by the\ngruCNN (after calibration) have higher confidence than those predicted by the\ncCNN. We propose to consider recurrent connections in the early stages of\nneural networks as a solution to computer vision under imperfect lighting\nconditions and noisy environments; challenges faced during real-time video\nstreams of autonomous driving at night, during rain or snow, and other\nnon-ideal situations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Neural machine translation (NMT) has been a new paradigm in machine\ntranslation, and the attention mechanism has become the dominant approach with\nthe state-of-the-art records in many language pairs. While there are variants\nof the attention mechanism, all of them use only temporal attention where one\nscalar value is assigned to one context vector corresponding to a source word.\nIn this paper, we propose a fine-grained (or 2D) attention mechanism where each\ndimension of a context vector will receive a separate attention score. In\nexperiments with the task of En-De and En-Fi translation, the fine-grained\nattention method improves the translation quality in terms of BLEU score. In\naddition, our alignment analysis reveals how the fine-grained attention\nmechanism exploits the internal structure of context vectors.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper studies the mixed $H_-/H_{\\infty}$ fault detection filtering of\nIt\\^o-type nonlinear stochastic systems. Mixed $H_-/H_{\\infty}$ filtering\ncombines the system robustness to the external disturbance and the sensitivity\nto the fault of the residual signal. Firstly, for It\\^o-type affine nonlinear\nstochastic systems, some sufficient criteria are obtained for the existence of\n$H_-/H_{\\infty}$ filter in terms of Hamilton-Jacobi inequalities (HJIs).\nSecondly, for a class of quasi-linear It\\^o systems, a sufficient condition is\ngiven for the existence of $H_-/H_{\\infty}$ filter by means of linear matrix\ninequalities (LMIs). Finally, a numerical example is presented to illustrate\nthe effectiveness of the proposed results.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Semi-annihilation is a generic feature of particle dark matter that is most\neasily probed by cosmic ray experiments. We explore models where the\nsemi-annihilation cross section is enhanced at late times and low temperatures\nby the presence of an s-channel resonance near threshold. The relic density is\nthen sensitive to the evolution of the dark matter temperature, and we compute\nexpressions for the associated Boltzmann equation valid in general\nsemi-annihilating models. At late times, a self-heating effect warms the dark\nmatter, allowing number-changing processes to remain effective long after\nkinetic decoupling of the dark and visible sectors. This allows the\nsemi-annihilation signal today to be enhanced by up to five orders of magnitude\nover the thermal relic cross section. As a case study, we apply this to a dark\nmatter explanation of the positron excess seen by AMS-02. We see that unlike\nannihilating dark matter, our model has no difficulty fitting the data while\nalso giving the correct relic density. However, constraints from the CMB and\n$\\gamma$-rays from the galactic centre do restrict the preferred regions of\nparameter space.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the problem of coded caching for nonuniform demands when the\nstructured clique cover algorithm proposed by Maddah-Ali and Niesen for\ndecentralized caching is used for delivery. We apply this algorithm to all user\ndemands regardless of their request probabilities. This allows for coding among\nthe files that have different request probabilities but makes the allocation of\nmemory to different files challenging during the content placement phase. As\nour main contribution, we analytically characterize the optimal placement\nstrategy that minimizes the expected delivery rate under a storage capacity\nconstraint. It is shown that the optimal placement follows either a two or a\nthree group strategy, where a set of less popular files are not cached at all\nand the files within each of the other sets are allocated identical amounts of\nstorage as if they had the same request probabilities. We show that for a\nfinite set of storage capacities, that we call the base-cases of the problem,\nthe two group strategy is always optimal. For other storage capacities, optimal\nplacement is achieved by memory sharing between certain base-cases and the\nresulting placement either follows a two or a three group strategy depending on\nthe corresponding base-cases used. We derive a polynomial time algorithm that\ndetermines the base-cases of the problem given the number of caches and\npopularity distribution of files. Given the base-cases of the problem, the\noptimal memory allocation parameters for any storage capacity are derived\nanalytically.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We explore the role of interaction for the problem of reliable computation\nover two-way multicast networks. Specifically we consider a four-node network\nin which two nodes wish to compute a modulo-sum of two independent Bernoulli\nsources generated from the other two, and a similar task is done in the other\ndirection. The main contribution of this work lies in the characterization of\nthe computation capacity region for a deterministic model of the network via a\nnovel transmission scheme. One consequence of this result is that, not only we\ncan get an interaction gain over the one-way non-feedback computation\ncapacities, but also we can sometimes get all the way to perfect-feedback\ncomputation capacities simultaneously in both directions. This result draws a\nparallel with the recent result developed in the context of two-way\ninterference channels.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This work presents a scalable solution to open-vocabulary visual speech\nrecognition. To achieve this, we constructed the largest existing visual speech\nrecognition dataset, consisting of pairs of text and video clips of faces\nspeaking (3,886 hours of video). In tandem, we designed and trained an\nintegrated lipreading system, consisting of a video processing pipeline that\nmaps raw video to stable videos of lips and sequences of phonemes, a scalable\ndeep neural network that maps the lip videos to sequences of phoneme\ndistributions, and a production-level speech decoder that outputs sequences of\nwords. The proposed system achieves a word error rate (WER) of 40.9% as\nmeasured on a held-out set. In comparison, professional lipreaders achieve\neither 86.4% or 92.9% WER on the same dataset when having access to additional\ntypes of contextual information. Our approach significantly improves on other\nlipreading approaches, including variants of LipNet and of Watch, Attend, and\nSpell (WAS), which are only capable of 89.8% and 76.8% WER respectively.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the interplay of electric and magnetic order in the one dimensional\nHeisenberg spin-1/2 XXZ chain with large Ising anisotropy in the presence of\nthe Dzyaloshinskii-Moriya (D-M) interaction and with longitudinal and\ntransverse magnetic fields, interpreting the D-M interaction as a coupling\nbetween the local electric polarization and an external electric field. We\nobtain the ground state phase diagram using the density matrix renormalization\ngroup method and compute various ground state quantities like the\nmagnetization, staggered magnetization, electric polarization and spin\ncorrelation functions, etc. In the presence of both longitudinal and transverse\nmagnetic fields, there are three different phases corresponding to a gapped\nN\\'{e}el phase with antiferromagnetic (AF) order, gapped saturated phase and a\ncritical incommensurate gapless phase. The external electric field modifies the\nphase boundaries but does not lead to any new phases. Both external magnetic\nfields and electric fields can be used to tune between the phases. We also show\nthat the transverse magnetic field induces a vector chiral order in the\nN\\'{e}el phase (even in the absence of an electric field) which can be\ninterpreted as an electric polarization in a direction parallel to the AF\norder.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a novel approach to construct cosmological models endowed with a\nparticular scalar field, the stealth. The model is constructed by studying a\nscalar field no-minimally coupled to the gravitational field with sources; as\nsources, we used a perfect fluid and analyzed the simplest case of dust and the\npower-law cosmology. Surprisingly, we find that these stealth fields, which\nhave no back-reaction to background space-time, have a contribution to\ncosmological dynamics. Furthermore, we provide analytic expressions of the\nstealth's contributions to the energy density in both cases, and for the\npressure in the power-low cosmology, which means that such contributions to\ncosmological evolution are quantifiable. Additionally, we discuss the behaviors\nof the self-interaction potential for some cases.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Working within the Stochastic Series Expansion (SSE) framework, we construct\nefficient quantum cluster algorithms for transverse field Ising\nantiferromagnets on the pyrochlore lattice and the planar pyrochlore lattice,\nfor the fully frustrated square lattice Ising model in a transverse field (dual\nto the 2+1 dimensional odd Ising gauge theory), and for a transverse field\nIsing model with multi-spin interactions on the square lattice, which is dual\nto a 2+1 dimensional even Ising gauge theory (and reduces to the two\ndimensional quantum loop model in a certain limit). Our cluster algorithms use\na microcanonical update procedure that generalizes and exploits the notion of\n\"pre-marked motifs\" introduced earlier in the context of a quantum cluster\nalgorithm for triangular lattice transverse field Ising antiferromagnets. We\ndemonstrate that the resulting algorithms are significantly more efficient than\nthe standard link percolation based quantum cluster approach. We also introduce\na new canonical update scheme that leads to a further improvement in\nmeasurement of some observables arising from its ability to make\none-dimensional clusters in the \"imaginary time\" direction. Finally, we\ndemonstrate that refinements in the choice of premarking strategies can lead to\nadditional improvements in the efficiency of the microcanonical updates. As a\nfirst example of the physics that can be studied using these algorithmic\ndevelopments, we obtain evidence for a power-law ordered\nintermediate-temperature phase associated with the two-step melting of\nlong-range order in the fully frustrated square lattice transverse field Ising\nmodel.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the finalized catalog of solar energetic proton events detected by\nWind/EPACT instrument over the period 1996-2016. Onset times, peak times, peak\nproton intensity and onset-to-peak proton fluence are evaluated for the two\navailable energy channels, at about 25 and 50 MeV. We describe the procedure\nutilized to identify the proton events and to relate them to their solar origin\n(in terms of flares and coronal mass ejections). The statistical relationships\nbetween the energetic protons and their origin (linear and partial correlation\nanalysis) are reported and discussed in view of earlier findings. Finally, the\ndifferent trends found in the first eight years of solar cycles 23 and 24 are\ndiscussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The question whether two indistinguishable particles are bosons or fermions\ncan be answered by observing the Hong-Ou-Mandel effect on a beam splitter.\nHowever, already for three particles one can consider symmetries that are\nneither bosonic nor fermionic. In this work, we describe a simple method of\nidentifying them experimentally and propose a measure of a genuine multipartite\nindistinguishability.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Our results can be viewed as applications of algebraic combinatorics in\nrandom matrix theory. These applications are motivated by the predictive power\nof random matrix theory for the statistical behavior of the celebrated Riemann\n$\\zeta$-function (and $L$-functions in general), which was discovered by\nMontgomery (with regard to zeros of $L$-functions) and by Keating and Snaith\n(with regard to values of $L$-functions).\n  The first results revolve around a new operation on partitions, which we call\noverlap. We prove two overlap identities for so-called Littlewood-Schur\nfunctions. The first overlap identity represents the Littlewood-Schur function\n$LS _\\lambda(X; Y)$ as a sum over subsets of $X$, while the second overlap\nidentity essentially represents $LS_\\lambda(X; Y)$ as a sum over pairs of\npartitions whose overlap equals $\\lambda$. Both identities are derived by\napplying Laplace expansion to a determinantal formula for Littlewood-Schur\nfunctions due to Moens and Van der Jeugt. In addition, we give two visual\ncharacterizations for the set of all pairs of partitions whose overlap is equal\nto a partition $\\lambda$.\n  The second result is an asymptotic formula for averages of mixed ratios of\ncharacteristic polynomials over the unitary group, where mixed ratios are\nproducts of ratios and/or logarithmic derivatives. Our proof of this formula is\na generalization of Bump and Gamburd's elegant combinatorial proof of Conrey,\nForrester and Snaith's formula for averages of ratios of characteristic\npolynomials over the unitary group. The generalization relies on three\ncombinatorial results, namely the first overlap identity, a new variant of the\nMurnaghan-Nakayama rule and an idea from vertex operator formalism. We conclude\nthis thesis by explaining how this approach might lead to new number theoretic\nproofs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  AdS/CFT correspondence gives us a bulk-boundary dictionary between CFT\noperators and local fields in the bulk. Can a bulk-boundary dictionary exist\nfor a non local bulk field? In this paper we consider a particular non local\ntheory and show that a bulk boundary dictionary relating it to CFT operators in\nthe bulk can indeed be constructed. In this dictionary the scale of non\nlocality of the bulk theory is related to the conformal dimension of the dual\nCFT operator.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we construct $K$-solitons of the focusing energy-critical\nnonlinear wave equation in five-dimensional space, i.e. solutions $u$ of the\nequation such that \\begin{equation*}\n\\|\\nabla_{t,x}u(t)-\\nabla_{t,x}\\big(\\sum_{k=1}^{K}W_{k}(t)\\big)\\|_{L^{2}}\\to\n0\\quad \\mathrm{as}\\ t\\to \\infty, \\end{equation*} where for any $k\\in\n\\{1,\\dots,K\\}$, $W_{k}$ is Lorentz transform of the explicit standing soliton\n$W(x)=(1+|x|^{2}/15)^{-3/2}$, with any speed $\\boldsymbol{\\ell}_{k}\\in\n\\mathbb{R}^{5}$ ,$|\\boldsymbol{\\ell}_{k}|<1$ ($\\boldsymbol{\\ell}_{k'}\\ne\n\\boldsymbol{\\ell}_{k}$ for $k'\\ne k$) satisfying an explicit smallness\ncondition.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider a spatially periodic (cosine) potential as a model for a\ncrystalline solid that interacts with a harmonically oscillating external\nelectric field. This problem is periodic both in space and time and can be\nsolved analytically using the Kramers-Henneberger co-moving frame. By analyzing\nthe stability of the closely related Mathieu-type differential equation, the\nelectronic band structure can be obtained. We demonstrate that by changing the\nfield intensity, the width of the zero-field band gaps can be drastically\nmodified, including the special case when the external field causes the band\ngaps to disappear\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Despite a lack of theoretical understanding, deep neural networks have\nachieved unparalleled performance in a wide range of applications. On the other\nhand, shallow representation learning with component analysis is associated\nwith rich intuition and theory, but smaller capacity often limits its\nusefulness. To bridge this gap, we introduce Deep Component Analysis (DeepCA),\nan expressive multilayer model formulation that enforces hierarchical structure\nthrough constraints on latent variables in each layer. For inference, we\npropose a differentiable optimization algorithm implemented using recurrent\nAlternating Direction Neural Networks (ADNNs) that enable parameter learning\nusing standard backpropagation. By interpreting feed-forward networks as\nsingle-iteration approximations of inference in our model, we provide both a\nnovel theoretical perspective for understanding them and a practical technique\nfor constraining predictions with prior knowledge. Experimentally, we\ndemonstrate performance improvements on a variety of tasks, including\nsingle-image depth prediction with sparse output constraints.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Techniques for multi-lingual and cross-lingual speech recognition can help in\nlow resource scenarios, to bootstrap systems and enable analysis of new\nlanguages and domains. End-to-end approaches, in particular sequence-based\ntechniques, are attractive because of their simplicity and elegance. While it\nis possible to integrate traditional multi-lingual bottleneck feature\nextractors as front-ends, we show that end-to-end multi-lingual training of\nsequence models is effective on context independent models trained using\nConnectionist Temporal Classification (CTC) loss. We show that our model\nimproves performance on Babel languages by over 6% absolute in terms of\nword/phoneme error rate when compared to mono-lingual systems built in the same\nsetting for these languages. We also show that the trained model can be adapted\ncross-lingually to an unseen language using just 25% of the target data. We\nshow that training on multiple languages is important for very low resource\ncross-lingual target scenarios, but not for multi-lingual testing scenarios.\nHere, it appears beneficial to include large well prepared datasets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper is to investigate the spectral properties of sample covariance\nmatrices under a more general population. We consider a class of matrices of\nthe form $\\mathbf S_n=\\frac1n\\mathbf B_n\\mathbf X_n\\mathbf X_n^*\\mathbf B_n^*$,\nwhere $\\mathbf B_n$ is a $p\\times m$ non-random matrix and $\\mathbf X_n$ is an\n$m\\times n$ matrix consisting of i.i.d standard complex entries. $p/n\\to c\\in\n(0,\\infty)$ as $n\\to \\infty$ while $m$ can be arbitrary. We proved that under\nsome mild assumptions, with probability 1, there will be no eigenvalues in any\nclosed interval contained in an open interval outside the supports of the\nlimiting distribution $F_{c_n,H_n}$, for all sufficiently large $n$. An\nextension of Bai-Yin law is also obtained.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the local mass of a dyadic branching Brownian motion $Z$ evolving in\n$\\mathbb{R}^d$. By 'local mass,' we refer to the number of particles of $Z$\nthat fall inside a ball with fixed radius and time-dependent center, lying in\nthe 'subcritical' zone. Using the strong law of large numbers for the local\nmass of branching Brownian motion and elementary geometric arguments, we find\nlarge deviation results giving the asymptotic behavior of the probability that\nthe local mass is atypically small on an exponential scale. As corollaries, we\nobtain an asymptotic result for the probability of absence of $Z$ in a ball\nwith fixed radius and time-dependent center, and lower tail asymptotics for the\nlocal mass in a fixed ball. The proofs are based on a bootstrap argument, which\nwe use to find the lower tail asymptotics for the mass outside a ball with\ntime-dependent radius and fixed center, as well.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A fundamental challenge in imperfect-information games is that states do not\nhave well-defined values. As a result, depth-limited search algorithms used in\nsingle-agent settings and perfect-information games do not apply. This paper\nintroduces a principled way to conduct depth-limited solving in\nimperfect-information games by allowing the opponent to choose among a number\nof strategies for the remainder of the game at the depth limit. Each one of\nthese strategies results in a different set of values for leaf nodes. This\nforces an agent to be robust to the different strategies an opponent may\nemploy. We demonstrate the effectiveness of this approach by building a\nmaster-level heads-up no-limit Texas hold'em poker AI that defeats two prior\ntop agents using only a 4-core CPU and 16 GB of memory. Developing such a\npowerful agent would have previously required a supercomputer.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Acute Coronary Syndrome (ACS) is a syndrome caused by a decrease in blood\nflow in the coronary arteries. The ACS is usually related to coronary\nthrombosis and is primarily caused by plaque rupture followed by plaque erosion\nand calcified nodule. Thin-cap fibroatheroma (TCFA) is known to be the most\nsimilar lesion morphologically to a plaque rupture. In this paper, we propose\nmethods to classify TCFA using various machine learning classifiers including\nFeed-forward Neural Network (FNN), K-Nearest Neighbor (KNN), Random Forest (RF)\nand Convolutional Neural Network (CNN) to figure out a classifier that shows\noptimal TCFA classification accuracy. In addition, we suggest pixel range based\nfeature extraction method to extract the ratio of pixels in the different\nregion of interests to reflect the physician's TCFA discrimination criteria. A\ntotal of 12,325 IVUS images were labeled with corresponding OCT images to train\nand evaluate the classifiers. We achieved 0.884, 0.890, 0.878 and 0.933 Area\nUnder the ROC Curve (AUC) in the order of using FNN, KNN, RF and CNN\nclassifier. As a result, the CNN classifier performed best and the top 10\nfeatures of the feature-based classifiers (FNN, KNN, RF) were found to be\nsimilar to the physician's TCFA diagnostic criteria.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we present a method to determine if a lift-and-project cut for\na mixed-integer linear program is irregular, in which case the cut is not\nequivalent to any intersection cut from the bases of the linear relaxation.\nThis is an important question due to the intense research activity for the past\ndecade on cuts from multiple rows of simplex tableau as well as on\nlift-and-project cuts from non-split disjunctions. While it is known since\nBalas and Perregaard (2003) that lift-and-project cuts from split disjunctions\nare always equivalent to intersection cuts and consequently to such multi-row\ncuts, Balas and Kis (2016) have recently shown that there is a necessary and\nsufficient condition in the case of arbitrary disjunctions: a lift-and-project\ncut is regular if, and only if, it corresponds to a regular basic solution of\nthe Cut Generating Linear Program (CGLP). This paper has four contributions.\nFirst, we state a result that simplifies the verification of regularity for\nbasic CGLP solutions from Balas and Kis (2016). Second, we provide a\nmixed-integer formulation that checks whether there is a regular CGLP solution\nfor a given cut that is regular in a broader sense, which also encompasses\nirregular cuts that are implied by the regular cut closure. Third, we describe\na numerical procedure based on such formulation that identifies irregular\nlift-and-project cuts. Finally, we use this method to evaluate how often\nlift-and-project cuts from simple $t$-branch split disjunctions are irregular,\nand thus not equivalent to multi-row cuts, on 74 instances of the MIPLIB\nbenchmarks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Two dimensional magnetic films with perpendicular magnetization spontaneously\nform magnetic domain patterns that evolve or undergo symmetry transformations\nas a function of temperature. When the system is driven from equilibrium by a\nrapid change in temperature, topological pattern defects are the elementary\npattern excitations that affect this evolution. An elastic continuum model is\nadapted to describe how a metastable population of topological defects alters\nthe domain density and the magnetic susceptibility of the \"stripe\" magnetic\ndomain pattern. Temporal changes in the susceptibility are interpreted using a\ndynamical equation describing the defect population. Recent experiments provide\na quantitative verification of the model, and illustrate the use of the\nmagnetic susceptibility to follow the population dynamics of topological\ndefects in this system, and its potential role in investigating a pattern\nmelting phase transition.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Deep artificial neural networks (ANNs) can represent a wide range of complex\nfunctions. Implementing ANNs in Von Neumann computing systems, though, incurs a\nhigh energy cost due to the bottleneck created between CPU and memory.\nImplementation on neuromorphic systems may help to reduce energy demand.\nConventional ANNs must be converted into equivalent Spiking Neural Networks\n(SNNs) in order to be deployed on neuromorphic chips. This paper presents a way\nto perform this translation. We map the ANN weights to SNN synapses\nlayer-by-layer by forming a least-square-error approximation problem at each\nlayer.\n  An optimal set of synapse weights may then be found for a given choice of ANN\nactivation function and SNN neuron. Using an appropriate constrained solver, we\ncan generate SNNs compatible with digital, analog, or hybrid chip\narchitectures. We present an optimal node pruning method to allow SNN layer\nsizes to be set by the designer. To illustrate this process, we convert three\nANNs, including one convolutional network, to SNNs. In all three cases, a\nsimple linear program solver was used. The experiments show that the resulting\nnetworks maintain agreement with the original ANN and excellent performance on\nthe evaluation tasks. The networks were also reduced in size with little loss\nin task performance.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A standard prediction of galaxy formation theory is that the ionizing\nbackground suppresses galaxy formation in haloes with peak circular velocities\nsmaller than Vpeak ~ 20 km/s, rendering the majority of haloes below this scale\ncompletely dark. We use a suite of cosmological zoom simulations of Milky\nWay-like haloes that include central Milky Way disk galaxy potentials to\ninvestigate the relationship between subhaloes and ultrafaint galaxies. We find\nthat there are far too few subhaloes within 50 kpc of the Milky Way that had\nVpeak > 20 km/s to account for the number of ultrafaint galaxies already known\nwithin that volume today. In order to match the observed count, we must\npopulate subhaloes down to Vpeak ~ 6 km/s with ultrafaint dwarfs. The required\nhaloes have peak virial temperatures as low as 1,500 K, well below the atomic\nhydrogen cooling limit of 10^4 K. Allowing for the possibility that the Large\nMagellanic Cloud contributes several of the satellites within 50 kpc could\npotentially raise this threshold to 10 km/s (4,000 K), still below the atomic\ncooling limit and far below the nominal reionization threshold.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Exploiting the mass transportation method, we prove a dual principle which\nimplies directly the sharp Gagliardo-Nirenberg trace inequalities which was\nrecently proved by Bolley et al. [BCFGG17]. Moreover, we determine all optimal\nfunctions for these obtained sharp Gagliardo-Nirenberg trace inequalities. This\nsettles a question left open in [BCFGG17]. Finally, we use the sharp\nGagliardo--Nirenberg trace inequality to establish their affine versions (i.e.,\nthe sharp affine Gagliardo-Nirenberg trace inequalities) which generalize a\nrecent result of De N\\'apoli et al. [DeNapoli]. It was shown that the affine\nversions are stronger and imply the sharp Gagliardo-Nirenberg trace\ninequalities. We also determine all extremal functions for the sharp affine\nGagliardo--Nirenberg trace inequalities.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the first observation of dynamically modulated quantum phase\ntransition (QPT) between two distinct charge density wave (CDW) phases in\n2-dimensional 2H-NbSe$_2$. There is recent spectroscopic evidence for the\npresence of these two quantum phases, but its evidence in bulk measurements\nremained elusive. We studied suspended, ultra-thin \\nbse devices fabricated on\npiezoelectric substrates - with tunable flakes thickness, disorder level and\nstrain. We find a surprising evolution of the conductance fluctuation spectra\nacross the CDW temperature: the conductance fluctuates between two precise\nvalues, separated by a quantum of conductance. These quantized fluctuations\ndisappear for disordered and on-substrate devices. With the help of mean-field\ncalculations, these observations can be explained as to arise from dynamical\nphase transition between the two CDW states. To affirm this idea, we vary the\nlateral strain across the device via piezoelectric medium and map out the phase\ndiagram near the quantum critical point (QCP). The results resolve a\nlong-standing mystery of the anomalously large spectroscopic gap in NbSe$_2$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A major challenge in understanding the generalization of deep learning is to\nexplain why (stochastic) gradient descent can exploit the network architecture\nto find solutions that have good generalization performance when using high\ncapacity models. We find simple but realistic examples showing that this\nphenomenon exists even when learning linear classifiers --- between two linear\nnetworks with the same capacity, the one with a convolutional layer can\ngeneralize better than the other when the data distribution has some underlying\nspatial structure. We argue that this difference results from a combination of\nthe convolution architecture, data distribution and gradient descent, all of\nwhich are necessary to be included in a meaningful analysis. We provide a\ngeneral analysis of the generalization performance as a function of data\ndistribution and convolutional filter size, given gradient descent as the\noptimization algorithm, then interpret the results using concrete examples.\nExperimental results show that our analysis is able to explain what happens in\nour introduced examples.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a novel coherence model for written asynchronous conversations\n(e.g., forums, emails), and show its applications in coherence assessment and\nthread reconstruction tasks. We conduct our research in two steps. First, we\npropose improvements to the recently proposed neural entity grid model by\nlexicalizing its entity transitions. Then, we extend the model to asynchronous\nconversations by incorporating the underlying conversational structure in the\nentity grid representation and feature computation. Our model achieves state of\nthe art results on standard coherence assessment tasks in monologue and\nconversations outperforming existing models. We also demonstrate its\neffectiveness in reconstructing thread structures.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Tseng's forward-backward-forward algorithm is a valuable alternative for\nKorpelevich's extragradient method when solving variational inequalities over a\nconvex and closed set governed by monotone and Lipschitz continuous operators,\nas it requires in every step only one projection operation. However, it is\nwell-known that Korpelevich's method converges and can therefore be used also\nfor solving variational inequalities governed by pseudo-monotone and Lipschitz\ncontinuous operators. In this paper, we first associate to a pseudo-monotone\nvariational inequality a forward-backward-forward dynamical system and carry\nout an asymptotic analysis for the generated trajectories. The explicit time\ndiscretization of this system results into Tseng's forward-backward-forward\nalgorithm with relaxation parameters, which we prove to converge also when it\nis applied to pseudo-monotone variational inequalities. In addition, we show\nthat linear convergence is guaranteed under strong pseudo-monotonicity.\nNumerical experiments are carried out for pseudo-monotone variational\ninequalities over polyhedral sets and fractional programming problems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We initiate the study of numerical linear algebra in the sliding window\nmodel, where only the most recent $W$ updates in a stream form the underlying\ndata set. We first introduce a unified row-sampling based framework that gives\nrandomized algorithms for spectral approximation, low-rank\napproximation/projection-cost preservation, and $\\ell_1$-subspace embeddings in\nthe sliding window model, which often use nearly optimal space and achieve\nnearly input sparsity runtime. Our algorithms are based on \"reverse online\"\nversions of offline sampling distributions such as (ridge) leverage scores,\n$\\ell_1$ sensitivities, and Lewis weights to quantify both the importance and\nthe recency of a row. Our row-sampling framework rather surprisingly implies\nconnections to the well-studied online model; our structural results also give\nthe first sample optimal (up to lower order terms) online algorithm for\nlow-rank approximation/projection-cost preservation. Using this powerful\nprimitive, we give online algorithms for column/row subset selection and\nprincipal component analysis that resolves the main open question of Bhaskara\net. al.,(FOCS 2019). We also give the first online algorithm for\n$\\ell_1$-subspace embeddings. We further formalize the connection between the\nonline model and the sliding window model by introducing an additional unified\nframework for deterministic algorithms using a merge and reduce paradigm and\nthe concept of online coresets. Our sampling based algorithms in the\nrow-arrival online model yield online coresets, giving deterministic algorithms\nfor spectral approximation, low-rank approximation/projection-cost\npreservation, and $\\ell_1$-subspace embeddings in the sliding window model that\nuse nearly optimal space.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Non-dominated sorting genetic algorithm II (NSGA-II) does well in dealing\nwith multi-objective problems. When evaluating validity of an algorithm for\nmulti-objective problems, two kinds of indices are often considered\nsimultaneously, i.e. the convergence to Pareto Front and the distribution\ncharacteristic. The crowding distance in the standard NSGA-II has the property\nthat solutions within a cubic have the same crowding distance, which has no\ncontribution to the convergence of the algorithm. Actually the closer to the\nPareto Front a solution is, the higher priority it should have. In the paper,\nthe crowding distance is redefined while keeping almost all the advantages of\nthe original one. Moreover, the speed of converging to the Pareto Front is\nfaster. Finally, the improvement is proved to be effective by applying it to\nsolve nine Benchmark problems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Book reviews play important roles in scholarly communication especially in\narts and humanities disciplines. By using Web of Science's Science Citation\nIndex Expanded, Social Sciences Citation Index, and Arts & Humanities Citation\nIndex, this study probed the patterns and dynamics of book reviews within these\nthree indexes empirically during the past decade (2006-2015). We found that the\nabsolute numbers of book reviews among all the three indexes were relatively\nstable but the relative shares were decreasing. Book reviews were very common\nin arts and humanities, common in social sciences, but rare in natural\nsciences. Book reviews are mainly contributed by authors from developed\neconomies such as the USA and the UK. Oppositely, scholars from China and Japan\nare unlikely to contribute to book reviews.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Raman scattering measurements are performed on benzene and a number of\n$p$-oligophenyls including biphenyl, $p$-terphenyl, $p$-quaterphenyl,\n$p$-quinquephenyl, and $p$-sexiphenyl at ambient conditions. The vibrational\nmodes of the intra- and intermolecular terms in these materials are analyzed\nand compared. Chain length effects on the vibrational properties are examined\nfor the C-H in-plane bending mode and the inter-ring C-C stretching mode at\naround 1200 cm$^{-1}$ and 1280 cm$^{-1}$, respectively, and the C-C stretching\nmodes at around 1600 cm$^{-1}$. The complex and fluctuating properties of these\nmodes result in an imprecise estimation of the chain length of these molecules.\nMeanwhile, the obtained ratio of the intensities of the 1200 cm$^{-1}$ mode and\n1280 cm$^{-1}$ mode is sensitive to the applied lasers. A librational motion\nmode with the lowest energy is found to have a monotonous change with the\nincrease in the chain length. This mode is simply relevant to the $c$ axis of\nthe unit cell. Such an obvious trend makes it a better indicator for\ndetermining the chain length effects on the physical and chemical properties in\nthese molecules.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper proposes Medley of Sub-Attention Networks (MoSAN), a new novel\nneural architecture for the group recommendation task. Group-level\nrecommendation is known to be a challenging task, in which intricate group\ndynamics have to be considered. As such, this is to be contrasted with the\nstandard recommendation problem where recommendations are personalized with\nrespect to a single user. Our proposed approach hinges upon the key intuition\nthat the decision making process (in groups) is generally dynamic, i.e., a\nuser's decision is highly dependent on the other group members. All in all, our\nkey motivation manifests in a form of an attentive neural model that captures\nfine-grained interactions between group members. In our MoSAN model, each\nsub-attention module is representative of a single member, which models a\nuser's preference with respect to all other group members. Subsequently, a\nMedley of Sub-Attention modules is then used to collectively make the group's\nfinal decision. Overall, our proposed model is both expressive and effective.\nVia a series of extensive experiments, we show that MoSAN not only achieves\nstate-of-the-art performance but also improves standard baselines by a\nconsiderable margin.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Culler-Shalen theory uses the algebraic geometry of the SL(2,C)-character\nvariety of a 3-manifold to construct essential surfaces in the manifold. There\nare module structures associated to the coordinate rings of the irreducible\ncomponents of character varieties that are intimately related to essential\nsurface construction. When these modules are finitely generated, we derive a\nformula for their rank that incorporates the irreducible component's field of\ndefinition and the Culler-Shalen norm.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider dynamics of simple waves in a two-component Bose-Einstein\ncondensates. The evolution of the condensate is described by the\nGross-Pitaevskii equations which can be reduced for simple wave solutions to a\nsystem of ordinary differential equations which coincide with those derived by\nOvsyannikov for the two-layer fuid dynamics. We solve the Ovsyannikov system\nfor two typical situations of large and small difference between inter-species\nand intra-species nonlinear interaction constants. Our analytic results are\nconfirmed by numerical simulations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Several problems in healthcare stem from the complex network of\nintermediaries and the lack of traceability of transactions. To mention a few:\nhealthcare data is fragmented across several silos negatively affecting\nresearch and services, about half of the clinical trials are never reported,\nthe cost of drug discovery is ever increasing, and substandard and fake\nmedicines are still a huge problem. Blockchain has the potential to solve these\nproblems as it provides trust without any intermediaries, has traceability as a\ndefault feature, and promises new business models by enabling novel incentive\nstructures. Due to its potential, blockchain has gathered significant interest\nin the healthcare industry. In this paper, we review major use cases of\nblockchain in healthcare: patient data management, pharmaceutical research,\nsupply chain management of medical goods, prescription management, billing\nclaims management, analytics, and telemedicine alongside the related projects.\nWe found that most of the blockchain projects are limited as white-papers,\nproof of concepts, and products with a limited user base. However, we observed\nthat the quantity, quality, and maturity of the projects are increasing. We\nalso discuss technical, regulatory, and business challenges to the adoption of\nblockchain in the healthcare industry\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The next generation of jobs will be characterized by an increased demand for\npeople with computational and problem solving skills. In Austria, computer\nscience topics are underrepresented in school curricula hence teaching time for\nthese topics is limited. From primary through secondary school, only a few\nopportunities exist for young students to explore programming. Furthermore,\ntoday's teachers are rarely trained in computer science, which impairs their\npotential to motivate students in these courses. Within the \"No One Left\nBehind\" (NOLB) project, teachers were supported to guide and assist their\nstudents in their learning processes by constructing ideas through game making.\nThus, students created games that referred to different subject areas by using\nthe programming tool Pocket Code, an app developed at Graz University of\nTechnology (TU-Graz). This tool helps students to take control of their own\neducation, becoming more engaged, interested, and empowered as a result. To\nensure an optimal integration of the app in diverse subjects the different\nbackgrounds (technical and non-technical) of teachers must be considered as\nwell. First, teachers were supported to use Pocket Code in the different\nsubjects in school within the feasibility study of the project. Observed\nchallenges and difficulties using the app have been gathered. Second, we\nconducted interviews with teachers and students to underpin our onsite\nobservations. As a result, it was possible to validate Pocket Codes' potential\nto be used in a diverse range of subjects. Third, we focused especially on\nthose teachers who were not technically trained to provide them with a\nframework for Pocket Code units, e.g., with the help of structured lesson plans\nand predefined templates.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We solve two long-standing open problems on word equations. Firstly, we prove\nthat a one-variable word equation with constants has either at most three or an\ninfinite number of solutions. The existence of such a bound had been\nconjectured, and the bound three is optimal. Secondly, we consider independent\nsystems of three-variable word equations without constants. If such a system\nhas a nonperiodic solution, then this system of equations is at most of size\n17. Although probably not optimal, this is the first finite bound found.\nHowever, the conjecture of that bound being actually two still remains open.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work we use matrix models to study the problem of strength\ndistributions. This is motivated by noticing near exponential fall offs of\nstrengths in calculated magnetic dipole excitations. We emphasize that the\nquality of the exponential fall offs depend on the parameters in our matrices,\nespecially the relative size of the couplings to the unperturbed level\nseparations. We also find a matrix for which all transitions vanish.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report on the self-induced electron trapping occurring in a ultracold\nneutral plasma that is set to expand freely. At the early stages of the plasma,\nthe ions are not thermalized follow a Gaussian spatial profile, providing the\ntrapping to the coldest electrons. In the present work, we provide a\ntheoretical model describing the electrostatic potential and perform molecular\ndynamics simulations to validate our findings. We show that in the strong\nconfinement regime, the plasma potential is of a Thomas-Fermi type, similar to\nthe case of heavy atomic species. The numerically simulated spatial profiles of\nthe particles corroborate this claim. We also extract the electron temperature\nand coupling parameter from the simulation, so the duration of the transient\nThomas-Fermi is obtained.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The basic $\\kappa$-color box-ball (BBS) system is an integrable cellular\nautomaton on one dimensional lattice whose local states take\n$\\{0,1,\\cdots,\\kappa \\}$ with $0$ regarded as an empty box. The time evolution\nis defined by a combinatorial rule of quantum group theoretical origin, and the\ncomplete set of conserved quantities is given by a $\\kappa$-tuple of Young\ndiagrams. In the randomized BBS, a probability distribution on\n$\\{0,1,\\cdots,\\kappa \\}$ to independently fill the consecutive $n$ sites in the\ninitial state induces a highly nontrivial probability measure on the\n$\\kappa$-tuple of those invariant Young diagrams. In a recent work\n\\cite{kuniba2018randomized}, their large $n$ `equilibrium shape' has been\ndetermined in terms of Schur polynomials by a Markov chain method and also by a\nvery different approach of Thermodynamic Bethe Ansatz (TBA). In this paper, we\nestablish a large deviations principle for the row lengths of the invariant\nYoung diagrams. As a corollary, they are shown to converge almost surely to the\nequilibrium shape at an exponential rate. We also refine the TBA analysis and\nobtain the exact scaling form of the vacancy, the row length and the column\nmultiplicity, which exhibit nontrivial factorization in a one-parameter\nspecialization.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Relative worst-order analysis is a technique for assessing the relative\nquality of online algorithms. We survey the most important results obtained\nwith this technique and compare it with other quality measures.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recently a new class of scalarized black holes in Einstein-Gauss-Bonnet (EGB)\ntheories was discovered. What is special for these black hole solutions is that\nthe scalarization is not due to the presence of matter, but {it is induced} by\nthe curvature of spacetime itself. Moreover, more than one branch of scalarized\nsolutions can bifurcate from the Schwarzschild branch, and these scalarized\nbranches are characterized by the number of nodes of the scalar field. The next\nstep is to consider the linear stability of these solutions, which is\nparticularly important due to the fact that the Schwarzschild black holes lose\nstability at the first point of bifurcation. Therefore we here study in detail\nthe radial perturbations of the scalarized EGB black holes. The results show\nthat all branches with a nontrivial scalar field with one or more nodes are\nunstable. The stability of the solutions on the fundamental branch, whose\nscalar field has no radial nodes, depends on the particular choice of the\ncoupling function between the scalar field and the Gauss-Bonnet invariant. We\nconsider two particular cases based on the previous studies of the background\nsolutions. If this coupling has the form used in \\cite{Doneva:2017bvd} the\nfundamental branch of solutions is stable, except for very small masses. In the\ncase of a coupling function quadratic in the scalar field \\cite{Silva:2017uqg},\nthough, the whole fundamental branch is unstable.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Blockchains have recently been under the spotlight due to the boom of\ncryptocurrencies and decentralized applications. There is an increasing demand\nfor querying the data stored in a blockchain database. To ensure query\nintegrity, the user can maintain the entire blockchain database and query the\ndata locally. However, this approach is not economic, if not infeasible,\nbecause of the blockchain's huge data size and considerable maintenance costs.\nIn this paper, we take the first step toward investigating the problem of\nverifiable query processing over blockchain databases. We propose a novel\nframework, called vChain, that alleviates the storage and computing costs of\nthe user and employs verifiable queries to guarantee the results' integrity. To\nsupport verifiable Boolean range queries, we propose an accumulator-based\nauthenticated data structure that enables dynamic aggregation over arbitrary\nquery attributes. Two new indexes are further developed to aggregate\nintra-block and inter-block data records for efficient query verification. We\nalso propose an inverted prefix tree structure to accelerate the processing of\na large number of subscription queries simultaneously. Security analysis and\nempirical study validate the robustness and practicality of the proposed\ntechniques.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  One of the biggest issues facing the use of machine learning in medical\nimaging is the lack of availability of large, labelled datasets. The annotation\nof medical images is not only expensive and time consuming but also highly\ndependent on the availability of expert observers. The limited amount of\ntraining data can inhibit the performance of supervised machine learning\nalgorithms which often need very large quantities of data on which to train to\navoid overfitting. So far, much effort has been directed at extracting as much\ninformation as possible from what data is available. Generative Adversarial\nNetworks (GANs) offer a novel way to unlock additional information from a\ndataset by generating synthetic samples with the appearance of real images.\nThis paper demonstrates the feasibility of introducing GAN derived synthetic\ndata to the training datasets in two brain segmentation tasks, leading to\nimprovements in Dice Similarity Coefficient (DSC) of between 1 and 5 percentage\npoints under different conditions, with the strongest effects seen fewer than\nten training image stacks are available.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In recent years, both online retail and video hosting service are\nexponentially growing. In this paper, we explore a new cross-domain task,\nVideo2Shop, targeting for matching clothes appeared in videos to the exact same\nitems in online shops. A novel deep neural network, called AsymNet, is proposed\nto explore this problem. For the image side, well-established methods are used\nto detect and extract features for clothing patches with arbitrary sizes. For\nthe video side, deep visual features are extracted from detected object regions\nin each frame, and further fed into a Long Short-Term Memory (LSTM) framework\nfor sequence modeling, which captures the temporal dynamics in videos. To\nconduct exact matching between videos and online shopping images, LSTM hidden\nstates, representing the video, and image features, which represent static\nobject images, are jointly modeled under the similarity network with\nreconfigurable deep tree structure. Moreover, an approximate training method is\nproposed to achieve the efficiency when training. Extensive experiments\nconducted on a large cross-domain dataset have demonstrated the effectiveness\nand efficiency of the proposed AsymNet, which outperforms the state-of-the-art\nmethods.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Predictive theory to geometrically engineer devices and materials in\ncontinuum systems to have desired topological-like effects is developed here by\nbridging the gap between quantum and continuum mechanical descriptions. A\nplatonic crystal, a bosonic-like system in the language of quantum mechanics,\nis shown to exhibit topological valley modes despite the system having no\ndirect physical connection to quantum effects. We emphasise a predictive,\nfirst-principle, approach, the strength of which is demonstrated by the ability\nto design well-defined broadband edge states, resistant to backscatter, using\ngeometric differences; the mechanism underlying energy transfer around gentle\nand sharp corners is described. Using perturbation methods and group theory,\nseveral distinct cases of symmetry-induced Dirac cones which when gapped yield\nnon-trivial band-gaps are identified and classified. The propagative behavior\nof the edge states around gentle or sharp bends depends strongly upon the\nsymmetry class of the bulk media and we illustrate this via numerical\nsimulations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The role of the de Broglie-Bohm potential, originally established as central\nto Bohmian quantum mechanics, is examined for two canonical Madelung systems in\nnonlinear optics. In a seminal case, a Madelung system derived by Wagner et al.\nvia the paraxial approximation and in which the de Broglie-Bohm potential is\npresent, is shown to admit a multi-parameter class of what are here introduced\nas \"q-gaussons\". In the limit as the Tsallis parameter q --> 1, the q-gaussons\nare shown to lead to standard gausson solitons as admitted by logarithmic\nnonlinear Schroedinger equation encapsulating the Madelung system. The\nq-gaussons are obtained for optical media with dual power-law refractive index.\nIn the second case, a Madelung system originally derived via an eikonal\napproximation in the context of laser beam propagation and in which the de\nBroglie Bohm term is neglected, is shown to admit invariance under a novel\nclass of two-parameter reciprocal transformations. Model optical laws analogous\nto the celebrated Karman-Tsien law of classical gasdynamics are introduced.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Subspace clustering is a useful technique for many computer vision\napplications in which the intrinsic dimension of high-dimensional data is often\nsmaller than the ambient dimension. Spectral clustering, as one of the main\napproaches to subspace clustering, often takes on a sparse representation or a\nlow-rank representation to learn a block diagonal self-representation matrix\nfor subspace generation. However, existing methods require solving a large\nscale convex optimization problem with a large set of data, with computational\ncomplexity reaches O(N^3) for N data points. Therefore, the efficiency and\nscalability of traditional spectral clustering methods can not be guaranteed\nfor large scale datasets. In this paper, we propose a subspace clustering model\nbased on the Kronecker product. Due to the property that the Kronecker product\nof a block diagonal matrix with any other matrix is still a block diagonal\nmatrix, we can efficiently learn the representation matrix which is formed by\nthe Kronecker product of k smaller matrices. By doing so, our model\nsignificantly reduces the computational complexity to O(kN^{3/k}). Furthermore,\nour model is general in nature, and can be adapted to different regularization\nbased subspace clustering methods. Experimental results on two public datasets\nshow that our model significantly improves the efficiency compared with several\nstate-of-the-art methods. Moreover, we have conducted experiments on synthetic\ndata to verify the scalability of our model for large scale datasets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The inclusion equations of the type $f \\in T ( x)$ where $T: X \\to\n2^{X^{\\ast}}$ is a maximal monotone map, are extensively studied in nonlinear\nanalysis. In this paper, we present a new construction of the degree of maximal\nmonotone maps of the form $T: Y \\to 2^{X^*}$, where $Y$ is a locally uniformly\nconvex and separable Banach space continuously embedded in the uniformly convex\nBanach space $X$. The advantage of the new construction lies in the remarkable\nsimplicity it offers for calculation of degree in comparison with the classical\none suggested by F. Browder. We prove a few classical theorems in convex\nanalysis through the suggested degree.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work, by employing Density Functional Theory, we compute and discuss\nsome geometric and magnetic properties of the monomer, dimer and trimer of\nNiFe2 O4 . The calculations are performed at the UDFT/ B3LYP level of\ncalculation, by employing the LANL2DZ effective pseudo potential. The results\nof the Mulliken spin densities and the spin polarization will be presented.\nFinally the outcome of the system density of states is considered.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Sr2Cr3As2O2 is composed of alternating square-lattice CrO2 and Cr2As2\nstacking layers, where CrO2 is isostructural to the CuO2 building-block of\ncuprate high-Tc superconductors and Cr2As2 to Fe2As2 of Fe-based\nsuperconductors. Current interest in this material is raised by theoretic\nprediction of possible superconductivity. In this neutron powder diffraction\nstudy, we discovered that magnetic moments of Cr(II) ions in the Cr2As2\nsublattice develop a C-type antiferromagnetic structure below 590 K, and the\nmoments of Cr(I) in the CrO2 sublattice form the La2CuO4 -like\nantiferromagnetic order below 291 K. The staggered magnetic moment 2.19(4){\\mu}\nB /Cr(II) in the more itinerant Cr2As2 layer is smaller than\n3.10(6){\\mu}_B/Cr(I) in the more localized CrO2 layer. Different from previous\nexpectation, a spin-flop transition of the Cr(II) magnetic order observed at\n291 K indicates a strong coupling between the CrO2 and Cr2As2 magnetic\nsubsystems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose speeding up a single ion heat pump based on a tapered ion trap. If\na trapped ion is excited in an oscillatory motion axially the radial degrees of\nfreedom are cyclically expanded and compressed such that heat can be pumped\nbetween two reservoirs coupled to the ion at the turning points of oscillation.\nThrough the use of invariant-based inverse engineering we can speed up the\nprocess without sacrificing the efficiency of each heat pump cycle. This\nadditional control can be supplied with additional control electrodes or it can\nbe encoded into the geometry of the radial trapping electrodes. We present\nnovel insight how speed up can be achieved through the use of inverted harmonic\npotentials and verified the stability of such trapping conditions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In 1950 Edward Nelson asked the following simple-sounding question:\n  \\emph{How many colors are needed to color the Euclidean plane $\\mathbb{E}^2$\nsuch that no two points distance $1$ apart are identically colored?}\n  We say that $1$ is a \\emph{forbidden} distance. For many years, we only knew\nthat the answer was $4$, $5$, $6$, or $7$. In a recent breakthrough, de Grey\n\\cite{degrey} proved that at least five colors are necessary.\n  In this paper we consider a related problem in which we require \\emph{two}\nforbidden distances, $1$ and $d$. In other words, for a given positive number\n$d\\neq 1$, how many colors are needed to color the plane such that no two\npoints distance $1$ \\underline{or} $d$ apart are assigned the same color? We\nfind several values of $d$, for which the answer to the previous question is at\nleast $5$. These results and graphs may be useful in constructing simpler\n$5$-chromatic unit distance graphs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We demonstrate seamless channel multiplexing and high bitrate superchannel\ntransmission of coherent optical orthogonal-frequency-division-multiplexing\n(CO-OFDM) data signals utilizing a dissipative Kerr soliton (DKS) frequency\ncomb generated in an on-chip microcavity. Aided by comb line multiplication\nthrough Nyquist pulse modulation, the high stability and mutual coherence among\nmode-locked Kerr comb lines are exploited for the first time to eliminate the\nguard intervals between communication channels and achieve full spectral\ndensity bandwidth utilization. Spectral efficiency as high as 2.625 bit/Hz/s is\nobtained for 180 CO-OFDM bands encoded with 12.75 Gbaud 8-QAM data, adding up\nto total bitrate of 6.885 Tb/s within 2.295 THz frequency comb bandwidth. Our\nstudy confirms that high coherence is the key superiority of Kerr soliton\nfrequency combs over independent laser diodes, as a multi-spectral coherent\nlaser source for high-bandwidth high-spectral-density transmission networks.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Barboza-Alcaniz EoS parametrization has been considered and its\n$q$-parametrization has been investigated in search for a thermodynamic\nmotivation. For this, we have studied the validity of the generalized second\nlaw of thermodynamics as well as the thermodynamic equilibrium considering the\ncosmological apparent horizon as the boundary. Also, an expression for the\nparticle creation rate has been obtained in terms of $q$ assuming an adiabatic\nparticle creation scenario and its behavior has been studied for consistency\nduring various phases of evolution of the Universe as suggested by various\nthermodynamic arguments found in the literature.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The cosmological utility of galaxy cluster catalogues is primarily limited by\nour ability to calibrate the relation between halo mass and observable mass\nproxies such as cluster richness, X-ray luminosity or the Sunyaev-Zeldovich\nsignal. Projection effects are a particularly pernicious systematic effect that\ncan impact observable mass proxies; structure along the line of sight can both\nbias and increase the scatter of the observable mass proxies used in cluster\nabundance studies. In this work, we develop an empirical method to characterize\nthe impact of projection effects on redMaPPer cluster catalogues. We use\nnumerical simulations to validate our method and illustrate its robustness. We\ndemonstrate that modeling of projection effects is a necessary component for\ncluster abundance studies capable of reaching $\\approx 5\\%$ mass calibration\nuncertainties (e.g. the Dark Energy Survey Year 1 sample). Specifically,\nignoring the impact of projection effects in the observable--mass relation ---\ni.e. marginalizing over a log-normal model only --- biases the posterior of the\ncluster normalization condition $S_8 \\equiv \\sigma_8 (\\Omega_{\\rm\nm}/0.3)^{1/2}$ by $\\Delta S_8 =0.05$, more than twice the uncertainty in the\nposterior for such an analysis.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Ongoing surveys are in the process of measuring the chemical abundances in\nlarge numbers of stars, with the ultimate goal of reconstructing the formation\nhistory of the Milky Way using abundances as tracers. However, interpretation\nof these data requires that we understand the relationship between stellar\ndistributions in chemical and physical space, i.e., how similar in chemical\nabundance do we expect a pair of stars to be as a function of the distance\nbetween their formation sites. We investigate this question by simulating the\ngravitational collapse of a turbulent molecular cloud extracted from a\ngalaxy-scale simulation, seeded with chemical inhomogeneities with different\ninitial spatial scales. We follow the collapse from galactic scales down to\nresolutions scales of $\\approx 10^{-3}$ pc, and find that, during this process,\nturbulence mixes the metal patterns, reducing the abundance scatter initially\npresent in the gas by an amount that depends on the initial scale of\ninhomogeneity of each metal field. However, we find that regardless of the\ninitial spatial structure of the metals at the onset of collapse, the final\nstellar abundances are highly correlated on distances below a few pc, and\nnearly uncorrelated on larger distances. Consequently, the star formation\nprocess defines a natural size scale of $\\sim 1$ pc for chemically-homogenous\nstar clusters, suggesting that any clusters identified as homogenous in\nchemical space must have formed within $\\sim 1$ pc of one another. However, in\norder to distinguish different star clusters in chemical space, observations\nacross multiple elements will be required, and the elements that are likely to\nbe most efficient at separating distinct clusters in chemical space are those\nwhose correlation length in the ISM is of order tens of pc, comparable to the\nsizes of individual molecular clouds.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we describe a novel shape classification method which is\nembedded in the Bayesian paradigm. We discuss the modelling and the resulting\nshape classification algorithm for two and three dimensional data shapes. We\nconclude by evaluating the efficiency and efficacy of the proposed algorithm on\nthe Kimia shape database for the two dimensional case.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Particle-antiparticle pairs are predicted by quantum field theory to appear\nas vacuum fluctuations. The model of the vacuum used here is postulated to have\nthe following properties: To minimize the violation of conservation energy\nallowed by the Heisenberg uncertainty principle and to avoid violating\nconservation of angular momentum, vacuum fluctuations of charged\nparticle-antiparticle pairs appear as bound states in the lowest energy level\nthat has zero angular momentum. These transient atoms are polarized by electric\nfields somewhat similarly to the way that ordinary matter is polarized. As a\nconsequence, the permittivity $\\epsilon_0$ of the vacuum can be calculated.\nOnce the permittivity of the vacuum has been calculated, formulas for the speed\nof light $c$ in the vacuum and the fine-structure constant $\\alpha$ immediately\nfollow. The values for $\\epsilon_0$, $c$, and $\\alpha$ calculated here agree\nwith the accepted values to within a few percent. Only the leading terms in the\nformulas have been retained in the calculations. The absence of dispersion in\nthe vacuum is discussed and explained.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper an adaptive load management system that uses predictive control\noptimization is introduced. This price elastic system is able to optimize the\nconsumption of power and is fully autonomous and responsive to market clearing\nprices. The area of application chosen was an air-conditioning system that\nallows the end user to select a comfort zone that serves as the boundary\nconditions for the optimization algorithm. The temperature function that\ngoverns our algorithm is also derived and tested. Numerical examples are then\npresented to show the effectiveness of this system on day-ahead and real-time\ndata from ISOs. The developed system showed promising results and savings that\nwill improve the utilization of present energy resources. Finally, the\nimplementation of this system was discussed and some preliminary modeling was\nperformed to show the potential realization of such a system\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  While there exist many methods in machine learning for comparison of letter\nstring data, most are better equipped to handle strings that represent natural\nlanguage, and their performance will not hold up when presented with strings\nthat correspond to mathematical expressions. Based on the graphical\nrepresentation of the expression tree, here we propose a simple method for\nencoding such expressions that is only sensitive to their structural\nproperties, and invariant to the specifics which can vary between two seemingly\ndifferent, but semantically similar mathematical expressions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report the discovery of a candidate to quadrupole gravitationally lensed\nsystem KiDS0239-3211 based on the public data release 3 of the KiDS survey and\nmachine learning techniques.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, a Novel Active Disturbance Rejection Control (N-ADRC) strategy\nis proposed that replaces the Linear Extended state observer (LESO) used in\nConventional ADRC (C-ADRC) with a Nested LESO. In the nested LESO, the\ninner-loop LESO actively estimates and eliminates the generalized disturbance.\nIncreasing the bandwidth improves the estimation accuracy which may tolerate\nnoise and conflict with H/W limitations and the sampling frequency of the\nsystem. Therefore, an alternative scenario is offered without increasing the\nbandwidth of the inner-loop LESO provided that the rate of change of the\ngeneralized disturbance estimation error is upper bounded. This is achieved by\nthe placing an outer-loop LESO in parallel with the inner one, it estimates and\neliminates the remaining generalized disturbance that eluded from the\ninner-loop LESO due to bandwidth limitations. The stability of LESO and nested\nLESO is investigated using Lyapunov stability analysis. Simulations on\nuncertain nonlinear SISO system with time-varying exogenous disturbance\nrevealed that the proposed nested LESO can successfully deal with a generalized\ndisturbance in both noisy and noise-free environments, where the Integral Time\nAbsolute Error (ITAE) of the tracking error for the nested LESO is reduced by\n69.87% from that of the LESO.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report a new Fast Radio Burst (FRB) discovered in real-time as part of the\nUTMOST project at the Molonglo Observatory Synthesis Radio Telescope (MOST).\nFRB170827 is the first detected with our low-latency ($< 24$ s),\nmachine-learning-based FRB detection system. The FRB discovery was accompanied\nby the capture of voltage data at the native time and frequency resolution of\nthe observing system, enabling coherent dedispersion and detailed off-line\nanalysis, which have unveiled fine temporal and frequency structure. The\ndispersion measure (DM) of 176.80 $\\pm$ 0.04 pc cm$^{-3}$, is the lowest of the\nFRB population. The Milky Way contribution along the line of sight is $\\sim$ 40\npc cm$^{-3}$, leaving an excess DM of $\\sim$ 145 pc cm$^{-3}$. The FRB has a\nfluence $>$ 20 $\\pm$ 7 Jy ms, and is narrow, with a width of $\\sim$ 400 $\\mu$s\nat 10$\\%$ of its maximum amplitude. However, the burst shows three temporal\ncomponents, the narrowest of which is $\\sim$ 30 $\\mu$s, and a scattering\ntimescale of $4.1 \\pm 2.7$ $\\mu$s. The FRB shows spectral modulations on\nfrequency scales of 1.5 MHz and 0.1 MHz. Both are prominent in the dynamic\nspectrum, which shows a very bright region of emission between 841 and 843 MHz,\nand weaker, patchy emission across the entire band. We show the fine spectral\nstructure could arise in the FRB host galaxy, or its immediate vicinity.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this note we consider the issue of the classical equivalence of\nscale-invariant gravity in the Einstein and in the Jordan frames. We first\nconsider the simplest example $f(R)=R^{2}$ and show explicitly that the\nequivalence breaks down when dealing with Ricci-flat solutions. We discuss the\nlink with the fact that flat solutions in quadratic gravity have zero energy.\nWe also consider the case of scale-invariant tensor-scalar gravity and general\n$f(R)$ theories. We argue that all scale-invariant gravity models have Ricci\nflat solutions in the Jordan frame that cannot be mapped into the Einstein\nframe. In particular, the Minkowski metric exists only in the Jordan frame. In\nthis sense, the two frames are not equivalent.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we propose an efficient and accurate message-passing interface\n(MPI)-based parallel simulator for streamer discharges in three dimensions\nusing the fluid model. First, we propose a new second-order semi-implicit\nscheme for the temporal discretization of the model that relaxes the dielectric\nrelaxation time restriction. Moreover, it requires solving the Poisson-type\nequation only once at each time step, while the classical second-order explicit\nscheme typically needs to do twice. Second, we introduce a geometric multigrid\npreconditioned FGMRES solver that dramatically improves the efficiency of\nsolving the Poisson-type equation with either constant or variable\ncoefficients. We show numerically that no more than 4 iterations are required\nfor the Poisson solver to converge to a relative residual of $10^{-8}$ during\nstreamer simulations; the FGMRES solver is much faster than R&B SOR and other\nKrylov subspace solvers. Last but not least, all the methods are implemented\nusing MPI. The parallel efficiency of the code and the fast algorithmic\nperformances are demonstrated by a series of numerical experiments using up to\n2560 cores on the Tianhe2-JK clusters. For applications, we study a\ndouble-headed streamer discharge as well as the interaction between two\nstreamers, using up to 10.7 billion mesh cells.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the problem of maximizing a monotone submodular function subject to\na matroid constraint and present a deterministic algorithm that achieves (1/2 +\n{\\epsilon})-approximation for the problem. This algorithm is the first\ndeterministic algorithm known to improve over the 1/2-approximation ratio of\nthe classical greedy algorithm proved by Nemhauser, Wolsely and Fisher in 1978.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Secondary eclipse observations of ultra-hot Jupiters have found evidence that\nhydrogen is dissociated on their daysides. Additionally, full-phase light curve\nobservations of ultra-hot Jupiters show a smaller day-night emitted flux\ncontrast than that expected from previous theory. Recently, it was proposed by\nBell & Cowan (2018) that the heat intake to dissociate hydrogen and heat\nrelease due to recombination of dissociated hydrogen can affect the atmospheric\ncirculation of ultra-hot Jupiters. In this work, we add cooling/heating due to\ndissociation/recombination into the analytic theory of Komacek & Showman (2016)\nand Zhang & Showman (2017) for the dayside-nightside temperature contrasts of\nhot Jupiters. We find that at high values of incident stellar flux, the\nday-night temperature contrast of ultra-hot Jupiters may decrease with\nincreasing incident stellar flux due to dissociation/recombination, the\nopposite of that expected without including the effects of\ndissociation/recombination. We propose that a combination of a greater number\nof full-phase light curve observations of ultra-hot Jupiters and future General\nCirculation Models that include the effects of dissociation/recombination could\ndetermine in detail how the atmospheric circulation of ultra-hot Jupiters\ndiffers from that of cooler planets.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we investigate a large-scale stochastic system with bilinear\ndrift and linear diffusion term. Such high dimensional systems appear for\nexample when discretizing a stochastic partial differential equations in space.\nWe study a particular model order reduction technique called balanced\ntruncation (BT) to reduce the order of spatially-discretized systems and hence\nreduce computational complexity. We introduce suitable Gramians to the system\nand prove energy estimates that can be used to identify states which contribute\nonly very little to the system dynamics. When BT is applied the reduced system\nis obtained by removing these states from the original system. The main\ncontribution of this paper is an $L^2$-error bound for BT for stochastic\nbilinear systems. This result is new even for deterministic bilinear equations.\nIn order to achieve it, we develop a new technique which is not available in\nthe literature so far.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We simulate $ SU(2) $ lattice gauge theory using dynamical reduced staggered\nfermions. The latter lead to two rather than four Dirac fermions in the\ncontinuum limit. We review the derivation and properties of reduced staggered\nfermions and show that in the case of fields in the fundamental representation\nof $SU(2)$ the theory does not exhibit a sign problem and can be simulated\nusing the RHMC algorithm. We present results on lattices up to $16^4$ for a\nwide range of bare fermion masses. We find a single site condensate appears at\nstrong coupling that spontaneously breaks the one global $U(1)$ symmetry\nremaining in the reduced fermion action.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We perform a complementarity study of gravitational waves and colliders in\nthe context of electroweak phase transitions choosing as our template the xSM\nmodel, which consists of the Standard Model augmented by a real scalar. We\ncarefully analyze the gravitational wave signal at benchmark points compatible\nwith a first order phase transition, taking into account subtle issues\npertaining to the bubble wall velocity and the hydrodynamics of the plasma. In\nparticular, we comment on the tension between requiring bubble wall velocities\nsmall enough to produce a net baryon number through the sphaleron process, and\nlarge enough to obtain appreciable gravitational wave production. For the most\npromising benchmark models, we study resonant di-Higgs production at the\nhigh-luminosity LHC using machine learning tools: a Gaussian process algorithm\nto jointly search for optimum cut thresholds and tuning hyperparameters, and a\nboosted decision trees algorithm to discriminate signal and background. The\nmultivariate analysis on the collider side is able either to discover or\nprovide strong statistical evidence of the benchmark points, opening the\npossibility for complementary searches for electroweak phase transitions in\ncollider and gravitational wave experiments.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  As adversarial attacks pose a serious threat to the security of AI system in\npractice, such attacks have been extensively studied in the context of computer\nvision applications. However, few attentions have been paid to the adversarial\nresearch on automatic path finding. In this paper, we show dominant adversarial\nexamples are effective when targeting A3C path finding, and design a Common\nDominant Adversarial Examples Generation Method (CDG) to generate dominant\nadversarial examples against any given map. In addition, we propose Gradient\nBand-based Adversarial Training, which trained with a single randomly choose\ndominant adversarial example without taking any modification, to realize the\n\"1:N\" attack immunity for generalized dominant adversarial examples. Extensive\nexperimental results show that, the lowest generation precision for CDG\nalgorithm is 91.91%, and the lowest immune precision for Gradient Band-based\nAdversarial Training is 93.89%, which can prove that our method can realize the\ngeneralized attack immunity of A3C path finding with a high confidence.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper introduces a machine for sampling approximate model-X knockoffs\nfor arbitrary and unspecified data distributions using deep generative models.\nThe main idea is to iteratively refine a knockoff sampling mechanism until a\ncriterion measuring the validity of the produced knockoffs is optimized; this\ncriterion is inspired by the popular maximum mean discrepancy in machine\nlearning and can be thought of as measuring the distance to pairwise\nexchangeability between original and knockoff features. By building upon the\nexisting model-X framework, we thus obtain a flexible and model-free\nstatistical tool to perform controlled variable selection. Extensive numerical\nexperiments and quantitative tests confirm the generality, effectiveness, and\npower of our deep knockoff machines. Finally, we apply this new method to a\nreal study of mutations linked to changes in drug resistance in the human\nimmunodeficiency virus.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Cassini-Huygens space mission revealed that Titan s thick brownish haze\nis initiated high in the atmosphere at about 1000 km of altitude, before a slow\ntransportation down to the surface. Close to the surface at altitudes below 130\nkm, the Huygens probe provided information on the chemical composition of the\nhaze. So far we do not have insights on a possible photochemical evolution of\nthe aerosols composing the haze during their descent. We address here this\natmospheric aerosol aging process, simulating in the laboratory how solar\nvacuum-ultraviolet (VUV) irradiation affects the aerosol optical properties as\nprobed by infrared spectroscopy. An important evolution is found, which could\nexplain the apparent contradiction between the nitrogen-poor infrared\nspectroscopic signature observed by Cassini below 600 km of altitude in Titan s\natmosphere, and a high nitrogen content as measured by the Aerosol Collector\nand Pyroliser of Huygens probe at the surface of Titan.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We analyze the combined Spitzer and ground-based data for OGLE-2017-BLG-1140\nand show that the event was generated by a Jupiter-class $(m_p\\simeq\n1.6\\,M_{\\rm jup})$ planet orbiting a mid-late M dwarf $(M\\simeq 0.2\\,M_\\odot)$\nthat lies $D_{LS}\\simeq 1.0\\,\\mathrm{kpc}$ in the foreground of the\nmicrolensed, Galactic-bar, source star. The planet-host projected separation is\n$a_\\perp \\simeq 1.0\\,\\mathrm{au}$, i.e., well-beyond the snow line. By\nmeasuring the source proper motion ${\\mathbf{\\mu}}_s$ from ongoing, long-term\nOGLE imaging, and combining this with the lens-source relative proper motion\n${\\mathbf{\\mu}}_\\mathrm{rel}$ derived from the microlensing solution, we show\nthat the lens proper motion ${\\mathbf{\\mu}}_l={\\mathbf{\\mu}}_\\mathrm{rel} +\n{\\mathbf{\\mu}}_s$ is consistent with the lens lying in the Galactic disk,\nalthough a bulge lens is not ruled out. We show that while the Spitzer and\nground-based data are comparably well fitted by planetary (i.e., binary-lens,\n2L1S) models and by binary-source (1L2S) models, the combination of Spitzer and\nground-based data decisively favor the planetary model. This is a new channel\nto resolve the 2L1S/1L2S degeneracy, which can be difficult to break in some\ncases.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We calculate the frequency-dependent equilibrium noise of a mesoscopic\ncapacitor in time-dependent density functional theory (TDDFT). The capacitor is\nmodeled as a single-level quantum dot with on-site Coulomb interaction and\ntunnel coupling to a nearby reservoir. The noise spectra are derived from\nlinear-response conductances via the fluctuation-dissipation theorem. Thereby,\nwe analyze the performance of a recently derived exchange-correlation potential\nwith time-nonlocal density dependence in the finite-frequency linear-response\nregime. We compare our TDDFT noise spectra with real-time perturbation theory\nand find excellent agreement for noise frequencies below the reservoir\ntemperature.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Users regularly enter sensitive data, such as passwords, credit card numbers,\nor tax information, into the browser window. While modern browsers provide\npowerful client-side privacy measures to protect this data, none of these\ndefenses prevent a browser compromised by malware from stealing it. In this\nwork, we present Fidelius, a new architecture that uses trusted hardware\nenclaves integrated into the browser to enable protection of user secrets\nduring web browsing sessions, even if the entire underlying browser and OS are\nfully controlled by a malicious attacker.\n  Fidelius solves many challenges involved in providing protection for browsers\nin a fully malicious environment, offering support for integrity and privacy\nfor form data, JavaScript execution, XMLHttpRequests, and protected web\nstorage, while minimizing the TCB. Moreover, interactions between the enclave\nand the browser, the keyboard, and the display all require new protocols, each\nwith their own security considerations. Finally, Fidelius takes into account UI\nconsiderations to ensure a consistent and simple interface for both developers\nand users.\n  As part of this project, we develop the first open source system that\nprovides a trusted path from input and output peripherals to a hardware enclave\nwith no reliance on additional hypervisor security assumptions. These\ncomponents may be of independent interest and useful to future projects.\n  We implement and evaluate Fidelius to measure its performance overhead,\nfinding that Fidelius imposes acceptable overhead on page load and user\ninteraction for secured pages and has no impact on pages and page components\nthat do not use its enhanced security features.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Object detection and classification of traffic signs in street-view imagery\nis an essential element for asset management, map making and autonomous\ndriving. However, some traffic signs occur rarely and consequently, they are\ndifficult to recognize automatically. To improve the detection and\nclassification rates, we propose to generate images of traffic signs, which are\nthen used to train a detector/classifier. In this research, we present an\nend-to-end framework that generates a realistic image of a traffic sign from a\ngiven image of a traffic sign and a pictogram of the target class. We propose a\nresidual attention mechanism with dense concatenation called Dense Residual\nAttention, that preserves the background information while transferring the\nobject information. We also propose to utilize multi-scale discriminators, so\nthat the smaller scales of the output guide the higher resolution output. We\nhave performed detection and classification tests across a large number of\ntraffic sign classes, by training the detector using the combination of real\nand generated data. The newly trained model reduces the number of false\npositives by 1.2 - 1.5% at 99% recall in the detection tests and an absolute\nimprovement of 4.65% (top-1 accuracy) in the classification tests.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider control of heterogeneous players repeatedly playing an\nanti-coordination network game. In an anti-coordination game, each player has\nan incentive to differentiate its action from its neighbors. At each round of\nplay, players take actions according to a learning algorithm that mimics the\niterated elimination of strictly dominated strategies. We show that the\nlearning dynamics may fail to reach anti-coordination in certain scenarios. We\nformulate an optimization problem with the objective to reach maximum\nanti-coordination while minimizing the number of players to control. We\nconsider both static and dynamic control policy formulations. Relating the\nproblem to a minimum vertex cover problem on bipartite networks, we develop a\nfeasible dynamic policy that is efficient to compute. Solving for optimal\npolicies on benchmark networks show that the vertex cover based policy can be a\nloose upper bound when there is a potential to make use of cascades caused by\nthe learning dynamics of uncontrolled players. We propose an algorithm that\nfinds feasible, though possibly suboptimal, policies by sequentially adding\nplayers to control considering their cascade potential. Numerical experiments\non random networks show the cascade-based algorithm can lower the control\neffort significantly compared to simpler control schemes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A finite size scaling theory, originally developed only for transitions to\nabsorbing states [Phys. Rev. E {\\bf 92}, 062126 (2015)], is extended to\ndistinct sorts of discontinuous nonequilibrium phase transitions. Expressions\nfor quantities such as, response functions, reduced cumulants and equal area\nprobability distributions, are derived from phenomenological arguments.\nIrrespective of system details, all these quantities scale with the volume,\nestablishing the dependence on size. The approach generality is illustrated\nthrough the analysis of different models. The present results are a relevant\nstep in trying to unify the scaling behavior description of nonequilibrium\ntransition processes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper proposes the use of a non-immersive virtual reality rehabilitation\nsystem ReHabgame developed using Microsoft Kinect and the Thalmic Labs Myo\ngesture control armband. The ReHabgame was developed based on two third-person\nvideo games that provide a feasible possibility of assessing postural control\nand functional reach tests. It accurately quantifies specific postural control\nmechanisms including timed standing balance, functional reach tests using\nreal-time anatomical landmark orientation, joint velocity, and acceleration\nwhile end trajectories were calculated using an inverse kinematics algorithm.\nThe game was designed to help patients with neurological impairment to be\nsubjected to physiotherapy activity and practice postures of daily activities.\nThe subjective experience of the ReHabgame was studied through the development\nof an Engagement Questionnaire (EQ) for qualitative, quantitative and Rasch\nmodel. The Monte-Carlo Tree Search (MCTS) and Random object (ROG) generator\nalgorithms were used to adapt the physical and gameplay intensity in the\nReHabgame based on the Motor Assessment Scale (MAS) and Hierarchical Scoring\nSystem (HSS). Rasch analysis was conducted to assess the psychometric\ncharacteristics of the ReHabgame and to identify if these are any misfitting\nitems in the game. Rasch rating scale model (RSM) was used to assess the\nengagement of players in the ReHabgame and evaluate the effectiveness and\nattractiveness of the game. The results showed that the scales assessing the\nrehabilitation process met Rasch expectations of reliability, and\nunidimensionality. Infit and outfit mean squares values are in the range of\n(0.68 1.52) for all considered 16 items. The Root Mean Square Residual (RMSR)\nand the person separation reliability were acceptable. The item/person map\nshowed that the persons and items were clustered symmetrically.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this article, we first provide a brief overview of optical transmission\nsystems and some of their performance specifications. We then present a simple,\nrobust, and bandwidth-efficient OFDM synchronization method, and carry out\nmeasurements to validate the presented synchronization method with the aid of\nan experimental setup.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Motivated by the recent activities on the Ni-based diamond lattice\nantiferromagnet NiRh$_2$O$_4$, we theoretically explore on a general ground the\nunique spin and orbital physics for the Ni$^{2+}$ ions with a $3d^8$ electron\nconfiguration in the tetrahedral crystal field environment and on a diamond\nlattice Mott insulator. The superexchange interaction between the local moments\nusually favors magnetic orders. Due to the particular electron configuration of\nthe Ni$^{2+}$ ion with a partially filled upper $t_{2g}$ level and a fully\nfilled lower $e_g$ level, the atomic spin-orbit coupling becomes active at the\nlinear order and would favor a spin-orbital-entangled singlet with quenched\nlocal moments in the single-ion limit. Thus, the spin-orbital entanglement\ncompetes with the superexchange and could drive the system to a quantum\ncritical point that separates the spin-orbital singlet and the magnetic order.\nWe further explore the effects of magnetic field and uniaxial pressure. The\nnon-trivial response to the magnetic field is intimately tied to the underlying\nspin-orbital structure of the local moments. We discuss the future experiments\nsuch as doping and pressure, and point out the correspondence between different\nelectron configurations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce a new measure of complexity (called spectral complexity) for\ndirected graphs. We start with splitting of the directed graph into its\nrecurrent and non-recurrent parts. We define the spectral complexity metric in\nterms of the spectrum of the recurrence matrix (associated with the reccurent\npart of the graph) and the Wasserstein distance. We show that the total\ncomplexity of the graph can then be defined in terms of the spectral\ncomplexity, complexities of individual components and edge weights. The\nessential property of the spectral complexity metric is that it accounts for\ndirected cycles in the graph. In engineered and software systems, such cycles\ngive rise to sub-system interdependencies and increase risk for unintended\nconsequences through positive feedback loops, instabilities, and infinite\nexecution loops in software. In addition, we present a structural decomposition\ntechnique that identifies such cycles using a spectral technique. We show that\nthis decomposition complements the well-known spectral decomposition analysis\nbased on the Fiedler vector. We provide several examples of computation of\nspectral and total complexities, including the demonstration that the\ncomplexity increases monotonically with the average degree of a random graph.\nWe also provide an example of spectral complexity computation for the\narchitecture of a realistic fixed wing aircraft system.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We develop and analyze an ultraweak variational formulation for a variant of\nthe Kirchhoff-Love plate bending model. Based on this formulation, we introduce\na discretization of the discontinuous Petrov-Galerkin type with optimal test\nfunctions (DPG). We prove well-posedness of the ultraweak formulation and\nquasi-optimal convergence of the DPG scheme. The variational formulation and\nits analysis require tools that control traces and jumps in $H^2$ (standard\nSobolev space of scalar functions) and $H(\\mathrm{div\\,Div})$ (symmetric tensor\nfunctions with $L_2$-components whose twice iterated divergence is in $L_2$),\nand their dualities. These tools are developed in two and three spatial\ndimensions. One specific result concerns localized traces in a dense subspace\nof $H(\\mathrm{div\\,Div})$. They are essential to construct basis functions for\nan approximation of $H(\\mathrm{div\\,Div})$. To illustrate the theory we\nconstruct basis functions of the lowest order and perform numerical experiments\nfor a smooth and a singular model solution. They confirm the expected\nconvergence behavior of the DPG method both for uniform and adaptively refined\nmeshes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let k be a perfect field of characteristic p>0 and W the ring of Witt vectors\nof k. In this article, we give a new proof of the Frobenius descent for\nconvergent isocrystals on a variety over k relative to W. This proof allows us\nto deduce an analogue of the de Rham complexes comparaison theorem of Berthelot\nwithout assuming a lifting of the Frobenius morphism. As an application, we\nprove a version of Berthelot's conjecture on the preservation of convergent\nisocrystals under the higher direct image by a smooth proper morphism of\nk-varieties.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  For generalized Dyck paths (i.e., directed lattice paths with any finite set\nof jumps), we analyse their local time at zero (i.e., the number of times the\npath is touching or crossing the abscissa). As we are in a discrete setting,\nthe event we analyse here is '' invisible '' to the tools of Brownian motion\ntheory. It is interesting that the key tool for analysing directed lattice\npaths, which is the kernel method, is not directly applicable here. Therefore,\nwe introduce a variant of this kernel method to get the trivariate generating\nfunction (length, final altitude, local time): this leads to an expression\ninvolving symmetric and algebraic functions. We apply this analysis to\ndifferent types of constrained lattice paths (meanders , excursions, bridges,.\n. .). Then, we illustrate this approach on 'basketball walks ' which are walks\ndefined by the jumps --2, --1, 0, +1, +2. We use singularity analysis to prove\nthat the limit laws for the local time are (depending on the drift and the type\nof walk) the geometric distribution, the negative binomial distribution, the\nRayleigh distribution, or the half-normal distribution (a universal\ndistribution up to now rarely encountered in analytic combinatorics).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The halo of the Milky Way has long been hypothesized to harbour significant\namounts of merger debris. This view has been supported over more than a decade\nby wide-field photometric surveys which have revealed the outer halo to be\nlumpy. The recent release of Gaia DR2 is allowing us to establish that mergers\nalso have been important and possibly built up the majority of the inner halo.\nIn this work we focus on the Helmi streams, a group of streams crossing the\nSolar vicinity and known for almost two decades. We characterize their\nproperties and relevance for the build-up of the Milky Way's halo. We identify\nnew members of the Helmi streams in an unprecedented dataset with full\nphase-space information combining Gaia DR2, and the APOGEE DR2, RAVE DR5 and\nLAMOST DR4 spectroscopic surveys. Based on the orbital properties of the stars,\nwe find new stream members up to a distance of 5 kpc from the Sun, which we\ncharacterize using photometry and metallicity information. We also perform\nN-body experiments to constrain the time of accretion and properties of the\nprogenitor of the streams. We find nearly 600 new members of the Helmi streams.\nTheir HR diagram reveals a broad age range, from approximately 11 to 13 Gyr,\nwhile their metallicity distribution goes from $\\sim$ 2.3 to $\\sim$1.0, and\npeaks at [Fe/H] $\\sim$1.5. These findings confirm that the streams originate in\na dwarf galaxy. Furthermore, we find 7 globular clusters to be likely\nassociated, and which follow a well-defined age-metallicity sequence whose\nproperties suggest a relatively massive progenitor object. Our N-body\nsimulations favour a system with a stellar mass of $\\sim\n10^8\\,\\mathrm{M}_\\odot$ accreted $5 - 8$ Gyr ago. The debris from the Helmi\nstreams is an important donor to the MilkyWay halo, contributing approximately\n15\\% of its mass in field stars and 10\\% of its globular clusters.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Self-assembly is the autonomous organization of components into patterns or\nstructures: an essential ingredient of biology and a desired route to complex\norganization. At equilibrium, the structure is encoded through specific\ninteractions, at an unfavorable entropic cost for the system. An alternative\napproach, widely used by Nature, uses energy input to bypass the entropy\nbottleneck and develop features otherwise impossible at equilibrium.\nDissipative building blocks that inject energy locally were made available by\nrecent advance in colloidal science but have not been used to control\nself-assembly. Here we show the robust formation of self-powered rotors and\ndynamical superstructures from active particles and harness non-equilibrium\nphoretic phenomena to tailor interactions and direct self-assembly. We use a\nphotoactive component that consumes fuel, hematite, to devise phototactic\nmicroswimmers that form self-spinning microgears following spatiotemporal light\npatterns. The gears are coupled via their chemical clouds and constitute the\nelementary bricks of synchronized superstructures, which autonomously regulate\ntheir dynamics. The results are quantitatively rationalized on the basis of a\nstochastic description of diffusio-phoretic oscillators dynamically coupled by\nchemical gradients to form directional interactions. Our findings demonstrate\nthat non-equilibrium phenomena can be harnessed to shape interactions and\nprogram hierarchical constructions. It lays the groundwork for the\nself-assembly of dynamical architectures and synchronized micro-machinery.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We employ matrix-product state techniques to numerically study the\nzero-temperature spin transport in a finite spin-1/2 XXZ chain coupled to\nfermionic leads with a spin bias voltage. Current-voltage characteristics are\ncalculated for parameters corresponding to the gapless XY phase and the gapped\nN\\'eel phase. In both cases, the low-bias spin current is strongly suppressed\nunless the parameters of the model are fine-tuned. For the XY phase, this\ncorresponds to a conducting fixed point where the conductance agrees with the\nLuttinger-liquid prediction. In the N\\'eel phase, fine-tuning the parameters\nsimilarly leads to an unsuppressed spin current with a linear current-voltage\ncharacteristic at low bias voltages. However, with increasing the bias voltage,\nthere occurs a sharp crossover to a region where a current-voltage\ncharacteristic is no longer linear and the smaller differential conductance is\nobserved. We furthermore show that the parameters maximizing the spin current\nminimize the Friedel oscillations at the interface, in agreement with the\nprevious analyses of the charge current for inhomogeneous Hubbard and spinless\nfermion chains.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  No-scale supergravity is the appropriate general framework for low-energy\neffective field theories derived from string theory. The simplest no-scale\nK\\\"ahler potential with a single chiral field corresponds to a compactification\nto flat Minkowski space with a single volume modulus, but generalizations to\nsingle-field no-scale models with de Sitter vacua are also known. In this paper\nwe generalize these de Sitter constructions to two- and multi-field models of\nthe types occurring in string compactifications with more than one relevant\nmodulus. We discuss the conditions for stability of the de Sitter solutions and\nholomorphy of the superpotential, and give examples whose superpotential\ncontains only integer powers of the chiral fields.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we present an integrated system for automatically generating\nand editing face images through face swapping, attribute-based editing, and\nrandom face parts synthesis. The proposed system is based on a deep neural\nnetwork that variationally learns the face and hair regions with large-scale\nface image datasets. Different from conventional variational methods, the\nproposed network represents the latent spaces individually for faces and hairs.\nWe refer to the proposed network as region-separative generative adversarial\nnetwork (RSGAN). The proposed network independently handles face and hair\nappearances in the latent spaces, and then, face swapping is achieved by\nreplacing the latent-space representations of the faces, and reconstruct the\nentire face image with them. This approach in the latent space robustly\nperforms face swapping even for images which the previous methods result in\nfailure due to inappropriate fitting or the 3D morphable models. In addition,\nthe proposed system can further edit face-swapped images with the same network\nby manipulating visual attributes or by composing them with randomly generated\nface or hair parts.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In the local Universe, the existence of very young galaxies (VYGs), having\nformed at least half their stellar mass in the last 1 Gyr, is debated. We\npredict the present-day fraction of VYGs among central galaxies as a function\nof galaxy stellar mass. For this, we apply to high mass resolution Monte-Carlo\nhalo merger trees (MCHMTs) three (one) analytical models of galaxy formation,\nwhere the ratio of stellar to halo mass (mass growth rate) is a function of\nhalo mass and redshift. Galaxy merging is delayed until orbital decay by\ndynamical friction. With starbursts associated with halo mergers, our models\npredict typically one percent of VYGs up to galaxy masses of $10^{10}$\nM$_\\odot$, falling rapidly at higher masses, and VYGs are usually associated\nwith recent major mergers of their haloes. Without these starbursts, two of the\nmodels have VYG fractions reduced by 1 or 2 dex at low or intermediate stellar\nmasses, and VYGs are rarely associated with major halo mergers. In comparison,\nthe state-of-the-art semi-analytical model (SAM) of Henriques et al. produces\nonly 0.01% of VYGs at intermediate masses. Finally, the Menci et al. SAM run on\nMCMHTs with Warm Dark Matter cosmology generates 10 times more VYGs at masses\nbelow $10^8$ M$_\\odot$ than when run with Cold Dark Matter. The wide range in\nthese VYG fractions illustrates the usefulness of VYGs to constrain both galaxy\nformation and cosmological models.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Spectral methods based on integral transforms may be efficiently used to\nsolve differential equations in some special cases. This paper considers a\ndifferent approach in which algorithms are proposed to calculate integral\nLaguerre transform by solving a one-dimensional transport equation. In contrast\nto the direct calculation of improper integrals of rapidly oscillating\nfunctions, these procedures make it possible to calculate the expansion\ncoefficients of a Laguerre series expansion with better stability, higher\naccuracy, and less computational burden.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Spin Asymmetries of the Nucleon Experiment (SANE) measured two double\nspin asymmetries using a polarized proton target and polarized electron beam at\ntwo beam energies, 4.7 GeV and 5.9 GeV. A large-acceptance open-configuration\ndetector package identified scattered electrons at 40$^{\\circ}$ and covered a\nwide range in Bjorken $x$ ($0.3 < x < 0.8$). Proportional to an average color\nLorentz force, the twist-3 matrix element, $\\tilde{d}_2^p$, was extracted from\nthe measured asymmetries at $Q^2$ values ranging from 2.0 to 6.0 GeV$^2$. The\ndata display the opposite sign compared to most quark models, including the\nlattice QCD result, and an apparently unexpected scale dependence. Furthermore\nwhen combined with the neutron data in the same $Q^2$ range the results suggest\na flavor independent average color Lorentz force.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Accurate detection and tracking of objects is vital for effective video\nunderstanding. In previous work, the two tasks have been combined in a way that\ntracking is based heavily on detection, but the detection benefits marginally\nfrom the tracking. To increase synergy, we propose to more tightly integrate\nthe tasks by conditioning the object detection in the current frame on\ntracklets computed in prior frames. With this approach, the object detection\nresults not only have high detection responses, but also improved coherence\nwith the existing tracklets. This greater coherence leads to estimated object\ntrajectories that are smoother and more stable than the jittered paths obtained\nwithout tracklet-conditioned detection. Over extensive experiments, this\napproach is shown to achieve state-of-the-art performance in terms of both\ndetection and tracking accuracy, as well as noticeable improvements in tracking\nstability.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Test suite reduction (TSR) aims at removing redundant test cases from\nregression test suites. A typical TSR approach ensures that structural profile\nelements covered by the original test suite are also covered by the reduced\ntest suite. It is plausible that structural profiles might be unable to\nsegregate failing runs from passing runs, which diminishes the effectiveness of\nTSR in regard to defect detection. This motivated us to explore state profiles,\nwhich are based on the collective values of program variables. This paper\npresents Substate Profiling, a new form of state profiling that enhances\nexisting profile-based analysis techniques such as TSR and coverage-based fault\nlocalization. Compared to current approaches for capturing program states,\nSubstate Profiling is more practical and finer grained. We evaluated our\napproach using thirteen multi-fault subject programs comprising 53 defects. Our\nstudy involved greedy TSR using Substate profiles and four structural profiles,\nnamely, basic-block, branch, def-use pair, and the combination of the three.\nFor the majority of the subjects, Substate Profiling detected considerably more\ndefects with a comparable level of reduction. Also, Substate profiles were\nfound to be complementary to structural profiles in many cases, thus, combining\nboth types is beneficial.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the problem of distribution testing when the samples can only be\naccessed using a locally differentially private mechanism and focus on two\nrepresentative testing questions of identity (goodness-of-fit) and independence\ntesting for discrete distributions. We are concerned with two settings: First,\nwhen we insist on using an already deployed, general-purpose locally\ndifferentially private mechanism such as the popular RAPPOR or the recently\nintroduced Hadamard Response for collecting data, and must build our tests\nbased on the data collected via this mechanism; and second, when no such\nrestriction is imposed, and we can design a bespoke mechanism specifically for\ntesting. For the latter purpose, we introduce the Randomized Aggregated Private\nTesting Optimal Response (RAPTOR) mechanism which is remarkably simple and\nrequires only one bit of communication per sample.\n  We propose tests based on these mechanisms and analyze their sample\ncomplexities. Each proposed test can be implemented efficiently. In each case\n(barring one), we complement our performance bounds for algorithms with\ninformation-theoretic lower bounds and establish sample optimality of our\nproposed algorithm. A peculiar feature that emerges is that our sample-optimal\nalgorithm based on RAPTOR uses public-coins, and any test based on RAPPOR or\nHadamard Response, which are both private-coin mechanisms, requires\nsignificantly more samples.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $\\mathscr{C}$ be a category with an involution $\\ast$. Suppose that\n$\\varphi : X \\rightarrow X$ is a morphism and $(\\varphi_1, Z, \\varphi_2)$ is an\n(epic, monic) factorization of $\\varphi$ through $Z$, then $\\varphi$ is core\ninvertible if and only if $(\\varphi^{\\ast})^2\\varphi_1$ and\n$\\varphi_2\\varphi_1$ are both left invertible if and only if\n$((\\varphi^{\\ast})^2\\varphi_1, Z, \\varphi_2)$, $(\\varphi_2^{\\ast}, Z,\n\\varphi_1^{\\ast}\\varphi^{\\ast}\\varphi)$ and $(\\varphi^{\\ast}\\varphi_2^{\\ast},\nZ, \\varphi_1^{\\ast}\\varphi)$ are all essentially unique (epic, monic)\nfactorizations of $(\\varphi^{\\ast})^2\\varphi$ through $Z$. We also give the\ncorresponding result about dual core inverse. In addition, we give some\ncharacterizations about the coexistence of core inverse and dual core inverse\nof an $R$-morphism in the category of $R$-modules of a given ring $R$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Group Activity Selection Problem (GASP) models situations where a group\nof agents needs to be distributed to a set of activities while taking into\naccount preferences of the agents w.r.t. individual activities and activity\nsizes. The problem, along with its two previously proposed variants sGASP and\ngGASP, has been studied in the parameterized complexity setting with various\nparameterizations, such as number of agents, number of activities and solution\nsize. However, the complexity of the problem parameterized by the number of\ntypes of agents, a parameter motivated and proposed already in the paper that\nintroduced GASP, has so far remained open.\n  In this paper we establish the complexity map for GASP, sGASP and gGASP when\nthe number of types of agents is the parameter. Our positive results,\nconsisting of one fixed-parameter algorithm and one XP algorithm, rely on a\ncombination of novel Subset Sum machinery (which may be of general interest)\nand identifying certain compression steps which allow us to focus on solutions\nwhich are \"acyclic\". These algorithms are complemented by matching lower\nbounds, which among others answer an open question of Gupta, Roy, Saurabh and\nZehavi (2017). In this direction, the techniques used to establish\nW[1]-hardness of sGASP are of particular interest: as an intermediate step, we\nuse Sidon sequences to show the W[1]-hardness of a highly restricted variant of\nmulti-dimensional Subset Sum, which may find applications in other settings as\nwell.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In our previous work, we propose a cross spectrum based method to extract\nsingle pulse signals from RFI contaminated data, which is originated from\ngeodetic VLBI postprocessing. This method fully utilizes fringe phase\ninformation of the cross spectrum and hence maximizes signal power, however the\nlocalization was not discussed in that work yet. As the continuation of that\nwork, in this paper, we further study how to localize single pulses using\nastrometric solving method. Assuming that the burst is a point source, we\nderive the burst position by solving a set of linear equations given the\nrelation between residual delay and offset to a priori position. We find that\nthe single pulse localization results given by both astrometric solving and\nradio imaging are consistent within 3 sigma level. Therefore we claim that it\nis possible to derive the position of a single pulse with reasonable precision\nbased on only 3 or even 2 baselines with 4 milliseconds integration. The\ncombination of cross spectrum based detection and the localization proposed in\nthis work then provide a thorough solution for searching single pulse in VLBI\nobservation. According to our calculation, our pipeline gives comparable\naccuracy as radio imaging pipeline. Moreover, the computational cost of our\npipeline is much smaller, which makes it more practical for FRB search in\nregular VLBI observation. The pipeline is now publicly available and we name it\nas \"VOLKS\", which is the acronym of \"VLBI Observation for frb Localization Keen\nSearcher\".\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This note studies perverse sheaves of categories, or schobers, on Riemann\nsurfaces, following ideas of Kapranov and Schechtman. For certain wall\ncrossings in geometric invariant theory, I construct a schober on the complex\nplane, singular at each imaginary integer. I use this to obtain schobers for\nstandard flops: in the 3-fold case, I relate these to a further schober on a\npartial compactification of a stringy Kaehler moduli space, and suggest an\napplication to mirror symmetry.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this work we present spectral algorithms for the numerical scattering for\nthe defocusing Davey-Stewartson (DS) II equation with initial data having\ncompact support on a disk, i.e., for the solution of d-bar problems. Our\nalgorithms use polar coordinates and implement a Chebychev spectral scheme for\nthe radial dependence and a Fourier spectral method for the azimuthal\ndependence. The focus is placed on the construction of complex geometric optics\n(CGO) solutions which are needed in the scattering approach for DS. We discuss\ntwo different approaches: The first constructs a fundamental solution to the\nd-bar system and applies the CGO conditions on the latter. This is especially\nefficient for small values of the modulus of the spectral parameter $k$. The\nsecond approach uses a fixed point iteration on a reformulated d-bar system\ncontaining the spectral parameter explicitly, a price paid to have simpler\nasymptotics. The approaches are illustrated for the example of the\ncharacteristic function of the disk and are shown to exhibit spectral\nconvergence, i.e., an exponential decay of the numerical error with the number\nof collocation points. An asymptotic formula for large $|k|$ is given for the\nreflection coefficient.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Computer vision is difficult, partly because the desired mathematical\nfunction connecting input and output data is often complex, fuzzy and thus hard\nto learn. Coarse-to-fine (C2F) learning is a promising direction, but it\nremains unclear how it is applied to a wide range of vision problems.\n  This paper presents a generalized C2F framework by making two technical\ncontributions. First, we provide a unified way of C2F propagation, in which the\ncoarse prediction (a class vector, a detected box, a segmentation mask, etc.)\nis encoded into a dense (pixel-level) matrix and concatenated to the original\ninput, so that the fine model takes the same design of the coarse model but\nsees additional information. Second, we present a progressive training strategy\nwhich starts with feeding the ground-truth instead of the coarse output into\nthe fine model, and gradually increases the fraction of coarse output, so that\nat the end of training the fine model is ready for testing. We also relate our\napproach to curriculum learning by showing that data difficulty keeps\nincreasing during the training process. We apply our framework to three vision\ntasks including image classification, object localization and semantic\nsegmentation, and demonstrate consistent accuracy gain compared to the baseline\ntraining strategy.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Binary data matrices can represent many types of data such as social\nnetworks, votes, or gene expression. In some cases, the analysis of binary\nmatrices can be tackled with nonnegative matrix factorization (NMF), where the\nobserved data matrix is approximated by the product of two smaller nonnegative\nmatrices. In this context, probabilistic NMF assumes a generative model where\nthe data is usually Bernoulli-distributed. Often, a link function is used to\nmap the factorization to the $[0,1]$ range, ensuring a valid Bernoulli mean\nparameter. However, link functions have the potential disadvantage to lead to\nuninterpretable models. Mean-parameterized NMF, on the contrary, overcomes this\nproblem. We propose a unified framework for Bayesian mean-parameterized\nnonnegative binary matrix factorization models (NBMF). We analyze three models\nwhich correspond to three possible constraints that respect the\nmean-parametrization without the need for link functions. Furthermore, we\nderive a novel collapsed Gibbs sampler and a collapsed variational algorithm to\ninfer the posterior distribution of the factors. Next, we extend the proposed\nmodels to a nonparametric setting where the number of used latent dimensions is\nautomatically driven by the observed data. We analyze the performance of our\nNBMF methods in multiple datasets for different tasks such as dictionary\nlearning and prediction of missing data. Experiments show that our methods\nprovide similar or superior results than the state of the art, while\nautomatically detecting the number of relevant components.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We investigate the formation and stability of the skyrmion crystal phase in\nantiferromagnetic thin films subjected to fieldlike torques such as, e.g.,\nthose induced by an electric current in CuMnAs and Mn$_{2}$Au via the inverse\nspin-galvanic effect. We show that the skyrmion lattice represents the ground\nstate of the antiferromagnet in a substantial area of the phase diagram,\nparametrized by the staggered field and the (effective) uniaxial anisotropy\nconstant. Skyrmion motion can be driven in the crystal phase by the spin\ntransfer effect. In the metallic scenario, itinerant electrons experience an\nemergent SU$(2)$-electromagnetic field associated with the (N\\'{e}el) skyrmion\nbackground, leading to a topological spin-Hall response. Experimental\nsignatures of the skyrmion crystal phase and readout schemes based on\ntopological transport are discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Online social dynamics based on human endeavours exhibit prominent complexity\nin the emergence of new features embodied in the appearance of collective\nsocial values. The vast amount of empirical data collected at various websites\nprovides a unique opportunity to quantitative study od the underlying social\ndynamics in full analogy with complex systems in the physics laboratory. Here,\nwe briefly describe the extent of these analogies and indicate the methods from\nother science disciplines that the physics theory can incorporate to provide\nthe adequate description of human entities and principles of their\nself-organisation. We demonstrate the approach on two examples using the\nempirical data regarding the knowledge creation processes in online chats and\nquestions-and-answers. Precisely, we describe the self-organised criticality as\nthe acting mechanisms in the social knowledge-sharing dynamics and demonstrate\nthe emergence of the hyperbolic geometry of the co-evolving networks that\nunderlie these stochastic processes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The bulk piezoelectric response, as measured by the piezoelectric modulus\ntensor (\\textbf{d}), is determined by a combination of charge redistribution\ndue to strain and the amount of strain produced by the application of stress\n(stiffness). Motivated by the notion that less stiff materials could exhibit\nlarge piezoelectric responses, herein we investigate the piezoelectric modulus\nof van der Waals-bonded quasi-2D ionic compounds using first-principles\ncalculations. From a pool of 869 known binary and ternary quasi-2D materials,\nwe have identified 135 non-centrosymmetric crystals of which 48 systems are\nfound to have \\textbf{d} components larger than the longitudinal piezoelectric\nmodulus of AlN (a common piezoelectric for resonators), and three systems with\nthe response greater than that of PbTiO$_3$, which is among the materials with\nlargest known piezoelectric modulus. None of the identified materials have\npreviously been considered for piezoelectric applications. Furthermore, we find\nthat large \\textbf{d} components always couple to the deformations (shearing or\naxial) of van der Waals \"gaps\" between the layers and are indeed enabled by the\nweak intra-layer interactions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we show that certain generalizations of the $C^r$-Whitney\ntopology, which include the H\\\"older-Whitney and Sobolev-Whitney topologies on\nsmooth manifolds, satisfy the Baire property, to wit, the countable\nintersection of open and dense sets is dense.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Computer vision technologies are very attractive for practical applications\nrunning on embedded systems. For such an application, it is desirable for the\ndeployed algorithms to run in high-speed and require no offline training. To\ndevelop a single-target tracking algorithm with these properties, we propose an\nensemble of the kernelized correlation filters (KCF), we call it EnKCF. A\ncommittee of KCFs is specifically designed to address the variations in scale\nand translation of moving objects. To guarantee a high-speed run-time\nperformance, we deploy each of KCFs in turn, instead of applying multiple KCFs\nto each frame. To minimize any potential drifts between individual KCFs\ntransition, we developed a particle filter. Experimental results showed that\nthe performance of ours is, on average, 70.10% for precision at 20 pixels,\n53.00% for success rate for the OTB100 data, and 54.50% and 40.2% for the\nUAV123 data. Experimental results showed that our method is better than other\nhigh-speed trackers over 5% on precision on 20 pixels and 10-20% on AUC on\naverage. Moreover, our implementation ran at 340 fps for the OTB100 and at 416\nfps for the UAV123 dataset that is faster than DCF (292 fps) for the OTB100 and\nKCF (292 fps) for the UAV123. To increase flexibility of the proposed EnKCF\nrunning on various platforms, we also explored different levels of deep\nconvolutional features.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Agile methods are receiving a growing interest from industry and these\napproaches are nowadays well accepted and deployed in software engineering.\nHowever, some issues remain to introduce agility in systems engineering. The\nobjective of this paper is to show an agile management implementation in an\neducational project consisting in developing a connected mobile robot, and to\nevaluate the issues and benefits of adopting an agile approach. Among the most\nfamous agile management methods, SCRUM has been chosen to lead this experiment.\nThis paper first presents the project and how students traditionally manage it,\nthen it describes how Scrum could be used instead. It evaluates the\ndifficulties and interests to introduce agility in this project, and concludes\non the ability of Scrum to design, test and progressively integrate the system,\nthus providing an operational prototype more quickly.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The efficiency to identify jets containing $b$-hadrons ($b$-jets) is measured\nusing a high purity sample of dileptonic top quark-antiquark pairs ($t\\bar{t}$)\nselected from the 36.1 fb$^{-1}$ of data collected by the ATLAS detector in\n2015 and 2016 from proton-proton collisions produced by the Large Hadron\nCollider at a centre-of-mass energy $\\sqrt{s}=13$ TeV. Two methods are used to\nextract the efficiency from $t\\bar{t}$ events, a combinatorial likelihood\napproach and a tag-and-probe method. A boosted decision tree, not using\n$b$-tagging information, is used to select events in which two $b$-jets are\npresent, which reduces the dominant uncertainty in the modelling of the flavour\nof the jets. The efficiency is extracted for jets in a transverse momentum\nrange from 20 to 300 GeV, with data-to-simulation scale factors calculated by\ncomparing the efficiency measured using collision data to that predicted by the\nsimulation. The two methods give compatible results, and achieve a similar\nlevel of precision, measuring data-to-simulation scale factors close to unity\nwith uncertainties ranging from 2% to 12% depending on the jet transverse\nmomentum.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Supernova Remnants and Pulsar Wind Nebulae are among the most significant\nsources of non-thermal X-rays in the sky, and the closest laboratories where\nrelativistic plasma dynamics and particle acceleration can be investigated.\nBeing strong synchrotron emitters, they are ideal candidates for X-ray\npolarimetry, and indeed the Crab nebula is up to present the only object where\nX-ray polarization has been detected with a high level of significance. Future\npolarimetric measures will likely provide us crucial informations on the level\nof turbulence that is expected at the particle acceleration sites, together\nwith the spacial and temporal coherence of the magnetic field geometry,\nenabling us to set stronger constraints on our acceleration models. In PWNe it\nwill also allow us to estimate the level of internal dissipation. I will\nbriefly review the current knowledge on the polarization signatures in SNR/PWNe\nand I will illustrate what can we hope to achieve with future missions like\nIXPE/XIPE.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We have seen a massive growth of online experiments at LinkedIn, and in\nindustry at large. It is now more important than ever to create an intelligent\nA/B platform that can truly democratize A/B testing by allowing everyone to\nmake quality decisions, regardless of their skillset. With the tremendous\nknowledge base created around experimentation, we are able to mine through\nhistorical data, and discover the most common causes for biased experiments. In\nthis paper, we share four of such common causes, and how we build into our A/B\ntesting platform the automatic detection and diagnosis of such root causes.\nThese root causes range from design-imposed bias, self-selection bias, novelty\neffect and trigger-day effect. We will discuss in detail what each bias is and\nthe scalable algorithm we developed to detect the bias. Surfacing up the\nexistence and root cause of bias automatically for every experiment is an\nimportant milestone towards intelligent A/B testing.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We develop new constructions of 2D classical and quantum superintegrable\nHamiltonians allowing separation of variables in Cartesian coordinates. In\nclassical mechanics we start from two functions on a one-dimensional phase\nspace, a natural Hamiltonian $H$ and a polynomial of order $N$ in the momentum\n$p.$ We assume that their Poisson commutator $\\{H,K\\}$ vanishes, is a constant,\na constant times $H$, or a constant times $K$. In the quantum case $H$ and $K$\nare operators and their Lie commutator has one of the above properties. We use\ntwo copies of such $(H,K)$ pairs to generate two-dimensional superintegrable\nsystems in the Euclidean space $E_2$, allowing the separation of variables in\nCartesian coordinates. All known separable superintegrable systems in $E_2$ can\nbe obtained in this manner and we obtain new ones for $N=4.$\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In many applications, one is faced with an inverse problem, where the known\nsignal depends in a bilinear way on two unknown input vectors. Often at least\none of the input vectors is assumed to be sparse, i.e., to have only few\nnon-zero entries. Sparse Power Factorization (SPF), proposed by Lee, Wu, and\nBresler, aims to tackle this problem. They have established recovery guarantees\nfor a somewhat restrictive class of signals under the assumption that the\nmeasurements are random. We generalize these recovery guarantees to a\nsignificantly enlarged and more realistic signal class at the expense of a\nmoderately increased number of measurements.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Hyperspectral satellite imaging attracts enormous research attention in the\nremote sensing community, hence automated approaches for precise segmentation\nof such imagery are being rapidly developed. In this letter, we share our\nobservations on the strategy for validating hyperspectral image segmentation\nalgorithms currently followed in the literature, and show that it can lead to\nover-optimistic experimental insights. We introduce a new routine for\ngenerating segmentation benchmarks, and use it to elaborate ready-to-use\nhyperspectral training-test data partitions. They can be utilized for fair\nvalidation of new and existing algorithms without any training-test data\nleakage.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Taking into account the interplay between the disorder and Coulomb\ninteraction, the phase diagram of three-dimensional anisotropic Weyl semimetal\nis studied by renormalization group theory. Weak disorder is irrelevant in\nanisotropic Weyl semimetal, while the disorder becomes relevant and drives a\nquantum phase transition from semimetal to compressible diffusive metal phases\nif the disorder strength is larger than a critical value. The long-range\nCoulomb interaction is irrelevant in clean anisotropic Weyl semimetal. However,\ninterestingly, we find that the long-range Coulomb interaction exerts a\ndramatic influence on the critical disorder strength for phase transition to\ncompressible diffusive metal. Specifically, the critical disorder strength can\nreceive a prominent change even though an arbitrarily weak Coulomb interaction\nis included. This novel behavior is closely related to the anisotropic\nscreening effect of Coulomb interaction,and essentially results from the\nspecifical energy dispersion of the fermion excitations in anisotropic Weyl\nsemimetal. The theoretical results are helpful for understanding the physical\nproperties of the candidates of anisotropic Weyl semimetal, such as pressured\nBiTeI, and some other related materials.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $G$ be a $p$-group and let $\\chi$ be an irreducible character of $G$. The\ncodegree of $\\chi$ is given by $|G:\\text{ker}(\\chi)|/\\chi(1)$. This paper\ninvestigates the relationship between the nilpotence class of a group and the\ninclusion of $p^2$ as a codegree. If $G$ is a finite $p$-group with coclass $2$\nand order at least $p^5$, or coclass $3$ and order at least $p^6$, then $G$ has\n$p^2$ as a codegree. With an additional hypothesis this result can be extended\nto $p$-groups with coclass $n\\ge 3$ and order at least $p^{2n}$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Strong gravitational lensing has been identified as a promising astrophysical\nprobe to study the particle nature of dark matter. In this paper we present a\ndetailed study of the power spectrum of the projected mass density\n(convergence) field of substructure in a Milky Way-sized halo. This power\nspectrum has been suggested as a key observable that can be extracted from\nstrongly lensed images and yield important clues about the matter distribution\nwithin the lens galaxy. We use two different $N$-body simulations from the\nETHOS framework: one with cold dark matter and another with self-interacting\ndark matter and a cutoff in the initial power spectrum. Despite earlier works\nthat identified $ k \\gtrsim 100$ kpc$^{-1}$ as the most promising scales to\nlearn about the particle nature of dark matter we find that even at lower\nwavenumbers - which are actually within reach of observations in the near\nfuture - we can gain important information about dark matter. Comparing the\namplitude and slope of the power spectrum on scales $0.1 \\lesssim k/$kpc$^{-1}\n\\lesssim 10$ from lenses at different redshifts can help us distinguish between\ncold dark matter and other exotic dark matter scenarios that alter the\nabundance and central densities of subhalos. Furthermore, by considering the\ncontribution of different mass bins to the power spectrum we find that subhalos\nin the mass range $10^7 - 10^8$ M$_{\\odot}$ are on average the largest\ncontributors to the power spectrum signal on scales $2 \\lesssim k/$kpc$^{-1}\n\\lesssim 15$, despite the numerous subhalos with masses $> 10^8$ M$_{\\odot}$ in\na typical lens galaxy. Finally, by comparing the power spectra obtained from\nthe subhalo catalogs to those from the particle data in the simulation\nsnapshots we find that the seemingly-too-simple halo model is in fact a fairly\ngood approximation to the much more complex array of substructure in the lens.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper presents a wavelet representation using baseband signals, by\nexploiting Kotel'nikov results. Details of how to obtain the processes of\nenvelope and phase at low frequency are shown. The archetypal interpretation of\nwavelets as an analysis with a filter bank of constant quality factor is\nrevisited on these bases. It is shown that if the wavelet spectral support is\nlimited into the band $[f_m,f_M]$, then an orthogonal analysis is guaranteed\nprovided that $f_M \\leq 3f_m$, a quite simple result, but that invokes some\nparallel with the Nyquist rate. Nevertheless, in cases of orthogonal wavelets\nwhose spectrum does not verify this condition, it is shown how to construct an\n\"equivalent\" filter bank with no spectral overlapping.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Let $G$ be a linearly reductive group acting on a vector space $V$, and $f$ a\n(semi-)invariant polynomial on $V$. In this paper we study systematically\ndecompositions of the Bernstein-Sato polynomial of $f$ in parallel with some\nrepresentation-theoretic properties of the action of $G$ on $V$. We provide a\ntechnique based on a multiplicity one property, that we use to compute the\nBernstein-Sato polynomials of several classical invariants in an elementary\nfashion. Furthermore, we derive a \"slice method\" which shows that the\ndecomposition of $V$ as a representation of $G$ can induce a decomposition of\nthe Bernstein-Sato polynomial of $f$ into a product of two Bernstein-Sato\npolynomials - that of an ideal and that of a semi-invariant of smaller degree.\nUsing the slice method, we compute Bernstein-Sato polynomials for a large class\nof semi-invariants of quivers.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Using density-functional theory calculations, the atomic and electronic\nstructure of single-layer WS_2 attached to Zr and Co contacts are determined.\nBoth metals form stable interfaces that are promising as contacts for injection\nof n-type carriers into the conduction band of WS_2 with Schottky barriers of\n0.45eV and 0.62eV for Zr and Co, respectively. With the help of quantum\ntransport calculations, we address the conductive properties of a free-standing\nWS_2 sheet suspended between two Zr contacts. It is found that such a device\nbehaves like a diode with steep I-V characteristics. Spin-polarized transport\nis calculated for such a device with a floating-gate Co electrode added.\nDepending on the geometrical shape of the Co gate and the energy of the\ncarriers in WS_2, the transmission of spin majority and minority electrons may\ndiffer by up to an order of magnitude. Thus the steep I-V characteristics of\nthe nanoscale device makes it possible to realize a spin filter.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Markovian master equations, often called Liouvillians or Lindbladians, are\nused to describe decay and decoherence of a quantum system induced by that\nsystem's environment. While a natural environment is detrimental to fragile\nquantum properties, an engineered environment can drive the system toward\nexotic phases of matter or toward subspaces protected from noise. These cases\noften require the Lindbladian to have more than one steady state, and such\nLindbladians are dissipative analogues of Hamiltonians with multiple ground\nstates. This thesis studies Lindbladian extensions of topics commonplace in\ndegenerate Hamiltonian systems, providing examples and historical context along\nthe way.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  To minimize data movement, state-of-the-art parallel sorting algorithms use\ntechniques based on sampling and histogramming to partition keys prior to\nredistribution. Sampling enables partitioning to be done using a representative\nsubset of the keys, while histogramming enables evaluation and iterative\nimprovement of a given partition. We introduce Histogram sort with sampling\n(HSS), which combines sampling and iterative histogramming to find high quality\npartitions with minimal data movement and high practical performance. Compared\nto the best known (recently introduced) algorithm for finding these partitions,\nour algorithm requires a factor of {\\Theta}(log(p)/ log log(p)) less\ncommunication, and substantially less when compared to standard variants of\nSample sort and Histogram sort. We provide a distributed memory implementation\nof the proposed algorithm, compare its performance to two existing\nimplementations, and provide a brief application study showing benefit of the\nnew algorithm.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This is the era of smart devices or things which are fueling the growth of\nInternet of Things (IoT). It is impacting every sphere around us, making our\nlife dependent on this technological feat. It is of high concern that these\nsmart things are being targeted by cyber criminals taking advantage of\nheterogeneity, minuscule security features and vulnerabilities within these\ndevices. Conventional centralized IT security measures have limitations in\nterms of scalability and cost. Therefore, these smart devices are required to\nbe monitored closer to their location ideally at the edge of IoT networks. In\nthis paper, we explore how some security features can be implemented at the\nnetwork edge to secure these smart devices. We explain the importance of\nNetwork Function Virtualization (NFV) in order to deploy security functions at\nthe network edge. To achieve this goal, we introduce NETRA - a novel\nlightweight Docker-based architecture for virtualizing network functions to\nprovide IoT security. Also, we highlight the advantages of the proposed\narchitecture over the standardized NFV architecture in terms of storage, memory\nusage, latency, throughput, load average, scalability and explain why the\nstandardized architecture is not suitable for IoT. We study the performance of\nproposed NFV based edge analysis for IoT security and show that attacks can be\ndetected with more than 95% accuracy in less than a second.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Thermosensitive microgels are widely studied hybrid systems combining\nproperties of polymers and colloidal particles in a unique way. Due to their\ncomplex morphology their interactions and packing, and consequentially the\nviscoelastcity of suspensions made from microgels, are still not fully\nunderstood, in particular under dense packing conditions. Here we study the\nfrequency-dependent linear viscoelastic properties of dense microgel\nsuspensions in conjunction with an analysis of the local particle structure and\nmorphology based on superresolution microscopy. By identifying the dominating\nmechanisms that control the elastic and dissipative response, we propose a\nunified framework that can explain the rheology of these widely studied soft\nparticle assemblies from the onset of elasticity deep into the overpacked\nregime. Our results clarify the transition and coupling between the regime\ndominated by fuzzy shell interactions and the one controlled by the densely\ncross-linked core.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Visually-aware recommender systems use visual signals present in the\nunderlying data to model the visual characteristics of items and users'\npreferences towards them. In the domain of clothing recommendation,\nincorporating items' visual information (e.g., product images) is particularly\nimportant since clothing item appearance is often a critical factor in\ninfluencing the user's purchasing decisions. Current state-of-the-art\nvisually-aware recommender systems utilize image features extracted from\npre-trained deep convolutional neural networks, however these extremely\nhigh-dimensional representations are difficult to interpret, especially in\nrelation to the relatively low number of visual properties that may guide\nusers' decisions.\n  In this paper we propose a novel approach to personalized clothing\nrecommendation that models the dynamics of individual users' visual\npreferences. By using interpretable image representations generated with a\nunique feature learning process, our model learns to explain users' prior\nfeedback in terms of their affinity towards specific visual attributes and\nstyles. Our approach achieves state-of-the-art performance on personalized\nranking tasks, and the incorporation of interpretable visual features allows\nfor powerful model introspection, which we demonstrate by using an interactive\nrecommendation algorithm and visualizing the rise and fall of fashion trends\nover time.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The 2-block intersection graph (2-BIG) of a twofold triple system (TTS) is\nthe graph whose vertex set is composed of the blocks of the TTS and two\nvertices are joined by an edge if the corresponding blocks intersect in exactly\ntwo elements. The 2-BIGs are themselves interesting graphs: each component is\ncubic and 3-connected, and a 2-BIG is bipartite exactly when the TTS is\ndecomposable to two Steiner triple systems. Any connected bipartite 2-BIG with\nno Hamilton cycle is a counter-example to a conjecture posed by Tutte in 1971.\nOur main result is that there exists an integer $N$ such that for all $v\\geq\nN$, if $v\\equiv 1$ or $3\\mod{6}$ then there exists a TTS($v$) whose 2-BIG is\nbipartite and connected but not Hamiltonian. Furthermore, $13<N\\leq 663$. Our\napproach is to construct a TTS($u$) whose 2-BIG is connected bipartite and\nnon-Hamiltonian and embed it within a TTS($v$) where $v>2u$ in such a way that,\nafter a single trade, the 2-BIG of the resulting TTS($v$) is bipartite\nconnected and non-Hamiltonian.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Cross-layer analysis has been gaining an increasing attention as a powerful\ntool to study and assess different quality-of-service (QoS) mechanisms in\nwireless networks. Regarding the physical and data-link layers, in this paper\nwe provide a cross-layer study for visible light communication (VLC) systems\noperating under statistical QoS constraints, which are inflicted as limits on\nthe delay violation and buffer overflow probabilities. We assume that the VLC\naccess point (AP) is unaware of the channel conditions, thus the AP sends the\ndata at a fixed rate. Under this assumption, and considering an ON-OFF data\nsource, we employ the maximum average data arrival rate at the AP buffer and\nthe non-asymptotic bounds on buffering delay as the main performance measures.\nThrough numerical results, we illustrate the impacts of different physical and\ndata-link parameters on the system performance.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Autonomous driving technology pledges safety, convenience, and energy\nefficiency. Challenges include the unknown intentions of other road users:\ncommunication between vehicles and with the road infrastructure is a possible\napproach to enhance awareness and enable cooperation. Connected and automated\nvehicles (CAVs) have the potential to disrupt mobility, extending what is\npossible with driving automation and connectivity alone. Applications include\nreal-time control and planning with increased awareness, routing with\nmicro-scale traffic information, coordinated platooning using traffic signals\ninformation, eco-mobility on demand with guaranteed parking. This paper\nintroduces a control and planning architecture for CAVs, and surveys the state\nof the art on each functional block therein; the main focus is on techniques to\nimprove energy efficiency. We provide an overview of existing algorithms and\ntheir mutual interactions, we present promising optimization-based approaches\nto CAVs control and identify future challenges.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We model the late evolution and mass loss history of rapidly rotating\nWolf-Rayet stars in the mass range $5\\,\\rm{M}_{\\odot}\\dots\n100\\,\\rm{M}_{\\odot}$. We find that quasi-chemically homogeneously evolving\nsingle stars computed with enhanced mixing retain very little or no helium and\nare compatible with Type\\,Ic supernovae. The more efficient removal of core\nangular momentum and the expected smaller compact object mass in our lower mass\nmodels lead to core spins in the range suggested for magnetar driven\nsuperluminous supernovae. Our more massive models retain larger specific core\nangular momenta, expected for long-duration gamma-ray bursts in the collapsar\nscenario. Due to the absence of a significant He envelope, the rapidly\nincreasing neutrino emission after core helium exhaustion leads to an\naccelerated contraction of the whole star, inducing a strong spin-up, and\ncentrifugally driven mass loss at rates of up to\n$10^{-2}\\,\\rm{M}_{\\odot}~\\rm{yr^{-1}}$ in the last years to decades before core\ncollapse. Since the angular momentum transport in our lower mass models\nenhances the envelope spin-up, they show the largest relative amounts of\ncentrifugally enforced mass loss, i.e., up to 25\\% of the expected ejecta mass.\nOur most massive models evolve into the pulsational pair-instability regime. We\nwould thus expect signatures of interaction with a C/O-rich circumstellar\nmedium for Type~Ic superluminous supernovae with ejecta masses below $\\sim\n10\\,\\rm{M}_{\\odot}$ and for the most massive engine-driven explosions with\nejecta masses above $\\sim 30\\,\\rm{M}_{\\odot}$. Signs of such interaction should\nbe observable at early epochs of the supernova explosion, and may be related to\nbumps observed in the light curves of superluminous supernovae, or to the\nmassive circumstellar CO-shell proposed for Type~Ic superluminous supernova\nGaia16apd.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The wrinkling of thin elastic objects provides a means of generating regular\npatterning at small scales in applications ranging from photovoltaics to\nmicrofluidic devices. Static wrinkle patterns are known to be governed by an\nenergetic balance between the object's bending stiffness and an effective\nsubstrate stiffness, which may originate from a true substrate stiffness or\nfrom tension and curvature along the wrinkles. Here we investigate dynamic\nwrinkling, induced by the impact of a solid sphere onto an ultra-thin polymer\nsheet floating on water. The vertical deflection of the sheet's centre induced\nby impact draws material radially inwards, resulting in an azimuthal\ncompression that is relieved by the wrinkling of the entire sheet. We show that\nthis wrinkling is truly dynamic, exhibiting features that are qualitatively\ndifferent to those seen in quasi-static wrinkling experiments. Moreover, we\nshow that the wrinkles coarsen dynamically because of the inhibiting effect of\nthe fluid inertia. This dynamic coarsening can be understood heuristically as\nthe result of a dynamic stiffness, which dominates the static stiffnesses\nreported thus far, and allows new controls of wrinkle wavelength.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In recent scans of 4D F-theory geometric models, it was shown that a dominant\nmajority of the base geometries only support SU(2), $G_2$, $F_4$ and $E_8$\ngauge groups. Moreover, most of these gauge groups are shown to couple to\nstrongly coupled \"conformal matter\" sectors. For example, the $E_8$ gauge group\ncan couple to the compactification of 6D E-string theory on a complex curve. In\nthis paper, we initiate the investigation of these strongly coupled sectors by\nstudying the spectrum of 6D E-string theory. We construct a resolved elliptic\nCalabi-Yau threefold of a non-minimal Weierstrass model, which contains a\nnon-flat fiber with the topology of generalized del Pezzo surface. The spectrum\nof E-string theory then arises from M2 brane wrapping modes on various 2-cycles\non the non-flat fiber. Finally, we discuss the compactification of these fields\nto 4D.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Unmanned aerial vehicles (UAVs) have gained great interest for rapid\ndeployment in both civil and military applications. UAV communication has its\nown distinctive channel characteristics compared with widely used cellular and\nsatellite systems. Thus, accurate channel characterization is crucial for the\nperformance optimization and design of efficient UAV communication systems.\nHowever, several challenges exist in UAV channel modeling. For example,\npropagation characteristics of UAV channels are still less explored for spatial\nand temporal variations in non\\textendash stationary channels. Also, airframe\nshadowing has not yet been investigated for small size rotary UAVs. This paper\nprovides an extensive survey on the measurement campaigns launched for UAV\nchannel modeling using low altitude platforms and discusses various channel\ncharacterization efforts. We also review the contemporary perspective of UAV\nchannel modeling approaches and outline some future research challenges in this\ndomain.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, a general cognitive radio system consisting of a set of users\nwith different level of spectrum access including two primary transceivers and\nseveral types of secondary users is considered. It is assumed that two\nsecondary users operate based on an underlay model at the same frequency\nbandwidth and at the same time as the primary users based on a multiple access\nbroadcast channel (MABC) bidirectional beamforming scheme. Other secondary\nusers provide a relaying service to the primary users in exchange for the\nopportunity to send their messages towards their own destinations for a fixed\nportion of the communication cycle. In addition, it is assumed that some\ninterferers are active during the communication cycle and cause interference\nfor the network. Furthermore, it is assumed that only partial channel state\ninformation (CSI) between interferers and other nodes in the network is\navailable.\n  We provide a robust optimization method against imperfection on the\ninterferers' CSI to maximize the joint primary and secondary\n{signal-to-interference-plus-noise-ratio (SINR)} with the assumption of limited\navailable power at the secondary relays. An amplify-and-forward (AF) relaying\nscheme is deployed at the secondary relays and the optimal beamforming is\nobtained using second order convex programming (SOCP) method. The simulation\nresults show the performance of the proposed beamforming method against the\nexistence of interferers, and demonstrate the effectiveness of our robust\nmethod against uncertainty in knowledge of interferers' CSIs.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The measurement data collected from the supervisory control and data\nacquisition (SCADA) system installed in distribution network can reflect the\noperational state of the network effectively. In this paper, a random matrix\ntheory (RMT) based approach is developed for early anomaly detection and\nlocalization by using the data. For every feeder in the distribution network, a\ncorresponding data matrix is formed. Based on the Marchenko-Pastur Law for the\nempirical spectral analysis of covariance `signal+noise' matrix, the linear\neigenvalue statistics are introduced to indicate the anomaly, and the outliers\nand their corresponding eigenvectors are analyzed for locating the anomaly. As\nfor the low observability feeders in the distribution network, an increasing\ndata dimension algorithm is designed for the formulated low-dimensional\nmatrices being more accurately analyzed. The developed approach can detect and\nlocalize the anomaly at an early stage, and it is robust to random disturbance\nand measurement error. Cases on Matpower simulation data and real SCADA data\ncorroborate the feasibility of the approach.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Gibbs paradox in the context of statistical mechanics addresses the issue of\nadditivity of entropy of mixing gases. The usual discussion attributes the\nparadoxical situation to classical distinguishability of identical particles\nand credits quantum theory for enabling indistinguishability of identical\nparticles to solve the problem. We argue that indistinguishability of identical\nparticles is already a feature in classical mechanics and this is clearly\nbrought out when the problem is treated in the language of information and\nassociated entropy. We pinpoint the physical criteria for indistinguishability\nthat is crucial for the treatment of the Gibbs' problem and the consistency of\nits solution with conventional thermodynamics. Quantum mechanics provides a\nquantitative criterion, not possible in the classical picture, for the degree\nof indistinguishability in terms of visibility of quantum interference, or\noverlap of the states as pointed out by von Neumann, thereby endowing the\nentropy expression with mathematical continuity and physical reasonableness.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  High-fidelity simulations of transcritical spray mixing and auto ignition in\na combustion chamber are performed at high pressure and temperature conditions\nusing a recently developed finite rate LES solver. The simulation framework is\nbased on a diffused-interface (DI) method that solves the compressible\nmulti-species conservation equations along with the Peng Robinson state\nequation and real-fluid transport properties. A finite volume approach with\nentropy stable scheme is employed to accurate simulate the non-linear real\nfluid flow. LES analysis is performed for non-reacting and reacting spray\nconditions targeting the ECN Spray A configuration at chamber conditions with a\npressure of 60 bar and temperatures between 800 K and 1200 K to investigate\neffects of the real-fluid environment and low-temperature chemistry.\nComparisons with measurements in terms of global spray parameters and mixture\nfraction distributions demonstrates the accuracy in modeling the turbulent\nmixing behavior. Good overall agreement of the auto-ignition process is\nobtained from simulation results at different ambient temperature conditions\nand the formation of intermediate species is captured by the simulations,\nindicating that the presented numerical framework adequately reproduces the\ncorresponding low-and-high-temperature ignition processes under high-pressure\nconditions that are relevant to realistic diesel fuel injection systems.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Ba4NbMn3O12 is reported, synthesized by a solid state method in air. The\ncrystal structure, determined by performing refinements on room temperature\npowder X-ray diffraction data by the Rietveld method, consists of Mn3O12\ntrimers in the configuration of three face-sharing MnO6 octahedra, with the\ntrimers arranged in triangular planes. An effective moment of 4.82 {\\mu}B/f.u\nis observed and competing antiferromagnetic and ferromagnetic interactions\nbetween Mn ions are inferred from the Weiss temperature of -4 K and the\nferrimagnetic ordering transition of approximately 42 K. Ba4NbMn3O12 is a\nsemiconductor with a transport activation energy of 0.37 eV.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In practice it is often found that large over-parameterized neural networks\ngeneralize better than their smaller counterparts, an observation that appears\nto conflict with classical notions of function complexity, which typically\nfavor smaller models. In this work, we investigate this tension between\ncomplexity and generalization through an extensive empirical exploration of two\nnatural metrics of complexity related to sensitivity to input perturbations.\nOur experiments survey thousands of models with various fully-connected\narchitectures, optimizers, and other hyper-parameters, as well as four\ndifferent image classification datasets.\n  We find that trained neural networks are more robust to input perturbations\nin the vicinity of the training data manifold, as measured by the norm of the\ninput-output Jacobian of the network, and that it correlates well with\ngeneralization. We further establish that factors associated with poor\ngeneralization $-$ such as full-batch training or using random labels $-$\ncorrespond to lower robustness, while factors associated with good\ngeneralization $-$ such as data augmentation and ReLU non-linearities $-$ give\nrise to more robust functions. Finally, we demonstrate how the input-output\nJacobian norm can be predictive of generalization at the level of individual\ntest points.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we present a novel approach to identify the generators and\nstates responsible for the small-signal stability of power networks. To this\nend, the newly developed notion of information transfer between the states of a\ndynamical system is used. In particular, using the concept of information\ntransfer, which characterizes influence between the various states and a linear\ncombination of states of a dynamical system, we identify the generators and\nstates which are responsible for causing instability of the power network.\nWhile characterizing influence from state to state, information transfer can\nalso describe influence from state to modes thereby generalizing the well-known\nnotion of participation factor while at the same time overcoming some of the\nlimitations of the participation factor. The developed framework is applied to\nstudy the three bus system identifying various cause of instabilities in the\nsystem. The simulation study is extended to IEEE 39 bus system.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report a statistical analysis of sizes and compositions of clusters\nproduced in cascades during irradiation of SiC. The results are obtained using\nmolecular dynamics (MD) simulations of cascades caused by primary knock-on\natoms (PKAs) with energies between 10 eV and 50 keV. The results are averaged\nover six crystallographic directions of the PKA and integrated over PKA energy\nspectrum derived from the Stopping and Range of Ions in Matter (SRIM) code.\nSpecific results are presented for 1 MeV Kr ion as an example of an impinging\nparticle. We find that distributions of cluster size n for both vacancies and\ninterstitials obey a power law f = An^(-S) and these clusters are dominated by\ncarbons defects. The fitted values of A and S are different than values\nreported for metals, which can be explained through different defect energetics\nand cascade morphology between the two classes of materials. In SiC, the\naverage carbon ratio for interstitial clusters is 91.5%, which is higher than\nthe ratio of C in vacancy clusters, which is 85.3%. Size and composition\ndistribution of in-cascade clusters provide a critical input for long-term\ndefect evolution models.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The one-dimensional Fermi-Hubbard model is used as testbed for strong global\nparameter quenches. With the aid of iterated equations of motion in combination\nwith a suitable scalar product for operators we describe the dynamics and the\nlong-term behavior in particular of the system after interaction quenches. This\nbecomes possible because the employed approximation allows for oscillatory\ndynamics avoiding spurious divergences. The infinite-time behavior is captured\nby an analytical approach based on stationary phases; no numerical averages\nover long times need to be computed. We study the most relevant frequencies in\nthe dynamics after the quench and find that the local interaction $U$ as well\nas the band width $W$ dominate. In contrast to former studies a crossover\ninstead of a sharp dynamical transition depending on the strength of the quench\nis identified. For weak quenches the band width is more important while for\nstrong quenches the local interaction $U$ dominates.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove that $\\operatorname{Aut}(F_n)$ has Kazhdan's property (T) for every\n$n \\geqslant 6$. Together with a previous result of Kaluba, Nowak, and Ozawa,\nthis gives the same statement for $n\\geqslant 5$.\n  We also provide explicit lower bounds for the Kazhdan constants of\n$\\operatorname{SAut}(F_n)$ (with $n \\geqslant 6$) and of\n$\\operatorname{SL}_n(\\mathbb{Z})$ (with $n \\geqslant 3$) with respect to\nnatural generating sets. In the latter case, these bounds improve upon\npreviously known lower bounds whenever $n > 6$.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Neutron beta decay is one of the most fundamental processes in nuclear\nphysics and provides sensitive means to uncover the details of the weak\ninteraction. Neutron beta decay can evaluate the ratio of axial-vector to\nvector coupling constants in the standard model, $\\lambda = g_A / g_V$, through\nmultiple decay correlations. The Nab experiment will carry out measurements of\nthe electron-neutrino correlation parameter $a$ with a precision of $\\delta a /\na = 10^{-3}$ and the Fierz interference term $b$ to $\\delta b = 3\\times10^{-3}$\nin unpolarized free neutron beta decay. These results, along with a more\nprecise measurement of the neutron lifetime, aim to deliver an independent\ndetermination of the ratio $\\lambda$ with a precision of $\\delta \\lambda /\n\\lambda = 0.03\\%$ that will allow an evaluation of $V_{ud}$ and sensitively\ntest CKM unitarity, independent of nuclear models. Nab utilizes a novel, long\nasymmetric spectrometer that guides the decay electron and proton to two large\narea silicon detectors in order to precisely determine the electron energy and\nan estimation of the proton momentum from the proton time of flight. The Nab\nspectrometer is being commissioned at the Fundamental Neutron Physics Beamline\nat the Spallation Neutron Source at Oak Ridge National Lab. We present an\noverview of the Nab experiment and recent updates on the spectrometer,\nanalysis, and systematic effects.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present accretion-disk structure measurements from continuum lags in the\nSloan Digital Sky Survey Reverberation Mapping (SDSS-RM) project. Lags are\nmeasured using the \\texttt{JAVELIN} software from the first-year SDSS-RM $g$\nand $i$ photometry, resulting in well-defined lags for 95 quasars, 33 of which\nhave lag SNR $>$ 2$\\sigma$. We also estimate lags using the \\texttt{ICCF}\nsoftware and find consistent results, though with larger uncertainties.\nAccretion-disk structure is fit using a Markov Chain Monte Carlo approach,\nparameterizing the measured continuum lags as a function of disk size\nnormalization, wavelength, black hole mass, and luminosity. In contrast with\nprevious observations, our best-fit disk sizes and color profiles are\nconsistent (within 1.5~$\\sigma$) with the \\citet{SS73} analytic solution. We\nalso find that more massive quasars have larger accretion disks, similarly\nconsistent with the analytic accretion-disk model. The data are inconclusive on\na correlation between disk size and continuum luminosity, with results that are\nconsistent with both no correlation and with the \\citet{SS73} expectation. The\ncontinuum lag fits have a large excess dispersion, indicating that our measured\nlag errors are underestimated and/or our best-fit model may be missing the\neffects of orientation, spin, and/or radiative efficiency. We demonstrate that\nfitting disk parameters using only the highest-SNR lag measurements biases\nbest-fit disk sizes to be larger than the disk sizes recovered using a Bayesian\napproach on the full sample of well-defined lags.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In many applications, a state-space model depends on a parameter which needs\nto be inferred from a data set. Quite often, it is necessary to perform the\nparameter inference online. In the maximum likelihood approach, this can be\ndone using stochastic gradient search and the optimal filter derivative.\nHowever, the optimal filter and its derivative are not analytically tractable\nfor a non-linear state-space model and need to be approximated numerically. In\n[Poyiadjis, Doucet and Singh, Biometrika 2011], a particle approximation to the\noptimal filter derivative has been proposed, while the corresponding $L_{p}$\nerror bonds and the central limit theorem have been provided in [Del Moral,\nDoucet and Singh, SIAM Journal on Control and Optimization 2015]. Here, the\nbias of this particle approximation is analyzed. We derive (relatively) tight\nbonds on the bias in terms of the number of particles. Under (strong) mixing\nconditions, the bounds are uniform in time and inversely proportional to the\nnumber of particles. The obtained results apply to a (relatively) broad class\nof state-space models met in practice.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the dynamics of a two-component Bose-Einstein condensate (BEC) of\n$^{174}$Yb atoms coherently driven on a narrow optical transition. The\nexcitation transfers the BEC to a superposition of states with different\ninternal and momentum quantum numbers. We observe a crossover with decreasing\ndriving strength between a regime of damped oscillations, where coherent\ndriving prevails, and an incoherent regime, where relaxation takes over.\nSeveral relaxation mechanisms are involved: inelastic losses involving two\nexcited atoms, leading to a non-exponential decay of populations; Doppler\nbroadening due to the finite momentum width of the BEC and inhomogeneous\nelastic interactions, both leading to dephasing and to damping of the\noscillations. We compare our observations to a two-component Gross-Pitaevskii\n(GP) model that fully includes these effects. For small or moderate densities,\nthe damping of the oscillations is mostly due to Doppler broadening. In this\nregime, we find excellent agreement between the model and the experimental\nresults. For higher densities, the role of interactions increases and so does\nthe damping rate of the oscillations. The damping in the GP model is less\npronounced than in the experiment, possibly a hint for many-body effects not\ncaptured by the mean-field description.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we consider an non-ideal successive interference cancellation\n(SIC) receiver based imperfect non-orthogonal multiple access (NOMA) schemes\nwhose performance is limited by three factors: 1) Power disparity \\&\nsensitivity constraints (PDSCs), 2) Intra-cluster interference (ICRI), and 3)\nIntercell-interference (ICI). By quantifying the residual interference with a\nfractional error factor (FEF), we show that NOMA cannot always perform better\nthan orthogonal multiple access (OMA) especially under certain receiver\nsensitivity and FEF levels. Assuming the existence of an offline/online ICI\nmanagement scheme, the proposed solution accounts for the ICI which is shown to\ndeteriorate the NOMA performance particularly when it becomes significant\ncompared to the ICRI. Then, a distributed cluster formation (CF) and\npower-bandwidth allocation (PBA) approach are proposed for downlink (DL)\nheterogeneous networks (HetNets) operating on the imperfect NOMA. We develop a\nhierarchically distributed solution methodology where BSs independently form\nclusters and distributively determine the power-bandwidth allowance of each\ncluster. A generic CF scheme is obtained by creating a multi-partite graph\n(MPG) via partitioning user equipments (UEs) with respect to their channel\ngains since NOMA performance is primarily determined by the channel gain\ndisparity of cluster members. A sequential weighted bi-partite matching method\nis proposed for solving the resulted weighted multi-partite matching problem.\nThereafter, we present a hierarchically distributed PBA approach which consists\nof the primary master, secondary masters, and slave problems...\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper we introduce a method for solving linear and nonlinear\nscattering problems for wave equations using a new hybrid approach. This new\napproach consists of a reformulation of the governing equations into a form\nthat can be solved by a combination of a domain-based method and a\nboundary-integral method.Our reformulation is aimed at a situation where we\nhave a collection of compact scattering objects located in an otherwise\nhomogeneous unbounded space. The domain-based method is used to propagate the\nequations governing the wave field inside the scattering objects forward in\ntime. The boundary integral method is used to supply the domain-based method\nwith the required boundary values for the wave field. In this way the best\nfeatures of both methods come into play; the response inside the scattering\nobjects, which can be caused by both material inhomogeneity and nonlinearities,\nis easily taken into account using the domain-based method, and the boundary\nconditions supplied by the boundary integral method makes it possible to\nconfine the domain based method to the inside of each scattering object.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study Red Misfits, a population of red, star-forming galaxies in the local\nUniverse. We classify galaxies based on inclination-corrected optical colours\nand specific star formation rates derived from the Sloan Digital Sky Survey\nData Release 7. Although the majority of blue galaxies are star-forming and\nmost red galaxies exhibit little to no ongoing star formation, a small but\nsignificant population of galaxies ($\\sim$11 per cent at all stellar masses)\nare classified as red in colour yet actively star-forming. We explore a number\nof properties of these galaxies and demonstrate that Red Misfits are not simply\ndusty or highly-inclined blue cloud galaxies or quiescent red galaxies with\npoorly-constrained star formation. The proportion of Red Misfits is nearly\nindependent of environment and this population exhibits both intermediate\nmorphologies and an enhanced likelihood of hosting an AGN. We conclude that Red\nMisfits are a transition population, gradually quenching on their way to the\nred sequence and this quenching is dominated by internal processes rather than\nenvironmentally-driven processes. We discuss the connection between Red Misfits\nand other transition galaxy populations, namely S0's, red spirals and green\nvalley galaxies.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We performed a near-infrared (NIR, $\\sim$1.0$\\mu$m-2.4$\\mu$m) stellar\npopulation study in a sample of early type galaxies. The synthesis was\nperformed using five different evolutionary population synthesis libraries of\nmodels. Our main results can be summarized as follows: low spectral resolution\nlibraries are not able to produce reliable results when applied to the NIR\nalone, with each library finding a different dominant population. The two\nnewest higher resolution models, on the other hand, perform considerably\nbetter, finding consistent results to each other and to literature values. We\nalso found that optical results are consistent with each other even for lower\nresolution models. We also compared optical and NIR results, and found out that\nlower resolution models tend to disagree in the optical and in the NIR, with\nhigher fraction of young populations in the NIR and dust extinction $\\sim$1\nmagnitude higher than optical values. For higher resolution models, optical and\nNIR results tend do aggree much better, suggesting that a higher spectral\nresolution is fundamental to improve the quality of the results.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In biological settings membranes typically interact locally with other\nmembranes or the extracellular matrix in the exterior, as well as with internal\ncellular structures such as the cytoskeleton. Characterization of the dynamic\nproperties of such interactions presents a difficult task. Significant progress\nhas been achieved through simulations and experiments, yet analytical progress\nin modelling pinned membranes has been impeded by the complexity of governing\nequations. Here we circumvent these difficulties by calculating analytically\nthe time-dependent Green's function of the operator governing the dynamics of\nan elastically pinned membrane in a hydrodynamic surrounding and subject to\nexternal forces. This enables us to calculate the equilibrium power spectral\ndensity for an overdamped membrane pinned by an elastic, permanently-attached\nspring subject to thermal excitations. By considering the effects of the finite\nexperimental resolution on the measured spectra, we show that the elasticity of\nthe pinning can be extracted from the experimentally measured spectrum.\nMembrane fluctuations can thus be used as a tool to probe mechanical properties\nof the underlying structures. Such a tool may be particularly relevant in the\ncontext of cell mechanics, where the elasticity of the membrane's attachment to\nthe cytoskeleton could be measured.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The process of aligning a pair of shapes is a fundamental operation in\ncomputer graphics. Traditional approaches rely heavily on matching\ncorresponding points or features to guide the alignment, a paradigm that\nfalters when significant shape portions are missing. These techniques generally\ndo not incorporate prior knowledge about expected shape characteristics, which\ncan help compensate for any misleading cues left by inaccuracies exhibited in\nthe input shapes. We present an approach based on a deep neural network,\nleveraging shape datasets to learn a shape-aware prior for source-to-target\nalignment that is robust to shape incompleteness. In the absence of ground\ntruth alignments for supervision, we train a network on the task of shape\nalignment using incomplete shapes generated from full shapes for\nself-supervision. Our network, called ALIGNet, is trained to warp complete\nsource shapes to incomplete targets, as if the target shapes were complete,\nthus essentially rendering the alignment partial-shape agnostic. We aim for the\nnetwork to develop specialized expertise over the common characteristics of the\nshapes in each dataset, thereby achieving a higher-level understanding of the\nexpected shape space to which a local approach would be oblivious. We constrain\nALIGNet through an anisotropic total variation identity regularization to\npromote piecewise smooth deformation fields, facilitating both partial-shape\nagnosticism and post-deformation applications. We demonstrate that ALIGNet\nlearns to align geometrically distinct shapes, and is able to infer plausible\nmappings even when the target shape is significantly incomplete. We show that\nour network learns the common expected characteristics of shape collections,\nwithout over-fitting or memorization, enabling it to produce plausible\ndeformations on unseen data during test time.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Semiconducting quantum wires defined within two-dimensional electron gases\nand strongly coupled to thin superconducting layers have been extensively\nexplored in recent experiments as promising platforms to host Majorana bound\nstates. We study numerically such a geometry, consisting of a\nquasi-one-dimensional wire coupled to a disordered three-dimensional\nsuperconducting layer. We find that, in the strong-coupling limit of a sizable\nproximity-induced superconducting gap, all transverse subbands of the wire are\nsignificantly shifted in energy relative to the chemical potential of the wire.\nFor the lowest subband, this band shift is comparable in magnitude to the\nspacing between quantized levels that arise due to the finite thickness of the\nsuperconductor (which typically is $\\sim500$ meV for a 10-nm-thick layer of\nAluminum); in higher subbands, the band shift is much larger. Additionally, we\nshow that the width of the system, which is usually much larger than the\nthickness, and moderate disorder within the superconductor have almost no\nimpact on the induced gap or band shift. We provide a detailed discussion of\nthe ramifications of our results, arguing that a huge band shift and\nsignificant renormalization of semiconducting material parameters in the\nstrong-coupling limit make it challenging to realize a topological phase in\nsuch a setup, as the strong coupling to the superconductor essentially\nmetallizes the semiconductor. This metallization of the semiconductor can be\ntested experimentally through the measurement of the band shift.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We derive the kinematic Hamiltonian for the so-called \"new general\nrelativity\" class of teleparallel gravity theories, which is the most general\nclass of theories whose Lagrangian is quadratic in the torsion tensor and does\nnot contain parity violating terms. Our approach makes use of an explicit\nexpression for the flat, in general, nonvanishing spin connection, which avoids\nthe use of Lagrange multipliers, while keeping the theory invariant under local\nLorentz transformations. We clarify the relation between the dynamics of the\nspin connection degrees of freedom and the tetrads. The terms constituting the\nHamiltonian of the theory can be decomposed into irreducible parts under the\nrotation group. Using this, we demonstrate that there are nine different\nclasses of theories, which are distinguished by the occurrence or\nnon-occurrence of certain primary constraints. We visualize these different\nclasses and show that the decomposition into irreducible parts allows us to\nwrite the Hamiltonian in a common form for all nine classes, which reproduces\nthe specific Hamiltonians of more restricted classes in which particular\nprimary constraints appear.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study stochastic bifurcation for a system under multiplicative stable Levy\nnoise (an important class of non-Gaussian noise), by examining the qualitative\nchanges of equilibrium states in its most probable phase portraits. We have\nfound some peculiar bifurcation phenomena in contrast to the deterministic\ncounterpart: (i) When the non-Gaussianity parameter in Levy noise varies, there\nis either one, two or none backward pitchfork type bifurcations; (ii) When a\nparameter in the vector field varies, there are two or three forward pitchfork\nbifurcations; (iii) The non-Gaussian Levy noise clearly leads to fundamentally\nmore complex bifurcation scenarios, since in the special case of Gaussian\nnoise, there is only one pitchfork bifurcation which is reminiscent of the\ndeterministic situation.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a new approach for computing tunneling rates in quantum or thermal\nfield theory with multiple scalar fields. It is based on exact analytical\nsolutions of piecewise linear potentials with many segments that describes any\ngiven potential to arbitrary precision. The method is first developed for the\nsingle field case in 3 and 4 space-time dimensions and demonstrated on examples\nof classical potentials as well as the calculation of quantum fluctuations. A\nsystematic expansion of the potential beyond the linear order is considered,\ntaking into account higher order corrections, which paves the way for multiple\nscalar fields. We thereby provide a fast semi-analytical tool for evaluating\nthe bounce action for theories with an extended scalar sector.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We use grey forecast model to predict the future energy consumption of four\nstates in the U.S, and make some improvments to the model.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The conversion of spin information into electrical signals is indispensable\nfor spintronic technologies. Spin-to-charge conversion in ferromagnetic tunnel\ncontacts is well-described using linear (spin-)transport equations, provided\nthat there is no applied bias, as in nonlocal spin detection. It is shown here\nthat in a biased ferromagnetic tunnel contact, spin detection is strongly\nnonlinear. As a result, the spin-detection efficiency is not equal to the\ntunnel spin polarization. In silicon-based 4-terminal spin-transport devices,\neven a small bias (tens of mV) across the Fe/MgO detector contact enhances the\nspin-detection efficiency to values up to 140 \\% (spin extraction bias) or, for\nspin injection bias, reduces it to almost zero, while, parenthetically, the\ncharge current remains highly spin polarized. Calculations reveal that the\nnonlinearity originates from the energy dispersion of the tunnel transmission\nand the resulting nonuniform energy distribution of the tunnel current,\noffering a route to engineer spin conversion. Taking nonlinear spin detection\ninto account is also shown to explain a multitude of peculiar and puzzling spin\nsignals in structures with a biased detector, including two- and three-terminal\ndevices, and provides a unified, consistent and quantitative description of\nspin signals in devices with a biased and unbiased detector.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Advanced LIGO and the next generation of ground-based detectors aim to\ncapture many more binary coalescences through improving sensitivity and duty\ncycle. Earthquakes have always been a limiting factor at low frequency where\nneither the pendulum suspension nor the active controls provide sufficient\nisolation to the test mass mirrors. Several control strategies have been\nproposed to reduce the impact of teleseismic events by switching to a robust\nconfiguration with less aggressive feedback. The continental United States has\nwitnessed a huge increase in the number of induced earthquake events primarily\nassociated with hydraulic fracking-related waste water re-injection. Effects\nfrom these differ from teleseismic earthquakes primarily because of their depth\nwhich is in turn linked to their triggering mechanism. In this paper, we\ndiscuss the impact caused due to these low magnitude regional earthquakes and\nexplore ways to minimize the impact of induced seismicity on the detector.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The study of resonant dielectric nanostructures with high refractive index is\na new research direction in nanoscale optics and metamaterial-inspired\nnanophotonics. Because of the unique optically-induced electric and magnetic\nMie resonances, high-index nanoscale structures are expected to complement or\neven replace different plasmonic components in a range of potential\napplications. Here we study strong coupling between modes of a single\nsubwavelength high-index dielectric resonator and analyse the mode\ntransformation and Fano resonances when resonator's aspect ratio varies. We\ndemonstrate that strong mode coupling results in resonances with high quality\nfactors, which are related to the physics of bound states in the continuum when\nthe radiative losses are almost suppressed due to the Friedrich-Wintgen\nscenario of destructive interference. We explain the physics of these states in\nterms of multipole decomposition and show that their appearance is accompanied\nby drastic change of the far-field radiation pattern. We reveal a fundamental\nlink between the formation of the high-quality resonances and peculiarities of\nthe Fano parameter in the scattering cross-section spectra. Our theoretical\nfindings are confirmed by microwave experiments for the scattering of a\nhigh-index cylindrical resonators with a tunable aspect ratio. The proposed\nmechanism of the strong mode coupling in single subwavelength high-index\nresonators accompanied by resonances with high quality factor helps to extend\nsubstantially functionalities of all-dielectric nanophotonics that opens new\nhorizons for active and passive nanoscale metadevices.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We construct an updated extended compilation of distinct (but possibly\ncorrelated) $f\\sigma_8(z)$ Redshift Space Distortion (RSD) data published\nbetween 2006 and 2018. It consists of 63 datapoints and is significantly larger\nthan previously used similar datasets. After fiducial model correction we\nobtain the best fit $\\Omega_{0m}-\\sigma_8$ $\\Lambda$CDM parameters and show\nthat they are at a $5\\sigma$ tension with the corresponding\nPlanck15/$\\Lambda$CDM values. Introducing a nontrivial covariance matrix\ncorrelating randomly $20\\%$ of the RSD datapoints has no significant effect on\nthe above tension level. We show that the tension disappears (becomes less than\n$1\\sigma$) when a subsample of the 20 most recently published data is used. A\npartial cause for this reduced tension is the fact that more recent data tend\nto probe higher redshifts (with higher errorbars) where there is degeneracy\namong different models due to matter domination. Allowing for a nontrivial\nevolution of the effective Newton's constant as\n$G_{\\textrm{eff}}(z)/G_{\\textrm{N}} = 1 + g_a \\left(\\frac{z}{1+z}\\right)^2 -\ng_a \\left(\\frac{z}{1+z}\\right)^4$ ($g_a$ is a parameter) and fixing a \\plcdm\nbackground we find $g_a=-0.91\\pm 0.17$ from the full $f\\sigma_8$ dataset while\nthe 20 earliest and 20 latest datapoints imply $g_a=-1.28^{+0.28}_{-0.26}$ and\n$g_a=-0.43^{+0.46}_{-0.41}$ respectively. Thus, the more recent $f\\sigma_8$\ndata appear to favor GR in contrast to earlier data. Finally, we show that the\nparametrization $f\\sigma_8(z)=\\lambda \\sigma_8 \\Omega(z)^\\gamma /(1+z)^\\beta$\nprovides an excellent fit to the solution of the growth equation for both GR\n($g_a=0$) and modified gravity ($g_a\\neq 0$).\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The purpose of this paper is twofold. Firstly, we generalize the notion of\ncharacteristic polynomials of hyperplane and toric arrangements to those of\ncertain abelian Lie group arrangements. Secondly, we give two interpretations\nfor the chromatic quasi-polynomials and their constituents through subspace and\ntoric viewpoints.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recent advances in artificial intelligence (AI) and machine learning have\ncreated a general perception that AI could be used to solve complex problems,\nand in some situations over-hyped as a tool that can be so easily used.\nUnfortunately, the barrier to realization of mass adoption of AI on various\nbusiness domains is too high because most domain experts have no background in\nAI. Developing AI applications involves multiple phases, namely data\npreparation, application modeling, and product deployment. The effort of AI\nresearch has been spent mostly on new AI models (in the model training stage)\nto improve the performance of benchmark tasks such as image recognition. Many\nother factors such as usability, efficiency and security of AI have not been\nwell addressed, and therefore form a barrier to democratizing AI. Further, for\nmany real world applications such as healthcare and autonomous driving,\nlearning via huge amounts of possibility exploration is not feasible since\nhumans are involved. In many complex applications such as healthcare, subject\nmatter experts (e.g. Clinicians) are the ones who appreciate the importance of\nfeatures that affect health, and their knowledge together with existing\nknowledge bases are critical to the end results. In this paper, we take a new\nperspective on developing AI solutions, and present a solution for making AI\nusable. We hope that this resolution will enable all subject matter experts\n(eg. Clinicians) to exploit AI like data scientists.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Based on the time-convolutionless master-equation approach, we investigate\nsqueezing of light field in a dissipative Jaynes-Cummings model. The results\nshow that squeezing light can be generated when the atom transits to a ground\nstate from an excited state, and then a collapse-revival phenomenon will occur\nin the squeezing of light field due to atom-cavity coupling. Enhancing the\natom-cavity coupling can increase the frequency of the collapse-revival of\nsqueezing. The stronger the non-Markovian effect is, the more obvious the\ncollapse-revival phenomenon is. The oscillatory frequency of the squeezing is\ndependents on the resonant frequency of the atom-cavity.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Building systems that autonomously create temporal abstractions from data is\na key challenge in scaling learning and planning in reinforcement learning. One\npopular approach for addressing this challenge is the options framework (Sutton\net al., 1999). However, only recently in (Bacon et al., 2017) was a policy\ngradient theorem derived for online learning of general purpose options in an\nend to end fashion. In this work, we extend previous work on this topic that\nonly focuses on learning a two-level hierarchy including options and primitive\nactions to enable learning simultaneously at multiple resolutions in time. We\nachieve this by considering an arbitrarily deep hierarchy of options where high\nlevel temporally extended options are composed of lower level options with\nfiner resolutions in time. We extend results from (Bacon et al., 2017) and\nderive policy gradient theorems for a deep hierarchy of options. Our proposed\nhierarchical option-critic architecture is capable of learning internal\npolicies, termination conditions, and hierarchical compositions over options\nwithout the need for any intrinsic rewards or subgoals. Our empirical results\nin both discrete and continuous environments demonstrate the efficiency of our\nframework.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  It is shown that the entropic force formula $F_e=-\\lambda\\partial S/\\partial\nA$ leads to a Newtonian $r^{-2}$ dependence. Here we employ the universal\nproperty of the information entropy $S=a+b\\ln N$ ($N$ is the number of\nparticles of a quantum system and $A$ is the area containing the system). This\nproperty was previously obtained for fermionic systems (atoms, atomic clusters,\nnuclei and infinite Fermi systems i.e. electron gas, liquid $^3$He and nuclear\nmatter) and bosonic ones (correlated boson-atoms in a trap). A similar\ndependence of the entropic force has been derived very recently by Plastino et\nal with a Bose or Fermi gas entropy, inspired by Verlinde's\nconjecture~\\cite{Verlide-11} that gravity is an emergent entropic force.\nFinally, we point out that our simple argument holds for classical systems as\nwell.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The diffusion of atoms and molecules in ices covering dust grains in dense\nclouds in interstellar space is an important but poorly characterized step in\nthe formation of complex molecules in space. Here we report the measurement of\ndiffusion of simple molecules in amorphous solid water (ASW), an analog of\ninterstellar ices, which are amorphous and made mostly of water molecules. The\nnew approach that we used relies on measuring in situ the change in band\nstrength and position of mid-infrared features of OH dangling bonds as\nmolecules move through pores and channels of ASW. We obtained the Arrhenius\npre-exponents and activation energies for diffusion of CO, O$_2$, N$_2$,\nCH$_4$, and Ar in ASW. The diffusion energy barrier of H$_2$ and D$_2$ were\nalso measured, but only upper limits were obtained. These values constitute the\nfirst comprehensive set of diffusion parameters of simple molecules on the pore\nsurface of ASW, and can be used in simulations of the chemical evolution of ISM\nenvironments, thus replacing unsupported estimates. We also present a set of\nargon temperature programmed desorption experiments to determine the desorption\nenergy distribution of argon on non-porous ASW.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this article, we study a class of semilinear stochastic partial\ndifferential equations driven by an additive space time white noise. We\nestablish Harnack inequalities for the semigroup associated with the solution\nby using coupling method, which implies the strong Feller property. Our results\ngeneralize the results of Zhang [Potential Analysis 33 (2010), no. 2, 137-151.]\nand can be applied to some types of SPDE such as reaction-diffusion equation\nand transport-diffusion equation perturbed by space time white noise.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  A method for determining the time delays in gravitationally lensed quasars is\nproposed, which offers a simple and transparent procedure to mitigate the\neffects of microlensing. The method is based on fundamental properties of\nrepresentation of quadratically integrable functions by their expansions in\northogonal polynomials series. The method was tested on the artificial light\ncurves simulated for the Time Delay Challenge campaign TDC0. The new estimates\nof the time delays in the gravitationally lensed quasars HE 0435-1223 and PG\n1115+080 are obtained and compared with the results reported by other authors\nearlier.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We show how a recently proposed solid state Majorana platform comprising a\nplanar Josephson junction proximitized to a 2D electron gas (2DEG) with Rashba\nspin-orbit coupling and Zeeman field can be viewed as an effectively one\ndimensional (1D) Kitaev chain with long-range pairing and hopping terms. We\nhighlight how the couplings of the 1D system may be tuned by changing\nexperimentally realistic parameters. We also show that the mapping is robust to\ndisorder by computing the Clifford pseudospectrum index in real space for the\nlong-range Kitaev chain across several topological phases. This mapping opens\nup the possibility of using current experimental setups to explore 1D\ntopological superconductors with non-standard, and tunable couplings.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In real-world visual recognition problems, the assumption that the training\ndata (source domain) and test data (target domain) are sampled from the same\ndistribution is often violated. This is known as the domain adaptation problem.\nIn this work, we propose a novel domain-adaptive dictionary learning framework\nfor cross-domain visual recognition. Our method generates a set of intermediate\ndomains. These intermediate domains form a smooth path and bridge the gap\nbetween the source and target domains. Specifically, we not only learn a common\ndictionary to encode the domain-shared features, but also learn a set of\ndomain-specific dictionaries to model the domain shift. The separation of the\ncommon and domain-specific dictionaries enables us to learn more compact and\nreconstructive dictionaries for domain adaptation. These dictionaries are\nlearned by alternating between domain-adaptive sparse coding and dictionary\nupdating steps. Meanwhile, our approach gradually recovers the feature\nrepresentations of both source and target data along the domain path. By\naligning all the recovered domain data, we derive the final domain-adaptive\nfeatures for cross-domain visual recognition. Extensive experiments on three\npublic datasets demonstrates that our approach outperforms most\nstate-of-the-art methods.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  To simulate a macroscopic system from a simulation cell, a direct summation\nof the elastic fields produced by periodic images can be used. If the cell\ncontains a non-zero elastic dipole component, the sum is known to be\nconditionally convergent. In analogy with systems containing electric or\nmagnetic dipoles, we show that the sum introduces a component which only\ndepends on the shape of the summation domain and on the dipole density. A\ncorrection to the direct summation is proposed for the strain and stress fields\nin the simulation cell, which ensures that zero tractions are imposed on the\nboundary of the macro-scopic system. The elastic fields then do not depend\nanymore on the shape of the domain. The effect of this correction is emphasized\non the kinetics of dislo-cation loop growth by absorption of point defects. It\nis shown that correcting elastic fields has an influence on the kinetics if\ndefects have different properties at stable and saddle points.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Convolutional Neural Networks (CNNs) have been widely used in computer vision\ntasks, such as face recognition and verification, and have achieved\nstate-of-the-art results due to their ability to capture discriminative deep\nfeatures. Conventionally, CNNs have been trained with softmax as supervision\nsignal to penalize the classification loss. In order to further enhance the\ndiscriminative capability of deep features, we introduce a joint supervision\nsignal, Git loss, which leverages on softmax and center loss functions. The aim\nof our loss function is to minimize the intra-class variations as well as\nmaximize the inter-class distances. Such minimization and maximization of deep\nfeatures are considered ideal for face recognition task. We perform experiments\non two popular face recognition benchmarks datasets and show that our proposed\nloss function achieves maximum separability between deep face features of\ndifferent identities and achieves state-of-the-art accuracy on two major face\nrecognition benchmark datasets: Labeled Faces in the Wild (LFW) and YouTube\nFaces (YTF). However, it should be noted that the major objective of Git loss\nis to achieve maximum separability between deep features of divergent\nidentities.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We report on the chemically stabilized epitaxial w-BN thin film grown on\nc-plane sapphire by pulsed laser deposition under slow kinetic condition.\nTraces of no other allotropes such as cubic (c) or hexagonal (h) BN phases are\npresent. Sapphire substrate plays a significant role in stabilizing the\nmetastable w-BN from h-BN target under unusual PLD growth condition involving\nlow temperature and pressure and is explained based on density functional\ntheory calculation. The hardness and the elastic modulus of the w-BN film are\n37 & 339 GPa, respectively measured by indentation along <0001> direction. The\nresults are extremely promising in advancing the microelectronic and mechanical\ntooling industry.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce Texar, an open-source toolkit aiming to support the broad set of\ntext generation tasks that transform any inputs into natural language, such as\nmachine translation, summarization, dialog, content manipulation, and so forth.\nWith the design goals of modularity, versatility, and extensibility in mind,\nTexar extracts common patterns underlying the diverse tasks and methodologies,\ncreates a library of highly reusable modules, and allows arbitrary model\narchitectures and algorithmic paradigms. In Texar, model architecture,\ninference, and learning processes are properly decomposed. Modules at a high\nconcept level can be freely assembled and plugged in/swapped out. The toolkit\nalso supports a rich set of large-scale pretrained models. Texar is thus\nparticularly suitable for researchers and practitioners to do fast prototyping\nand experimentation. The versatile toolkit also fosters technique sharing\nacross different text generation tasks. Texar supports both TensorFlow and\nPyTorch, and is released under Apache License 2.0 at https://www.texar.io.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Only star clusters that are sufficiently compact and massive survive largely\nunharmed beyond 10 Myr. However, their compactness means a high stellar density\nwhich can lead to strong gravitational interactions between the stars. As young\nstars are often initially surrounded by protoplanetary disks and later on\npotentially by planetary systems, the question arises to what degree these\nstrong gravitational interactions influence planet formation and the properties\nof planetary systems. Here, we perform simulations of the evolution of compact\nhigh-mass clusters like Trumpler 14 and Westerlund 2 from the embedded to the\ngas-free phase and study the influence of stellar interactions. We concentrate\non the development of the mean disk size in these environments. Our simulations\nshow that in high-mass open clusters $80-90\\%$ of all disks/planetary systems\nshould be smaller than 50 AU just due to the strong stellar interactions in\nthese environments. Already in the initial phases, 3-4 close fly-bys lead to\ntypical disk sizes within the range of 18-27 AU. Afterwards, the disk sizes are\naltered only to a small extent. Our findings agree with the recent observation\nthat the disk sizes in the once dense environment of the Upper Scorpio OB\nassociation, NGC~2362, and h/$\\chi$Persei are at least three times smaller in\nsize than, for example, in Taurus. We conclude that the observed planetary\nsystems in high-mass open clusters should also be on average smaller than those\nfound around field stars; in particular, planets on wide orbits are expected to\nbe extremely rare in such environments.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The mass-period or radius-period distribution of close-in exoplanets shows a\npaucity of intermediate mass/size (sub-Jovian) planets with periods ~< 3 days.\nWe show that this sub-Jovian desert can be explained by the photoevaporation of\nhighly irradiated sub-Neptunes and the tidal disruption barrier for gas giants\nundergoing high-eccentricity migration. The distinctive triangular shape of the\nsub-Jovain desert result from the fact that photoevaporation is more effective\ncloser to the host star, and that in order for a gas giant to tidally\ncircularise closer to the star without tidal disruption it needs to be more\nmassive. Our work indicates that super-Earths/mini-Neptunes and hot-Jupiters\nhad distinctly separate formation channels and arrived at their present\nlocations at different times.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Structural balance in social network theory starts from signed networks with\nactive relationships (friendly or hostile) to establish a hierarchy between\nfour different types of triadic relationships. The lack of an active link also\nprovides information about the network. To exploit the information that remains\nuncovered by structural balance, we introduce the inactive relationship that\naccounts for both neutral and nonexistent ties between two agents. This\naddition results in ten types of triads, with the advantage that the network\nanalysis can be done with complete networks. To each type of triadic\nrelationship, we assign an energy that is a measure for its average occupation\nprobability. Finite temperatures account for a persistent form of disorder in\nthe formation of the triadic relationships. We propose a Hamiltonian with three\ninteraction terms and a chemical potential (capturing the cost of edge\nactivation) as an underlying model for the triadic energy levels. Our model is\nsuitable for empirical analysis of political networks and allows to uncover\ngenerative mechanisms. It is tested on an extended data set for the standings\nbetween two classes of alliances in a massively multi-player on-line game\n(MMOG) and on real-world data for the relationships between countries during\nthe Cold War era. We find emergent properties in the triadic relationships\nbetween the nodes in a political network. For example, we observe a persistent\nhierarchy between the ten triadic energy levels across time and networks. In\naddition, the analysis reveals consistency in the extracted model parameters\nand a universal data collapse of a derived combination of global properties of\nthe networks. We illustrate that the model has predictive power for the\ntransition probabilities between the different triadic states.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Our main motivation is to propose an efficient approach to generate novel\nmulti-element stable chemical compounds that can be used in real world\napplications. This task can be formulated as a combinatorial problem, and it\ntakes many hours of human experts to construct, and to evaluate new data.\nUnsupervised learning methods such as Generative Adversarial Networks (GANs)\ncan be efficiently used to produce new data. Cross-domain Generative\nAdversarial Networks were reported to achieve exciting results in image\nprocessing applications. However, in the domain of materials science, there is\na need to synthesize data with higher order complexity compared to observed\nsamples, and the state-of-the-art cross-domain GANs can not be adapted\ndirectly. In this contribution, we propose a novel GAN called CrystalGAN which\ngenerates new chemically stable crystallographic structures with increased\ndomain complexity. We introduce an original architecture, we provide the\ncorresponding loss functions, and we show that the CrystalGAN generates very\nreasonable data. We illustrate the efficiency of the proposed method on a real\noriginal problem of novel hydrides discovery that can be further used in\ndevelopment of hydrogen storage materials.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We describe the global geometry, symmetries and tensors for Double Field\nTheory over pairs of nilmanifolds with fluxes or gerbes. This is achieved by a\nrather straightforward application of a formalism we developed previously. This\nformalism constructs the analogue of a Courant algebroid over the\ncorrespondence space of a T-duality, using the language of graded manifolds,\nderived brackets and we use the description of nilmanifolds in terms of\nperiodicity conditions rather than local patches. The strong section condition\narises purely algebraically, and we show that for a particularly symmetric\nsolution of this condition, we recover the Courant algebroids of both\nnilmanifolds with fluxes. We also discuss the finite, global symmetries of\ngeneral local Double Field Theory and explain how this specializes to the case\nof T-duality between nilmanifolds.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper studies gradient almost Ricci-harmonic soliton with respect to a\nfixed metric. We rely on analytic techniques to estabilish some basic elliptic\nand integral equations for the structure of almost Ricci-harmonic soliton which\ngeneralizes that of Ricci-hamonic solitons on one hand and that of almost Ricci\nsoliton on the other hand. The consequences of these formulas in relation to\nclassification and rigidity results for gradient almost Ricci-harmonic solitons\nare also discussed.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  In this paper, we generalize Bonahon's characterization of geometrically\ninfinite torsion-free discrete subgroups of PSL(2, $\\mathbb{C}$) to\ngeometrically infinite discrete subgroups $\\Gamma$ of isometries of negatively\npinched Hadamard manifolds $X$. We then generalize a theorem of Bishop to prove\nthat every discrete geometrically infinite isometry subgroup $\\Gamma$ has a set\nof nonconical limit points with the cardinality of the continuum.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recently, there is a rising interest in perceiving image aesthetics. The\nexisting works deal with image aesthetics as a classification or regression\nproblem. To extend the cognition from rating to reasoning, a deeper\nunderstanding of aesthetics should be based on revealing why a high- or\nlow-aesthetic score should be assigned to an image. From such a point of view,\nwe propose a model referred to as Neural Aesthetic Image Reviewer, which can\nnot only give an aesthetic score for an image, but also generate a textual\ndescription explaining why the image leads to a plausible rating score.\nSpecifically, we propose two multi-task architectures based on shared\naesthetically semantic layers and task-specific embedding layers at a high\nlevel for performance improvement on different tasks. To facilitate researches\non this problem, we collect the AVA-Reviews dataset, which contains 52,118\nimages and 312,708 comments in total. Through multi-task learning, the proposed\nmodels can rate aesthetic images as well as produce comments in an end-to-end\nmanner. It is confirmed that the proposed models outperform the baselines\naccording to the performance evaluation on the AVA-Reviews dataset. Moreover,\nwe demonstrate experimentally that our model can generate textual reviews\nrelated to aesthetics, which are consistent with human perception.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Driver gaze has been shown to be an excellent surrogate for driver attention\nin intelligent vehicles. With the recent surge of highly autonomous vehicles,\ndriver gaze can be useful for determining the handoff time to a human driver.\nWhile there has been significant improvement in personalized driver gaze zone\nestimation systems, a generalized system which is invariant to different\nsubjects, perspectives and scales is still lacking. We take a step towards this\ngeneralized system using Convolutional Neural Networks (CNNs). We finetune 4\npopular CNN architectures for this task, and provide extensive comparisons of\ntheir outputs. We additionally experiment with different input image patches,\nand also examine how image size affects performance. For training and testing\nthe networks, we collect a large naturalistic driving dataset comprising of 11\nlong drives, driven by 10 subjects in two different cars. Our best performing\nmodel achieves an accuracy of 95.18% during cross-subject testing,\noutperforming current state of the art techniques for this task. Finally, we\nevaluate our best performing model on the publicly available Columbia Gaze\nDataset comprising of images from 56 subjects with varying head pose and gaze\ndirections. Without any training, our model successfully encodes the different\ngaze directions on this diverse dataset, demonstrating good generalization\ncapabilities.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  With the advent of small-scale prototype quantum computers, researchers can\nnow code and run quantum algorithms that were previously proposed but not fully\nimplemented. In support of this growing interest in quantum computing\nexperimentation, programmers need new tools and techniques to write and debug\nQC code. In this work, we implement a range of QC algorithms and programs in\norder to discover what types of bugs occur and what defenses against those bugs\nare possible in QC programs. We conduct our study by running small-sized QC\nprograms in QC simulators in order to replicate published results in QC\nimplementations. Where possible, we cross-validate results from programs\nwritten in different QC languages for the same problems and inputs. Drawing on\nthis experience, we provide a taxonomy for QC bugs, and we propose QC language\nfeatures that would aid in writing correct code.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We propose a global invariant $\\sigma_c$ for contact manifolds which admit a\nstrictly pseudoconvex CR structure, analogous to the Yamabe invariant $\\sigma$.\nWe prove that this invariant is non-decreasing under handle attaching and under\nconnected sum. We then give a lower bound on $\\sigma_c$ in a particular case.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Design of new wireless communication systems for industrial applications,\ne.g. control applications, is currently a hot research topic, as they deal as a\nkey enabler for more flexible solutions at a lower cost compared to systems\nbased on wired communication. However, one of their main drawbacks is, that\nthey provide a huge potential for miscellaneous cyber attacks due to the open\nnature of the wireless channel in combination with the huge economic potential\nthey are able to provide. Therefore, security measures need to be taken into\naccount for the design of such systems. Within this work, an approach for the\nsecurity architecture of local wireless systems with respect to the needs of\ncontrol applications is presented and discussed. Further, new security\nsolutions based on Physical Layer Security are introduced in order to overcome\nthe drawbacks of state of the art security technologies within that scope.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We introduce new tools for studying modular flow in AdS/CFT. These tools\nallow us to efficiently extract bulk information related to causality and\nlocality. For example, we discuss the relation between analyticity in modular\ntime and entanglement wedge nesting which can then be used to extract the\nlocation of the Ryu-Takayanagi (RT) surface directly from the boundary theory.\nProbing the RT surface close to the boundary our results reduce to the recent\nproof of the Quantum Null Energy Condition. We focus on heavy probe operators\nwhose correlation functions are determined by spacelike geodesics. These\ngeodesics interplay with the RT surface via a set of rules that we conjecture\nand give evidence for using the replica trick.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Star-forming regions on different scales, such as giant molecular clouds in\nour Galaxy and star-forming galaxies, emit GeV gamma-rays. These are thought to\noriginate from hadronic interactions of cosmic-ray (CR) nuclei with the\ninterstellar medium. It has recently been shown that the gamma-ray luminosity\n($L_\\gamma$) of star-forming galaxies is well correlated with their star\nformation rates (SFR). We investigated \\textsl{Fermi} data of eight Galactic\nmolecular clouds in the Gould belt and found that molecular clouds do not\nfollow the $L_\\gamma-{\\rm SFR}$ correlation of star-forming galaxies. We also\ncompared the scaling relations of gamma-ray luminosity, SFR, and the gas mass\nfor molecular clouds and star-forming galaxies. Using a multiple-variable\nregression analysis, we found different dependences of gamma-ray emission on\nSFR or mass for molecular clouds and star-forming galaxies. This suggests that\ndifferent mechanisms may govern the production of gamma-rays in these two types\nof sources. Specifically, the strong dependence on mass supports that gamma-ray\nemission of molecular clouds primarily comes from {\\em \\textup{passive}}\ninteraction by diffuse Galactic CRs, whereas the strong dependence on SFR\nsupports that gamma-ray emission of star-forming galaxies originates from CRs\nthat are accelerated by local {\\em \\textup{active}} sources.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recently, the LIGO-Virgo collaboration discovered gravitational waves and in\ntheir first publication on the subject the authors also presented a graviton\nmass constraint as $m_g < 1.2 \\times 10^{-22}$ eV (Abbott et al., 2016).\n  In the paper we analyze a potential to reduce upper bounds for graviton mass\nwith future observational data on trajectories of bright stars near the\nGalactic Center. Since gravitational potentials are different for these two\ncases, expressions for relativistic advance for general relativity and Yukawa\npotential are different functions on eccentricity and semimajor axis, it gives\nan opportunity to improve current estimates of graviton mass with future\nobservational facilities. In our considerations of an improvement potential for\na graviton mass estimate we adopt a conservative strategy and assume that\ntrajectories of bright stars and their apocenter advance will be described with\ngeneral relativity expressions and it gives opportunities to improve graviton\nmass constraints. In contrast with our previous studies, where we present\ncurrent constraints on parameters of Yukawa gravity (Borka et al., 2013) and\ngraviton mass (Zakharov et al., 2016) from observations of S2 star, in the\npaper we express expectations to improve current constraints for graviton mass,\nassuming the GR predictions about apocenter shifts will be confirmed with\nfuture observations. We concluded that if future observations of bright star\norbits during around fifty years will confirm GR predictions about apocenter\nshifts of bright star orbits it give an opportunity to constrain a graviton\nmass at a level around $5 \\times 10^{-23}$ eV or slightly better than current\nestimates obtained with LIGO observations.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Brain tumor is considered as one of the deadliest and most common form of\ncancer both in children and in adults. Consequently, determining the correct\ntype of brain tumor in early stages is of significant importance to devise a\nprecise treatment plan and predict patient's response to the adopted treatment.\nIn this regard, there has been a recent surge of interest in designing\nConvolutional Neural Networks (CNNs) for the problem of brain tumor type\nclassification. However, CNNs typically require large amount of training data\nand can not properly handle input transformations. Capsule networks (referred\nto as CapsNets) are brand new machine learning architectures proposed very\nrecently to overcome these shortcomings of CNNs, and posed to revolutionize\ndeep learning solutions. Of particular interest to this work is that Capsule\nnetworks are robust to rotation and affine transformation, and require far less\ntraining data, which is the case for processing medical image datasets\nincluding brain Magnetic Resonance Imaging (MRI) images. In this paper, we\nfocus to achieve the following four objectives: (i) Adopt and incorporate\nCapsNets for the problem of brain tumor classification to design an improved\narchitecture which maximizes the accuracy of the classification problem at\nhand; (ii) Investigate the over-fitting problem of CapsNets based on a real set\nof MRI images; (iii) Explore whether or not CapsNets are capable of providing\nbetter fit for the whole brain images or just the segmented tumor, and; (iv)\nDevelop a visualization paradigm for the output of the CapsNet to better\nexplain the learned features. Our results show that the proposed approach can\nsuccessfully overcome CNNs for the brain tumor classification problem.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We consider Lyapunov exponents for flat bundles over hyperbolic curves\ndefined via parallel transport over the geodesic flow. We refine a lower bound\nobtained by Eskin, Kontsevich, Moeller and Zorich showing that the sum of the\nfirst k exponents is greater or equal than the sum of the degree of any rank k\nholomorphic subbundle of the flat bundle and the asymptotic degree of its\nequivariant developing map. We also show that this inequality is an equality if\nthe base curve is compact. We moreover relate the asymptotic degree to the\ndynamical degree defined by Daniel and Deroin. We then use the previous results\nto study properties of Lyapunov exponents on variations of Hodge structures and\non Shatz strata of the de Rham moduli space. In particular we show that the top\nLyapunov exponent function is unbounded on the maximal Shatz stratum, the oper\nlocus. In the final part of the work we specialize to the rank two case,\ngeneralizing a result of Deroin and Dujardin about Lyapunov exponents of\nholonomies of projective structures.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the resonant dipole-dipole interaction energy between two uniformly\naccelerated identical atoms, one excited and the other in the ground state,\nprepared in a correlated {\\em Bell-type} state, and interacting with the scalar\nfield or the electromagnetic field nearby a perfectly reflecting plate. We\nsuppose the two atoms moving with the same uniform acceleration, parallel to\nthe plane boundary, and that their separation is constant during the motion. We\nseparate the contributions of vacuum fluctuations and radiation reaction field\nto the resonance energy shift of the two-atom system, and show that Unruh\nthermal fluctuations do not affect the resonance interaction, which is\nexclusively related to the radiation reaction field. However, nonthermal\neffects of acceleration in the radiation-reaction contribution, beyond the\nUnruh acceleration-temperature equivalence, affect the resonance interaction\nenergy. By considering specific geometric configurations of the two-atom system\nrelative to the plate, we show that the presence of the mirror significantly\nmodifies the resonance interaction energy between the two accelerated atoms. In\nparticular, we find that new and different features appear with respect to the\ncase of atoms in the free space, related to the presence of the boundary and to\nthe peculiar structure of the quantum electromagnetic field vacuum in the\nlocally inertial frame. Our results suggest the possibility to exploit the\nresonance interaction between accelerated atoms, as a probe for detecting the\nelusive effects of atomic acceleration on radiative processes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Given the recent detection of gravitational waves from individual sources it\nis almost a certainty that some form of background of gravitational waves will\nbe detected in future. The most promising candidate for such a detection are\nbackgrounds made up of incoherent superposition of the signal of unresolved\nastrophysical or, backgrounds sourced by earlier cosmological events. Such\nbackgrounds will also contain anisotropies about an average value. The\ninformation contained in the background level and any anisotropies will be\nextremely valuable as an astrophysical and cosmological probe. As such, the\nability to reconstruct sky maps of the signal will become important as the\nsensitivity increases. We build and test a pixel--based, maximum--likelihood\nGravitational Wave Background (GWB) map-maker that uses the cross-correlation\nof sets of generalised baselines as input. The resulting maps are a\nrepresentation of the GWB power, or strain \"intensity\" on the sky. We test the\nalgorithm by reconstructing known input maps with different baseline\nconfigurations. We also apply the map-maker to a subset of the Advance LIGO\ndata.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We prove the existence of multi-soliton and kink-multi-soliton solutions of\nthe Euler-Korteweg system in dimension one. Such solutions behaves\nasymptotically in time like several traveling waves far away from each other. A\nkink is a traveling wave with different limits at $\\pm$$\\infty$. The main\nassumption is the linear stability of the solitons, and we prove that this\nassumption is satisfied at least in the transonic limit. The proof relies on a\nclassical approach based on energy estimates and a compactness argument.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  For successful object manipulation with robotic hands, it is important to\nensure that the object remains in the grasp at all times. In addition to grasp\nconstraints associated with slipping and singular hand configurations,\nexcessive rolling is an important grasp concern where the contact points roll\noff of the fingertip surface. Related literature focus only on a subset of\ngrasp constraints, or assume grasp constraint satisfaction without providing\nguarantees of such a claim. In this paper, we propose a control approach that\nsystematically handles all grasp constraints. The proposed controller ensures\nthat the object does not slip, joints do not exceed joint angle constraints\n(e.g. reach singular configurations), and the contact points remain in the\nfingertip workspace. The proposed controller accepts a nominal manipulation\ncontrol, and ensures the grasping constraints are satisfied to support the\nassumptions made in the literature. Simulation results validate the proposed\napproach.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Computations, where the number of results is much smaller than the input data\nand are produced through some sort of accumulation, are called Reductions.\nReductions appear in many scientific applications. Usually, reductions admit an\nassociative and commutative binary operator over accumulation. Reductions are\ntherefore highly parallel. Given unbounded fan-in, one can execute a reduction\nin constant/linear time provided that the data is available. However, due to\nthe fact that real machines have bounded fan-in, accumulations cannot be\nperformed in one time step and have to be broken into parts. Thus, a (partial)\nserialization of reductions becomes necessary. This makes scheduling reductions\na difficult and interesting problem.\n  There have been a number of research works in the context of scheduling\nreductions. We focus on the scheduling techniques presented in Gupta et al.,\nidentify a potential issue in their scheduling algorithm and provide a\nsolution. In addition, we demonstrate how these scheduling techniques can be\nextended to \"tile\" reductions and briefly survey other studies that address the\nproblem of scheduling reductions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Motivated by the recent experiments that reported signatures of many-body\nlocalization of ultracold atoms in optical lattices [M. Schreiber {\\it et al.},\nScience {\\bf 349}, 842 (2015)], we study dynamics of highly excited states in\nthe strongly disordered Hubbard model in one dimension. Owing to the $SU(2)$\nspin symmetry, spin degrees of freedom form a delocalized thermal bath with a\nnarrow bandwidth. The spin bath mediates slow particle transport, eventually\nleading to delocalization of particles. The particle hopping rate is\nexponentially small in $t/W$ ($t$, $W$ being hopping and disorder scales) owing\nto the narrow bandwidth of the spin bath. We find the optimal lenghtscale for\nparticle hopping, and show that the particle transport rate depends strongly on\nthe density of singly occupied sites in the initial state. The delocalization\nrate is zero for initial states with only doubly occupied or empty sites,\nsuggesting that such states are truly many-body localized, and therefore the\nHubbard model may host both localized and delocalized states. Full many-body\nlocalization can be induced by breaking spin rotational symmetry.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Recent JLAB measurements of inclusive (e,A) cross sections as a function of\noutgoing lepton momentum may provide information on the nucleon spectral\nfunction in targets that will be relevant for the planned DUNE neutrino\nlong-baseline experiment. They also provide an important testing ground for\nneutrino generators. We have therefore used the transport theoretical framework\nand code GiBUU to calculate the cross sections for the targets C, Ar and Ti. We\ncompare the calculations with the experimental data. The overall agreement is\ngood. Relatively small discrepancies appear mainly on the low-electronenergy\nside of the QE-peak where QE and 2p2h excitation processes overlap.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The 16O nucleus was investigated through the 15N(p,{\\alpha})12C reaction at\nexcitation energies from Ex = 12 231 to 15 700 keV using proton beams from a 5\nMeV Van de Graaff accelerator at beam energies of Ep = 331 to 3800 keV. Alpha\ndecay from resonant states in 16O was strongly observed for ten known excited\nstates in this region. The candidate 4-alpha cluster state at Ex = 15.1 MeV was\ninvestigated particularly intensely in order to understand its particle decay\nchannels.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the SPHINX suite of cosmological adaptive mesh refinement\nsimulations, the first radiation-hydrodynamical simulations to simultaneously\ncapture large-scale reionization and the escape of ionizing radiation from\nthousands of resolved galaxies. Our $5$ and $10$ co-moving Mpc volumes resolve\nhaloes down to the atomic cooling limit and model the inter-stellar medium with\nbetter than $\\approx10$ pc resolution. The project has numerous goals in\nimproving our understanding of reionization and making predictions for future\nobservations. In this first paper we study how the inclusion of binary stars in\ncomputing stellar luminosities impacts reionization, compared to a model that\nincludes only single stars. Owing to the suppression of galaxy growth via\nstrong feedback, our galaxies are in good agreement with observational\nestimates of the galaxy luminosity function. We find that binaries have a\nsignificant impact on the timing of reionization: with binaries, our boxes are\n$99.9$ percent ionized by volume at $z\\approx 7$, while without them our\nvolumes fail to reionize by $z=6$. These results are robust to changes in\nvolume size, resolution, and feedback efficiency. The escape of ionizing\nradiation from individual galaxies varies strongly and frequently. On average,\nbinaries lead to escape fractions of $\\approx 7-10$ percent, about $3.5$ times\nhigher than with single stars only. The higher escape fraction is a result of a\nshallower decline in ionizing luminosity with age, and is the primary reason\nfor earlier reionization, although the higher integrated luminosity with\nbinaries also plays a sub-dominant role.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The filamentary infrared dark cloud L1287 is actively forming a dense cluster\nof low-mass YSOs at its inner $\\sim$0.1 pc region. To help understand the\norigin of this low-mass YSO cluster, the present work aims at resolving the gas\nstructures and kinematics. We have performed $\\sim$1$\"$ angular resolution\n($\\sim$930 AU) SMA observations at $\\sim$1.3 mm. From a $\\sim$2$\"$ resolution\n1.3 mm continuum image we identified six dense cores, namely SMA1-6 with masses\nin the range of $\\sim0.4-4$ M$_\\odot$. From a $\\sim$1$\"$ resolution 1.3 mm\ncontinuum image, we find a high fragmentation level, with 14 compact millimeter\nsources within 0.1 pc (two of them associated with the known accretion outburst\nYSOs RNO 1C and RNO 1B). The dense gas tracer DCN (3--2) traces well the dust\ncontinuum emission and shows a clear velocity gradient along the NW-SE\ndirection centered at SMA3. There is another velocity gradient with opposite\ndirection around the most luminous YSO IRAS 00338+6312. The fragmentation\nwithin 0.1 pc in L1287 is very high compared to other regions at the same\nspatial scales. The incoherent motions of dense gas flows are sometimes\ninterpreted by being influenced by (proto)stellar feedback (e.g., outflows),\nwhich is not yet ruled out in this particular target source. The directions of\nthe velocity gradients traced by DCN are approximately perpendicular to those\nof the dominant CO outflow(s). Therefore, we alternatively hypothesize that the\nvelocity gradients revealed by DCN trace the convergence from the $\\gtrsim$0.1\npc scales infalling motion towards the rotational motions around the more\ncompact ($\\sim0.02$ pc) sources. This global molecular gas converging flow may\nfeed the formation of the dense low-mass YSO cluster. IRAS 00338+6312 is the\nmost likely powering source of the dominant CO outflow. A compact blue-shifted\noutflow from RNO 1C is also identified.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The Dirac-Hartree-Fock plus many-body perturbation theory (DHF+MBPT) method\nhas been used to calculate hyperfine structure constants for Fr. Calculated\nhyperfine structure anomaly for hydrogen-like ion has been shown to be in good\nagreement with analytical expressions. It has been shown that the ratio of the\nanomalies for $s$ and $p_{1/2}$ states is weakly dependent on the principal\nquantum number. Finally, we estimate Bohr--Weisskopf corrections for several Fr\nisotopes. Our results may be used to improve experimental accuracy for the\nnuclear $g$ factors of short-lived isotopes.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present a variational renormalization group (RG) approach using a deep\ngenerative model based on normalizing flows. The model performs hierarchical\nchange-of-variables transformations from the physical space to a latent space\nwith reduced mutual information. Conversely, the neural net directly maps\nindependent Gaussian noises to physical configurations following the inverse RG\nflow. The model has an exact and tractable likelihood, which allows unbiased\ntraining and direct access to the renormalized energy function of the latent\nvariables. To train the model, we employ probability density distillation for\nthe bare energy function of the physical problem, in which the training loss\nprovides a variational upper bound of the physical free energy. We demonstrate\npractical usage of the approach by identifying mutually independent collective\nvariables of the Ising model and performing accelerated hybrid Monte Carlo\nsampling in the latent space. Lastly, we comment on the connection of the\npresent approach to the wavelet formulation of RG and the modern pursuit of\ninformation preserving RG.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Secure firmware update is an important stage in the IoT device life-cycle.\nPrior techniques, designed for other computational settings, are not readily\nsuitable for IoT devices, since they do not consider idiosyncrasies of a\nrealistic large-scale IoT deployment. This motivates our design of ASSURED, a\nsecure and scalable update framework for IoT. ASSURED includes all stakeholders\nin a typical IoT update ecosystem, while providing end-to-end security between\nmanufacturers and devices. To demonstrate its feasibility and practicality,\nASSURED is instantiated and experimentally evaluated on two commodity hardware\nplatforms. Results show that ASSURED is considerably faster than current update\nmechanisms in realistic settings.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Orbital angular momentum (OAM) carried by helical light beams is an unbounded\ndegree of freedom of photons that offers a promising playground in modern\nphotonics. So far, integrated sources of coherent light carrying OAM are based\non resonators whose design imposes a single, non-tailorable chirality of the\nwavefront (i.e. clockwise or counter clockwise vortices). Here, we propose and\ndemonstrate the realization of an integrated microlaser where the chirality of\nthe wavefront can be optically controlled. Importantly, the scheme that we use,\nbased on an effective spin-orbit coupling of photons in a semiconductor\nmicrocavity, can be extended to different laser architectures, thus paving the\nway to the realization of a new generation of OAM microlasers with tunable\nchirality.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Seven temperate Earth-sized exoplanets readily amenable for atmospheric\nstudies transit the nearby ultracool dwarf star TRAPPIST-1 (refs 1,2). Their\natmospheric regime is unknown and could range from extended primordial\nhydrogen-dominated to depleted atmospheres (refs 3-6). Hydrogen in particular\nis a powerful greenhouse gas that may prevent the habitability of inner planets\nwhile enabling the habitability of outer ones (refs 6-8). An atmosphere largely\ndominated by hydrogen, if cloud-free, should yield prominent spectroscopic\nsignatures in the near-infrared detectable during transits. Observations of the\ninnermost planets have ruled out such signatures (ref 9). However, the\noutermost planets are more likely to have sustained such a Neptune-like\natmosphere (refs 10,11). Here, we report observations for the four planets\nwithin or near the system's habitable zone, the circumstellar region where\nliquid water could exist on a planetary surface (refs 12-14). These planets do\nnot exhibit prominent spectroscopic signatures at near-infrared wavelengths\neither, which rules out cloud-free hydrogen-dominated atmospheres for\nTRAPPIST-1 d, e and f, with significance of 8, 6 and 4 sigma, respectively.\nSuch an atmosphere is instead not excluded for planet g. As high-altitude\nclouds and hazes are not expected in hydrogen-dominated atmospheres around\nplanets with such insolation (refs 15,16), these observations further support\ntheir terrestrial and potentially habitable nature.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Stellar coronal mass ejections remain experimentally unconstrained, unlike\ntheir stellar flare counterparts which are observed ubiquitously across the\nelectromagnetic spectrum. Low frequency radio bursts in the form of a type II\nburst offer the best means of identifying and constraining the rate and\nproperties of stellar CMEs. CME properties can be further improved through the\nuse of proposed solar-stellar scaling relations and multi-wavelength\nobservations of CMEs through the use of type II bursts and the associated flare\nexpected to occur occur alongside. We report on 20 hours of observation of the\nnearby, magnetically active, and well characterized M dwarf star EQ Peg. The\nobservations are simultaneously observed with the Jansky Very Large Array at\ntheir P-band (230-470 MHz) and at the Apache Point observatory in the SDSS u'\nfilter ($\\lambda$ = 3557 \\AA). Dynamic spectra of the P band data, constructed\nto search for signals in the frequency-time domains, did not reveal evidence\nfor drifting radio bursts that could be ascribed to type II bursts. Given the\nsensitivity of our observations, we are able to place limits on the brightness\ntemperature and source size of any bursts which may have occurred. Using solar\nscaling rations on four observed stellar flares, we predict CME parameters.\nGiven the constraints on coronal density and photospheric field strength, our\nmodels suggest that the observed flares would have been insufficient to produce\ndetectable type II bursts at our observed frequencies. We consider the\nimplications of these results, and other recent findings, on stellar mass loss.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We have obtained a smooth time series for the Electric Vector Position Angle\n(EVPA) of the blazar OJ 287 at centimeter wavelengths, by making $\\pm n\\pi$\nadjustments to archival values from 1974 to 2016. The data display rotation\nreversals in which the EVPA rotates counter-clockwise (CCW) for 180 deg and\nthen rotates clockwise (CW) by a similar amount. The time scale of the\nrotations is a few weeks to a year, and the scale for a double rotation,\nincluding the reversal, is one to three years. We have seen four of these\nevents in 40 years. A model consisting of two successive outbursts in polarized\nflux density, with EVPAs counter-rotating, superposed on a steady polarized\njet, can explain many of the details of the observations. Polarization images\nsupport this interpretation. The model can also help to explain similar events\nseen at optical wavelengths. The outbursts needed for the model can be\ngenerated by the super-magnetosonic jet model of Nakamura et al. (2010) and\nNakamura and Meier (2014), which requires a strong helical magnetic field. This\nmodel produces forward and reverse pairs of fast and slow MHD waves, and the\nplasma inside the two fast/slow pairs rotates around the jet axis, but in\nopposite directions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  The aim of this paper is two-fold. We first prove several new interpretations\nof a kind of $(q,t)$-Catalan numbers along with their corresponding\n$\\gamma$-expansions using pattern avoiding permutations. Secondly, we give a\ncomplete characterization of certain $(-1)$-phenomenon for each subset of\npermutations avoiding a single pattern of length three, and discuss their\n$q$-analogues utilizing the newly obtained $q$-$\\gamma$-expansions, as well as\nthe continued fraction of a quint-variate generating function due to Shin and\nthe fourth author. Moreover, we enumerate the alternating permutations avoiding\nsimultaneously two patterns, namely $(2413,3142)$ and $(1342,2431)$, of length\nfour, and consider such $(-1)$-phenomenon for these two subsets as well.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Sign recognition is an integral part of autonomous cars. Any\nmisclassification of traffic signs can potentially lead to a multitude of\ndisastrous consequences, ranging from a life-threatening accident to even a\nlarge-scale interruption of transportation services relying on autonomous cars.\nIn this paper, we propose and examine security attacks against sign recognition\nsystems for Deceiving Autonomous caRs with Toxic Signs (we call the proposed\nattacks DARTS). In particular, we introduce two novel methods to create these\ntoxic signs. First, we propose Out-of-Distribution attacks, which expand the\nscope of adversarial examples by enabling the adversary to generate these\nstarting from an arbitrary point in the image space compared to prior attacks\nwhich are restricted to existing training/test data (In-Distribution). Second,\nwe present the Lenticular Printing attack, which relies on an optical\nphenomenon to deceive the traffic sign recognition system. We extensively\nevaluate the effectiveness of the proposed attacks in both virtual and\nreal-world settings and consider both white-box and black-box threat models.\nOur results demonstrate that the proposed attacks are successful under both\nsettings and threat models. We further show that Out-of-Distribution attacks\ncan outperform In-Distribution attacks on classifiers defended using the\nadversarial training defense, exposing a new attack vector for these defenses.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We present the Mixed Likelihood Gaussian process latent variable model\n(GP-LVM), capable of modeling data with attributes of different types. The\nstandard formulation of GP-LVM assumes that each observation is drawn from a\nGaussian distribution, which makes the model unsuited for data with e.g.\ncategorical or nominal attributes. Our model, for which we use a sampling based\nvariational inference, instead assumes a separate likelihood for each observed\ndimension. This formulation results in more meaningful latent representations,\nand give better predictive performance for real world data with dimensions of\ndifferent types.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  This paper presents a library of second-order models for synchronous machines\nthat can be utilized in power system dynamic performance analysis and control\ndesign tasks. The models have a similar structure to the classical model in\nthat they consist of two dynamic states, the power angle and the angular speed.\nHowever, unlike the classical model, the models find applications beyond first\nswing stability analysis; for example, they can also be utilized in transient\nstability studies. The models are developed through a systematic reduction of a\nnineteenth-order model, using singular perturbation techniques, and they are\nvalidated by comparing their voltage, frequency, and phase profiles with that\nof the high-order model and that of the classical model.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Double-stranded DNA may contain mismatched base pairs beyond the Watson-Crick\npairs guanine-cytosine and adenine-thymine. Such mismatches bear adverse\nconsequences for human health. We utilize molecular dynamics and metadynamics\ncomputer simulations to study the equilibrium structure and dynamics for both\nmatched and mismatched base pairs. We discover significant differences between\nmatched and mismatched pairs in structure, hydrogen bonding, and base flip work\nprofiles. Mismatched pairs shift further in the plane normal to the DNA strand\nand are more likely to exhibit non-canonical structures, including the e-motif.\nWe discuss potential implications on mismatch repair enzymes' detection of DNA\nmismatches.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  Not all smartphone owners use their device in the same way. In this work, we\nuncover broad, latent patterns of mobile phone use behavior. We conducted a\nstudy where, via a dedicated logging app, we collected daily mobile phone\nactivity data from a sample of 340 participants for a period of four weeks.\nThrough an unsupervised learning approach and a methodologically rigorous\nanalysis, we reveal five generic phone use profiles which describe at least 10%\nof the participants each: limited use, business use, power use, and\npersonality- & externally induced problematic use. We provide evidence that\nintense mobile phone use alone does not predict negative well-being. Instead,\nour approach automatically revealed two groups with tendencies for lower\nwell-being, which are characterized by nightly phone use sessions.\n\n\n###\n\n", "completion": " 18\n"}
{"prompt": "  We study the influence of spinless impurities on a frustrated magnet\nfeaturing a spin-density wave (stripe) phase by means of Monte Carlo\nsimulations. We demonstrate that the interplay between the impurities and an\norder parameter that breaks a real-space symmetry triggers the emergence of a\nrandom-field mechanism which destroys the stripe-ordered phase. Importantly,\nthe strength of the emerging random fields can be tuned by the repulsion\nbetween the impurity atoms; they vanish for perfect anticorrelations between\nneighboring impurities. This provides a novel way of controlling the phase\ndiagram of a many-particle system. In addition, we also investigate the effects\nof the impurities on the character of the phase transitions between the\nstripe-ordered, ferromagnetic, and paramagnetic phases.\n\n\n###\n\n", "completion": " 18\n"}
