{"prompt": "  We study the spectral asymptotics of nodal (i.e., sign-changing) solutions of\nthe problem\n  \\begin{equation*} (H) \\qquad \\qquad \\left \\{\n  \\begin{aligned}\n  -\\Delta u &=|x|^\\alpha |u|^{p-2}u&&\\qquad \\text{in ${\\bf B}$,} \\\\\n  u&=0&&\\qquad \\text{on $\\partial {\\bf B}$,}\n  \\end{aligned}\n  \\right.\n  \\end{equation*}\n  in the unit ball ${\\bf B} \\subset \\mathbb{R}^N,N\\geq 3$, $p>2$ in the limit\n$\\alpha \\to +\\infty$. More precisely, for a given positive integer $K$, we\nderive asymptotic $C^1$-expansions for the negative eigenvalues of the\nlinearization of the unique radial solution $u_\\alpha$ of $(H)$ with precisely\n$K$ nodal domains and $u_\\alpha(0)>0$. As an application, we derive the\nexistence of an unbounded sequence of bifurcation points on the radial solution\nbranch $\\alpha \\mapsto (\\alpha,u_\\alpha)$ which all give rise to bifurcation of\nnonradial solutions whose nodal sets remain homeomorphic to a disjoint union of\nconcentric spheres.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this survey we explain the results of the recent article arXiv:1806.06471.\nFollowing a 1973 article by Lawvere one can define metrics on categories, and\nfollowing Kelly's 1982 book one can complete a category with respect to its\nmetric. We specialize these general constructions to triangulated categories,\nand restrict our attention to \"good metrics\". And the remarkable new theorem is\nthat, when we start with a triangulated category $\\mathcal S$ with a good\nmetric, its completion $\\mathfrak{L}(\\mathcal{S})$ contains an interesting\nsubcategory $\\mathfrak{S}(\\mathcal{S})$ which is always triangulated.\n  As special cases we obtain $\\mathcal{H}^0(\\mathrm{Perf}(X))$ and\n$D^b_{\\mathrm{coh}}(X)$ from each other. We also give a couple of other\nexamples.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Inverse rendering aims to estimate physical attributes of a scene, e.g.,\nreflectance, geometry, and lighting, from image(s). Inverse rendering has been\nstudied primarily for single objects or with methods that solve for only one of\nthe scene attributes. We propose the first learning-based approach that jointly\nestimates albedo, normals, and lighting of an indoor scene from a single image.\nOur key contribution is the Residual Appearance Renderer (RAR), which can be\ntrained to synthesize complex appearance effects (e.g., inter-reflection, cast\nshadows, near-field illumination, and realistic shading), which would be\nneglected otherwise. This enables us to perform self-supervised learning on\nreal data using a reconstruction loss, based on re-synthesizing the input image\nfrom the estimated components. We finetune with real data after pretraining\nwith synthetic data. To this end, we use physically-based rendering to create a\nlarge-scale synthetic dataset, which is a significant improvement over prior\ndatasets. Experimental results show that our approach outperforms\nstate-of-the-art methods that estimate one or more scene attributes.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The Fourier extension method, also known as the Fourier continuation method,\nis a method for approximating non-periodic functions on an interval using\ntruncated Fourier series with period larger than the interval on which the\nfunction is defined. When the function being approximated is known at only\nfinitely many points, the approximation is constructed as a projection based on\nthis discrete set of points. In this paper we address the issue of estimating\nthe absolute error in the approximation. The error can be expressed in terms of\na system of discrete orthogonal polynomials on an arc of the unit circle, and\nthese polynomials are then evaluated asymptotically using Riemann--Hilbert\nmethods.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We revisit the geometry of involutions in groups of finite Morley rank. Our\napproach unifies and generalises numerous results, both old and recent, that\nhave exploited this geometry; though in fact, we prove much more. We also\nconjecture that this path leads to a new identification theorem for\n$\\operatorname{PGL}_2(\\mathbb{K})$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We studied the charge radius, rms radius and neutron skin thickness $\\Delta\nr_{np}$ in even-even isotopes of Si, S, Ar and Ca and isotones of N =20, 28, 50\nand 82. The $\\Delta r_{np}$ in doubly-magic $^{48}$Ca, $^{68}$Ni,\n$^{120,132}$Sn and $^{208}$Pb nuclei has also been calculated. Theoretical\ncalculations are done with the Hartree-Fock-Bogoliubov theory with the\neffective Skyrme interactions. Calculated theoretical estimates are in good\nagreement with the recently available experimental data. The charge radii for\nSi, S, Ar and Ca isotopes is observed to be minimum at neutron number N =14.\nThe theoretically computed results with UNEDF0 model parameterization of\nfunctional are reasonably reproducing the experimental data for $\\Delta r_{np}$\nin $^{48}$Ca, $^{68}$Ni and $^{120,132}$Sn. The energy density functional of\nUNEDF1 model provides much improved result of $\\Delta r_{np}$ for $^{208}$Pb.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A general mathematical framework and recovery algorithm is presented for the\nholographic phase retrieval problem. In this problem, which arises in\nholographic coherent diffraction imaging, a \"reference\" portion of the signal\nto be recovered via phase retrieval is a priori known from experimental design.\nA generic formula is also derived for the expected recovery error when the\nmeasurement data is corrupted by Poisson shot noise. This facilitates an\noptimization perspective towards reference design and analysis. We employ this\noptimization perspective towards quantifying the performance of various\nreference choices.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We determine the small Bjorken $x$ asymptotics of the quark and gluon orbital\nangular momentum (OAM) distributions in the proton in the double-logarithmic\napproximation (DLA), which resums powers of $\\alpha_s \\ln^2 (1/x)$ with\n$\\alpha_s$ the strong coupling constant. Starting with the operator definitions\nfor the quark and gluon OAM, we simplify them at small $x$, relating them,\nrespectively, to the polarized dipole amplitudes for the quark and gluon\nhelicities defined in our earlier works. Using the small-$x$ evolution\nequations derived for these polarized dipole amplitudes earlier we arrive at\nthe following small-$x$ asymptotics of the quark and gluon OAM distributions in\nthe large-$N_c$ limit:\n  \\begin{align}\n  L_{q + \\bar{q}} (x, Q^2) = - \\Delta \\Sigma (x, Q^2) \\sim\n  \\left(\\frac{1}{x}\\right)^{\\frac{4}{\\sqrt{3}} \\, \\sqrt{\\frac{\\alpha_s\n  \\, N_c}{2 \\pi}} }, \\ \\ \\ \\ \\\n  L_G (x, Q^2) \\sim \\Delta G (x, Q^2) \\sim\n  \\left(\\frac{1}{x}\\right)^{\\frac{13}{4 \\sqrt{3}} \\, \\sqrt{\\frac{\\alpha_s\n  \\, N_c}{2 \\pi}}} . \\end{align}\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  This book describes some computational methods to deal with modular\ncharacters of finite groups. It is the theoretical background of the MOC system\nof the same authors. This system was, and is still used, to compute the modular\ncharacter tables of sporadic simple groups.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Due to the ability of deep neural nets to learn rich representations, recent\nadvances in unsupervised domain adaptation have focused on learning\ndomain-invariant features that achieve a small error on the source domain. The\nhope is that the learnt representation, together with the hypothesis learnt\nfrom the source domain, can generalize to the target domain. In this paper, we\nfirst construct a simple counterexample showing that, contrary to common\nbelief, the above conditions are not sufficient to guarantee successful domain\nadaptation. In particular, the counterexample exhibits \\emph{conditional\nshift}: the class-conditional distributions of input features change between\nsource and target domains. To give a sufficient condition for domain\nadaptation, we propose a natural and interpretable generalization upper bound\nthat explicitly takes into account the aforementioned shift. Moreover, we shed\nnew light on the problem by proving an information-theoretic lower bound on the\njoint error of \\emph{any} domain adaptation method that attempts to learn\ninvariant representations. Our result characterizes a fundamental tradeoff\nbetween learning invariant representations and achieving small joint error on\nboth domains when the marginal label distributions differ from source to\ntarget. Finally, we conduct experiments on real-world datasets that corroborate\nour theoretical findings. We believe these insights are helpful in guiding the\nfuture design of domain adaptation and representation learning algorithms.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Converting a set of sequencing reads into a lossless compact data structure\nthat encodes all the relevant biological information is a major challenge. The\nclassical approaches are to build the string graph or the de Bruijn graph. Each\nhas advantages over the other depending on the application. Still, the ideal\nsetting would be to have an index of the reads that is easy to build and can be\nadapted to any type of biological analysis. In this paper, we propose a new\ndata structure we call rBOSS, which gets close to that ideal. Our rBOSS is a de\nBruijn graph in practice, but it simulates any length up to k and can compute\noverlaps of size at least m between the labels of the nodes, with k and m being\nparameters. If we choose the parameter k equal to the size of the reads, then\nwe can simulate a complete string graph. As most BWT-based structures, rBOSS is\nunidirectional, but it exploits the property of the DNA reverse complements to\nsimulate bi-directionality with some time-space trade-offs. We implemented a\ngenome assembler on top of rBOSS to demonstrate its usefulness. Our\nexperimental results show that using k = 100, rBOSS can assemble 185 MB of\nreads in less than 15 minutes and using 110 MB in total. It produces contigs of\nmean sizes over 10,000, which is twice the size obtained by using a pure de\nBruijn graph of fixed length k.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A common approach to implementing similarity search applications is the usage\nof distance functions, where small distances indicate high similarity. In the\ncase of metric distance functions, metric index structures can be used to\naccelerate nearest neighbor queries. On the other hand, many applications ask\nfor approximate subsequences or subsets, e.g. searching for a similar partial\nsequence of a gene, for a similar scene in a movie, or for a similar object in\na picture which is represented by a set of multidimensional features. Metric\nindex structures such as the M-Tree cannot be utilized for these tasks because\nof the symmetry of the metric distance functions. In this work, we propose the\nSuperM-Tree as an extension of the M-Tree where approximate subsequence and\nsubset queries become nearest neighbor queries. In order to do this, we\nintroduce metric subset spaces as a generalized concept of metric spaces.\nVarious metric distance functions can be extended to metric subset distance\nfunctions, e.g. the Euclidean distance (on windows), the Hausdorff distance (on\nsubsets), the Edit distance and the Dog-Keeper distance (on subsequences). We\nshow that these examples subsume the applications mentioned above.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Knowledge graphs have recently become the state-of-the-art tool for\nrepresenting the diverse and complex knowledge of the world. Examples include\nthe proprietary knowledge graphs of companies such as Google, Facebook, IBM, or\nMicrosoft, but also freely available ones such as YAGO, DBpedia, and Wikidata.\nA distinguishing feature of Wikidata is that the knowledge is collaboratively\nedited and curated. While this greatly enhances the scope of Wikidata, it also\nmakes it impossible for a single individual to grasp complex connections\nbetween properties or understand the global impact of edits in the graph. We\napply Formal Concept Analysis to efficiently identify comprehensible\nimplications that are implicitly present in the data. Although the complex\nstructure of data modelling in Wikidata is not amenable to a direct approach,\nwe overcome this limitation by extracting contextual representations of parts\nof Wikidata in a systematic fashion. We demonstrate the practical feasibility\nof our approach through several experiments and show that the results may lead\nto the discovery of interesting implicational knowledge. Besides providing a\nmethod for obtaining large real-world data sets for FCA, we sketch potential\napplications in offering semantic assistance for editing and curating Wikidata.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The Fuglede conjecture states that a set is spectral if and only if it tiles\nby translation. The conjecture was disproved by T. Tao for dimensions 5 and\nhigher by giving a counterexample in $\\mathbb{Z}_3^5$. We present a computer\nprogram that determines that the Fuglede conjecture holds in $\\mathbb{Z}_5^3$\nby exhausting the search space. A. Iosevich, A. Mayeli and J. Pakianathan\nshowed that the Fuglede conjecture holds over prime fields when the dimension\ndoes not exceed 2. The question for dimension 3 was previously addressed by\nAten et al. for $p=3$. In this paper we build upon the results of their work to\nallow a computer to carry out the lengthy computations.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We perform a parameter-free calculation for the high-energy proton-nucleus\nscattering based on the Glauber theory. A complete evaluation of the so-called\nGlauber amplitude is made by using the factorization of the single-particle\nwave functions. The multiple-scattering or multistep processes are fully taken\ninto account within the Glauber theory. We demonstrate that proton- $^{12}$C,\n$^{20}$Ne, and $^{28}$Si elastic and inelastic scattering ($J^\\pi=0^+ \\to 2^+$\nand $0^+ \\to 4^+$) processes are very well described in a wide range of the\nincident energies from $\\sim$50 MeV to $\\sim$ 1 GeV. We evaluate the validity\nof a simple one-step approximation andfind that the approximation works fairly\nwell for the inelastic $0^+ \\to 2^+$ processes but not for $0^+ \\to 4^+$ where\nthe multistep processes become more important. As an application, we quantify\nthe difference between the total reaction and interaction cross sections of\nproton-$^{12}$C, $^{20}$Ne, and $^{28}$Si collisions.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Smart grid has integrated an increasing number of distributed energy\nresources to improve the efficiency and flexibility of power generation and\nconsumption as well as the resilience of the power grid. The energy consumers\non the power grid (e.g., households) equipped with the distributed energy\nresources can be considered as \"microgrids\" that both generate and consume\nelectricity. In this paper, we study the energy community discovery problems\nwhich identify multiple kinds of energy communities for the microgrids to\nfacilitate energy management (e.g., power supply adjustment, load balancing,\nenergy sharing) on the grid, such as homogeneous energy communities (HECs),\nmixed energy communities (MECs), and self-sufficient energy communities (SECs).\nSpecifically, we present efficient algorithms to discover such communities of\nmicrogrids by taking into account not only their geo-locations but also their\nnet energy over any period. Finally, we experimentally validate the performance\nof the algorithms using both synthetic and real datasets.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The cosmic electron energy spectrum recently observed by the DAMPE experiment\nexhibits two interesting features, including a break around 0.9 TeV and a sharp\nresonance near 1.4 TeV. In this analysis, we propose a dark matter explanation\nto both exotic features seen by DAMPE. In our model, dark matter annihilates in\nthe galaxy via two different channels that lead to both a narrow resonance\nspectrum near 1.4 TeV and electron excess events over an extended energy range\nthus generating the break structure around TeV. The two annihilation channels\nare mediated by two gauge bosons that interact both with dark matter and with\nthe standard model fermions. Dark matter annihilations through the s-channel\nprocess mediated by the heavier boson produce monoenergetic electron-positron\npairs leading to the resonance excess. The lighter boson has a mass smaller\nthan the dark matter such that they can be on-shell produced in dark matter\nannihilations in the galaxy; the lighter bosons in the final state subsequently\ndecay to generate the extended excess events due to the smeared electron energy\nspectrum in this process. We further analyze constraints from various\nexperiments, including HESS, Fermi, AMS, and LHC, to the parameter space of the\nmodel where both excess events can be accounted for. In order to interpret the\ntwo new features in the DAMPE data, dark matter annihilation cross sections in\nthe current galaxy are typically much larger than the canonical thermal cross\nsection needed for the correct dark matter relic abundance. This discrepancy,\nhowever, is remedied by the nonperturbative Sommerfeld enhancement because of\nthe existence of a lighter mediator in the model.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In most classical holomorphic function spaces on the unit disk in which the\npolynomials are dense, a function $f$ can be approximated in norm by its\ndilates $f_r(z):=f(rz)~(r<1)$, in other words, $\\lim_{r\\to1^-}\\|f_r-f\\|=0$. We\nconstruct a de Branges-Rovnyak space ${\\mathcal H}(b)$ in which the polynomials\nare dense, and a function $f\\in{\\mathcal H}(b)$ such that\n$\\lim_{r\\to1^-}\\|f_r\\|_{{\\mathcal H}(b)}=\\infty$. The essential feature of our\nconstruction lies in the fact that $b$ is an outer function.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In the general submatrix detection problem, the task is to detect the\npresence of a small $k \\times k$ submatrix with entries sampled from a\ndistribution $\\mathcal{P}$ in an $n \\times n$ matrix of samples from\n$\\mathcal{Q}$. This formulation includes a number of well-studied problems,\nsuch as biclustering when $\\mathcal{P}$ and $\\mathcal{Q}$ are Gaussians and the\nplanted dense subgraph formulation of community detection when the submatrix is\na principal minor and $\\mathcal{P}$ and $\\mathcal{Q}$ are Bernoulli random\nvariables. These problems all seem to exhibit a universal phenomenon: there is\na statistical-computational gap depending on $\\mathcal{P}$ and $\\mathcal{Q}$\nbetween the minimum $k$ at which this task can be solved and the minimum $k$ at\nwhich it can be solved in polynomial time. Our main result is to tightly\ncharacterize this computational barrier as a tradeoff between $k$ and the KL\ndivergences between $\\mathcal{P}$ and $\\mathcal{Q}$ through average-case\nreductions from the planted clique conjecture. These computational lower bounds\nhold given mild assumptions on $\\mathcal{P}$ and $\\mathcal{Q}$ arising\nnaturally from classical binary hypothesis testing. Our results recover and\ngeneralize the planted clique lower bounds for Gaussian biclustering in Ma-Wu\n(2015) and Brennan et al. (2018) and for the sparse and general regimes of\nplanted dense subgraph in Hajek et al. (2015) and Brennan et al. (2018). This\nyields the first universality principle for computational lower bounds obtained\nthrough average-case reductions.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We have developed a Python package ZMCintegral for multi-dimensional Monte\nCarlo integration on multiple Graphics Processing Units(GPUs). The package\nemploys a stratified sampling and heuristic tree search algorithm. We have\nbuilt three versions of this package: one with Tensorflow and other two with\nNumba, and both support general user defined functions with a user-friendly\ninterface. We have demonstrated that Tensorflow and Numba help inexperienced\nscientific researchers to parallelize their programs on multiple GPUs with\nlittle work. The precision and speed of our package is compared with that of\nVEGAS for two typical integrands, a 6-dimensional oscillating function and a\n9-dimensional Gaussian function. The results show that the speed of ZMCintegral\nis comparable to that of the VEGAS with a given precision. For heavy\ncalculations, the algorithm can be scaled on distributed clusters of GPUs.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In the magnetohydrodynamics (MHD) experiment performed by Bondarenko and his\nco-workers in 1979, the Kolmogorov flow loses stability and transits into a\nsecondary steady state flow at the Reynolds number $R=O(10^3)$. This problem is\nmodelled as a MHD flow bounded between lateral walls under slip wall boundary\ncondition. The existence of the secondary steady state flow is now proved. The\ntheoretical solution has a very good agreement with the flow measured in\nlaboratory experiment at $R=O(10^3)$. Further transition of the secondary flow\nis observed numerically. Especially, well developed turbulence arises at\n$R=O(10^4)$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We give a purely combinatorial proof for a two-fold generalization of van der\nWaerden-Brauer's theorem and Hindman's theorem. We also give tower bounds for a\nfinite version of it.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The formation possibility of a new (Zr0.25Nb0.25Ti0.25V0.25)C high-entropy\nceramic (ZHC-1) was first analyzed by the first-principles calculations and\nthermodynamical analysis and then it was successfully fabricated by hot\npressing sintering technique. The first-principles calculation results showed\nthat the mixing enthalpy of ZHC-1 was 5.526 kJ/mol and the mixing entropy of\nZHC-1 was in the range of 0.693R-1.040R. The thermodynamical analysis results\nshowed that ZHC-1 was thermodynamically stable above 959 K owing to its\nnegative mixing Gibbs free energy. The experimental results showed that the\nas-prepared ZHC-1 (95.1% relative density) possessed a single rock-salt crystal\nstructure, some interesting nanoplate-like structures and high compositional\nuniformity from nanoscale to microscale. By taking advantage of these unique\nfeatures, compared with the initial metal carbides (ZrC, NbC, TiC and VC), it\nshowed a relatively low thermal conductivity of 15.3 + - 0.3 W/(m.K) at room\ntemperature, which was due to the presence of solid solution effects,\nnanoplates and porosity. Meanwhile, it exhibited the relatively high\nnanohardness of 30.3 + - 0.7 GPa and elastic modulus of 460.4 + - 19.2 GPa and\nthe higher fracture toughness of 4.7 + - 0.5 MPa.m1/2, which were attributed to\nthe solid solution strengthening mechanism and nanoplate pullout and microcrack\ndeflection toughening mechanism.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Graph partitioning is the problem of dividing the nodes of a graph into\nbalanced partitions while minimizing the edge cut across the partitions. Due to\nits combinatorial nature, many approximate solutions have been developed,\nincluding variants of multi-level methods and spectral clustering. We propose\nGAP, a Generalizable Approximate Partitioning framework that takes a deep\nlearning approach to graph partitioning. We define a differentiable loss\nfunction that represents the partitioning objective and use backpropagation to\noptimize the network parameters. Unlike baselines that redo the optimization\nper graph, GAP is capable of generalization, allowing us to train models that\nproduce performant partitions at inference time, even on unseen graphs.\nFurthermore, because we learn the representation of the graph while jointly\noptimizing for the partitioning loss function, GAP can be easily tuned for a\nvariety of graph structures. We evaluate the performance of GAP on graphs of\nvarying sizes and structures, including graphs of widely used machine learning\nmodels (e.g., ResNet, VGG, and Inception-V3), scale-free graphs, and random\ngraphs. We show that GAP achieves competitive partitions while being up to 100\ntimes faster than the baseline and generalizes to unseen graphs.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Superluminous supernovae have been proposed to arise from Population III\nprogenitors that explode as pair-instability supernovae. Pop III stars are the\nfirst generation of stars in the Universe, and are thought to form as late as\n$z \\sim 6$. Future near-infrared imaging facilities such as ULTIMATE-Subaru can\npotentially detect and identify these PISNe with a dedicated survey.\nGravitational lensing by intervening structure in the Universe can aid in the\ndetection of these rare objects by magnifying the high-$z$ source population\ninto detectability. We perform a mock survey with ULTIMATE-Subaru, taking into\naccount lensing by line-of-sight structure to evaluate its impact on the\npredicted detection rate. We compare a LOS mass reconstruction using\nobservational data from the Hyper Suprime Cam survey to results from\ncosmological simulations to test their consistency in calculating the\nmagnification distribution in the Universe to high-$z$, but find that the\ndata-based method is still limited by an inability to accurately characterize\nstructure beyond $z \\sim1.2$. We also evaluate a survey strategy of targeting\nmassive galaxy clusters to take advantage of their large areas of high\nmagnification. We find that targeting clusters can result in a gain of a factor\nof $\\sim$two in the predicted number of detected PISNe at $z > 5$, and even\nhigher gains with increasing redshift, given our assumed survey parameters. For\nthe highest-redshift sources at $z \\sim 7-9$, blank field surveys will not\ndetect any sources, and lensing magnification by massive clusters will be\nnecessary to observe this population.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A family $\\F$ of sets is said to be intersecting if any two sets in $\\F$ have\nnonempty intersection. The celebrated Erd{\\H o}s-Ko-Rado theorem determines the\nsize and structure of the largest intersecting family of $k$-sets on an $n$-set\n$X$. An $(s,t)$-union intersecting family is a family of $k$-sets on an $n$-set\n$X$ such that for any $A_1,\\ldots,A_{s+t}$ in this family,\n$\\left(\\cup_{i=1}^sA_i\\right)\\cap\\left(\\cup_{i=1}^t A_{i+s}\\right)\\neq\n\\varnothing.$ Let $\\ell(\\F)$ be the minimum number of sets in $\\F$ such that by\nremoving them the resulting subfamily is intersecting. In this paper, for\nsufficiently large $n$, we characterize the size and structure of $(s,t)$-union\nintersecting families with maximum possible size and $\\ell(\\F)\\geq s+\\beta$.\nThis allows us to find out the size and structure of some large and maximal\n$(s,t)$-union intersecting families.\n  Our results are nontrivial extensions of some recent generalizations of the\nErd{\\H o}s-Ko-Rado theorem such as the Han and Kohayakawa theorem 2017 which\nfinds the structure of the third largest intersecting family, the Kostochka and\nMubayi theorem 2017, and the more recent Kupavskii's theorem 2018 whose both\nresults determine the size and structure of the $i$th largest intersecting\nfamily of $k$-sets for $i\\leq k+1$. In particular, we prove that a\nHilton-Milner-type stability theorem holds for $(1,t)$-union intersecting\nfamilies, that indeed, confirms a conjecture of Alishahi and Taherkhani 2018.\nWe extend our results to $K_{s_1,\\ldots,s_{r+1}}$-free subgraphs of Kneser\ngraphs. In fact, when $n$ is sufficiently large, we characterize the size and\nstructure of large and maximal $K_{s_1,\\ldots,s_{r+1}}$-free subgraphs of\nKneser graphs. In particular, when $s_1=\\cdots=s_{r+1}=1$ our result provides\nsome stability results related to the famous Erd{\\H o}s matching conjecture.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this paper, we aim at providing an introduction to the gradient descent\nbased optimization algorithms for learning deep neural network models. Deep\nlearning models involving multiple nonlinear projection layers are very\nchallenging to train. Nowadays, most of the deep learning model training still\nrelies on the back propagation algorithm actually. In back propagation, the\nmodel variables will be updated iteratively until convergence with gradient\ndescent based optimization algorithms. Besides the conventional vanilla\ngradient descent algorithm, many gradient descent variants have also been\nproposed in recent years to improve the learning performance, including\nMomentum, Adagrad, Adam, Gadam, etc., which will all be introduced in this\npaper respectively.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Let $(\\omega^n,\\preceq)$ be the direct power of $n$ instances of\n$(\\omega,\\leq)$, natural numbers with the standard ordering, $(\\omega^n,\\prec)$\nthe direct power of $n$ instances of $(\\omega,<)$. We show that for all finite\n$n$, the modal logics of $(\\omega^n,\\preceq)$ and of $(\\omega^n,\\prec)$ have\nthe finite model property and moreover, the modal algebras of the frames\n$(\\omega^n,\\preceq)$ and $(\\omega^n,\\prec)$ are locally finite.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this paper, we present exploitability descent, a new algorithm to compute\napproximate equilibria in two-player zero-sum extensive-form games with\nimperfect information, by direct policy optimization against worst-case\nopponents. We prove that when following this optimization, the exploitability\nof a player's strategy converges asymptotically to zero, and hence when both\nplayers employ this optimization, the joint policies converge to a Nash\nequilibrium. Unlike fictitious play (XFP) and counterfactual regret\nminimization (CFR), our convergence result pertains to the policies being\noptimized rather than the average policies. Our experiments demonstrate\nconvergence rates comparable to XFP and CFR in four benchmark games in the\ntabular case. Using function approximation, we find that our algorithm\noutperforms the tabular version in two of the games, which, to the best of our\nknowledge, is the first such result in imperfect information games among this\nclass of algorithms.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Teledyne's H2RG detector images suffer from cross-hatch like patterns which\narises from sub-pixel quantum efficiency (QE) variation. In this paper we\npresent our measurements of this sub-pixel QE variation in the Habitable-Zone\nPlanet Finder's H2RG detector. We present a simple model to estimate the impact\nof sub-pixel QE variations on the radial velocity, and how a first order\ncorrection can be implemented to correct for the artifact in the spectrum. We\nalso present how the HPF's future upgraded laser frequency comb will enable us\nto implement this correction.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  With huge data acquisition progresses realized in the past decades and\nacquisition systems now able to produce high resolution grids and point clouds,\nthe digitization of physical terrains becomes increasingly more precise. Such\nextreme quantities of generated and modeled data greatly impact computational\nperformances on many levels of high-performance computing (HPC): storage media,\nmemory requirements, transfer capability, and finally simulation interactivity,\nnecessary to exploit this instance of big data. Efficient representations and\nstorage are thus becoming \"enabling technologies'' in HPC experimental and\nsimulation science. We propose HexaShrink, an original decomposition scheme for\nstructured hexahedral volume meshes. The latter are used for instance in\nbiomedical engineering, materials science, or geosciences. HexaShrink provides\na comprehensive framework allowing efficient mesh visualization and storage.\nIts exactly reversible multiresolution decomposition yields a hierarchy of\nmeshes of increasing levels of details, in terms of either geometry, continuous\nor categorical properties of cells. Starting with an overview of volume meshes\ncompression techniques, our contribution blends coherently different\nmultiresolution wavelet schemes in different dimensions. It results in a global\nframework preserving discontinuities (faults) across scales, implemented as a\nfully reversible upscaling at different resolutions. Experimental results are\nprovided on meshes of varying size and complexity. They emphasize the\nconsistency of the proposed representation, in terms of visualization,\nattribute downsampling and distribution at different resolutions. Finally,\nHexaShrink yields gains in storage space when combined to lossless compression\ntechniques.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A dynamic coloring of the vertices of a graph $G$ starts with an initial\nsubset $F$ of colored vertices, with all remaining vertices being non-colored.\nAt each time step, a colored vertex with exactly one non-colored neighbor\nforces this non-colored neighbor to be colored. The initial set $F$ is called a\nforcing set of $G$ if, by iteratively applying the forcing process, every\nvertex in $G$ becomes colored. The forcing number of a graph $G$, denoted by\n$F(G)$, is the cardinality of a minimum forcing set of $G$. The maximum nullity\nof $G$, denoted by $M(G)$, is defined to be the largest possible nullity over\nall real symmetric matrices $A$ whose $a_{ij} \\neq 0$ for $i \\neq j$, whenever\ntwo vertices $u_{i}$ and $u_{j}$ of $G$ are adjacent. In this paper, we\ncharacterize all graphs $G$ of order $n$, maximum degree at most three, and\n$F(G)=3$. Also we classify these graphs with their maximum nullity.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  With over 3.5 million refugees, Turkey continues to host the world's largest\nrefugee population. This introduced several challenges in many areas including\naccess to healthcare system. Refugees have legal rights to free healthcare\nservices in Turkey's public hospitals. With the aim of increasing healthcare\naccess for refugees, we looked at where the lack of infrastructure is felt the\nmost. Our study attempts to address these problems by assessing whether Migrant\nHealth Centers' locations are optimal. The aim of this study is to improve\nrefugees' access to healthcare services in Istanbul by improving the locations\nof health facilities available to them. We used call data records provided by\nTurk Telekom.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Given the ever-increasing complexity of adaptable software systems and their\ncommonly hidden internal information (e.g., software runs in the public cloud),\nmachine learning based performance modeling has gained momentum for evaluating,\nunderstanding and predicting software performance, which facilitates better\ninformed self-adaptations. As performance data accumulates during the run of\nthe software, updating the performance models becomes necessary. To this end,\nthere are two conventional modeling methods: the retrained modeling that always\ndiscard the old model and retrain a new one using all available data; or the\nincremental modeling that retains the existing model and tunes it using one\nnewly arrival data sample. Generally, literature on machine learning based\nperformance modeling for adaptable software chooses either of those methods\naccording to a general belief, but they provide insufficient evidences or\nreferences to justify their choice. This paper is the first to report on a\ncomprehensive empirical study that examines both modeling methods under\ndistinct domains of adaptable software, 5 performance indicators, 8 learning\nalgorithms and settings, covering a total of 1,360 different conditions. Our\nfindings challenge the general belief, which is shown to be only partially\ncorrect, and reveal some of the important, statistically significant factors\nthat are often overlooked in existing work, providing evidence-based insights\non the choice.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Binary neutron stars (BNS) mergers are prime sites for $r$-process\nnucleosynthesis. Their rate determines the chemical evolution of heavy elements\nin the Milky Way. The merger rate of BNS is a convolution of their birth rate\nand the gravitational radiation spiral-in delay time. Using the observed\npopulation of Galactic BNS we show here that the lifetimes of pulsars in\nobserved BNSs are sufficiently short that the ages of BNSs have little to no\neffect on the observed merger time distribution. We find that at late times\n($t\\gtrsim 1$ Gyr) the gravitational wave delay time distribution (DTD) follows\nthe expected $ t^{-1}$. However, a significant excess of rapidly merging\nsystems (between $40-60\\%$ of the entire population) is apparent at shorter\ntimes. Although the exact shape of the DTD cannot be determined with the\nexisting data, in all models that adequately describe the data we find at least\n$40\\%$ of BNSs with merger times less than 1Gyr. This population of rapid\nmergers implies a declining deposition rate of $r$-process materials that is\nconsistent with several independent observations of heavy element abundances in\nthe Milky Way. At the same time this population that requires initial binary\nseparations of roughly one solar radius clearly indicates that these binaries\nhad common envelope progenitors. Our results suggest that a significant\nfraction of future LIGO/Virgo BNS mergers would reside in star forming\ngalaxies.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  All-sky and wide parameter space searches for continuous gravitational waves\nare generally template-matching schemes which test a bank of signal waveforms\nagainst data from a gravitational wave detector. Such searches can offer\noptimal sensitivity for a given computing cost and signal model, but are\nhighly-tuned to specific signal types and are computationally expensive, even\nfor semi-coherent searches. We have developed a search method based on the\nwell-known Viterbi algorithm which is model-agnostic and has a computational\ncost several orders of magnitude lower than template methods, with a modest\nreduction in sensitivity. In particular, this method can search for signals\nwhich have an unknown frequency evolution. We test the algorithm on three\nsimulated and real data sets: gapless Gaussian noise, Gaussian noise with gaps\nand real data from the final run of initial LIGO (S6). We show that at 95%\nefficiency, with a 1% false alarm rate, the algorithm has a depth sensitivity\nof $\\sim 33$, $10$ and $13$ ,Hz$^{-1/2}$ with corresponding SNRs of $\\sim 60$,\n$72$ and $74$ in these datasets. we discuss the use of this algorithm for\ndetecting a wide range of quasi-monochromatic gravitational wave signals and\ninstrumental lines.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We characterize, using commuting zero-flux homologies, those\nvolume-preserving vector fields on a $3$-manifold that are steady solutions of\nthe Euler equations for some Riemannian metric. This result extends Sullivan's\nhomological characterization of geodesible flows in the volume-preserving case.\nAs an application, we show that the steady Euler flows cannot be constructed\nusing plugs (as in Wilson's or Kuperberg's constructions). Analogous results in\nhigher dimensions are also proved.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this paper we consider plane quartics with to involutions. We compute the\nDixmier invariants, the bitangents and the Matrix representation problem of\nthese curves, showing that they have symbolic solutions for the last two\nquestions.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Owing to the significance of combinatorial search strategies both for\nacademia and industry, the introduction of new techniques is a fast growing\nresearch field these days. These strategies have really taken different forms\nranging from simple to complex strategies in order to solve all forms of\ncombinatorial problems. Nonetheless, despite the kind of problem these\napproaches solve, they are prone to heavy computation with the number of\ncombinations and growing search space dimensions. This paper presents a new\napproach to speed up the generation and search processes using a combination of\nstack and hash table data structures. This approach could be put to practice\nfor the combinatorial approaches to speed up the generation of combinations and\nsearch process in the search space. Furthermore, this new approach proved its\nperformance in diverse stages better than other known strategies.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The concept of boundary values of holomorphic semigroups in a general Banach\nspace is studied. As an application, we consider the Riemann-Liouville\nsemigroup of integration operator in the little H\\\"older spaces\n$\\rm{lip}_0^\\alpha[0,\\, 1] , \\, 0<\\alpha<1$ and prove that it admits a strongly\ncontinuous boundary group, which is the group of fractional integration of\npurely imaginary order. The corresponding result for the $L^p$-spaces\n($1<p<\\infty$) has been known for some time, the case $p=2$ dating back to the\nmonograph by Hille and Phillips. In the context of $L^p$ spaces, we establish\nthe existence of the boundary group of the Hadamard fractional integration\noperators using semigroup methods. In the general framework, using a suitable\nspectral decomposition,we give a partial treatment of the inverse problem,\nnamely: Which $C_0$-groups are boundary values of some holomorphic semigroup of\nangle $\\pi/2$?\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Along with the development of virtual reality (VR), omnidirectional images\nplay an important role in producing multimedia content with immersive\nexperience. However, despite various existing approaches for omnidirectional\nimage stitching, how to quantitatively assess the quality of stitched images is\nstill insufficiently explored. To address this problem, we establish a novel\nomnidirectional image dataset containing stitched images as well as\ndual-fisheye images captured from standard quarters of 0$^\\circ$, 90$^\\circ$,\n180$^\\circ$ and 270$^\\circ$. In this manner, when evaluating the quality of an\nimage stitched from a pair of fisheye images (e.g., 0$^\\circ$ and 180$^\\circ$),\nthe other pair of fisheye images (e.g., 90$^\\circ$ and 270$^\\circ$) can be used\nas the cross-reference to provide ground-truth observations of the stitching\nregions. Based on this dataset, we further benchmark six widely used stitching\nmodels with seven evaluation metrics for IQA. To the best of our knowledge, it\nis the first dataset that focuses on assessing the stitching quality of\nomnidirectional images.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Simulation of multiphase poromechanics involves solving a multi-physics\nproblem in which multiphase flow and transport are tightly coupled with the\nporous medium deformation. To capture this dynamic interplay, fully implicit\nmethods, also known as monolithic approaches, are usually preferred. The main\nbottleneck of a monolithic approach is that it requires solution of large\nlinear systems that result from the discretization and linearization of the\ngoverning balance equations. Because such systems are non-symmetric,\nindefinite, and highly ill-conditioned, preconditioning is critical for fast\nconvergence. Recently, most efforts in designing efficient preconditioners for\nmultiphase poromechanics have been dominated by physics-based strategies.\nCurrent state-of-the-art \"black-box\" solvers such as algebraic multigrid (AMG)\nare ineffective because they cannot effectively capture the strong coupling\nbetween the mechanics and the flow sub-problems, as well as the coupling\ninherent in the multiphase flow and transport process. In this work, we develop\nan algebraic framework based on multigrid reduction (MGR) that is suited for\ntightly coupled systems of PDEs. Using this framework, the decoupling between\nthe equations is done algebraically through defining appropriate interpolation\nand restriction operators. One can then employ existing solvers for each of the\ndecoupled blocks or design a new solver based on knowledge of the physics. We\ndemonstrate the applicability of our framework when used as a \"black-box\"\nsolver for multiphase poromechanics. We show that the framework is flexible to\naccommodate a wide range of scenarios, as well as efficient and scalable for\nlarge problems.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Automated hyperparameter tuning aspires to facilitate the application of\nmachine learning for non-experts. In the literature, different optimization\napproaches are applied for that purpose. This paper investigates the\nperformance of Differential Evolution for tuning hyperparameters of supervised\nlearning algorithms for classification tasks. This empirical study involves a\nrange of different machine learning algorithms and datasets with various\ncharacteristics to compare the performance of Differential Evolution with\nSequential Model-based Algorithm Configuration (SMAC), a reference Bayesian\nOptimization approach. The results indicate that Differential Evolution\noutperforms SMAC for most datasets when tuning a given machine learning\nalgorithm - particularly when breaking ties in a first-to-report fashion. Only\nfor the tightest of computational budgets SMAC performs better. On small\ndatasets, Differential Evolution outperforms SMAC by 19% (37% after\ntie-breaking). In a second experiment across a range of representative datasets\ntaken from the literature, Differential Evolution scores 15% (23% after\ntie-breaking) more wins than SMAC.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  This document describes the framework of the Softwire ''Hub and Spoke''\nsolution with the Layer Two Tunneling Protocol version 2 (L2TPv2). The\nimplementation details specified in this document should be followed to achieve\ninteroperability among different vendor implementations.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We present a fully-differential calculation of the $H\\rightarrow\nb\\overline{b}$ decay at next-to-next- to-next-to-leading order (N$^3$LO)\naccuracy. Our calculation considers diagrams in which the Higgs boson couples\ndirectly to the bottom quarks, i.e. the perturbative order we consider is\n$\\mathcal{O}(\\alpha_s^3y_b^2)$. In order to regulate the infrared divergences\npresent at this order we use the Projection-to-Born technique coupled with\nN-jettiness slicing. After validating our methodology at\nnext-to-next-to-leading order (NNLO) we present exclusive jet rates and\ndifferential distributions for jet observables at N3LO accuracy using the\nDurham jet algorithm in the Higgs rest frame.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  This paper investigates the robustness of strong structural controllability\nfor linear time-invariant and linear time-varying directed networks with\nrespect to structural perturbations, including edge deletions and additions. In\nthis direction, we introduce a new construct referred to as a perfect graph\nassociated with a network with a given set of control nodes. The tight upper\nbounds on the number of edges that can be added to, or removed from a network,\nwhile ensuring strong structural controllability, are then derived. Moreover,\nwe obtain a characterization of critical edge-sets, the maximal sets of edges\nwhose any subset can be respectively added to, or removed from a network, while\npreserving strong structural controllability. In addition, procedures for\ncombining networks to obtain strongly structurally controllable\nnetwork-of-networks are proposed. Finally, controllability conditions are\nproposed for networks whose edge weights, as well as their structures, can vary\nover time.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Background and Purpose: A current algorithm to obtain a synthetic myelin\nvolume fraction map (SyMVF) from rapid simultaneous relaxometry imaging (RSRI)\nhas a potential problem, that it does not incorporate information from\nsurrounding pixels. The purpose of this study was to develop a method that\nutilizes a convolutional neural network (CNN) to overcome this problem.\nMethods: RSRI and magnetization transfer images from 20 healthy volunteers were\nincluded. A CNN was trained to reconstruct RSRI-related metric maps into a\nmyelin volume-related index (generated myelin volume index: GenMVI) map using\nthe myelin volume index map calculated from magnetization transfer images\n(MTMVI) as reference. The SyMVF and GenMVI maps were statistically compared by\ntesting how well they correlated with the MTMVI map. The correlations were\nevaluated based on: (i) averaged values obtained from 164 atlas-based ROIs, and\n(ii) pixel-based comparison for ROIs defined in four different tissue types\n(cortical and subcortical gray matter, white matter, and whole brain). Results:\nFor atlas-based ROIs, the overall correlation with the MTMVI map was higher for\nthe GenMVI map than for the SyMVF map. In the pixel-based comparison,\ncorrelation with the MTMVI map was stronger for the GenMVI map than for the\nSyMVF map, and the difference in the distribution for the volunteers was\nsignificant (Wilcoxon sign-rank test, P<.001) in all tissue types. Conclusion:\nThe proposed method is useful, as it can incorporate more specific information\nabout local tissue properties than the existing method.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this work we introduce Lifting Autoencoders, a generative 3D surface-based\nmodel of object categories. We bring together ideas from non-rigid structure\nfrom motion, image formation, and morphable models to learn a controllable,\ngeometric model of 3D categories in an entirely unsupervised manner from an\nunstructured set of images. We exploit the 3D geometric nature of our model and\nuse normal information to disentangle appearance into illumination, shading and\nalbedo. We further use weak supervision to disentangle the non-rigid shape\nvariability of human faces into identity and expression. We combine the 3D\nrepresentation with a differentiable renderer to generate RGB images and append\nan adversarially trained refinement network to obtain sharp, photorealistic\nimage reconstruction results. The learned generative model can be controlled in\nterms of interpretable geometry and appearance factors, allowing us to perform\nphotorealistic image manipulation of identity, expression, 3D pose, and\nillumination properties.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Fluorescence microscopy has led to impressive quantitative models and new\ninsights gained from richer sets of biomedical imagery. However, there is a\ndearth of rigorous and established bioimaging strategies for modeling\nspatiotemporal behavior of diffuse, subcellular components such as mitochondria\nor actin. In many cases, these structures are assessed by hand or with other\nsemi-quantitative measures. We propose to build descriptive and dynamic models\nof diffuse subcellular morphologies, using the mitochondrial protein patterns\nof cervical epithelial (HeLa) cells. We develop a parametric representation of\nthe patterns as a mixture of probability masses. This mixture is iteratively\nperturbed over time to fit the evolving spatiotemporal behavior of the\nsubcellular structures. We convert the resulting trajectory into a series of\ngraph Laplacians to formally define a dynamic network. Finally, we demonstrate\nhow graph theoretic analyses of the trajectories yield biologically-meaningful\nquantifications of the structures.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Given a continuum $X$ and $p\\in X$, we will consider the hyperspace $C(p,X)$\nof all subcontinua of $X$ containing $p$ and the family $K(X)$ of all\nhyperspaces $C(q,X)$, where $q\\in X$. In this paper we give some conditions on\nthe points $p,q\\in X$ to guarantee that $C(p,X)$ and $C(q,X)$ are homeomorphic,\nfor finite graphs $X$. Also, we study the relationship between the homogeneity\ndegree of a finite graph $X$ and the number of topologically distinct spaces in\n$K(X)$, called the size of $K(X)$. In addition, we construct for each positive\ninteger $n$, a finite graph $X_n$ such that $K(X_n)$ has size $n$, and we\npresent a theorem that allows to construct finite graphs $X$ with a degree of\nhomogeneity different from the size of the family $K(X)$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We report the results of simulations of rigid colloidal helices suspended in\na shear flow, using dissipative particle dynamics for a coarse-grained\nrepresentation of the suspending fluid, as well as deterministic trajectories\nof non-Brownian helices calculated from the resistance tensor derived under the\nslender-body approximation. The shear flow produces nonuniform rotation of the\nhelices, similarly to other high aspect ratio particles, such that more\nelongated helices spend more time aligned with the fluid velocity. We introduce\na geometric effective aspect ratio calculated directly from the helix geometry\nand a dynamical effective aspect ratio derived from the trajectories of the\nparticles and find that the two effective aspect ratios are approximately equal\nover the entire parameter range tested. We also describe observed transient\ndeflections of the helical axis into the vorticity direction that can occur\nwhen the helix is rotating through the gradient direction and that depend on\nthe rotation of the helix about its axis.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this paper, we consider the electroweak production cross-section of a\nsingle anti-top-quark, a neutrino and a photon via charged current through the\n$e^-p \\to e^-\\bar b \\to \\bar t \\nu_e \\gamma \\to \\bar t(\\to W^- \\to (qq', l^-\n\\bar\\nu_l)+b) \\nu_e\\gamma$ signal. Further, we derived the sensitivity expected\nto the magnetic dipole moment $(\\hat a_V)$ and the electric dipole moment\n$(\\hat a_A)$ of the top-quark at the Future Circular Collider Hadron Electron\n(FCC-he). We present our study for $\\sqrt{s}=7.07, 10\\hspace{0.8mm}TeV$, ${\\cal\nL}=50, 100, 300, 500, 1000\\hspace{0.8mm}fb^{-1}$, $\\delta_{sys}=0, 3,\n5\\hspace{0.8mm}\\%$ and $P_{e^-}=0\\%, 80\\%, -80\\%$, respectively. We find that\nthe sensitivity estimated on dipole moments of the top-quark is of the order of\nmagnitude ${\\cal O}(10^{-1})$ for both hadronic and leptonic decay modes of\n$W^-$: $\\hat a_V=[-0.2308, 0.2204]$, $|\\hat a_A|=0.2259$ at $95\\%$ C.L. in the\nhadronic channel with unpolarized electron beam $P_{e^-}=0\\%$. Our results with\npolarized electron beam for $P_{e^-}=80\\%$ and $P_{e^-}=-80\\%$ are $\\hat\na_V=[-0.3428, 0.3321]$, $|\\hat a_A|=0.3371$ and $\\hat a_V=[-0.2041, 0.1858]$,\n$|\\hat a_A|=0.1939$ at $95\\%$ C.L. in the hadronic channel. The corresponding\nresults for the leptonic channel with $P_{e^-}=0\\%, 80\\% -80\\%$ are $\\hat\na_V=[-0.3067, 0.2963]$, $|\\hat a_A|=0.3019$, $\\hat a_V=[-0.4563, 0.4456]$,\n$|\\hat a_A|=0.4505$ and $\\hat a_V=[-0.2695, 0.2512]$, $|\\hat a_A|=0.2592$,\nrespectively. The results for $\\hat a_V$ and $\\hat a_A$ in the leptonic channel\nare weaker by a factor of 0.75 than those corresponding to the hadronic\nchannel. Given these prospective sensitivities we highlight that the FCC-he is\npotential top-quark factory that is particularly well suited to sensitivity\nstudy on its dipole moments and with cleaner environments.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Larkin and Ovchinnikov established that the viscous flow of magnetic flux\nquanta in current-biased superconductor films placed in a perpendicular\nmagnetic field can lose stability due to a decrease in the vortex viscosity\ncoefficient $\\eta$ with increasing velocity of the vortices $v$. The dependence\nof $\\eta$ on $v$ leads to a $nonlinear$ section in the current-voltage\n($I$-$V$) curve which ends at the flux-flow instability point with a voltage\njump to a highly resistive state. At the same time, in contradistinction with\nthe nonlinear conductivity regime, instability jumps often occur in $linear$\n$I$-$V$ sections. Here, for the elucidation of such jumps we develop a theory\nof local instability of the magnetic flux flow occurring not in the entire film\nbut in a narrow strip across the film width in which vortices move much faster\nthan outside it. The predictions of the developed theory are in agreement with\nexperiments on Nb films for which the heat removal coefficients and the\ninelastic scattering times of quasiparticles are deduced. The presented model\nof local instability is also relevant for the characterization of\nsuperconducting thin films whose performance is examined for fast single-photon\ndetection.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Coordination failure reduces match quality among employers and candidates in\nthe job market, resulting in a large number of unfilled positions and/or\nunstable, short-term employment. Centralized job search engines provide a\nplatform that connects directly employers with job-seekers. However, they\nrequire users to disclose a significant amount of personal data, i.e., build a\nuser profile, in order to provide meaningful recommendations. In this paper, we\npresent PrivateJobMatch -- a privacy-oriented deferred multi-match recommender\nsystem -- which generates stable pairings while requiring users to provide only\na partial ranking of their preferences. PrivateJobMatch explores a series of\nadaptations of the game-theoretic Gale-Shapley deferred-acceptance algorithm\nwhich combine the flexibility of decentralized markets with the intelligence of\ncentralized matching. We identify the shortcomings of the original algorithm\nwhen applied to a job market and propose novel solutions that rely on machine\nlearning techniques. Experimental results on real and synthetic data confirm\nthe benefits of the proposed algorithms across several quality measures. Over\nthe past year, we have implemented a PrivateJobMatch prototype and deployed it\nin an active job market economy. Using the gathered real-user preference data,\nwe find that the match-recommendations are superior to a typical decentralized\njob market---while requiring only a partial ranking of the user preferences.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Construction of future Muon Collider tangential to the Large Hadron Collider\nwill give opportunity to realize mu-p collisions at multi-TeV center of mass\nenergies. Using nominal parameters of high luminosity and high energy upgrades\nof the LHC, as well as design parameters of muon colliders, it is shown that\nL_mu-p of order of 10^33 cm^-2s^-1 is achievable for different options with\nsqrt(s)_mu-p from 4.58 TeV to 12.7 TeV. Certainly, proposed mu-p colliders have\na huge potential for clarifying QCD basics and searches for new physics.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We study a class of optimal stopping games (Dynkin games) of preemption type,\nwith uncertainty about the existence of competitors. The set-up is well-suited\nto model, for example, real options in the context of investors who do not want\nto publicly reveal their interest in a certain business opportunity. We show\nthat there exists a Nash equilibrium in randomized stopping times which is\ndescribed explicitly in terms of the corresponding one-player game.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  This paper is concerned with normal approximation under relaxed moment\nconditions using Stein's method. We obtain the explicit rates of convergence in\nthe central limit theorem for (i) nonlinear statistics with finite absolute\nmoment of order $2+\\delta\\in(2,3];$ (ii) nonlinear statistics with vanishing\nthird moment and finite absolute moment of order $3+\\delta\\in(3,4].$ When\napplied to specific examples, these rates are of the optimal order\n$O(n^{-\\frac{\\delta}{2}})$ and $O(n^{-\\frac{1+\\delta}{2}}).$ Our proof are\nbased on the covariance identify formula and simple observations about the\nsolution of Stein's equation.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Relaxation of few-body quantum systems can strongly depend on the initial\nstate when the system's semiclassical phase space is mixed, i.e., regions of\nchaotic motion coexist with regular islands. In recent years, there has been\nmuch effort to understand the process of thermalization in strongly interacting\nquantum systems that often lack an obvious semiclassical limit. Time-dependent\nvariational principle (TDVP) allows to systematically derive an effective\nclassical (nonlinear) dynamical system by projecting unitary many-body dynamics\nonto a manifold of weakly-entangled variational states. We demonstrate that\nsuch dynamical systems generally possess mixed phase space. When TDVP errors\nare small, the mixed phase space leaves a footprint on the exact dynamics of\nthe quantum model. For example, when the system is initialized in a state\nbelonging to a stable periodic orbit or the surrounding regular region, it\nexhibits persistent many-body quantum revivals. As a proof of principle, we\nidentify new types of \"quantum many-body scars\", i.e., initial states that lead\nto long-time oscillations in a model of interacting Rydberg atoms in one and\ntwo dimensions. Intriguingly, the initial states that give rise to most robust\nrevivals are typically entangled states. On the other hand, even when TDVP\nerrors are large, as in the thermalizing tilted-field Ising model, initializing\nthe system in a regular region of phase space leads to slowdown of\nthermalization. Our work establishes TDVP as a method for identifying\ninteracting quantum systems with anomalous dynamics in arbitrary dimensions.\nMoreover, the mixed-phase space classical variational equations allow to find\nslowly-thermalizing initial conditions in interacting models. Our results shed\nlight on a link between classical and quantum chaos, pointing towards possible\nextensions of classical Kolmogorov-Arnold-Moser theorem to quantum systems.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We consider a controlled linear-quadratic (LQ) large-population system with\nmixture of three types agents: major leader, minor leaders and minor followers.\nThe Stackelberg-Nash-Cournot (SNC) approximate equilibrium is studied by a\nmajor-minor mean-field game (MFG) coupled with a leader-follower Stackelberg\ngame. By variational method, the SNC approximate equilibrium strategy can be\nrepresented by some forward-backward-stochastic-differential-equations (FBSDEs)\nin the open-loop sense. And we pay great effort to give the feedback form of\nthe open-loop strategy by some Riccati equations.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We investigate the high-dimensional data clustering problem by proposing a\nnovel and unsupervised representation learning model called Robust Flexible\nAuto-weighted Local-coordinate Concept Factorization (RFA-LCF). RFA-LCF\nintegrates the robust flexible CF, robust sparse local-coordinate coding and\nthe adaptive reconstruction weighting learning into a unified model. The\nadaptive weighting is driven by including the joint manifold preserving\nconstraints on the recovered clean data, basis concepts and new representation.\nSpecifically, our RFA-LCF uses a L2,1-norm based flexible residue to encode the\nmismatch between clean data and its reconstruction, and also applies the robust\nadaptive sparse local-coordinate coding to represent the data using a few\nnearby basis concepts, which can make the factorization more accurate and\nrobust to noise. The robust flexible factorization is also performed in the\nrecovered clean data space for enhancing representations. RFA-LCF also\nconsiders preserving the local manifold structures of clean data space, basis\nconcept space and the new coordinate space jointly in an adaptive manner way.\nExtensive comparisons show that RFA-LCF can deliver enhanced clustering\nresults.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Over recent years, devising classification algorithms that are robust to\nadversarial perturbations has emerged as a challenging problem. In particular,\ndeep neural nets (DNNs) seem to be susceptible to small imperceptible changes\nover test instances. However, the line of work in provable robustness, so far,\nhas been focused on information-theoretic robustness, ruling out even the\nexistence of any adversarial examples. In this work, we study whether there is\na hope to benefit from algorithmic nature of an attacker that searches for\nadversarial examples, and ask whether there is any learning task for which it\nis possible to design classifiers that are only robust against polynomial-time\nadversaries. Indeed, numerous cryptographic tasks can only be secure against\ncomputationally bounded adversaries, and are indeed impossible for\ncomputationally unbounded attackers. Thus, it is natural to ask if the same\nstrategy could help robust learning.\n  We show that computational limitation of attackers can indeed be useful in\nrobust learning by demonstrating the possibility of a classifier for some\nlearning task for which computational and information theoretic adversaries of\nbounded perturbations have very different power. Namely, while computationally\nunbounded adversaries can attack successfully and find adversarial examples\nwith small perturbation, polynomial time adversaries are unable to do so unless\nthey can break standard cryptographic hardness assumptions. Our results,\ntherefore, indicate that perhaps a similar approach to cryptography (relying on\ncomputational hardness) holds promise for achieving computationally robust\nmachine learning. On the reverse directions, we also show that the existence of\nsuch learning task in which computational robustness beats information\ntheoretic robustness requires computational hardness by implying (average-case)\nhardness of NP.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  While Nash equilibrium in extensive-form games is well understood, very\nlittle is known about the properties of extensive-form correlated equilibrium\n(EFCE), both from a behavioral and from a computational point of view. In this\nsetting, the strategic behavior of players is complemented by an external\ndevice that privately recommends moves to agents as the game progresses;\nplayers are free to deviate at any time, but will then not receive future\nrecommendations. Our contributions are threefold. First, we show that an EFCE\ncan be formulated as the solution to a bilinear saddle-point problem. To\nshowcase how this novel formulation can inspire new algorithms to compute\nEFCEs, we propose a simple subgradient descent method which exploits this\nformulation and structural properties of EFCEs. Our method has better\nscalability than the prior approach based on linear programming. Second, we\npropose two benchmark games, which we hope will serve as the basis for future\nevaluation of EFCE solvers. These games were chosen so as to cover two natural\napplication domains for EFCE: conflict resolution via a mediator, and\nbargaining and negotiation. Third, we document the qualitative behavior of EFCE\nin our proposed games. We show that the social-welfare-maximizing equilibria in\nthese games are highly nontrivial and exhibit surprisingly subtle sequential\nbehavior that so far has not received attention in the literature.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A Gallai coloring of a complete graph is an edge-coloring such that no\ntriangle has all its edges colored differently. A Gallai $k$-coloring is a\nGallai coloring that uses $k$ colors. Given a graph $H$ and an integer $k\\geq\n1$, the Gallai-Ramsey number $GR_k(H)$ of $H$ is the least positive integer $N$\nsuch that every Gallai $k$-coloring of the complete graph $K_N$ contains a\nmonochromatic copy of $H$. Let $W_{2n} $ denote an even wheel on $2n+1\\ge5$\nvertices. In this note, we study Gallai-Ramsey number of $W_{2n}$ and\ncompletely determine the exact value of $GR_k(W_4)$ for all $k\\ge2$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We present the results of the monitoring campaign of the Type IIn supernova\n(SN) 2018cnf (aka ASASSN-18mr). It was discovered about 10 days before the\nmaximum light (on MJD = 58293.4+-5.7 in the V band, with MV = -18.13+-0.15\nmag). The multiband light curves show an immediate post-peak decline with some\nminor luminosity fluctuations, followed by a flattening starting about 40 days\nafter maximum. The early spectra are relatively blue and show narrow Balmer\nlines with P Cygni profiles. Additionally, Fe II, O I, He I and Ca II are\ndetected. The spectra show little evolution with time, with intermediate-width\nfeatures becoming progressively more prominent, indicating stronger interaction\nof the SN ejecta with the circumstellar medium. The inspection of archival\nimages from the Panoramic Survey Telescope and Rapid Response System\n(Pan-STARRS) survey has revealed a variable source at the SN position, with a\nbrightest detection in December 2015 at Mr = -14.66+-0.17 mag. This was likely\nan eruptive phase from the massive progenitor star started from at least\nmid-2011, and that produced the circumstellar environment within which the star\nexploded as a Type IIn SN. The overall properties of SN 2018cnf closely\nresemble those of transients such as SN 2009ip. This similarity favours a\nmassive hypergiant, perhaps a luminous blue variable, as progenitor for SN\n2018cnf.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A phase-field study has been conducted to obtain an understanding of the\nformation mechanism of the script lamellar pattern of MoSi2/Mo5Si3 eutectic\ncomposite, which is a promising candidate for high-temperature structural\napplication. The spacing of the lamellar pattern in the simulation results\nshows good agreement with that of experimental observations and analytical\nsolutions under three growth rates: 10 mm/h, 50 mm/h, and 100 mm/h. The\ndiscontinuity of Mo5Si3 rods, in contrast to the regular eutectic with a\ncontinuous pattern, is claimed to be caused by the instability of the\nsolid-liquid interface. In this study, the implementation of Mo5Si3 nucleation\nover the solid-liquid interface has been proposed and successfully reproduced\nthe characteristic of discontinuity. A highly random and intersected lamellar\npattern similar to that observed in the ternary MoSi2/Mo5Si3 eutectic alloyed\nwith 0.1at% Co has been obtained in simulation owing to the increase in the\nfrequency of nucleation. In addition, it has been demonstrated that the\ninclination of the Mo5Si3 rod can be reproduced by taking into account the\nstrong relaxation of lattice strain energy, which is generally considered to be\nnegligible in eutectic reaction, as the result of the formation of\nledge-terrace structure.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  It is known that (i) a subspace ${\\mathcal N}$ of the Hardy space $H^2$ which\nis invariant under the backward shift operator can be represented as the range\nof the observability operator of a conservative discrete-time linear system,\n(ii) the transfer-function of this conservative linear system in turn is the\ninner Beurling-Lax representer for the forward-shift invariant subspace\n${\\mathcal M} : = {\\mathcal N}^\\perp$, and (iii) this transfer function also\nserves as the Sz.-Nagy-Foias characteristic function of the pure contraction\noperator $T$ given by $T = P_{\\mathcal N} M_z |_{\\mathcal N}$. The main focus\nof this paper is to present the extension of this structure to a more general\nsetting. The Hardy space is replaced by the full weighted Bergman-Fock space of\nformal power series in $d$ freely noncommutative indeterminates, where the\nshift is replaced by the right shift tuple, where the conservative/dissipative\ndiscrete-time linear system becomes a certain type of conservative/dissipative\nmultidimensional linear system with time-varying weights and with evolution\nalong a rooted tree with each node having $d$ forward branches, where a\nbackward shift-invariant subspace ${\\mathcal N}$ is the range of the\nobservability operator for such a weighted-Bergman multidimensional linear\nsystem, and where the transfer function of this system is the Beurling-Lax\nrepresenter for the forward shift-invariant subspace ${\\mathcal M} = {\\mathcal\nN}^{[\\perp]}$, and where this transfer function also serves as the\ncharacteristic function for the operator tuple having\nhypercontractive-operator-tuple adjoint equal to the restriction of the\nbackward-shift tuple to $\\mathcal N$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this work, we consider the use of model-driven deep learning techniques\nfor massive multiple-input multiple-output (MIMO) detection. Compared with\nconventional MIMO systems, massive MIMO promises improved spectral efficiency,\ncoverage and range. Unfortunately, these benefits are coming at the cost of\nsignificantly increased computational complexity. To reduce the complexity of\nsignal detection and guarantee the performance, we present a learned conjugate\ngradient descent network (LcgNet), which is constructed by unfolding the\niterative conjugate gradient descent (CG) detector. In the proposed network,\ninstead of calculating the exact values of the scalar step-sizes, we explicitly\nlearn their universal values. Also, we can enhance the proposed network by\naugmenting the dimensions of these step-sizes. Furthermore, in order to reduce\nthe memory costs, a novel quantized LcgNet is proposed, where a low-resolution\nnonuniform quantizer is integrated into the LcgNet to smartly quantize the\naforementioned step-sizes. The quantizer is based on a specially designed soft\nstaircase function with learnable parameters to adjust its shape. Meanwhile,\ndue to fact that the number of learnable parameters is limited, the proposed\nnetworks are easy and fast to train. Numerical results demonstrate that the\nproposed network can achieve promising performance with much lower complexity.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We explore the behavior of micron-scale autophoretic Janus (Au/Pt) rods,\nhaving various Au/Pt length ratios, swimming near a wall in an imposed\nbackground flow. We find that their ability to robustly orient and move\nupstream, i.e. to rheotax, depends strongly on the Au/Pt ratio, which is easily\ntunable in synthesis. Numerical simulations of swimming rods actuated by a\nsurface slip show a similar rheotactic tunability when varying the location of\nthe surface slip versus surface drag. Slip location determines whether swimmers\nare Pushers (rear-actuated), Pullers (front-actuated), or in between. Our\nsimulations and modeling show that Pullers rheotax most robustly due to their\nlarger tilt angle to the wall, which makes them responsive to flow gradients.\nThus, rheotactic response infers the nature of difficult to measure flow-fields\nof an active particle, establishes its dependence on swimmer type, and shows\nhow Janus rods can be tuned for flow responsiveness. We demonstrate the\neffectiveness of a simple geometric sieve for rheotactic ability.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Cosmic Ray Muon Radiography utilizes highly-penetrating cosmic ray muons to\nimage the density profile of an object of interest. Here we report on the first\ntrial to use a portable field-deployable cosmic ray tracking system in order to\nimage the whole overburden of a UK railway tunnel with short duration scans (c.\n30 minutes). A unknown overburden void was identified and, post-trial,\nconfirmed by railway authorities. These experiments demonstrate the\nidentification of hidden construction shafts with high levels of statistical\nsignificance as density anomalies within the data.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Wiener index and Harary index are two classic and well-known topological\nindices for the characterization of molecular graphs. Recently, Yu et al.\n\\cite{YYSX} established some sufficient conditions for a graph to be pancyclic\nin terms of the edge number, the spectral radius and the signless Laplacian\nspectral radius of the graph. In this paper, we give some sufficient conditions\nfor a graph being pancyclic in terms of the Wiener index, the Harary index, the\ndistance spectral radius and the Harary spectral radius of a graph.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this work a homoclinic-like loop of a piecewise smooth vector field\npassing through a typical singularity is analyzed. We have shown that such a\nloop is robust in one-parameter families of Filippov systems. The basin of\nattraction of this connection is computed as well as its bifurcation diagram.\nIt is worthwhile to mention that this phenomenon has no counterpart in the\nsmooth world and the techniques used in this analysis differ from the usual\nones.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We present the design and performance of a simple fixed-frequency\nsuperconducting lumped-element resonator developed for axion and hidden photon\ndark matter detection. A rectangular NbTi inductor was coupled to a Nb-coated\nsapphire capacitor and immersed in liquid helium within a superconducting\nshield. The resonator was transformer-coupled to a DC SQUID for readout. We\nmeasured a quality factor of $\\sim$40,000 at the resonant frequency of 492.027\nkHz and set a simple exclusion limit on $\\sim$2 neV hidden photons with kinetic\nmixing angle $\\varepsilon\\gtrsim1.5\\times10^{-9}$ based on 5.14 hours of\nintegrated noise. This test device informs the development of the Dark Matter\nRadio, a tunable superconducting lumped-element resonator which will search for\naxions and hidden photons over the 100 Hz to 300 MHz frequency range.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We introduce a notion of connected perimeter for planar sets defined as the\nlower semi-continuous envelope of perimeters of approximating sets which are\nmeasure-theoretically connected. A companion notion of simply connected\nperimeter is also studied. We prove a representation formula which links the\nconnected perimeter, the classical perimeter, and the length of suitable\nSteiner trees. We also discuss the application of this notion to the existence\nof solutions to a nonlocal minimization problem.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Cross-correlated contrast source inversion (CC-CSI) is a non-linear iterative\ninversion method that is proposed recently for solving the inverse scattering\nproblems. In CC-CSI, a cross-correlated error is constructed and introduced to\nthe cost functional, which improves the inversion ability when compared to the\nclassical design of the cost functional by exploiting the mismatch between the\ndata error and state error. In this paper, the multi-frequency inversion for\nelectromagnetic waves is considered and a multi-frequency version of CC-CSI is\nproposed. Numerical and experimental inversion results of both transverse\nmagnetic (TM) and transverse electric (TE) polarization demonstrate that, when\nmulti-frequency data are available, CC-CSI still outperforms the\nmultiplicative-regularized CSI method (MR-CSI) in the inversion of more\ncomplicated scatterers.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The determination of the Hubble constant $H_0$ from the Cosmic Microwave\nBackground by the Planck Collaboration [Aghanim et al. 2018] is in tension at\n$4.2\\sigma$ with respect to the local determination of $H_0$ by the SH0ES\ncollaboration [Reid et al. 2019]. Here, we improve upon the local\ndetermination, which fixes the deceleration parameter to the standard\n$\\Lambda$CDM model value of $q_0=-0.55$, that is, uses information from\nobservations beyond the local universe. First, we derive the effective\ncalibration prior on the absolute magnitude $M_B$ of Supernovae Ia, which can\nbe used in cosmological analyses in order to avoid the double counting of\nlow-redshift supernovae. We find $M_B = -19.2334 \\pm 0.0404$ mag. Then, we use\nthe above $M_B$ prior in order to obtain a determination of the local $H_0$\nwhich only uses local observations and only assumes the cosmological principle,\nthat is, large-scale homogeneity and isotropy. This is achieved by adopting an\nuninformative flat prior for $q_0$ in the cosmographic expansion of the\nluminosity distance. We use the latest Pantheon sample and find $H_0= 75.35 \\pm\n1.68 \\text{ km s}^{-1} {\\rm Mpc}^{-1}$, which features a 2.2% uncertainty,\nclose to the 1.9% error obtained by the SH0ES Collaboration. Our determination\nis at the higher tension of $4.5\\sigma$ with the latest results from the Planck\nCollaboration that assume the $\\Lambda$CDM model. Furthermore, we also\nconstrain the deceleration parameter to $q_0= -1.08 \\pm 0.29$, which disagrees\nwith Planck at the $1.9\\sigma$ level. These estimations only use supernovae in\nthe redshift range $0.023\\le z\\le 0.15$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Named entity recognition (NER) is one of the best studied tasks in natural\nlanguage processing. However, most approaches are not capable of handling\nnested structures which are common in many applications. In this paper we\nintroduce a novel neural network architecture that first merges tokens and/or\nentities into entities forming nested structures, and then labels each of them\nindependently. Unlike previous work, our merge and label approach predicts\nreal-valued instead of discrete segmentation structures, which allow it to\ncombine word and nested entity embeddings while maintaining differentiability.\n%which smoothly groups entities into single vectors across multiple levels. We\nevaluate our approach using the ACE 2005 Corpus, where it achieves\nstate-of-the-art F1 of 74.6, further improved with contextual embeddings (BERT)\nto 82.4, an overall improvement of close to 8 F1 points over previous\napproaches trained on the same data. Additionally we compare it against\nBiLSTM-CRFs, the dominant approach for flat NER structures, demonstrating that\nits ability to predict nested structures does not impact performance in simpler\ncases.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Given any numeration system, we call carry propagation at a number $N$ the\nnumber of digits that are changed when going from the representation of $N$ to\nthe one of $N+1$, and amortized carry propagation the limit of the mean of the\ncarry propagations at the first $N$ integers, when $N$ tends to infinity, if\nthis limit exists.\n  In the case of the usual base $p$ numeration system, it can be shown that the\nlimit indeed exists and is equal to $p/(p-1)$. We recover a similar value for\nthose numeration systems we consider and for which the limit exists.\n  We address the problem of the existence of the amortized carry propagation in\nnon-standard numeration systems of various kinds: abstract numeration systems,\nrational base numeration systems, greedy numeration systems and\nbeta-numeration. We tackle the problem by three different types of techniques:\ncombinatorial, algebraic, and ergodic. For each kind of numeration systems that\nwe consider, the relevant method allows for establishing sufficient conditions\nfor the existence of the carry propagation and examples show that these\nconditions are close to being necessary conditions.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  How to integrate human factors into the motion planning system is of great\nsignificance for improving the acceptance of intelligent vehicles. Decomposing\nmotion into primitives and then accurately and smoothly joining the motion\nprimitives (MPs) is an essential issue in the motion planning system.\nTherefore, the purpose of this paper is to regenerate and join the learned MPs\nin the library. By applying a representation algorithm based on the modified\ndynamic movement primitives (DMPs) and singular value decomposition (SVD), our\nmethod separates the basic shape parameters and fine-tuning shape parameters\nfrom the same type of demonstration trajectories in the MP library. Moreover,\nwe convert the MP joining problem into a re-representation problem and use the\ncharacteristics of the proposed representation algorithm to achieve an accurate\nand smooth transition. This paper demonstrates that the proposed method can\neffectively reduce the number of shape adjustment parameters when the MPs are\nregenerated without affecting the accuracy of the representation. Besides, we\nalso present the ability of the proposed method to smooth the velocity jump\nwhen the MPs are connected and evaluate its effect on the accuracy of tracking\nthe set target points. The results show that the proposed method can not only\nimprove the adjustment ability of a single MP in response to different motion\nplanning requirements but also meet the basic requirements of MP joining in the\ngeneration of MP sequences.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The Copenhagen interpretation of quantum mechanics, which first took shape in\nBohr's landmark 1928 paper on complementarity, remains an enigma. Although many\nphysicists are skeptical about the necessity of Bohr's philosophical\nconclusions, his pragmatic message about the importance of the whole\nexperimental arrangement is widely accepted. It is, however, generally also\nagreed that the Copenhagen interpretation has no direct consequences for the\nmathematical structure of quantum mechanics. Here I show that the application\nof Bohr's main concepts of complementarity to the subsystems of a closed system\nrequires a change in the definition of the quantum state. The appropriate\ndefinition is as an equivalence class similar to that used by von Neumann to\ndescribe macroscopic subsystems. He showed that such equivalence classes are\nnecessary in order to maximize information entropy and achieve agreement with\nexperimental entropy. However, the significance of these results for the\nquantum theory of measurement has been overlooked. Current formulations of\nmeasurement theory are therefore manifestly in conflict with experiment. This\nconflict is resolved by the definition of the quantum state proposed here.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Phase separation in a low-density gas-like phase and a high-density\nliquid-like one is a common trait of biological and synthetic self-propelling\nparticles' systems. The competition between motility and stochastic forces is\nassumed to fix the boundary between the homogeneous and the phase-separated\nphase. Here we demonstrate that motility does also promote the homogeneous\nphase allowing particles to resolve their collisions. This new understanding\nallows quantitatively predicting the spinodal-line of hard self-propelling\nBrownian particles, the prototypical model exhibiting a motility induced phase\nseparation. Furthermore, we demonstrate that frictional forces control the\nphysical process by which motility promotes the homogeneous phase. Hence,\nfriction emerges as an experimentally variable parameter to control the\nmotility induced phase diagram.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We propose an integrated control architecture to address the gap that\ncurrently exists for efficient real-time implementation of MPC-based control\napproaches for highly nonlinear systems with fast dynamics and a large number\nof control constraints. The proposed architecture contains two types of\ncontrollers: base controllers that are tuned or optimized offline, and parallel\ncontrollers that solve an optimization-based control problem online. The\ncontrol inputs computed by the base controllers provide starting points for the\noptimization problem of the parallel controllers, which operate in parallel\nwithin a limited time budget that does not exceed the control sampling time.\nThe resulting control system is very flexible and its architecture can easily\nbe modified or changed online, e.g., by adding or eliminating controllers, for\nonline improvement of the performance of the controlled system. In a case\nstudy, the proposed control architecture is implemented for highway traffic,\nwhich is characterized by nonlinear, fast dynamics with multiple control\nconstraints, to minimize the overall travel time of the vehicles, while\nincreasing their total traveled distance within the fixed simulation time\nwindow. The results of the simulation show the excellent real-time (i.e.,\nwithin the given time budget) performance of the proposed control architecture,\nwith the least realized value of the overall cost function. Moreover, among the\nonline control approaches considered for the case study, the average cost per\nvehicle for the base-parallel control approach is the closest to the online\nMPC-based controllers, which have excellent performance but may involve\ncomputation times that exceed the given time budget.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this note we study several topics related to the schema of local\nreflection $\\mathsf{Rfn}(T)$ and its partial and relativized variants. Firstly,\nwe introduce the principle of uniform reflection with $\\Sigma_n$-definable\nparameters, establish its relationship with the relativized local reflection\nprinciples and corresponding versions of induction with definable parameters.\nUsing this schema we give a new model-theoretic proof of the\n$\\Sigma_{n+2}$-conservativity of uniform $\\Sigma_{n+1}$-reflection over\nrelativized local $\\Sigma_{n+1}$-reflection. We also study the proof-theoretic\nstrength of Feferman's theorem, i.e., the assertion of $1$-provability in $S$\nof the local reflection schema $\\mathsf{Rfn}(S)$, and its generalized versions.\nWe relate this assertion to the uniform $\\Sigma_2$-reflection schema and, in\nparticular, obtain an alternative axiomatization of $\\mathsf{I}\\Sigma_1$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Epidemiologists use a variety of statistical algorithms for the early\ndetection of outbreaks. The practical usefulness of such methods highly depends\non the trade-off between the detection rate of outbreaks and the chances of\nraising a false alarm. Recent research has shown that the use of machine\nlearning for the fusion of multiple statistical algorithms improves outbreak\ndetection. Instead of relying only on the binary output (alarm or no alarm) of\nthe statistical algorithms, we propose to make use of their p-values for\ntraining a fusion classifier. In addition, we also show that adding additional\nfeatures and adapting the labeling of an epidemic period may further improve\nperformance. For comparison and evaluation, a new measure is introduced which\ncaptures the performance of an outbreak detection method with respect to a low\nrate of false alarms more precisely than previous works. Our results on\nsynthetic data show that it is challenging to improve the performance with a\ntrainable fusion method based on machine learning. In particular, the use of a\nfusion classifier that is only based on binary outputs of the statistical\nsurveillance methods can make the overall performance worse than directly using\nthe underlying algorithms. However, the use of p-values and additional\ninformation for the learning is promising, enabling to identify more valuable\npatterns to detect outbreaks.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Recently, effects of nonlinearity on topologically nontrivial systems have\nattracted attention and the stability of topologically protected edge states\nhas been studied for a quantum walk with nonlinear effects, which is akin to\ntime-periodically driven systems (Floquet systems). In the previous work, it\nhas been found that the edge states can be stable attractors or unstable\nrepellers depending on their intrinsic topological property, while the\nstability is not affected by the strength of nonlinearity. In the present work,\nwe find additional bifurcations at which edge states change from stable\nattractors to unstable repellers with increasing the strength of nonlinearity\nin nonlinear quantum walks, for the first time. The new bifurcations are unique\nto Floquet systems, since we take dynamical properties of Floquet systems into\nconsideration by directly applying the time-evolution operator of the quantum\nwalks to the linear stability analysis. Our results shed new light on nonlinear\neffects on topological edge states in Floquet systems.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We show that there exist absolute constants $\\Delta > \\delta > 0$ such that,\nfor all $n \\geqslant 2$, there exists a polynomial $P$ of degree $n$, with $\\pm\n1$ coefficients, such that $$\\delta\\sqrt{n} \\leqslant |P(z)| \\leqslant\n\\Delta\\sqrt{n}$$ for all $z\\in\\mathbb{C}$ with $|z|=1$. This confirms a\nconjecture of Littlewood from 1966.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Motivated by the recent development of terahertz pump-probe experiments, we\ninvestigate the short-time dynamics in superconductors with multiple attractive\npairing channels. Studying a single-band square lattice model with spin-spin\ninteraction as an example, we find the signatures of collective excitations of\nthe pairing symmetries (known as Bardasis-Schrieffer modes) as well as the\norder parameter amplitude (Higgs mode) in the short-time dynamics of the\nspectral gap and quasiparticle distribution after an excitation by a pump\npulse. We show that the polarization and intensity of the pulse can be used to\ncontrol the symmetry of the non-equilibrium state as well as frequencies and\nrelative intensities of the contributions of different collective modes. We\nfind particularly strong signatures of the Bardasis-Schrieffer mode in the\ndynamics of the quasiparticle distribution function. Our work shows the\npotential of modern ultrafast experiments to address the collective excitations\nin unconventional superconductors and highlights the importance of sub-dominant\ninteractions for the non-equilibrium dynamics in these systems.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The asymmetric dark matter (ADM) scenario can solve the coincidence problem\nbetween the baryon and the dark matter (DM) abundance when the DM mass is of\n${\\cal O}(1)\\,$GeV. In the ADM scenarios, composite dark matter is particularly\nmotivated, as it can naturally provide the DM mass in the ${\\cal O}(1)\\,$GeV\nrange and a large annihilation cross section simultaneously. In this paper, we\ndiscuss the indirect detection constraints on the composite ADM model. The\nportal operators connecting the $B-L$ asymmetries in the dark and the Standard\nModel(SM) sectors are assumed to be generated in association with the seesaw\nmechanism. In this model, composite dark matter inevitably obtains a tiny\nMajorana mass which induces a pair-annihilation of ADM at late times. We show\nthat the model can be efficiently tested by the searches for the $\\gamma$-ray\nfrom the dwarf spheroidal galaxies and the interstellar electron/positron flux.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A $W^{1,p}$-metric on an $n$-dimensional closed Riemannian manifold naturally\ninduces a distance function, provided $p$ is sufficiently close to $n$. If a\nsequence of metrics $g_k$ converges in $W^{1,p}$ to a limit metric $g$, then\nthe corresponding distance functions $d_{g_k}$ subconverge to a limit distance\nfunction $d$, which satisfies $d\\le d_g$.\n  As an application, we show that the above convergence result applies to a\nsequence of conformal metrics with $L^{n/2}$-bounded scalar curvatures, under\ncertain geometric assumptions. In particular, in this special setting, the\nlimit distance function $d$ actually coincides with $d_{g}$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The IceCube neutrino event detected 360 s before the trigger of LIGO/Virgo\nS190728q is unlikely to be physically associated with the GW event because of\nan energy budget reason.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Leighton's graph covering theorem says that two finite graphs with a common\ncover have a common finite cover. We present a new proof of this using\ngroupoids, and use this as a model to prove two generalisations of the theorem.\nThe first generalisation, which we refer to as the symmetry-restricted version,\nrestricts how balls of a given size in the universal cover can map down to the\ntwo finite graphs when factoring through the common finite cover - this answers\na question of Neumann. Secondly, we consider covers of graphs of spaces (or of\nmore general objects), which leads to an even more general version of\nLeighton's Theorem. We also compute upper bounds for the sizes of the finite\ncovers obtained in Leighton's Theorem and its generalisations. An appendix by\nGardam and Woodhouse provides an alternative proof of the symmetry-restricted\nversion, that uses Haar measure instead of groupoids.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The contribution to the spin of the proton from the gluon helicity is\nstarting to come into focus: for gluons carrying a large fraction $x$ of the\nproton momentum, evidence of positive gluon polarization has been observed, via\nmeasurements of the longitudinal double-spin asymmetry $A_{LL}$ for inclusive\njet and dijet production. $A_{LL}$ is sensitive to the polarized gluon\ndistribution function, $\\Delta g(x)$, and while it is positive at high $x$, it\nis not well constrained for $x<0.05$. Recent measurements at STAR of\nobservables originating dominantly from quark-gluon and gluon-gluon\nsubprocesses aim to improve the precision of $\\Delta g(x)$ at high $x$, as well\nas for the first time provide insight into the low-$x$ contribution. $A_{LL}$\nmeasurements of inclusive jets and dijets at midrapidity $(|\\eta|<1)$ and\nintermediate rapidity $(0.8<\\eta<2)$ at STAR at $\\sqrt{s}=200$ and $510$ GeV\nwill be shown, along with the statuses of ongoing analyses; these measurements\nwill help improve the $\\Delta g(x)$ precision for $x\\gtrsim 0.01$. Recent\n$\\pi^0$ $A_{LL}$ measurements in the forward region $(2.65<\\eta<3.9)$ at\n$\\sqrt{s}=510$ GeV will also be presented, which probe $\\Delta g(x)$ down to\n$x{\\sim}10^{-3}$. Comparisons of these results to recent global analyses and\nextrapolations will be discussed.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Time Series Motif Discovery (TSMD) is defined as searching for patterns that\nare previously unknown and appear with a given frequency in time series.\nAnother problem strongly related with TSMD is Word Segmentation. This problem\nhas received much attention from the community that studies early language\nacquisition in babies and toddlers. The development of biologically plausible\nmodels for word segmentation could greatly advance this field. Therefore, in\nthis article, we propose the Variable Input Length Map (VILMAP) for Motif\nDiscovery and Word Segmentation. The model is based on the Self-Organizing Maps\nand can identify Motifs with different lengths in time series. In our\nexperiments, we show that VILMAP presents good results in finding Motifs in a\nstandard Motif discovery dataset and can avoid catastrophic forgetting when\ntrained with datasets with increasing values of input size. We also show that\nVILMAP achieves results similar or superior to other methods in the literature\ndeveloped for the task of word segmentation.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Motivated by the need of the linking records across various databases, we\npropose a novel graphical model based classifier that uses a mixture of Poisson\ndistributions with latent variables. The idea is to derive insight into each\npair of hypothesis records that match by inferring its underlying latent rate\nof error using Bayesian Modeling techniques. The novel approach of using gamma\npriors for learning the latent variables along with supervised labels is unique\nand allows for active learning. The naive assumption is made deliberately as to\nthe independence of the fields to propose a generalized theory for this class\nof problems and not to undermine the hierarchical dependencies that could be\npresent in different scenarios. This classifier is able to work with sparse and\nstreaming data. The application to record linkage is able to meet several\nchallenges of sparsity, data streams and varying nature of the data-sets.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We set up a vacuum theory of gravity with an extra dimension of vanishing\nproper length. The most general solution to the field equations are presented.\nThis formulation is free of Kaluza-Klein modes and does not allow the\npropagation of gravitons along the invisible fifth direction. Apart from a\nvacuum energy and radiation, the associated emergent theory exhibits a\nnonpropagating vector-tensor multiplet which has no analogue in standard\nEinstein gravity. It is naturally inert, obeys a bounded equation of state and\nhas coupling properties radically different from ordinary matter. Based on\nthese distinctive features, we propose that this geometric multiplet could\nsupercede the hypothetical ``dark matter''. As further evidence in support of\nthis possibility, we show that the galactic rotation curves are predicted to be\nasymptotically flat.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We investigate the evolution of the cross-plane thermal conductivity $\\kappa$\nof superlattices (SLs) as interfaces change from perfectly abrupt to totally\nintermixed, by using non-equilibrium molecular dynamics simulations in\ncombination with the spectral heat current calculations. We highlight the role\nof surface-interdiffusion-driven intermixing by calculating the $\\kappa$ of SLs\nwith changing interface roughness, whose tuning allows for the $\\kappa$ values\nmuch lower than the \"alloy limit\" and the abrupt interface limit in same cases.\nThe interplay between alloy and interface scattering in different frequency\nranges provides a physical basis to predict a minimum of thermal conductivity.\nMore specifically, we also explore how the interface roughness affects the\nthermal conductivities for SLs materials with a broad span of atomic mass and\nbond strength. In particular, we find that (i) only when the \"spacer\" thickness\nof SLs increases up to a critical value the $\\kappa$ of rough SLs can break the\ncorresponding \"alloy limit\". (ii) Whether the $\\kappa$ changes monotonically as\ninterface roughness strongly depends on the period length and intrinsic\nbehavior of phonon transport for SLs materials. Especially, for the SL with\nlarge period length, there exists an optimal interface roughness which can\nminimize the thermal conductivity. (iii) Surface-interdiffusion-driven\nintermixing is more effective in achieving the low $\\kappa$ below the alloy\nlimit for SL materials with large mass mismatch than with small one. (iv) It's\npossible for SLs materials with large lattice mismatch (i.e., bond strength) to\ndesign an ideally abrupt interface structure with $\\kappa$ much below the\n\"alloy limit\". These results have a clear implications for optimization of\nthermal transport for heat management and for the development of thermoelectric\nmaterials.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Widely-used public benchmarks are of huge importance to computer vision and\nmachine learning research, especially with the computational resources required\nto reproduce state of the art results quickly becoming untenable. In medical\nimage computing, the wide variety of image modalities and problem formulations\nyields a huge task-space for benchmarks to cover, and thus the widespread\nadoption of standard benchmarks has been slow, and barriers to releasing\nmedical data exacerbate this issue. In this paper, we examine the role that\npublicly available data has played in MICCAI papers from the past five years.\nWe find that more than half of these papers are based on private data alone,\nalthough this proportion seems to be decreasing over time. Additionally, we\nobserved that after controlling for open access publication and the release of\ncode, papers based on public data were cited over 60% more per year than their\nprivate-data counterparts. Further, we found that more than 20% of papers using\npublic data did not provide a citation to the dataset or associated manuscript,\nhighlighting the \"second-rate\" status that data contributions often take\ncompared to theoretical ones. We conclude by making recommendations for MICCAI\npolicies which could help to better incentivise data sharing and move the field\ntoward more efficient and reproducible science.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The genealogical structure of self-similar growth-fragmentations can be\ndescribed in terms of a branching random walk. The so-called intrinsic area\n$\\mathrm{A}$ arises in this setting as the terminal value of a remarkable\nadditive martingale. Motivated by connections with some models of random planar\ngeometry, the purpose of this work is to investigate the effect of conditioning\na self-similar growth-fragmentation on its intrinsic area. The distribution of\n$\\mathrm{A}$ satisfies a useful smoothing transform which enables us to\nestablish the existence of a regular density $a$ and to determine the\nasymptotic behavior of $a(r)$ as $r\\to \\infty$ (this can be seen as a local\nversion of Kesten-Grincevicius-Goldie theorem's for random affine fixed point\nequations in a particular setting). In turn, this yields a family of\nmartingales from which the formal conditioning on $\\mathrm{A}=r$ can be\nrealized by probability tilting. We point at a limit theorem for the\nconditional distribution given $\\mathrm{A}=r$ as $r\\to \\infty$, and also\nobserve that such conditioning still makes sense under the so-called canonical\nmeasure for which the growth-fragmentation starts from $0$\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We construct an action of the Neron--Severi part of the\nLooijenga-Lunts-Verbitsky Lie algebra on the Chow ring of the Hilbert scheme of\npoints on a K3 surface. This yields a simplification of Maulik and Negut's\nproof that the cycle class map is injective on the subring generated by divisor\nclasses as conjectured by Beauville. The key step in the construction is an\nexplicit formula for Lefschetz duals in terms of Nakajima operators. Our\nresults also lead to a formula for the monodromy action on Hilbert schemes in\nterms of Nakajima operators.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Despite the growing popularity of human mobility studies that collect GPS\nlocation data, the problem of determining the minimum required length of GPS\nmonitoring has not been addressed in the current statistical literature. In\nthis paper we tackle this problem by laying out a theoretical framework for\nassessing the temporal stability of human mobility based on GPS location data.\nWe define several measures of the temporal dynamics of human spatiotemporal\ntrajectories based on the average velocity process, and on activity\ndistributions in a spatial observation window. We demonstrate the use of our\nmethods with data that comprise the GPS locations of 185 individuals over the\ncourse of 18 months. Our empirical results suggest that GPS monitoring should\nbe performed over periods of time that are significantly longer than what has\nbeen previously suggested. Furthermore, we argue that GPS study designs should\ntake into account demographic groups.\n  KEYWORDS: Density estimation; global positioning systems (GPS); human\nmobility; spatiotemporal trajectories; temporal dynamics\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We study generating functions of moduli-space integrals at genus one that are\nexpected to form a basis for massless $n$-point one-loop amplitudes of open\nsuperstrings and open bosonic strings. These integrals are shown to satisfy the\nsame type of linear and homogeneous first-order differential equation w.r.t.\nthe modular parameter $\\tau$ which is known from the A-elliptic\nKnizhnik--Zamolodchikov--Bernard associator. The expressions for their\n$\\tau$-derivatives take a universal form for the integration cycles in planar\nand non-planar one-loop open-string amplitudes. These differential equations\nmanifest the uniformly transcendental appearance of iterated integrals over\nholomorphic Eisenstein series in the low-energy expansion w.r.t. the inverse\nstring tension $\\alpha'$. In fact, we are led to matrix representations of\ncertain derivations dual to Eisenstein series. Like this, also the\n$\\alpha'$-expansion of non-planar integrals is manifestly expressible in terms\nof iterated Eisenstein integrals without referring to twisted elliptic multiple\nzeta values. The degeneration of the moduli-space integrals at $\\tau\n\\rightarrow i\\infty$ is expressed in terms of their genus-zero analogues --\n$(n{+}2)$-point Parke--Taylor integrals over disk boundaries. Our results yield\na compact formula for $\\alpha'$-expansions of $n$-point integrals over\nboundaries of cylinder- or Moebius-strip worldsheets, where any desired order\nis accessible from elementary operations.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Let $\\psi $ be a conformal map of $\\mathbb{D}$ onto an unbounded domain and,\nfor $\\alpha >0$, let ${F_\\alpha }=\\left\\{ {z \\in \\mathbb{D}:\\left| {\\psi \\left(\nz \\right)} \\right| = \\alpha } \\right\\}$. If $\\omega _\\mathbb{D}\\left(\n{0,{F_\\alpha }} \\right)$ denotes the harmonic measure at $0$ of $F_\\alpha $ and\n$d_\\mathbb{D} {\\left( {0,{F_\\alpha }} \\right)}$ denotes the hyperbolic distance\nbetween $0$ and $F_\\alpha$ in $\\mathbb{D}$, then an application of the\nBeurling-Nevanlinna projection theorem implies that ${\\omega _\\mathbb{D}}\\left(\n{0,{F_\\alpha }} \\right) \\ge \\frac{2}{\\pi }{e^{ - {d_\\mathbb{D}}\\left(\n{0,{F_\\alpha }} \\right)}}$. Thus a natural question, first stated by P.\nPoggi-Corradini, is the following: Does there exist a positive constant $K$\nsuch that for every $\\alpha >0$, ${\\omega _\\mathbb{D}}\\left( {0,{F_\\alpha }}\n\\right) \\le K{e^{ - {d_\\mathbb{D}}\\left( {0,{F_\\alpha }} \\right)}}$? In\ngeneral, we prove that the answer is negative by means of two different\nexamples. However, under additional assumptions involving the number of\ncomponents of $F_\\alpha$ and the hyperbolic geometry of the domain $\\psi \\left(\n\\mathbb{D} \\right)$, we prove that the answer is positive.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We use the method of brackets to evaluate quadratic and quartic type\nintegrals. We recall the operational rules of the method and give examples to\nillustrate its working. The method is then used to evaluate the quadratic type\nintegrals which occur in entries 3.251.1,3,4 in the table of integrals by\nGradshteyn and Ryzhik and obtain closed form expressions in terms of\nhypergeometric functions. The method is further used to evaluate the quartic\nintegrals, entry 2.161.5 and 6 in the table. We also present generalization of\nboth types of integrals with closed form expression in terms of hypergeometric\nfunctions.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this contribution we present a lattice calculation of the leading-order\nelectromagnetic and strong isospin-breaking (IB) corrections to the\nquark-connected hadronic-vacuum-polarization (HVP) contribution to the\nanomalous magnetic moment of the muon. The results are obtained adopting the\nRM123 approach in the quenched-QED approximation and using the QCD gauge\nconfigurations generated by the ETM Collaboration with $N_f = 2+1+1$ dynamical\nquarks, at three values of the lattice spacing ($a \\simeq 0.062, 0.082, 0.089$\nfm), at several lattice volumes and with pion masses between $\\simeq 210$ and\n$\\simeq 450$ MeV. After the extrapolations to the physical pion mass and to the\ncontinuum and infinite-volume limits the contributions of the light, strange\nand charm quarks are respectively equal to $\\delta a_\\mu^{\\rm HVP}(ud) = 7.1 ~\n(2.5) \\cdot 10^{-10}$, $\\delta a_\\mu^{\\rm HVP}(s) = -0.0053 ~ (33) \\cdot\n10^{-10}$ and $\\delta a_\\mu^{\\rm HVP}(c) = 0.0182 ~ (36) \\cdot 10^{-10}$. At\nleading order in $\\alpha_{em}$ and $(m_d - m_u) / \\Lambda_{QCD}$ we obtain\n$\\delta a_\\mu^{\\rm HVP}(udsc) = 7.1 ~ (2.9) \\cdot 10^{-10}$, which is currently\nthe most accurate determination of the IB corrections to $a_\\mu^{\\rm HVP}$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this article, I will review how observations performed with extensive air\nshowers are being used to probe hadronic interactions at high energy. I will\nbriefly overview the new studies exploring the connection between the dynamics\nof air showers and multiparticle production, and how this knowledge can be\ntranslated into constraints on high energy hadronic models. I will also\noverview direct measurements, complementary to, and beyond the reach of,\naccelerator experiments.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  If a $Spin(7)$ manifold $N^8$ admits a free $S^1$ action preserving the\nfundamental $4$-form then the quotient space $M^7$ is naturally endowed with a\n$G_2$-structure. We derive equations relating the intrinsic torsion of the\n$Spin(7)$-structure to that of the $G_2$-structure together with the additional\ndata of a Higgs field and the curvature of the $S^1$-bundle; this can be\ninterpreted as a Gibbons-Hawking-type ansatz for $Spin(7)$-structures. We focus\non the three $Spin(7)$ torsion classes: torsion-free, locally conformally\nparallel and balanced. In particular we show that if $N$ is a $Spin(7)$\nmanifold then $M$ cannot have holonomy contained in $G_2$ unless $N$ is in fact\na Calabi-Yau $4$-fold and $M$ is the product of a Calabi-Yau $3$-fold and an\ninterval. We also derive a new formula for the Ricci curvature of\n$Spin(7)$-structures in terms of the torsion forms. We then describe this\n$S^1$-quotient construction in detail for the Bryant-Salamon $Spin(7)$ metric\non the spinor bundle of $S^4$ and for the flat metric on $\\mathbb{R}^8$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Let $\\Omega \\subset \\mathbb{R}^N$, $N \\geq 2$, be a smooth bounded domain. We\nconsider the boundary value problem \\begin{equation}\n\\label{Plambda-Abstract-ch3} \\tag{$P_{\\lambda}$} -\\Delta u = c_{\\lambda}(x) u +\n\\mu |\\nabla u|^2 + h(x)\\,, \\quad u \\in H_0^1(\\Omega) \\cap L^{\\infty}(\\Omega)\\,,\n\\end{equation} where $c_{\\lambda}$ and $h$ belong to $L^q(\\Omega)$ for some $q\n> N/2$, $\\mu$ belongs to $\\mathbb{R} \\setminus \\{0\\}$ and we write\n$c_{\\lambda}$ under the form $c_{\\lambda}:= \\lambda c_{+} - c_{-}$ with $c_{+}\n\\gneqq 0$, $c_{-} \\geq 0$, $c_{+} c_{-} \\equiv 0$ and $\\lambda \\in \\mathbb{R}$.\nHere $c_{\\lambda}$ and $h$ are both allowed to change sign. As a first main\nresult we give a necessary and sufficient condition which guarantees the\nexistence of a unique solution to \\eqref{Plambda-Abstract-ch3} when $\\lambda\n\\leq 0$. Then, assuming that $(P_0)$ has a solution, we prove existence and\nmultiplicity results for $\\lambda > 0$. Our proofs rely on a suitable change of\nvariable of type $v = F(u)$ and the combination of variational methods with\nlower and upper solution techniques.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Deep learning has largely reduced the need for manual feature selection in\nimage segmentation. Nevertheless, network architecture optimization and\nhyperparameter tuning are mostly manual and time consuming. Although there are\nincreasing research efforts on network architecture search in computer vision,\nmost works concentrate on image classification but not segmentation, and there\nare very limited efforts on medical image segmentation especially in 3D. To\nremedy this, here we propose a framework, SegNAS3D, for network architecture\nsearch of 3D image segmentation. In this framework, a network architecture\ncomprises interconnected building blocks that consist of operations such as\nconvolution and skip connection. By representing the block structure as a\nlearnable directed acyclic graph, hyperparameters such as the number of feature\nchannels and the option of using deep supervision can be learned together\nthrough derivative-free global optimization. Experiments on 43 3D brain\nmagnetic resonance images with 19 structures achieved an average Dice\ncoefficient of 82%. Each architecture search required less than three days on\nthree GPUs and produced architectures that were much smaller than the\nstate-of-the-art manually created architectures.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The proliferation of ride sharing systems is a major drive in the advancement\nof autonomous and electric vehicle technologies. This paper considers the joint\nrouting, battery charging, and pricing problem faced by a profit-maximizing\ntransportation service provider that operates a fleet of autonomous electric\nvehicles. We first establish the static planning problem by considering\ntime-invariant system parameters and determine the optimal static policy. While\nthe static policy provides stability of customer queues waiting for rides even\nif consider the system dynamics, we see that it is inefficient to utilize a\nstatic policy as it can lead to long wait times for customers and low profits.\nTo accommodate for the stochastic nature of trip demands, renewable energy\navailability, and electricity prices and to further optimally manage the\nautonomous fleet given the need to generate integer allocations, a real-time\npolicy is required. The optimal real-time policy that executes actions based on\nfull state information of the system is the solution of a complex dynamic\nprogram. However, we argue that it is intractable to exactly solve for the\noptimal policy using exact dynamic programming methods and therefore apply deep\nreinforcement learning to develop a near-optimal control policy. The two case\nstudies we conducted in Manhattan and San Francisco demonstrate the efficacy of\nour real-time policy in terms of network stability and profits, while keeping\nthe queue lengths up to 200 times less than the static policy.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We derive non-asymptotic quantitative bounds for convergence to equilibrium\nof the exact preconditioned Hamiltonian Monte Carlo algorithm (pHMC) on a\nHilbert space. As a consequence, explicit and dimension-free bounds for pHMC\napplied to high-dimensional distributions arising in transition path sampling\nand path integral molecular dynamics are given. Global convexity of the\nunderlying potential energies is not required. Our results are based on a\ntwo-scale coupling which is contractive in a carefully designed distance.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We address the problem of severe class imbalance in unsupervised domain\nadaptation, when the class spaces in source and target domains diverge\nconsiderably. Till recently, domain adaptation methods assumed the aligned\nclass spaces, such that reducing distribution divergence makes the transfer\nbetween domains easier. Such an alignment assumption is invalidated in real\nworld scenarios where some source classes are often under-represented or simply\nabsent in the target domain. We revise the current approaches to class\nimbalance and propose a new one that uses latent codes in the adversarial\ndomain adaptation framework. We show how the latent codes can be used to\ndisentangle the silent structure of the target domain and to identify\nunder-represented classes. We show how to learn the latent code reconstruction\njointly with the domain invariant representation and use them to accurately\nestimate the target labels.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Given the recent progress in language modeling using Transformer-based neural\nmodels and an active interest in generating stylized text, we present an\napproach to leverage the generalization capabilities of a language model to\nrewrite an input text in a target author's style. Our proposed approach adapts\na pre-trained language model to generate author-stylized text by fine-tuning on\nthe author-specific corpus using a denoising autoencoder (DAE) loss in a\ncascaded encoder-decoder framework. Optimizing over DAE loss allows our model\nto learn the nuances of an author's style without relying on parallel data,\nwhich has been a severe limitation of the previous related works in this space.\nTo evaluate the efficacy of our approach, we propose a linguistically-motivated\nframework to quantify stylistic alignment of the generated text to the target\nauthor at lexical, syntactic and surface levels. The evaluation framework is\nboth interpretable as it leads to several insights about the model, and\nself-contained as it does not rely on external classifiers, e.g. sentiment or\nformality classifiers. Qualitative and quantitative assessment indicates that\nthe proposed approach rewrites the input text with better alignment to the\ntarget style while preserving the original content better than state-of-the-art\nbaselines.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We show that, generically, finding the $k$-th root of a braid is very fast.\nMore precisely, we provide an algorithm which, given a braid $x$ on $n$ strands\nand canonical length $l$, and an integer $k>1$, computes a $k$-th root of $x$,\nif it exists, or guarantees that such a root does not exist. The generic-case\ncomplexity of this algorithm is $O(l(l+n)n^3\\log n)$. The non-generic cases are\ntreated using a previously known algorithm by Sang-Jin Lee.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Continuing previous work, we show the existence of stable, anisotropic future\nattractors in Bianchi invariant sets with a $p$-form field ($p\\,\\in\\,\\{1,3\\}$)\nand a perfect fluid. In particular, we consider the not previously investigated\nBianchi invariant sets $\\mathcal{B}$(II), $\\mathcal{B}$(IV),\n$\\mathcal{B}$(VII$_0$) and $\\mathcal{B}$(VII$_{h})$ and examine their\nasymptotic behaviour. We find that the isolated equilibrium set Wonderland is a\nfuture attractor on all of its existence ($2/3<\\,\\gamma\\,<2$) in all these sets\nexcept in $\\mathcal{B}$(II), where the peculiar equilibrium sets Edge and Rope\nshow up, taking over the stability for certain values of $\\gamma$. In addition,\nin $\\mathcal{B}$(IV) and $\\mathcal{B}$(VII$_h$) plane gravitational wave\nsolutions (with a non-zero $p$-form) serve as attractors whenever\n$2/3<\\,\\gamma\\,<2$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  AI-synthesized face-swapping videos, commonly known as DeepFakes, is an\nemerging problem threatening the trustworthiness of online information. The\nneed to develop and evaluate DeepFake detection algorithms calls for\nlarge-scale datasets. However, current DeepFake datasets suffer from low visual\nquality and do not resemble DeepFake videos circulated on the Internet. We\npresent a new large-scale challenging DeepFake video dataset, Celeb-DF, which\ncontains 5,639 high-quality DeepFake videos of celebrities generated using\nimproved synthesis process. We conduct a comprehensive evaluation of DeepFake\ndetection methods and datasets to demonstrate the escalated level of challenges\nposed by Celeb-DF.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  This paper proposes a methodology for the automated construction of\nrectangular floorplans (RFPs) while addressing dimensional constraints and\nadjacency relations. Here, adjacency relations are taken in the form of a\ndimensionless rectangular arrangement (RA) ensuring the existence of a RFP,\nwhile dimensional constraints are given in terms of minimum width and aspect\nratio range for each room. A linear optimization model is then presented to\nobtain a feasible dimensioned RFP for user-defined constraints. A GUI is also\ndeveloped for the automated generation of RFPs. The proposed model is able to\ngenerate feasible solutions for every possible RA in a reasonable amount of\ntime. From the architectural perspective, this work can be seen as a\nre-generation of well-known architectural plans with modified dimensions. In\nthe end, the regeneration of existing legacy RFPs (corresponding to the\nuser-defined dimensions) has been demonstrated, taking their image as input.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  For a group $G$ and a finite set $A$, denote by $\\text{End}(A^G)$ the monoid\nof all continuous shift commuting self-maps of $A^G$ and by $\\text{Aut}(A^G)$\nits group of units. We study the minimal cardinality of a generating set, known\nas the rank, of $\\text{End}(A^G)$ and $\\text{Aut}(A^G)$. In the first part,\nwhen $G$ is a finite group, we give upper and lower bounds for the rank of\n$\\text{Aut}(A^G)$ in terms of the number of conjugacy classes of subgroups of\n$G$. In the second part, we apply our bounds to show that if $G$ has an\ninfinite descending chain of normal subgroups of finite index, then\n$\\text{End}(A^G)$ is not finitely generated; such is the case for wide classes\nof infinite groups, such as infinite residually finite or infinite locally\ngraded groups.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We semianalytically investigate the scalar self-force experienced in the\nfinal stages of extreme mass ratio inspirals of nonspinning scalar particles\ninto supermassive nearly extremal Kerr black holes. We exploit the near-horizon\nconformal symmetry to find the self-force for general corotating equatorial\ngeodesics. The angular component of the self-force is shown to be universal at\nleading order in the high spin limit. We verify that the energy and angular\nmomentum losses of the scalar particle match with the asymptotic fluxes of\nscalar radiation. In particular, we relate the previously described persistent\noscillations in the asymptotic energy and angular momentum fluxes with the\nlocal self-force. Such oscillations arise from traveling waves that prevent the\nnear-horizon and the asymptotic region to fully decouple in the extremal limit.\nConformal invariance is therefore reduced to discrete scale invariance with\nassociated logarithmic periodicity.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  With the rising interest in graph representation learning, a variety of\napproaches have been proposed to effectively capture a graph's properties.\nWhile these approaches have improved performance in graph machine learning\ntasks compared to traditional graph techniques, they are still perceived as\ntechniques with limited insight into the information encoded in these\nrepresentations. In this work, we explore methods to interpret node embeddings\nand propose the creation of a robust evaluation framework for comparing graph\nrepresentation learning algorithms and hyperparameters. We test our methods on\ngraphs with different properties and investigate the relationship between\nembedding training parameters and the ability of the produced embedding to\nrecover the structure of the original graph in a downstream task.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Experimental protocols at synchrotron light sources typically process and\nvalidate data only after an experiment has completed, which can lead to\nundetected errors and cannot enable online steering. Real-time data analysis\ncan enable both detection of, and recovery from, errors, and optimization of\ndata acquisition. However, modern scientific instruments, such as detectors at\nsynchrotron light sources, can generate data at GBs/sec rates. Data processing\nmethods such as the widely used computational tomography usually require\nconsiderable computational resources, and yield poor quality reconstructions in\nthe early stages of data acquisition when available views are sparse. We\ndescribe here how a deep convolutional neural network can be integrated into\nthe real-time streaming tomography pipeline to enable better-quality images in\nthe early stages of data acquisition. Compared with conventional streaming\ntomography processing, our method can significantly improve tomography image\nquality, deliver comparable images using only 32% of the data needed for\nconventional streaming processing, and save 68% experiment time for data\nacquisition.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We present a detailed observational and modeling study of the hot core VLA 3\nin the high-mass star-forming region AFGL 2591, which is a target region of the\nNOrthern Extended Millimeter Array (NOEMA) large program CORE. Using NOEMA\nobservations at 1.37 mm with an angular resolution of ~0.\"42 (1 400 au at 3.33\nkpc), we derived the physical and chemical structure of the source. We modeled\nthe observed molecular abundances with the chemical evolution code MUSCLE\n(MUlti Stage ChemicaL codE). Results. With the kinetic temperature tracers\nCH3CN and H2CO we observe a temperature distribution with a power-law index of\nq = 0.41+-0.08. Using the visibilities of the continuum emission we derive a\ndensity structure with a power-law index of p = 1.7+-0.1. The hot core spectra\nreveal high molecular abundances and a rich diversity in complex molecules. The\nmajority of the molecules have an asymmetric spatial distribution around the\nforming protostar(s), which indicates a complex physical structure on scales <\n1 400 au. Using MUSCLE, we are able to explain the observed molecular abundance\nof 10 out of 14 modeled species at an estimated hot core chemical age of ~21\n100 years. In contrast to the observational analysis, our chemical modeling\npredicts a lower density power-law index of p < 1.4. Reasons for this\ndiscrepancy are discussed. Conclusions. Combining high spatial resolution\nobservations with detailed chemical modeling allows us to derive a concise\npicture of the physical and chemical structure of the famous AFGL 2591 hot\ncore. The next steps are to conduct a similar analysis for the whole CORE\nsample, and then use this analysis to constrain the chemical diversity in\nhigh-mass star formation to a much greater depth.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  This work is concerned with the rating of players/teams in face-to-face games\nwith three possible outcomes: loss, win, and draw. This is one of the\nfundamental problems in sport analytics, where the very simple and popular,\nnon-trivial algorithm was proposed by Arpad Elo in late fifties to rate chess\nplayers. In this work we explain the mathematical model underlying the Elo\nalgorithm and, in particular, we explain what is the implicit but not yet\nspelled out, assumption about the model of draws. We further extend the model\nto provide flexibility and remove the unrealistic implicit assumptions of the\nElo algorithm. This yields the new rating algorithm, we call $\\kappa$-Elo,\nwhich is equally simple as the Elo algorithm but provides a possibility to\nadjust to the frequency of draws. The discussion of the importance of the\nappropriate choice of the parameters is carried out and illustrated using\nresults from English Premier League football seasons.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this paper lower bounds are obtained for quasi-local masses in terms of\ncharge, angular momentum, and horizon area. In particular we treat three\nquasi-local masses based on a Hamiltonian approach, namely the Brown-York,\nLiu-Yau, and Wang-Yau masses. The geometric inequalities are motivated by\nanalogous results for the ADM mass. They may be interpreted as localized\nversions of these inequalities, and are also closely tied to the conjectured\nBekenstein bounds for entropy of macroscopic bodies. In addition, we give a new\nproof of the positivity property for the Wang-Yau mass which is used to remove\nthe spin condition in higher dimensions. Furthermore, we generalize a recent\nresult of Lu and Miao to obtain a localized version of the Penrose inequality\nfor the static Wang-Yau mass.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Coulomb interaction might have important effects on the physical observables\nin topological semimetals with vanishing density of states at the band touching\ndue to the weak screening. In this work, we show that Kohn's theorem is not\nfulfilled in nodal-line semimetals (NLSMs), which implies non-vanishing\ninteraction corrections to the conductivity. Using renormalized perturbation\ntheory, we determine the first-order optical conductivity in a clean NLSM to be\n$\\sigma_{\\perp \\perp}(\\Omega) = 2 \\sigma_{\\parallel \\parallel}(\\Omega) =\n\\sigma_0 [1 + C_2 \\alpha_R(\\Omega)]$, where $\\perp$ and $\\parallel$ denote the\nperpendicular and parallel components with respect to the nodal loop, $\\sigma_0\n= (2 \\pi k_0) e^2/(16h)$ is the conductivity in the noninteracting limit, $2\n\\pi k_0$ is the nodal loop perimeter, $C_2 = (19-6\\pi)/12 \\simeq 0.013$ is a\nnumerical constant and $\\alpha_R(\\Omega)$ is the renormalized fine structure\nconstant in the NLSM. The analogies between NLSMs and 2D Dirac fermions are\nreflected in the universal character of the correction $C_2 \\alpha_R(\\Omega)$,\nwhich is exactly parallel to that of graphene. Finally, we analyze some\nexperiments that have determined the optical conductivity in NLSMs, discussing\nthe possibility of experimentally measuring our result.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A method of approximating the inverse Radon transform on the plane by\nintegrating against a smooth kernel is investigated. For piecewise smooth\nintegrable functions, convergence theorems are proven and Gibbs phenomena are\nruled out. Geometric properties of the kernel and their implications for\ncomputer implementation are discussed. Suggestions are made for applications\nand an example is presented.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this work, a recently developed novel solution of the famous \"Sommerfeld\nRadiation Problem\" is revisited. The solution is based on an analysis performed\nentirely in the spectral domain, through which a compact asymptotic formula\ndescribes the behavior of the EM field, which emanates from a vertical Hertzian\nradiating dipole, located above flat, lossy ground. The paper is divided into\ntwo parts. First, we demonstrate an efficient technique for the accurate\nnumeric calculation of the well - known Sommerfeld integrals, required for the\nevaluation of the field. The results are compared against alternative\ncalculation approaches and validated with the corresponding Norton figures for\nthe Surface Wave. Then, in the second part, we briefly introduce the asymptotic\nsolution of interest and investigate its performance; we contrast the solution\nversus the accurate numerical evaluation for the total received EM field and\nalso with a more basic asymptotic solution to the given problem, obtained via\nthe application of the Stationary Phase Method (SPM). Simulations for various\nfrequencies, distances, altitudes and ground characteristics are illustrated\nand inferences for the applicability of the solution are made. Finally, special\ncases, leading to analytic field expressions, close as well as far from the\ninterface, are examined.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  This study aims to reconcile quantum theory with the universality of the\nspeed of light in vacuum and its implications on relativity, through an\ninformation-theoretic approach. We introduce the concepts of a holographic\nsphere and variational potential. Entropy variation expressed in terms of\ninformation capacity of this sphere results in the concept of binary potential\nin units of negative, squared speed of light in vacuum. Accordingly, the event\nhorizon is a fundamental holographic sphere in thermodynamic equilibrium with\nonly one exterior side: a noncompressible binary message that maximizes Shannon\nentropy. Therefore, the Jordan-Brouwer separation theorem and generalized\nStokes theorem do not hold for black holes. We introduce the concept of\ninertial potential and demonstrate its equivalence to the variational\npotential, which ensures that any inertial acceleration represents a\nnonequilibrium thermodynamic condition. We introduce the concept of the\ncomplementary time period and relate it with the classical time period through\nintegral powers of the imaginary unit to formulate the notions of unobservable\nvelocity and acceleration, which are perpendicular and tangential to the\nholographic sphere, respectively, and bounded with the observable velocity and\nacceleration based on Pythagorean relations. We further discuss certain\ndynamics scenarios between the two masses. The concept of black hole\ninformation-less emission is introduced as a complement to informationless\nBekenstein absorption and extended to arbitrary wavelengths. Black hole quantum\nstatistics with degeneracy interpret-ed as the number of Planck areas on the\nevent horizon are discussed. The study concludes that holographic screens and\nequipotential surfaces are spherical equivalents, and every observer is a\nsphere in nonequilibrium thermodynamic condition. Lastly, we propose a solution\nto the black hole information paradox.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this paper, we present a nonlinear robust model predictive control (MPC)\nframework for general (state and input dependent) disturbances. This approach\nuses an online constructed tube in order to tighten the nominal (state and\ninput) constraints. To facilitate an efficient online implementation, the shape\nof the tube is based on an offline computed incremental Lyapunov function with\na corresponding (nonlinear) incrementally stabilizing feedback. Crucially, the\nonline optimization only implicitly includes these nonlinear functions in terms\nof scalar bounds, which enables an efficient implementation. Furthermore, to\naccount for an efficient evaluation of the worst case disturbance, a simple\nfunction is constructed offline that upper bounds the possible disturbance\nrealizations in a neighbourhood of a given point of the open-loop trajectory.\nThe resulting MPC scheme ensures robust constraint satisfaction and practical\nasymptotic stability with a moderate increase in the online computational\ndemand compared to a nominal MPC. We demonstrate the applicability of the\nproposed framework in comparison to state of the art robust MPC approaches with\na nonlinear benchmark example. This paper is an extended version of [1], and\ncontains further details and additional considers: continuous-time systems\n(App. A), more general nonlinear constraints (App. B) and special cases (Sec.\nIV).\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Remarkable progress has been made in object instance detection and\nsegmentation in recent years. However, existing state-of-the-art methods are\nmostly evaluated with fairly balanced and class-limited benchmarks, such as\nMicrosoft COCO dataset [8]. In this report, we investigate the performance drop\nphenomenon of state-of-the-art two-stage instance segmentation models when\nprocessing extreme long-tail training data based on the LVIS [5] dataset, and\nfind a major cause is the inaccurate classification of object proposals. Based\non this observation, we propose to calibrate the prediction of classification\nhead to improve recognition performance for the tail classes. Without much\nadditional cost and modification of the detection model architecture, our\ncalibration method improves the performance of the baseline by a large margin\non the tail classes. Codes will be available. Importantly, after the\nsubmission, we find significant improvement can be further achieved by\nmodifying the calibration head, which we will update later.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Despite significant progress on stability analysis of conventional multiagent\nnetworked systems with weakly coupled state-network dynamics, most of the\nexisting results have shortcomings in addressing multiagent systems with highly\ncoupled state-network dynamics. Motivated by numerous applications of such\ndynamics, in our previous work [1], we initiated a new direction for stability\nanalysis of such systems that uses a sequential optimization framework.\nBuilding upon that, in this paper, we extend our results by providing another\nangle on multiagent network dynamics from a duality perspective, which allows\nus to view the network structure as dual variables of a constrained nonlinear\nprogram. Leveraging that idea, we show that the evolution of the coupled\nstate-network multiagent dynamics can be viewed as iterates of a primal-dual\nalgorithm for a static constrained optimization/saddle-point problem. This view\nbridges the Lyapunov stability of state-dependent network dynamics and\nfrequently used optimization techniques such as block coordinated descent,\nmirror descent, the Newton method, and the subgradient method. As a result, we\ndevelop a systematic framework for analyzing the Lyapunov stability of\nstate-dependent network dynamics using techniques from nonlinear optimization.\nFinally, we support our theoretical results through numerical simulations from\nsocial science.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Rewriting is a framework for reasoning about functional programming. The\ndependency pair criterion is a well-known mechanism to analyze termination of\nterm rewriting systems. Functional specifications with an operational semantics\nbased on evaluation are related, in the rewriting framework, to the innermost\nreduction relation. This paper presents a PVS formalization of the dependency\npair criterion for the innermost reduction relation: a term rewriting system is\ninnermost terminating if and only if it is terminating by the dependency pair\ncriterion. The paper also discusses the application of this criterion to check\ntermination of functional specifications.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this paper we prove quantitative results about geodesic approximations to\nsubmanifolds in negatively curved spaces. Among the main tools is a new and\ngeneral Jarn\\'{i}k-Besicovitch type theorem in Diophantine approximation. The\nframework we develop is flexible enough to treat manifolds of variable negative\ncurvature, a variety of geometric targets, and logarithm laws as well as\nspiraling phenomena in both measure and dimension aspect. Several of the\nresults are new also for manifolds of constant negative sectional curvature. We\nfurther establish a large intersection property of Falconer in this context.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Aligning multiple protein structures can yield valuable information about\nstructural similarities among related proteins, as well as provide insight into\nevolutionary relationships between proteins in a family. We have developed an\nalgorithm (msTALI) for aligning multiple protein structures using biochemical\nand biophysical properties, including torsion angles, secondary structure,\nhydrophobicity, and surface accessibility. The algorithm is a progressive\nalignment algorithm motivated by popular techniques from multiple sequence\nalignment. It has demonstrated success in aligning the major structural regions\nof a set of proteins from the s/r kinase family. The algorithm was also\nsuccessful at aligning functional residues of these proteins. In addition, the\nalgorithm was also successful in aligning seven members of the acyl carrier\nprotein family, including both experimentally derived as well as\ncomputationally modeled structures.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Photodissociation regions (PDRs) are parts of the ISM consisting of\npredominantly neutral gas, located at the interface between H II regions and\nmolecular clouds. The physical conditions within these regions show variations\non very short spatial scales, and therefore PDRs constitute ideal laboratories\nfor investigating the properties and evolution of dust grains. We have mapped\nIC 63 at high resolution from the UV to the NIR (275 nm to 1.6 $\\mu$m), using\nthe Hubble Space Telescope WFC3. Using a Bayesian SED fitting tool, we\nsimultaneously derive a set of stellar ($T_\\text{eff}$, $\\log(g)$, distance)\nand extinction ($A_V$, $R_V$) parameters for 520 background stars. We present\nmaps of $A_V$ and $R_V$ with a resolution of 25 arcsec based on these results.\nThe extinction properties vary across the PDR, with values for $A_V$ between\n0.5 and 1.4 mag, and a decreasing trend in $R_V$, going from 3.7 at the front\nof the nebula to values as low as 2.5 further in. This provides evidence for\nevolution of the dust optical properties. We fit two modified blackbodies to\nthe MIR and FIR SED, obtained by combining the $A_V$ map with data from Spitzer\nand Herschel. We derive effective temperatures (30 K and 227 K) and the ratio\nof opacities at 160 $\\mu$m to V band $\\kappa_{160} / \\kappa_V$ ($7.0 \\times\n10^{-4}$ and $2.9 \\times 10^{-9}$) for the two dust populations. Similar fits\nto individual pixels show spatial variations of $\\kappa_{160} / \\kappa_{V}$.\nThe analysis of our HST data, combined with these Spitzer and Herschel data,\nprovides the first panchromatic view of dust within a PDR.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We report quantum ground state cooling of a levitated nanoparticle in a room\ntemperature environment. Using coherent scattering into an optical cavity we\ncool the center of mass motion of a $143$ nm diameter silica particle by more\nthan $7$ orders of magnitude to $n_x=0.43\\pm0.03$ phonons along the cavity\naxis, corresponding to a temperature of $12~\\mu$K. We infer a heating rate of\n$\\Gamma_x/2\\pi = 21\\pm 3$ kHz, which results in a coherence time of $7.6~\\mu$s\n-- or $15$ coherent oscillations -- while the particle is optically trapped at\na pressure of $10^{-6}$ mbar. The inferred optomechanical coupling rate of\n$g_x/2\\pi = 71$ kHz places the system well into the regime of strong\ncooperativity ($C \\approx 5$). We expect that a combination of ultra-high\nvacuum with free-fall dynamics will allow to further expand the spatio-temporal\ncoherence of such nanoparticles by several orders of magnitude, thereby opening\nup new opportunities for macrosopic quantum experiments.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Upgrading the productivity of nanoparticles (NPs), generated by pulsed laser\nablation in liquid (PLAL), still remains challenging. Here a novel variant of\nPLAL was developed, where a doubled frequency Nd:YAG laser beam (532 nm, ~ 5\nns, 10 Hz) at different fluences and for different times was directed into a\nsealed vessel, toward the interface of the meniscus of ethanol with a tilted\nbulk metal target. Palladium, copper and silver NPs, synthesized in the\nperformed proof of concept experiments, were mass quantified, by an inductively\ncoupled plasma optical emission spectrometry, and characterized by\nultraviolet-visible extinction spectroscopy, transmission electron microscopy\nand X-ray diffraction. The NPs consist of crystalline metals of a few nm size\nand their ablation rates and agglomeration levels depend on the employed laser\nfluences. The ensuing laser power-specific productivity curves for each metal,\npeaked at specific laser fluences, were fitted to the results of a simple model\naccounting for plasma absorption and heat transfer. The resulting peaked yields\nand concentrations were more than an order of magnitude higher than those\nobtained for totally immersed targets. Besides, the measured productivities\nshowed nearly linear dependencies during time intervals up to 30 min of\nablation, but became saturated at 1 h, due to accumulation of a significant\nnumber of NPs along the laser beam path, reducing the laser intensity reaching\nthe target. This suggested approach could inspire future studies that will\ncontribute to further developments of efficient generation of NPs with\ncontrolled characteristics.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this work we introduce the generic conditions for the existence of a\nnon-equilibrium attractor that is an invariant manifold determined by the\nlong-wavelength modes of the physical system. We investigate the topological\nproperties of the global flow structure of the Gubser flow for the\nIsrael-Stewart theory and a kinetic model for the Boltzmann equation by\nemploying Morse-Smale theory. We present a complete classification of the\ninvariant submanifolds of the flow and determine all the possible flow lines\nconnecting any pair of UV/IR fixed points. The formal transseries solutions to\nthe Gubser dynamical system around the early-time (UV) and late-time (IR) fixed\npoints are constructed and analyzed. It is proven that these solutions are\npurely perturbative (or power-law asymptotic) series with a finite radius of\nconvergence. Based on these analyses, we find that Gubser-like expanding\nkinetic systems do not hydrodynamize owing to the failure of the\nhydrodynamization process which heavily relies on the classification of\n(non)hydrodynamic modes in the IR regime. This is in contrast to longitudinal\nboost-invariant plasmas where the asymptotic dynamics is described by a few\nterms of the hydrodynamic gradient expansion. We finally compare our results\nfor both Bjorken and Gubser conformal kinetic models.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Hindman and Leader first introduced the notion of semigroup of ultrafilters\nconverging to zero for a dense subsemigroups of $((0,\\infty),+)$. Using the\nalgebraic structure of the Stone-$\\breve{C}$ech compactification, Tootkabani\nand Vahed generalized and extended this notion to an idempotent instead of\nzero, that is a semigroup of ultrafilters converging to an idempotent $e$ for a\ndense subsemigroups of a semitopological semigroup $(T, +)$ and they gave the\ncombinatorial proof of central set theorem near $e$. Algebraically one can also\ndefine quasi-central sets near $e$ for dense subsemigroups of $(T, +)$. In a\ndense subsemigroup of $(T,+)$, C-sets near $e$ are the sets, which satisfy the\nconclusions of the central sets theorem near $e$. S. K. Patra gave dynamical\ncharacterizations of these combinatorially rich sets near zero. In this paper\nwe shall prove these dynamical characterizations for these combinatorially rich\nsets near $e$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The paper is focused on temporal logics for the description of the behaviour\nof real-time pushdown reactive systems. The paper is motivated to bridge\ntractable logics specialized for expressing separately dense-time real-time\nproperties and context-free properties by ensuring decidability and\ntractability in the combined setting. To this end we introduce two real-time\nlinear temporal logics for specifying quantitative timing context-free\nrequirements in a pointwise semantics setting: Event-Clock Nested Temporal\nLogic (EC_NTL) and Nested Metric Temporal Logic (NMTL). The logic EC_NTL is an\nextension of both the logic CaRet (a context-free extension of standard LTL)\nand Event-Clock Temporal Logic (a tractable real-time logical framework related\nto the class of Event-Clock automata). We prove that satisfiability of EC_NTL\nand visibly model-checking of Visibly Pushdown Timed Automata (VPTA) against\nEC_NTL are decidable and EXPTIME-complete. The other proposed logic NMTL is a\ncontext-free extension of standard Metric Temporal Logic (MTL). It is well\nknown that satisfiability of future MTL is undecidable when interpreted over\ninfinite timed words but decidable over finite timed words. On the other hand,\nwe show that by augmenting future MTL with future context-free temporal\noperators, the satisfiability problem turns out to be undecidable also for\nfinite timed words. On the positive side, we devise a meaningful and decidable\nfragment of the logic NMTL which is expressively equivalent to EC_NTL and for\nwhich satisfiability and visibly model-checking of VPTA are EXPTIME-complete.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We study the convergence of graphs consisting of finitely many internal rays\nfor degenerating Newton maps. We state a sufficient condition to guarantee the\nconvergence. As an application, we investigate the boundedness of hyperbolic\ncomponents in the moduli space of quartic Newton maps. We prove that such a\nhyperbolic component is bounded if and only if every element has degree $2$ on\nthe immediate basin of each root.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We propose a means to relate properties of an interconnected system to its\nseparate component systems in the presence of cascade-like phenomena. Building\non a theory of interconnection reminiscent of the behavioral approach to\nsystems theory, we introduce the notion of generativity, and its byproduct,\ngenerative effects. Cascade effects, enclosing contagion phenomena and\ncascading failures, are seen as instances of generative effects. The latter are\nprecisely the instances where properties of interest are not preserved or\nbehave very badly when systems interact. The goal is to overcome that\nobstruction. We will show how to extract mathematical objects from the systems,\nthat encode their generativity: their potential to generate new phenomena upon\ninteraction. Those objects may then be used to link the properties of the\ninterconnected system to its separate systems. Such a link will be executed\nthrough the use of exact sequences from commutative algebra.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Let $\\alpha=\\alpha(G)$ be the independence number of a simple graph $G$ with\n$n$ vertices and $I(G)$ be its edge ideal in $S=K[x_1,\\ldots, x_n]$. If\n$S/I(G)$ is Gorenstein, the graph $G$ is called Gorenstein over $K$ and if $G$\nis Gorenstein over every field, then we simply say that $G$ is Gorenstein. In\nthis article, first we state a condition equivalent to $G$ being Gorenstein and\nusing this we give a characterization of Gorenstein graphs with $\\alpha=2$.\nThen we present some properties of Gorenstein graphs with $\\alpha=3$ and as an\napplication of these results we characterize triangle-free Gorenstein graphs\nwith $\\alpha=3$.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We proceed further with the study of minimum weak Riesz energy problems for\ncondensers with touching plates, initiated jointly with Bent Fuglede (Potential\nAnal. 51 (2019), 197--217). Having now added to the analysis constraint and\nexternal source of energy, we obtain a Gauss type problem, but with weak energy\ninvolved. We establish sufficient and/or necessary conditions for the existence\nof solutions to the problem and describe their potentials. Treating the\nsolution as a function of the condenser and the constraint, we prove its\ncontinuity relative to the vague topology and the topologies determined by the\nweak and standard energy norms. We show that the criteria for the solvability\nthus obtained fail in general once the problem is reformulated in the setting\nof standard energy, thereby justifying an advantage of weak energy when dealing\nwith condensers with touching plates.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this work, we analyze the ferroelectric (FE) domain-wall (DW) induced\nnegative capacitance (NC) effect in Metal-FE-Insulator-Metal (MFIM) and\nMetal-FE-Insulator-Semiconductor (MFIS) stacks. Our analysis is based on 2D\nphase field simulations. Considering HZO as the FE material, we study 180 FE\ndomain formation in MFIM and MFIS stacks and their voltage-dependent DW motion.\nOur analysis signifies that, when FE is in multi-domain (MD) state with\nsoft-DW, the stored energy in the DW leads to non-hysteretic NC effect in FE,\nwhich provides an enhanced charge response in the MFIM stack, compared to\nMetal-Insulator-Metal. According to our analysis, the DW-induced NC effect\nyields local negative permittivity in FE in the domain and DW regions, which\nleads to an average negative effective permittivity in FE. Furthermore, we show\nthat the NC trajectory of FE is dependent on its thickness, the gradient energy\ncoefficient and the in-plane permittivity of the underline DE material but not\non the DE thickness. Similar to MFIM, MFIS also exhibits an enhancement in the\noverall charge response and the capacitance compared to MOS capacitor. At the\nsame time, the MD state of FE induces non-homogenous potential profile across\nthe underlying DE and semiconductor layer. In the low voltage regime, such\nnon-homogenous surface potential leads to the co-existence of electron and hole\nin an undoped semiconductor, while at higher voltages, the carrier\nconcentration in the semiconductor becomes electron dominated. In addition, we\nshow that with FE being in the 180 MD state, the minimum potential at FE-DE\ninterface and hence, the minimum surface potential in the semiconductor, does\nnot exceed the applied voltage (in-spite of the local differential\namplification and charge enhancement).\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We completely determine those natural numbers $n$ for which the full matrix\nring $M_n(F_2)$ and the triangular matrix ring $T_n(F_2)$ over the two elements\nfield $F_2$ are either n-torsion clean or are almost n-torsion clean,\nrespectively. These results somewhat address and settle a question, recently\nposed by Danchev-Matczuk in Contemp. Math. (2019) as well as they supply in a\nmore precise aspect the nil-cleanness property of the full matrix $n\\times n$\nring $M_n(F_2)$ for all naturals $n \\geq 1$, established in Linear Algebra and\nAppl. (2013) by Breaz-Calugareanu-Danchev-Micu and again in Linear Algebra &\nAppl. (2018) by Ster as well as in Indag. Math. (2020) by Shitov.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Soit $K$ un corps $p$-adique et soit $V$ une repr\\'esentation $p$-adique de\n$\\mathcal{G}_K = \\mathrm{Gal}(\\bar{K}/K)$. La surconvergence des\n$(\\phi,\\tau)$-modules nous permet d'attacher \\`a $V$ un $\\phi$-module\ndiff\\'erentiel \\`a connexion $D_{\\tau,\\mathrm{rig}}^\\dagger(V)$ sur l'anneau de\nRobba $\\mathbf{B}_{\\tau,\\mathrm{rig},K}^\\dagger$. On montre dans cet article\ncomment retrouver les invariants $D_{\\mathrm{cris}}(V)$ et $D_{\\mathrm{st}}(V)$\n\\`a partir de $D_{\\tau,\\mathrm{rig}}^\\dagger(V)$, et comment caract\\'eriser les\nrepr\\'esentations potentiellement semi-stables, ainsi que celles de $E$-hauteur\nfinie, \\`a partir de la connexion.\n  Let $K$ be a $p$-adic field and let $V$ be a $p$-adic representation of\n$\\mathcal{G}_K=\\mathrm{Gal}(\\bar{K}/K)$. The overconvergence of\n$(\\phi,\\tau)$-modules allows us to attach to $V$ a differential $\\phi$-module\n$D_{\\tau,\\mathrm{rig}}^\\dagger(V)$ on the Robba ring\n$\\mathbf{B}_{\\tau,\\mathrm{rig},K}^\\dagger$ that comes equipped with a\nconnection. We show in this paper how to recover the invariants\n$D_{\\mathrm{cris}}(V)$ and $D_{\\mathrm{st}}(V)$ from\n$D_{\\tau,\\mathrm{rig}}^\\dagger(V)$, and give a characterization of both\npotentially semi-stable representations of $\\mathcal{G}_K$ and finite\n$E$-height representations in terms of the connection operator.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  This chapter proposes a view from inside the DAD, starting from determining\nsome essential resources missing of DAD, to proposing 10 programs of\nresearch/development for developing it. It could be considered as a follow-up\nof Chapter 1, where Ghislaine Gueudet situates the current state of DAD in\nlooking back to its origin: chapter 12 proposes a possible future of this\napproach in analyzing its current state. It determines the missing resources of\nDAD in questioning current and past PhD students who have anchored their\nresearch in DAD. What did/do they learn in using DAD as a main theoretical\nresource; to which extent did/do they estimate that they have enriched DAD by\ntheir own work? Which are, according to them, the still missing resources of\nDAD? Which of these resources should be developed by DAD from itself, and/or in\nco-working with other theoretical framework? From this inquiry, this chapter\nproposes ten perspectives of research, aiming to develop some theoretical blind\npoints of DAD, or to develop some methodological tools, or to deepen the\ncultural/social aspects of DAD in questioning the naming systems used by\nteachers when interacting with resources. This chapter echoes actually\ndifferent perspectives of research already present, as promising germs, in\nprevious chapters of the book.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  A lattice of three-state stochastic phase-coupled oscillators introduced by\nWood it et al. exhibits a phase transition at a critical value of the coupling\nparameter $a$, leading to stable global oscillations (GO). On a complete graph,\nupon further increase in $a$, the model exhibits an infinite-period (IP) phase\ntransition, at which collective oscillations cease and discrete rotational\n($C_3$) symmetry is broken. In the case of large negative values of the\ncoupling, Escaff et al. discovered the stability of travelling-wave states with\nno global synchronization but with local order. Here, we verify the IP phase in\nsystems with long-range coupling but of lower connectivity than a complete\ngraph and show that even for large positive coupling, the system sometimes\nfails to reach global order. The ensuing travelling-wave state appears to be a\nmetastable configuration whose birth and decay (into the previously described\nphases) are associated with the initial conditions and fluctuations.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The policy gradient theorem is defined based on an objective with respect to\nthe initial distribution over states. In the discounted case, this results in\npolicies that are optimal for one distribution over initial states, but may not\nbe uniformly optimal for others, no matter where the agent starts from.\nFurthermore, to obtain unbiased gradient estimates, the starting point of the\npolicy gradient estimator requires sampling states from a normalized discounted\nweighting of states. However, the difficulty of estimating the normalized\ndiscounted weighting of states, or the stationary state distribution, is quite\nwell-known. Additionally, the large sample complexity of policy gradient\nmethods is often attributed to insufficient exploration, and to remedy this, it\nis often assumed that the restart distribution provides sufficient exploration\nin these algorithms. In this work, we propose exploration in policy gradient\nmethods based on maximizing entropy of the discounted future state\ndistribution. The key contribution of our work includes providing a practically\nfeasible algorithm to estimate the normalized discounted weighting of states,\ni.e, the \\textit{discounted future state distribution}. We propose that\nexploration can be achieved by entropy regularization with the discounted state\ndistribution in policy gradients, where a metric for maximal coverage of the\nstate space can be based on the entropy of the induced state distribution. The\nproposed approach can be considered as a three time-scale algorithm and under\nsome mild technical conditions, we prove its convergence to a locally optimal\npolicy. Experimentally, we demonstrate usefulness of regularization with the\ndiscounted future state distribution in terms of increased state space coverage\nand faster learning on a range of complex tasks.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Gravitational wave (GW) oscillations occur whenever there are additional\ntensor modes interacting with the perturbations of the metric coupled to\nmatter. These extra modes can arise from new spin-2 fields (as in e.g.\nbigravity theories) or from non-trivial realisations of the cosmological\nprinciple induced by background vector fields with internal symmetries (e.g.\nYang-Mills, gaugids or multi-Proca). We develop a general cosmological\nframework to study such novel features due to oscillations. The evolution of\nthe two tensor modes is described by a linear system of coupled second order\ndifferential equations exhibiting friction, velocity, chirality and mass\nmixing. We follow appropriate schemes to obtain approximate solutions for the\nevolution of both modes and show the corresponding phenomenology for different\nmixings. Observational signatures include modulations of the wave-form,\noscillations of the GW luminosity distance, anomalous GW speed and chirality.\nWe discuss the prospects of observing these effects with present and future GW\nobservatories such as LIGO/VIRGO and LISA.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Standard Bayesian inference is known to be sensitive to model\nmisspecification, leading to unreliable uncertainty quantification and poor\npredictive performance. However, finding generally applicable and\ncomputationally feasible methods for robust Bayesian inference under\nmisspecification has proven to be a difficult challenge. An intriguing,\neasy-to-use, and widely applicable approach is to use bagging on the Bayesian\nposterior (\"BayesBag\"); that is, to use the average of posterior distributions\nconditioned on bootstrapped datasets. In this paper, we develop the asymptotic\ntheory of BayesBag, propose a model-data mismatch index for model criticism\nusing BayesBag, and empirically validate our theory and methodology on\nsynthetic and real-world data in linear regression, sparse logistic regression,\nand a hierarchical mixed effects model. We find that in the presence of\nsignificant misspecification, BayesBag yields more reproducible inferences and\nhas better predictive accuracy than the standard Bayesian posterior; on the\nother hand, when the model is correctly specified, BayesBag produces superior\nor equally good results. Overall, our results demonstrate that BayesBag\ncombines the attractive modeling features of standard Bayesian inference with\nthe distributional robustness properties of frequentist methods, providing\nbenefits over both Bayes alone and the bootstrap alone.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  We present an analytic and numerical study for realizing single photon\nsideband cooling in an ultracold sample of fermionic Lithium trapped in a\nperiodic optical potential. We develop an analytical model and obtain a master\nequation for the bound level populations. The cooling sequence is simulated\nboth with a laser at a fixed frequency and with a frequency sweep. Finally, a\nMonte Carlo simulation is performed taking into account the full hyperfine\nspectrum of $^6\\!$Li. We find that a gas of $^6\\!$Li atoms loaded from a\nMagneto-Optical trap into a deep optical lattice can be cooled down to a $99\\%$\noccupancy of the lattice ground state after a 5mm single photon sideband\ncooling using the D1 line of Li.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Learning about cause and effect is arguably the main goal in applied\neconometrics. In practice, the validity of these causal inferences is\ncontingent on a number of critical assumptions regarding the type of data that\nhas been collected and the substantive knowledge that is available. For\ninstance, unobserved confounding factors threaten the internal validity of\nestimates, data availability is often limited to non-random, selection-biased\nsamples, causal effects need to be learned from surrogate experiments with\nimperfect compliance, and causal knowledge has to be extrapolated across\nstructurally heterogeneous populations. A powerful causal inference framework\nis required to tackle these challenges, which plague most data analysis to\nvarying degrees. Building on the structural approach to causality introduced by\nHaavelmo (1943) and the graph-theoretic framework proposed by Pearl (1995), the\nartificial intelligence (AI) literature has developed a wide array of\ntechniques for causal learning that allow to leverage information from various\nimperfect, heterogeneous, and biased data sources (Bareinboim and Pearl, 2016).\nIn this paper, we discuss recent advances in this literature that have the\npotential to contribute to econometric methodology along three dimensions.\nFirst, they provide a unified and comprehensive framework for causal inference,\nin which the aforementioned problems can be addressed in full generality.\nSecond, due to their origin in AI, they come together with sound, efficient,\nand complete algorithmic criteria for automatization of the corresponding\nidentification task. And third, because of the nonparametric description of\nstructural models that graph-theoretic approaches build on, they combine the\nstrengths of both structural econometrics as well as the potential outcomes\nframework, and thus offer an effective middle ground between these two\nliterature streams.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  In this paper, we determine the achromatic and diachromatic numbers of some\ncirculant graphs and digraphs each one with two lengths and give bounds for\nother circulant graphs and digraphs with two lengths. In particular, for the\nachromatic number we state that $\\alpha(C_{16q^2+20q+7}(1,2))=8q+5$, and for\nthe diachromatic number we state that\n$dac(\\overrightarrow{C}_{32q^2+24q+5}(1,2))=8q+3$. In general, we give the\nlower bounds $\\alpha(C_{4q^2+aq+1}(1,a))\\geq 4q+1$ and\n$dac(\\overrightarrow{C}_{8q^2+2(a+4)q+a+3}(1,a))\\geq 4q+3$ when $a$ is a non\nquadratic residue of $\\mathbb{Z}_{4q+1}$ for graphs and $\\mathbb{Z}_{4q+3}$ for\ndigraphs, and the equality is attained, in both cases, for $a=3$. Finally, we\ndetermine the achromatic index for circulant graphs of $q^2+q+1$ vertices when\nthe projective cyclic plane of odd order $q$ exists.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  The rank three tensor model with tetrahedral interaction was shown by\nCarrozza and Tanasa to admit a $1/N$ expansion, dominated by melonic diagrams,\nand double tadpoles decorated with melons at next-to-leading order. This model\nhas generated a renewed interest in tensor models because it has the same large\n$N$ limit as the SYK model. In contrast with matrix models, there is no method\nwhich would be able to prove the existence of $1/N$ expansions in arbitrary\ntensor models. The method used by Carrozza and Tanasa proves the existence of\nthe $1/N$ expansion using two-dimensional topology, before identifying the\nleading order and next-to-leading graphs. However, another method was required\nfor complex, rank three tensor models with planar interactions, which is based\non flips. The latter are moves which cut two propagators of Feynman graphs and\nreglue them differently. They allow transforming graphs while tracking their\norders in the $1/N$ expansion. Here we use this method to re-prove the results\nof Carrozza and Tanasa, thereby proving the existence of the $1/N$ expansion,\nthe melonic dominance at leading order and the melon-decorated double tadpoles\nat next-to-leading order, all in one go.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Droplets of quark-gluon plasma (QGP), an exotic state of strongly interacting\nquantum chromodynamics (QCD) matter, are routinely produced in heavy nuclei\nhigh-energy collisions. Although the experimental signatures marked a paradigm\nshift away from expectations of a weakly coupled QGP, a challenge remains as to\nhow the locally deconfined state with a lifetime of a few fm can be resolved.\nThe only colored particle that decays mostly within the QGP is the top quark.\nHere we demonstrate, for the first time, that top quark decay products are\nidentified, irrespective of whether interacting with the medium (bottom quarks)\nor not (leptonically decaying W bosons). Using $1.7 \\pm 0.1\\,\\mathrm{nb^{-1}}$\nof lead-lead ($A = 208$) collision data recorded by the CMS experiment at a\nnucleon-nucleon center-of-mass energy of 5.02 TeV, we report evidence of top\nquark pair ($\\mathrm{t\\bar{t}}$) production. Dilepton final states are\nselected, and the cross section ($\\sigma_\\mathrm{t\\bar{t}}$) is measured from a\nlikelihood fit to a multivariate discriminator using lepton kinematic\nvariables. The $\\sigma_\\mathrm{t\\bar{t}}$ measurement is additionally performed\nconsidering the jets originating from the hadronization of bottom quarks, which\nimprove the sensitivity to the $\\mathrm{t\\bar{t}}$ signal process. After\nbackground subtraction and analysis corrections, the measured\n$\\sigma_\\mathrm{t\\bar{t}}$ is $2.02 \\pm 0.69\\,\\rm{(tot)}$ and $2.56\\pm\n0.82\\,\\rm{(tot)}\\,\\mu\\mathrm{b}$ in the two cases, respectively, consistent\nwith predictions from perturbative QCD.\n\n\n###\n\n", "completion": "2019"}
{"prompt": "  Microlocal analysis techniques are extended and applied to stochastic partial\ndifferential equations (SPDEs). In particular, the H\\\"ormander propagation of\nsingularities theorem is shown to be valid for hyperbolic SPDEs driven by a\nstandard Brownian motion. In this case the wave front set of the solution is\ninvariant under the stochastic Hamiltonian flow associated to the principal\nsymbol of the SPDE. This study leads to the introduction of a class of random\npseudodifferential operators.\n\n\n###\n\n", "completion": "2019"}
