{"prompt": "  The recent research on the connection between gravity and thermodynamics\nsuggests that gravity could be an emergent phenomenon. Following this,\nPadmanabhan proposed a novel idea that the expansion of the universe can be\ninterpreted as equivalent to the emergence of space with the progress of cosmic\ntime. In this approach, the expansion of the universe is described by what is\nknown as the law of emergence, which states that the expansion of the universe\nis driven by the difference between the number of bulk and surface degrees of\nfreedom in a region bounded by the Hubble radius. This principle correctly\nreproduces the standard evolution of a Friedmann universe. We establish the\nconnection of the law of emergence, which is conceptually different from the\nconventional paradigm to describe cosmology, with other well-established\nresults in thermodynamics. It has been shown that the law of emergence can be\nderived from the unified first law of thermodynamics, which can then be\nconsidered as the backbone of the law. However, the law of emergence is rich in\nstructure than implied by the First law thermodynamics alone. It further\nexplains the evolution of the universe towards a state of maximum horizon\nentropy. Following this, it can be considered that the first law of\nthermodynamics, along with the additional constraints imposed by the\nmaximisation of the horizon entropy, can together lead to the law of emergence.\nIn the present article, we first make a brief review of Padmanabhan's proposal\nand then studies its connection with the thermodynamics of the horizon in the\ncontext of Einstein's, Gauss-Bonnet, and more general Lovelock gravity\ntheories.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We continue the study of graph classes in which the treewidth can only be\nlarge due to the presence of a large clique, and, more specifically, of graph\nclasses with bounded tree-independence number. In [Dallard, Milani\\v{c}, and\n\\v{S}torgel, Treewidth versus clique number. {II}. Tree-independence number,\n2022], it was shown that the Maximum Weight Independent Packing problem, which\nis a common generalization of the Independent Set and Induced Matching\nproblems, can be solved in polynomial time provided that the input graph is\ngiven along with a tree decomposition with bounded independence number. We\nprovide further examples of algorithmic problems that can be solved in\npolynomial time under this assumption. This includes, for all even positive\nintegers $d$, the problem of packing subgraphs at distance at least $d$\n(generalizing the Maximum Weight Independent Packing problem) and the problem\nof finding a large induced sparse subgraph satisfying an arbitrary but fixed\nproperty expressible in counting monadic second-order logic. As part of our\napproach, we generalize some classical results on powers of chordal graphs to\nthe context of general graphs and their tree-independence numbers.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Advancements in smart vehicle design have enabled the creation of Internet of\nVehicle (IoV) technologies that can utilize the information provided by various\nsensors and wireless communication to perform complex functionality. Many of\nthese functionalities rely on high computational power and low latency. Mobile\nEdge Computing (MEC) technologies have been proposed as a way to meet these\nrequirements, as their proximity and decentralization provide unique benefits\nfor networks like real-time communication, higher throughput, and flexibility.\nDiverse challenges to the process of offloading data in a MEC-enabled IoV\nnetwork have emerged, such as offloading reliability in highly mobile\nenvironments, security for users within the same network, and energy management\nto keep users from being disincentivized to participate in the network. This\narticle surveys research studies that use AI as part of the data offloading\nprocess, categorized based on four main issues: reliability, security, energy\nmanagement, and service seller profit. Afterward, this article discusses\nchallenges and future perspectives for IoV technologies.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  This paper gives a detailed overview and a number of worked out examples\nillustrating the Kovacic \\cite{Kovacic86} algorithm for solving second order\nlinear differential equation ${A(x) y\"+ B(x) y' + C(x) y=0}$ where $A,B,C$ are\nrational functions with complex coefficients in the independent variable $x$.\nAll three cases of the algorithm were implemented in a software package based\non an object oriented design and complete source code listing given in the\nappendix with usage examples. Implementation used the Maple computer algebra\nlanguage. The complete Kovacic package in one mpl file accompany the arXiv\nversion of this paper. This package was then used to analyze the distribution\nof Kovacic algorithm cases on $3000$ differential equations\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  Previous works show that Pre-trained Language Models (PLMs) can capture\nfactual knowledge. However, some analyses reveal that PLMs fail to perform it\nrobustly, e.g., being sensitive to the changes of prompts when extracting\nfactual knowledge. To mitigate this issue, we propose to let PLMs learn the\ndeterministic relationship between the remaining context and the masked\ncontent. The deterministic relationship ensures that the masked factual content\ncan be deterministically inferable based on the existing clues in the context.\nThat would provide more stable patterns for PLMs to capture factual knowledge\nthan randomly masking. Two pre-training tasks are further introduced to\nmotivate PLMs to rely on the deterministic relationship when filling masks.\nSpecifically, we use an external Knowledge Base (KB) to identify deterministic\nrelationships and continuously pre-train PLMs with the proposed methods. The\nfactual knowledge probing experiments indicate that the continuously\npre-trained PLMs achieve better robustness in factual knowledge capturing.\nFurther experiments on question-answering datasets show that trying to learn a\ndeterministic relationship with the proposed methods can also help other\nknowledge-intensive tasks.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  In this paper, we propose a novel computer vision-based approach to aid\nReconfigurable Intelligent Surface (RIS) for dynamic beam tracking and then\nimplement the corresponding prototype verification system. A camera is attached\nat the RIS to obtain the visual information about the surrounding environment,\nwith which RIS identifies the desired reflected beam direction and then adjusts\nthe reflection coefficients according to the pre-designed codebook. Compared to\nthe conventional approaches that utilize channel estimation or beam sweeping to\nobtain the reflection coefficients, the proposed one not only saves beam\ntraining overhead but also eliminates the requirement for extra feedback links.\nWe build a 20-by-20 RIS running at 5.4 GHz and develop a high-speed control\nboard to ensure the real-time refresh of the reflection coefficients. Meanwhile\nwe implement an independent peer-to-peer communication system to simulate the\ncommunication between the base station and the user equipment. The vision-aided\nRIS prototype system is tested in two mobile scenarios: RIS works in near-field\nconditions as a passive array antenna of the base station; RIS works in\nfar-field conditions to assist the communication between the base station and\nthe user equipment. The experimental results show that RIS can quickly adjust\nthe reflection coefficients for dynamic beam tracking with the help of visual\ninformation.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Mass Spectrometry Imaging (MSI), using traditional rectilinear scanning,\ntakes hours to days for high spatial resolution acquisitions. Given that most\npixels within a sample's field of view are often neither relevant to underlying\nbiological structures nor chemically informative, MSI presents as a prime\ncandidate for integration with sparse and dynamic sampling algorithms. During a\nscan, stochastic models determine which locations probabilistically contain\ninformation critical to the generation of low-error reconstructions. Decreasing\nthe number of required physical measurements thereby minimizes overall\nacquisition times. A Deep Learning Approach for Dynamic Sampling (DLADS),\nutilizing a Convolutional Neural Network (CNN) and encapsulating molecular mass\nintensity distributions within a third dimension, demonstrates a simulated 70%\nthroughput improvement for Nanospray Desorption Electrospray Ionization\n(nano-DESI) MSI tissues. Evaluations are conducted between DLADS and a\nSupervised Learning Approach for Dynamic Sampling, with Least-Squares\nregression (SLADS-LS) and a Multi-Layer Perceptron (MLP) network (SLADS-Net).\nWhen compared with SLADS-LS, limited to a single m/z channel, as well as\nmultichannel SLADS-LS and SLADS-Net, DLADS respectively improves regression\nperformance by 36.7%, 7.0%, and 6.2%, resulting in gains to reconstruction\nquality of 6.0%, 2.1%, and 3.4% for acquisition of targeted m/z.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We consider the $Sp(4)$ gauge theory coupled to $N_f=2$ fundamental and\n$n_f=3$ antisymmetric flavours of Dirac fermions in four dimensions. This\ntheory serves as the microscopic origin for composite Higgs models with\n$SU(4)/Sp(4)$ coset, supplemented by partial top compositeness. We study\nnumerically its lattice realisation, and couple the fundamental plaquette\naction to Wilson-Dirac fermions in mixed representations, by adopting a\n(rational) hybrid Monte Carlo method, to perform non-trivial tests of the\nproperties of the resulting lattice theory.\n  We find evidence of a surface (with boundaries) of first-order bulk phase\ntransitions in the three-dimensional space of bare parameters (one coupling and\ntwo masses). Explicit evaluation of the Dirac eigenvalues confirms the expected\npatterns of global symmetry breaking. After investigating finite volume effects\nin the weak-coupling phase of the theory, for the largest available lattice we\nstudy the mass spectra of the lightest spin-0 and spin-1 flavoured mesons\ncomposed of fermions in each representation, and of the lightest half-integer\nspin composite particle made of fermions in different representations -- the\nchimera baryon. This work sets the stage for future systematical studies of the\nnon-perturbative dynamics in phenomenologically relevant regions of parameter\nspace.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  A noncontextual system of random variables may become contextual if one adds\nto it a set of new variables, even if each of them is obtained by the same\ncontext-wise function of the old variables. This fact follows from the\ndefinition of contextuality, and its demonstration is trivial for\ninconsistently connected systems (i.e. systems with disturbance). However, it\nalso holds for consistently connected (and even strongly consistently\nconnected) systems, provided one acknowledges that if a given property was not\nmeasured in a given context, this information can be used in defining functions\namong the random variables.\n\n\n###\n\n", "completion": " 04"}
{"prompt": "  For summarization, human preference is critical to tame outputs of the\nsummarizer in favor of human interests, as ground-truth summaries are scarce\nand ambiguous. Practical settings require dynamic exchanges between human and\nAI agent wherein feedback is provided in an online manner, a few at a time. In\nthis paper, we introduce a new framework to train summarization models with\npreference feedback interactively. By properly leveraging offline data and a\nnovel reward model, we improve the performance regarding ROUGE scores and\nsample-efficiency. Our experiments on three various datasets confirm the\nbenefit of the proposed framework in active, few-shot and online settings of\npreference learning.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  A network of agents is considered whose decision processes are described by\nthe quantum decision theory previously advanced by the authors. Decision making\nis done by evaluating the utility of alternatives, their attractiveness, and\nthe available information, whose combinations form the probabilities to choose\na given alternative. As a result of the interplay between these three\ncontributions, the process of choice between several alternatives is\nmultimodal. The agents interact by exchanging information, which can take two\nforms: (i) information that an agent can directly receive from another agent\nand (ii) information collectively created by the members of the society. The\ninformation field common to all agents tends to smooth out sharp variations in\nthe temporal behaviour of the probabilities and can even remove them. For\nagents with short-term memory, the probabilities often tend to their limiting\nvalues through strong oscillations and, for a range of parameters, these\noscillations last for ever, representing an ever lasting hesitation of the\ndecision makers. Switching on the information field makes the amplitude of the\noscillations smaller and even can halt the everlasting oscillations forcing the\nprobabilities to converge to fixed limits. The dynamic disjunction effect is\ndescribed.\n\n\n###\n\n", "completion": " 05"}
{"prompt": "  Concerted experimental and numerical studies of step bunching on vicinal\ncrystal surfaces resulting from step-down electromigration of partially charged\nadatoms, confirmed the theoretical prediction of scaling dependence of the\nminimal bunch distance $l_{\\rm min}$ on the bunch size $N$: $l_{\\rm min} \\sim\nN^{-\\gamma}$, with $\\gamma = 2/3$. The value of the so called size-scaling\nexponent $\\gamma$ was observed in experiments on vicinal surfaces of\nsemiconducting, metallic, and dielectric materials. Careful theoretical\ninvestigations and numerical calculations predict a second value of $\\gamma =\n1/2$. However, this value is still not been reported from experiments. And we\nreport here experimental observation of step bunching in the universality class\nrelative to $\\gamma = 1/2$. This is achieved by monitoring step flow during\nsublimation of Si(111)-vicinals heated by a direct step-down current at\n~1200$^\\circ$C. In the experiment we also measure other characteristic for the\nbunching quantities, such as the mean total number of steps in the bunch $N$\nand the mean bunch width $W$. We then compare our findings with published\nexperimental and numerical data to arrive at a theoretically consistent\nframework in terms of universality classes. The ultimate benefit of our study\nis not only to advance fundamental knowledge but also to provide further\nguidance for bottom-up synthesis of vicinal nanotemplates.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We define a parametric variant of generalized Euler sums and construct\ncontour integration to give some explicit evaluations of these parametric Euler\nsums. In particular, we establish several explicit formulas of (Hurwitz) zeta\nfunctions, linear and quadratic parametric Euler sums. Furthermore, we also\ngive an explicit evaluation of alternating double zeta values\n$\\ze(\\overline{2j},2m+1)$ in terms of a combination of alternating Riemann zeta\nvalues by using the parametric Euler sums.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Automated decision systems (ADS) are increasingly used for consequential\ndecision-making. These systems often rely on sophisticated yet opaque machine\nlearning models, which do not allow for understanding how a given decision was\narrived at. In this work, we conduct a human subject study to assess people's\nperceptions of informational fairness (i.e., whether people think they are\ngiven adequate information on and explanation of the process and its outcomes)\nand trustworthiness of an underlying ADS when provided with varying types of\ninformation about the system. More specifically, we instantiate an ADS in the\narea of automated loan approval and generate different explanations that are\ncommonly used in the literature. We randomize the amount of information that\nstudy participants get to see by providing certain groups of people with the\nsame explanations as others plus additional explanations. From our quantitative\nanalyses, we observe that different amounts of information as well as people's\n(self-assessed) AI literacy significantly influence the perceived informational\nfairness, which, in turn, positively relates to perceived trustworthiness of\nthe ADS. A comprehensive analysis of qualitative feedback sheds light on\npeople's desiderata for explanations, among which are (i) consistency (both\nwith people's expectations and across different explanations), (ii) disclosure\nof monotonic relationships between features and outcome, and (iii)\nactionability of recommendations.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Multi-turn dialogue modeling as a challenging branch of natural language\nunderstanding (NLU), aims to build representations for machines to understand\nhuman dialogues, which provides a solid foundation for multiple downstream\ntasks. Recent studies of dialogue modeling commonly employ pre-trained language\nmodels (PrLMs) to encode the dialogue history as successive tokens, which is\ninsufficient in capturing the temporal characteristics of dialogues. Therefore,\nwe propose Bidirectional Information Decoupling Network (BiDeN) as a universal\ndialogue encoder, which explicitly incorporates both the past and future\ncontexts and can be generalized to a wide range of dialogue-related tasks.\nExperimental results on datasets of different downstream tasks demonstrate the\nuniversality and effectiveness of our BiDeN.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We generalize Grover algorithm with two arbitrary phases in a density matrix\nset up. We give exact analytic expressions for the success probability after\narbitrary number of iteration of the generalized Grover operator as a function\nof number of iterations, two phase angles ({\\alpha}, \\{beta}) and parameter\n{\\xi} introduced in the off diagonal terms of the density matrix in a sense to\ncapture the coherence present in the initial quantum register. We extend Li and\nLi's idea and show for the phase matching condition {\\alpha} = -\\{beta} =\n0.35{\\pi} with two iterations and {\\xi} = 1, we can achieve success probability\n>= 0.8 only with a knowledge about the lower bound of {\\lambda} = 0.166 where\n{\\lambda} is the ratio of marked to total number states in the database.\nFinally we quantify success probability of the algorithm with decrease in\ncoherence of the initial quantum state against modest noise in this simple\nmodel.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Joint, radio-based communication, localization and sensing is a rapidly\nemerging research field with various application potentials. Greatly benefiting\nfrom these capabilities, smart city, mobility, and logistic concepts are key\ncomponents for maximizing the efficiency of modern transportation systems. In\nurban environments, both the search for parking space and freight transport are\ntime- and space-consuming and present the bottlenecks for these transportation\nchains. Providing location information for these heterogeneous requirement\nprofiles (both active and passive localization of objects), can be realized by\nusing retrofittable wireless sensor networks, which are typically only deployed\nfor active localization. An additional passive detection of objects can be\nachieved by assessing signal reflections and multipath properties of the\ntransmission channel stored within the Channel Impulse Response (CIR). In this\nwork, a proof-of-concept realization and preliminary experimental results of a\nCIR-based occupancy detection for parking lots are presented. As the time\nresolution is dependent on available bandwidth, the CIR of Ultra-wideband\ntransceivers are used. For this, the CIR is smoothed and time-variant changes\nwithin it are detected by performing a background subtraction. Finally, the\nreflecting objects are mapped to individual parking lots. The developed method\nis tested in an in-house parking garage. The work provided is a foundation for\npassive occupancy detection, whose capabilities can prospectively be enhanced\nby exploiting additional physical layers, such as 5G or even 6G.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  THz fields induce orientation in gas phase molecules via resonant\ndipole-field interaction. The degree of orientation however remains severely\nlimited due to the practical shortage of high THz-field amplitudes. In this\npaper, we experimentally demonstrate a concerted Near-IR and THz excitation\nscheme that provides significant increase in the degree of orientation at room\ntemperature gas ensembles. The experimental results are supported by\ntheoretical simulations and a detailed discussion of the multiple coherent\ntransition pathways involved in the scheme is presented.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Lexical semantics and cognitive science point to affordances (i.e. the\nactions that objects support) as critical for understanding and representing\nnouns and verbs. However, study of these semantic features has not yet been\nintegrated with the \"foundation\" models that currently dominate language\nrepresentation research. We hypothesize that predictive modeling of object\nstate over time will result in representations that encode object affordance\ninformation \"for free\". We train a neural network to predict objects'\ntrajectories in a simulated interaction and show that our network's latent\nrepresentations differentiate between both observed and unobserved affordances.\nWe find that models trained using 3D simulations from our SPATIAL dataset\noutperform conventional 2D computer vision models trained on a similar task,\nand, on initial inspection, that differences between concepts correspond to\nexpected features (e.g., roll entails rotation). Our results suggest a way in\nwhich modern deep learning approaches to grounded language learning can be\nintegrated with traditional formal semantic notions of lexical representations.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Bilevel optimization have gained growing interests, with numerous\napplications found in meta learning, minimax games, reinforcement learning, and\nnested composition optimization. This paper studies the problem of distributed\nbilevel optimization over a network where agents can only communicate with\nneighbors, including examples from multi-task, multi-agent learning and\nfederated learning. In this paper, we propose a gossip-based distributed\nbilevel learning algorithm that allows networked agents to solve both the inner\nand outer optimization problems in a single timescale and share information via\nnetwork propagation. We show that our algorithm enjoys the\n$\\mathcal{O}(\\frac{1}{K \\epsilon^2})$ per-agent sample complexity for general\nnonconvex bilevel optimization and $\\mathcal{O}(\\frac{1}{K \\epsilon})$ for\nstrongly convex objective, achieving a speedup that scales linearly with the\nnetwork size. The sample complexities are optimal in both $\\epsilon$ and $K$.\nWe test our algorithm on the examples of hyperparameter tuning and\ndecentralized reinforcement learning. Simulated experiments confirmed that our\nalgorithm achieves the state-of-the-art training efficiency and test accuracy.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We discover superconductivity (SC) in LaAgSb$_2$ at ambient pressure and its\nclose correlation with a charge density wave (CDW) under pressure. The\nsuperconducting transition temperature ($T_c$) exhibits a sharp peak at the CDW\ncritical pressure of 3.2 GPa. We demonstrate that the carriers inhabiting the\nSb-square net is crucial not only in the formation of CDW but also in SC for\ntheir relatively strong electron-phonon coupling (EPC). Furthermore,\ntheoretical EPC strength in pristine LaAgSb$_2$ cannot explain the observed\npeak with $T_c\\sim 1$ K, which indicates that an additional mechanism\nreinforces SC only around the CDW critical pressure.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We give an explicit formulation of the weight part of Serre's conjecture for\nGL_2 using Kummer theory. This avoids any reference to p-adic Hodge theory. The\nkey inputs are a description of the reduction modulo p of crystalline\nextensions in terms of certain \"G_K-Artin-Scheier cocycles\" and a result of\nAbrashkin which describes these cocycles in terms of Kummer theory. An\nalternative explicit formulation in terms of local class field theory was\npreviously given by Dembele-Diamond-Roberts in the unramified case and by the\nsecond author in general. We show that the description of\nDembele-Diamond-Roberts can be recovered directly from ours using the explicit\nreciprocity laws of Brueckner-Shaferevich-Vostokov. These calculations\nillustrate how our use of Kummer theory eliminates certain combinatorial\ncomplications appearing in these two papers.\n\n\n###\n\n", "completion": " 05"}
{"prompt": "  This paper addresses a distributed convex optimization problem with a class\nof coupled constraints, which arise in a multi-agent system composed of\nmultiple communities modeled by cliques. First, we propose a fully distributed\ngradient-based algorithm with a novel operator inspired by the convex\nprojection, called the clique-based projection. Next, we scrutinize the\nconvergence properties for both diminishing and fixed step sizes. For\ndiminishing ones, we show the convergence to an optimal solution under the\nassumptions of the smoothness of an objective function and the compactness of\nthe constraint set. Additionally, when the objective function is strongly\nmonotone, the strict convergence to the unique solution is proved without the\nassumption of compactness. For fixed step sizes, we prove the non-ergodic\nconvergence rate of O(1/k) concerning the objective residual under the\nassumption of the smoothness of the objective function. Furthermore, we apply\nNesterov's acceleration method to the proposed algorithm and establish the\nconvergence rate of O(1/k^2). Numerical experiments illustrate the\neffectiveness of the proposed method.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  In mathematical psychology, decision makers are modeled using the Lindbladian\nequations from quantum mechanics to capture important human-centric features\nsuch as order effects and violation of the sure thing principle. We consider\nhuman-machine interaction involving a quantum decision maker (human) and a\ncontroller (machine). Given a sequence of human decisions over time, how can\nthe controller dynamically provide input messages to adapt these decisions so\nas to converge to a specific decision? We show via novel stochastic Lyapunov\narguments how the Lindbladian dynamics of the quantum decision maker can be\ncontrolled to converge to a specific decision asymptotically. Our methodology\nyields a useful mathematical framework for human-sensor decision making. The\nstochastic Lyapunov results are also of independent interest as they generalize\nrecent results in the literature.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  We study the behaviour of Husimi, Wigner and T{\\\"o}plitz symbols of quantum\ndensity matrices when quantum statistics are tested on them, that is when on\nexchange two coordinates in one of the two variables of their integral kernel.\nWe show that to each of these actions is associated a canonical transform on\nthe cotangent bundle of the underlying classical phase space. Equivalently can\none associate a complex canonical transform on the complexification of the\nphase-space. In the off-diagonal T{\\\"o}plitz representation introduced in [P],\nthe action considered is associated to a complex aanticanonical relation.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  Proving linear inequalities and identities of Shannon's information measures,\npossibly with linear constraints on the information measures, is an important\nproblem in information theory. For this purpose, ITIP and other variant\nalgorithms have been developed and implemented, which are all based on solving\na linear program (LP). In particular, an identity $f = 0$ is verified by\nsolving two LPs, one for $f \\ge 0$ and one for $f \\le 0$. In this paper, we\ndevelop a set of algorithms that can be implemented by symbolic computation.\nBased on these algorithms, procedures for verifying linear information\ninequalities and identities are devised. Compared with LP-based algorithms, our\nprocedures can produce analytical proofs that are both human-verifiable and\nfree of numerical errors. Our procedures are also more efficient\ncomputationally. For constrained inequalities, by taking advantage of the\nalgebraic structure of the problem, the size of the LP that needs to be solved\ncan be significantly reduced. For identities, instead of solving two LPs, the\nidentity can be verified directly with very little computation.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  In the present work we investigate the $\\eta_c K$, $J/\\psi K$, $\\eta_c K^*$\nand $J/\\psi K^*$ hidden-charm decay modes for the $c\\bar{c}s\\bar{u}$ four-quark\nsystem in the molecular and compact tetraquark scenarios using the\nquark-exchange model. Our theoretical results indicate that if the newly\nobserved states $Z_{cs}(3985)$ and $Z_{cs}(4000)$ are two different states,\n$Z_{cs}(4000)$ may be interpreted as the mixture\n$\\frac{1}{\\sqrt{2}}(D^0D_s^{*-}+D^{*0}D_s^{-})$ of which the $J/\\psi K$ partial\ndecay width is about $\\Gamma\\sim2.89$ MeV, while $Z_{cs}(3985)$ may be\nexplained as the mixture $\\frac{1}{\\sqrt{2}}(-D^0D_s^{*-}+D^{*0}D_s^{-})$ of\nwhich the $J/\\psi K$ partial decay width is small to zero. Moreover, if the\nstate $Z_{cs}(4000)$ can be explained as the mixed state\n$\\frac{1}{\\sqrt{2}}(D^0D_s^{*-}+D^{*0}D_s^{-})$ indeed, the partial decay width\nratio between $J/\\psi K$ and $\\eta_cK^*$ is close to unit, which indicates the\ndecay channel $\\eta_cK^*$ may be a ideal channel as well to decode the inner\nstructure of $Z_{cs}(4000)$. In addition, the partial decay width for the\ntensor molecular state $|D^{*0}D_s^{*-}\\rangle_{2^+}$ decaying into $J/\\psi\nK^*$ can reach up to a few MeV, which shows this tensor molecular state has a\ngood potential to be observed in this decay channel.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  In this paper, we focus on one particular instance of the shape\nreconstruction problem, in which the shape we wish to reconstruct is an\norientable smooth submanifold of the Euclidean space. Assuming we have as input\na simplicial complex K that approximates the submanifold (such as the Cech\ncomplex or the Rips complex), we recast the reconstruction problem as a L1-norm\nminimization problem in which the optimization variable is a chain of K.\nProviding that K satisfies certain reasonable conditions, we prove that the\nconsidered minimization problem has a unique solution which triangulates the\nsubmanifold and coincides with the flat Delaunay complex introduced and studied\nin a companion paper. Since the objective is a weighted L1-norm and the\ncontraints are linear, the triangulation process can thus be implemented by\nlinear programming.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We develop a general framework for the insertion of vertex operator on the\nstring worldsheet, in BV formalism. Such insertions correspond to deformations\nof the Master Action which breaks the gauge symmetry to a subgroup, and then\nrestoring the full gauge symmetry by integrating over a cycle in the space of\nLagrangian submanifolds. We provide the general construction, global on the\nmoduli space, which was previously conjectured in a form local on the\nworldsheet. We explain how the enhancement of the gauge symmetry in equivariant\nBV formalism can be seen as an application of the general idea of BV effective\naction. We derive an integral formula for the deformation of the contraction\noperator due to the vertex insertion.\n\n\n###\n\n", "completion": " 07"}
{"prompt": "  We study the geometric behavior of constant mean curvature surfaces invariant\nunder screw motion in the homogeneous 3-manifolds $\\mathbb{E}(\\kappa,\\tau)$ as\nwell as the space-forms of non-negative curvature and give a complete\nclassification. We give a unified presentation of results that have appeared in\nthe literature in various forms.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Microbial colonization of surfaces represents the first step towards biofilm\nformation, which is a recurring phenomenon in nature with beneficial and\ndetrimental implications in technological and medical settings. Consequently,\nthere is a current interest in elucidating the fundamental aspects of the\ninitial stages of biofilm formation of microorganisms on solid surfaces. While\nmost of the research is oriented to understand bacterial surface colonization,\nsuch observations at a fundamental level using photosynthetic microalgae are\nthus far elusive. Recent single-cell studies showed that the flagellar adhesion\nof Chlamydomonas is switched on in blue light and switched off under red light\n[Kreis et al., Nature Physics, 2018, 14, 45-49]. Here, we study this\nlight-switchable surface association of C. reinhardtii on the population level\nand measure the kinetics of adsorption and desorption of suspensions of motile\ncells on glass surfaces using bright field optical microscopy. We observe that\nboth processes exhibit a response lag relative to the time at which the blue-\nand red-light conditions are set and model this feature using time-delayed\nLangmuir-type kinetics. We find that cell adsorption occurs significantly\nfaster than desorption, which we attribute to the protein-mediated molecular\nadhesion mechanism of the cells. Adsorption experiments using phototactically\nblind Chlamydomonas mutants demonstrate that phototaxis does not affect the\ncell adsorption kinetics. Hence, this method can be used as an assay for\ncharacterizing the dynamics of the surface colonization of microbial species\nexhibiting light-regulated surface adhesion.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Convolutional neural network-based medical image classifiers have been shown\nto be especially susceptible to adversarial examples. Such instabilities are\nlikely to be unacceptable in the future of automated diagnoses. Though\nstatistical adversarial example detection methods have proven to be effective\ndefense mechanisms, additional research is necessary that investigates the\nfundamental vulnerabilities of deep-learning-based systems and how best to\nbuild models that jointly maximize traditional and robust accuracy. This paper\npresents the inclusion of attention mechanisms in CNN-based medical image\nclassifiers as a reliable and effective strategy for increasing robust accuracy\nwithout sacrifice. This method is able to increase robust accuracy by up to 16%\nin typical adversarial scenarios and up to 2700% in extreme cases.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We present our follow-up observations with GRANDMA of transient sources\nrevealed by the Zwicky Transient Facility (ZTF). Over a period of six months,\nall ZTF triggers were examined in real time by a dedicated science module\nimplemented in the Fink broker, which will be used for the data processing of\nthe Vera C. Rubin Observatory. In this article, we present three selection\nmethods to identify kilonova candidates. Out of more than 35 million\ncandidates, a hundred sources have passed our selection criteria. Six were then\nfollowed-up by GRANDMA (by both professional and amateur astronomers). The\nmajority were finally classified either as asteroids or as supernovae events.\nWe mobilized 37 telescopes, bringing together a large sample of images, taken\nunder various conditions and quality. To complement the orphan kilonova\ncandidates (those without associated gamma-ray bursts, which were all), we\nincluded three additional supernovae alerts to conduct further observations of\nduring summer 2021. We demonstrate the importance of the amateur astronomer\ncommunity that contributed images for scientific analyzes of new sources\ndiscovered in a magnitude range r'=17-19 mag. We based our rapid kilonova\nclassification on the decay rate of the optical source that should exceed 0.3\nmag/day. GRANDMA's follow-up determined the fading rate within 1.5+/-1.2 days\npost-discovery, without waiting for further observations from ZTF. No confirmed\nkilonovae were discovered during our observing campaign. This work will be\ncontinued in the coming months in the view of preparing for kilonova searches\nin the next gravitational-wave observing run O4.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  The goal of fine-grained action recognition is to successfully discriminate\nbetween action categories with subtle differences. To tackle this, we derive\ninspiration from the human visual system which contains specialized regions in\nthe brain that are dedicated towards handling specific tasks. We design a novel\nDynamic Spatio-Temporal Specialization (DSTS) module, which consists of\nspecialized neurons that are only activated for a subset of samples that are\nhighly similar. During training, the loss forces the specialized neurons to\nlearn discriminative fine-grained differences to distinguish between these\nsimilar samples, improving fine-grained recognition. Moreover, a\nspatio-temporal specialization method further optimizes the architectures of\nthe specialized neurons to capture either more spatial or temporal fine-grained\ninformation, to better tackle the large range of spatio-temporal variations in\nthe videos. Lastly, we design an Upstream-Downstream Learning algorithm to\noptimize our model's dynamic decisions during training, improving the\nperformance of our DSTS module. We obtain state-of-the-art performance on two\nwidely-used fine-grained action recognition datasets.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We show that the lowest quantum Cram\\'{e}r-Rao bound achievable in\ninterferometry with a one-axis twisted spin coherent state is saturated by the\nasymptotic method-of-moments error of a protocol that uses one call to the\none-axis twisting, one call to time-reversed one-axis twisting, and a final\ntotal spin measurement (i.e., a twist-untwist protocol). The result is derived\nby first showing that the metrological phase diagram for one-axis twisting is\nasymptotically characterized by a single quantum Fisher information value\n$N(N+1)/2$ for all times, then constructing a twist-untwist protocol having a\nmethod-of-moments error that saturates this value. The case of finite-range\none-axis twisting is similarly analyzed, and a simple functional form for the\nmetrological phase diagram is found in both the short-range and long-range\ninteraction regimes. Numerical evidence suggests that the finite-range\nanalogues of twist-untwist protocols can exhibit a method-of-moments error that\nasymptotically saturates the lowest quantum Cram\\'{e}r-Rao bound achievable in\ninterferometry with finite-range one-axis twisted spin coherent states for all\ninteraction times.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  Recent experiments on Ce$_2$Zr$_2$O$_7$ suggest that this material may host a\nnovel form of quantum spin ice, a three-dimensional quantum spin liquid with an\nemergent photon. The Ce$^{3+}$ local moments on the pyrochlore lattice are\ndescribed by pseudospin 1/2 degrees of freedom, whose components transform as\ndipolar and octupolar moments under symmetry operations. In principle, there\nexist four possible quantum spin ice regimes, depending on whether the Ising\ncomponent is in the dipolar/octupolar channel, and two possible flux\nconfigurations of the emergent gauge field. In this work, using exact\ndiagonalization and molecular dynamics, we investigate the equal-time and\ndynamical spin structure factors in all four quantum spin ice regimes using\nquantum and classical computations. Contrasting the distinct signatures of\nquantum and classical results for the four possible quantum spin ice regimes\nand elucidating the role of quantum fluctuations, we show that the quantum\nstructure factor computed for the $\\pi$-flux octupolar quantum spin ice regime\nis most compatible with the neutron scattering results on Ce$_2$Zr$_2$O$_7$.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Computation offloading in multi-access edge computing (MEC) is an effective\nparadigm for enabling resource-intensive smart applications. However, when the\nwireless channel utilized for offloading computing activities is hostile, the\nproper advantages of MEC may not be completely realized. Intelligent reflecting\nsurface (IRS) is a new technology that has recently attracted significant\ninterest can optimize the wireless transmission environment in a programmable\nway and improving the connectivity between user equipment (UE) and base station\n(BS). In this paper, the performance of MEC architecture is analyzed\nconsidering both IRS-assisted and without IRS communication scenarios in the\ncontext of the urban micro cellular scenarios. The research obtained that the\ndeployment of IRS can reduce the spectrum and energy consumption significantly.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We define common thermodynamic concepts purely within the framework of\ngeneral Markov chains and derive Jarzynski's equality and Crooks' fluctuation\ntheorem in this setup. Regarding non-equilibrium thermodynamics, we provide a\nnew proof of Jarzynski's equality without physical reversibility assumptions.\nMoreover, we discuss an asymmetry in the definition of work that appears in the\nusual formulation of Crooks' fluctuation theorem, but only surfaces in the\nnon-continuous case. We show how this asymmetry can be cured, requiring,\nhowever, a new condition regarding the energy protocol. We notice, because of\nthe way in which one can prepare a thermodynamic system in the Boltzmann\ndistribution, the new requirement is fulfilled by all previous experimental\nsetups supporting Crooks' fluctuation theorem.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  SFILES is a text-based notation for chemical process flowsheets. It was\noriginally proposed by d'Anterroches (2006) who was inspired by the text-based\nSMILES notation for molecules. The text-based format has several advantages\ncompared to flowsheet images regarding the storage format, computational\naccessibility, and eventually for data analysis and processing. However, the\noriginal SFILES version cannot describe essential flowsheet configurations\nunambiguously, such as the distinction between top and bottom products. Neither\nis it capable of describing the control structure required for the safe and\nreliable operation of chemical processes. Also, there is no publicly available\nsoftware for decoding or encoding chemical process topologies to SFILES. We\npropose the SFILES 2.0 with a complete description of the extended notation and\nnaming conventions. Additionally, we provide open-source software for the\nautomated conversion between flowsheet graphs and SFILES 2.0 strings. This way,\nwe hope to encourage researchers and engineers to publish their flowsheet\ntopologies as SFILES 2.0 strings. The ultimate goal is to set the standards for\ncreating a FAIR database of chemical process flowsheets, which would be of\ngreat value for future data analysis and processing.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Inspired by the coupled-layer construction of the X-Cube model, we introduce\nthe X-Cube Floquet code, a dynamical quantum error-correcting code where the\nnumber of encoded logical qubits grows with system size. The X-Cube Floquet\ncode is defined on a three-dimensional lattice, built from intersecting\ntwo-dimensional layers in the $xy$, $yz$, and $xz$ directions, and consists of\na periodic sequence of two-qubit measurements which couple the layers together.\nWithin a single Floquet cycle, the codespace switches between that of the\nX-Cube fracton order and layers of entangled, two-dimensional toric codes. The\nencoded logical qubits' dynamics are analyzed, and we argue that the new code\nhas a non-zero error threshold. We provide a new Hamiltonian realization of the\nX-Cube model and, more generally, explore the phase diagram related to the\nsequence of measurements that define the X-Cube Floquet code.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Extreme Classification (XC) seeks to tag data points with the most relevant\nsubset of labels from an extremely large label set. Performing deep XC with\ndense, learnt representations for data points and labels has attracted much\nattention due to its superiority over earlier XC methods that used sparse,\nhand-crafted features. Negative mining techniques have emerged as a critical\ncomponent of all deep XC methods that allow them to scale to millions of\nlabels. However, despite recent advances, training deep XC models with large\nencoder architectures such as transformers remains challenging. This paper\nidentifies that memory overheads of popular negative mining techniques often\nforce mini-batch sizes to remain small and slow training down. In response,\nthis paper introduces NGAME, a light-weight mini-batch creation technique that\noffers provably accurate in-batch negative samples. This allows training with\nlarger mini-batches offering significantly faster convergence and higher\naccuracies than existing negative sampling techniques. NGAME was found to be up\nto 16% more accurate than state-of-the-art methods on a wide array of benchmark\ndatasets for extreme classification, as well as 3% more accurate at retrieving\nsearch engine queries in response to a user webpage visit to show personalized\nads. In live A/B tests on a popular search engine, NGAME yielded up to 23%\ngains in click-through-rates.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We consider the equivalence of some norms in Sobolev spaces on bounded\ndomains of the d-dimensional real Euclidean space and also in Sobolev spaces on\nthe boundaries of those domains.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  We introduce a class of polytopes that concisely capture the structure of UV\nand IR divergences of general Feynman integrals in Schwinger parameter space,\ntreating them in a unified way as worldline segments shrinking and expanding at\ndifferent relative rates. While these polytopes conventionally arise as convex\nhulls - via Newton polytopes of Symanzik polynomials - we show that they also\nhave a remarkably simple dual description as cut out by linear inequalities\ndefining the facets. It is this dual definition that makes it possible to\ntransparently understand and efficiently compute leading UV and IR divergences\nfor any Feynman integral. In the case of the UV, this provides a transparent\ngeometric understanding of the familiar nested and overlapping divergences. In\nthe IR, the polytope exposes a new perspective on soft/collinear singularities\nand their intricate generalizations. Tropical geometry furnishes a simple\nframework for calculating the leading UV/IR divergences of any Feynman\nintegral, associating them with the volumes of certain dual cones. As concrete\napplications, we generalize Weinberg's theorem to include a characterization of\nIR divergences, and classify space-time dimensions in which general IR\ndivergences (logarithmic as well as power-law) can occur. We also compute the\nleading IR divergence of rectangular fishnet diagrams at all loop orders, which\nturn out to have a surprisingly simple combinatorial description.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Photoactive iridium complexes are of broad interest due to their applications\nranging from lighting to photocatalysis. However, the excited state property\nprediction of these complexes challenges ab initio methods such as\ntime-dependent density functional theory (TDDFT) both from an accuracy and a\ncomputational cost perspective, complicating high throughput virtual screening\n(HTVS). We instead leverage low-cost machine learning (ML) models to predict\nthe excited state properties of photoactive iridium complexes. We use\nexperimental data of 1,380 iridium complexes to train and evaluate the ML\nmodels and identify the best-performing and most transferable models to be\nthose trained on electronic structure features from low-cost density functional\ntheory tight binding calculations. Using these models, we predict the three\nexcited state properties considered, mean emission energy of phosphorescence,\nexcited state lifetime, and emission spectral integral, with accuracy\ncompetitive with or superseding TDDFT. We conduct feature importance analysis\nto identify which iridium complex attributes govern excited state properties\nand we validate these trends with explicit examples. As a demonstration of how\nour ML models can be used for HTVS and the acceleration of chemical discovery,\nwe curate a set of novel hypothetical iridium complexes and identify promising\nligands for the design of new phosphors.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We present a strong object detector with encoder-decoder pretraining and\nfinetuning. Our method, called Group DETR v2, is built upon a vision\ntransformer encoder ViT-Huge~\\cite{dosovitskiy2020image}, a DETR variant\nDINO~\\cite{zhang2022dino}, and an efficient DETR training method Group\nDETR~\\cite{chen2022group}. The training process consists of self-supervised\npretraining and finetuning a ViT-Huge encoder on ImageNet-1K, pretraining the\ndetector on Object365, and finally finetuning it on COCO. Group DETR v2\nachieves $\\textbf{64.5}$ mAP on COCO test-dev, and establishes a new SoTA on\nthe COCO leaderboard https://paperswithcode.com/sota/object-detection-on-coco\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Localization in aerial imagery-based maps offers many advantages, such as\nglobal consistency, geo-referenced maps, and the availability of publicly\naccessible data. However, the landmarks that can be observed from both aerial\nimagery and on-board sensors is limited. This leads to ambiguities or aliasing\nduring the data association.\n  Building upon a highly informative representation (that allows efficient data\nassociation), this paper presents a complete pipeline for resolving these\nambiguities. Its core is a robust self-tuning data association that adapts the\nsearch area depending on the entropy of the measurements. Additionally, to\nsmooth the final result, we adjust the information matrix for the associated\ndata as a function of the relative transform produced by the data association\nprocess.\n  We evaluate our method on real data from urban and rural scenarios around the\ncity of Karlsruhe in Germany. We compare state-of-the-art outlier mitigation\nmethods with our self-tuning approach, demonstrating a considerable\nimprovement, especially for outer-urban scenarios.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In this article a multi-segmented planar tensegrity mechanism was presented.\nThis mechanism has a three-segment structure with each segment residing on top\nof another. The size of the segments may decrease proportionally from base to\ntop, resulting in a tapered shape from base to tip like an elephant trunk. The\nsystem was mechanically formulated as having linear springs and cables\nfunctioning as actuators. The singularities, as well as the stability of the\nparallel mechanism, were analyzed by using the principle of minimum energy.\nOptimization was also done to obtain the greatest angular deflection for a\nsegment according to a ratio between the size of the base and the moving\nplatform of the robotic system. The result of this work is a family of\nmechanisms that can generate the same workspace for different stability\nproperties.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  The wave-particle duality is often considered as the modern and satisfactory\nanswer that man found in searching to know the nature of light after more than\n2000 years of questioning. It is also the answer given by quantum physics\nconcerning the nature of matter particles and any other radiations. The aim of\nthis work is to perform an analysis of this concept of wave-particle duality\nfrom a historical, philosophical and scientific point of view and to study and\ndiscuss about the relations which exist between it, the uncertainty principle\nand the concepts of phase space and microstates considered in statistical\nmechanics. These relations will be described and analyzed both from a\nphysico-mathematical and historico-philosophical perspective. It is, in\nparticular, highlighted that while the concepts of phase space and microstates\nwere already introduced in classical physics long before the discovery of the\nwave-particle duality, a correct understanding of them cannot be achieved\nwithout quantum physics. But conversely, it is also shown that the relations of\nthe wave-particle duality with uncertainty principle, phase space and\nmicrostates that are highlighted can help in a deeper understanding and more\nadequate description of this duality.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Self-supervised representation learning of Multivariate Time Series (MTS) is\na challenging task and attracts increasing research interests in recent years.\nMany previous works focus on the pretext task of self-supervised learning and\nusually neglect the complex problem of MTS encoding, leading to unpromising\nresults. In this paper, we tackle this challenge from two aspects: encoder and\npretext task, and propose a unified channel-aware self-supervised learning\nframework CaSS. Specifically, we first design a new Transformer-based encoder\nChannel-aware Transformer (CaT) to capture the complex relationships between\ndifferent time channels of MTS. Second, we combine two novel pretext tasks Next\nTrend Prediction (NTP) and Contextual Similarity (CS) for the self-supervised\nrepresentation learning with our proposed encoder. Extensive experiments are\nconducted on several commonly used benchmark datasets. The experimental results\nshow that our framework achieves new state-of-the-art comparing with previous\nself-supervised MTS representation learning methods (up to +7.70\\% improvement\non LSST dataset) and can be well applied to the downstream MTS classification.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  The total solar irradiance (TSI) varies on timescales of minute to centuries.\nOn short timescales it varies due to the superposition of intensity\nfluctuations produced by turbulent convection and acoustic oscillations. On\nlonger scale times, it changes due to photospheric magnetic activity, mainly\nbecause of the facular brightenings and dimmings caused by sunspots. While\nmodern TSI variations have been monitored from space since 1970s, TSI\nvariations over much longer periods can only be estimated using either\nhistorical observations of magnetic features, possibly supported by flux\ntransport models, or from the measurements of the cosmogenic isotope (e.g.,\n\\textsuperscript{14}C or \\textsuperscript{10}Be) concentrations in tree rings\nand ice cores. The reconstruction of the TSI in the last few centuries,\nparticularly in the 17th/18th centuries during the Maunder minimum, is of\nprimary importance for studying climatic effects. To separate the temporal\ncomponents of the irradiance variations, specifically the magnetic cycle from\nsecular variability, we decomposed the signals associated with historical\nobservations of magnetic features and the solar modulation potential $\\Phi$ by\napplying an Empirical Mode Decomposition algorithm. Thus, the reconstruction is\nempirical and does not require any feature contrast or field transport model.\nThe assessed difference between the mean value during the Maunder minimum and\nthe present value is $\\simeq2.5 Wm^{-2}$. Moreover it shows, in the first half\nof the last century, a growth of $\\simeq 1.5 W m^{-2}$ which stops around the\nmiddle of the century to remain constant for the next 50 years, apart from the\nmodulation due to the solar cycle.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  In this article, we study the class of surfaces of revolution in the\n3-dimensional Lorentz-Minkowski space with nonvanishing Gauss curvature whose\nposition vector x satisfies the condition {\\Delta}IIIx = Ax, where A is a\nsquare matrix of order 3 and {\\Delta}III denotes the Laplace operator of the\nsecond fundamental form III of the surface. We show that such surfaces are\neither minimal or pseudospheres of a real or imaginary radius.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We study the complexity of computational problems arising from existence\ntheorems in extremal combinatorics. For some of these problems, a solution is\nguaranteed to exist based on an iterated application of the Pigeonhole\nPrinciple. This results in the definition of a new complexity class within\nTFNP, which we call PLC (for \"polynomial long choice\"). PLC includes all of\nPPP, as well as numerous previously unclassified total problems, including\nsearch problems related to Ramsey's theorem, the Sunflower theorem, the\nErd\\H{o}s-Ko-Rado lemma, and K\\\"onig's lemma. Whether the first two of these\nfour problems are PLC-complete is an important open question which we pursue;\nin contrast, we show that the latter two are PPP-complete. Finally, we reframe\nPPP as an optimization problem, and define a hierarchy of such problems related\nto Tur\\'an's theorem.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  Making music with other people is a social activity as well as an artistic\none. Music therapists take advantage of the social aspects of music to obtain\nbenefits for the patients, interacting with them musically, but this activity\nrequires an high level of expertise. We propose a serious game that helps\npeople even without musical skills interact with each other by collaboratively\ncreating a rhythm with MIDI drum pads. The gaming system analyzes the rhythm in\nreal time to add a musical feedback that enhances the aesthetical experience\nthat is a crucial part of the musical interaction. The system is evaluated\nthrough a questionnaire asking subjects who tried in couples the system if they\nperceived it as helping their interaction. Despite the early development stage\nof the game, the results of the questionnaire show positive reception.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Using the formalism of order series, we provide new proofs of a couple of\nresults by Ramanujan and generalize one of his results dealing with the values\nof the zeta function. Consider the operad generated by a binary associative and\ncommutative operation and a binary associative operation, order series are one\nof the algebras over this operad. In our interpretation, Ramanujan worked with\nseries inheriting the structure of the disjoint union of posets. Using zeta\nvalues, we derive an algebra over the operad of series-parallel posets.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  The event camera is a bio-vision inspired camera with high dynamic range,\nhigh response speed, and low power consumption, recently attracting extensive\nattention for its use in vast vision tasks. Unlike the conventional cameras\nthat output intensity frame at a fixed time interval, event camera records the\npixel brightness change (a.k.a., event) asynchronously (in time) and sparsely\n(in space). Existing methods often aggregate events occurred in a predefined\ntemporal duration for downstream tasks, which apparently overlook varying\nbehaviors of fine-grained temporal events. This work proposes the Event\nTransformer to directly process the event sequence in its native vectorized\ntensor format. It cascades a Local Transformer (LXformer) for exploiting the\nlocal temporal correlation, a Sparse Conformer (SCformer) for embedding the\nlocal spatial similarity, and a Global Transformer (GXformer) for further\naggregating the global information in a serial means to effectively\ncharacterize the time and space correlations from input raw events for the\ngeneration of effective spatiotemporal features used for tasks. %In both\nLXformer and SCformer, Experimental studies have been extensively conducted in\ncomparison to another fourteen existing algorithms upon five different datasets\nwidely used for classification. Quantitative results report the\nstate-of-the-arts classification accuracy and the least computational resource\nrequirements, of the Event Transformer, making it practically attractive for\nevent-based vision tasks.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  This work proposes a novel method to generate realistic talking head videos\nusing audio and visual streams. We animate a source image by transferring head\nmotion from a driving video using a dense motion field generated using\nlearnable keypoints. We improve the quality of lip sync using audio as an\nadditional input, helping the network to attend to the mouth region. We use\nadditional priors using face segmentation and face mesh to improve the\nstructure of the reconstructed faces. Finally, we improve the visual quality of\nthe generations by incorporating a carefully designed identity-aware generator\nmodule. The identity-aware generator takes the source image and the warped\nmotion features as input to generate a high-quality output with fine-grained\ndetails. Our method produces state-of-the-art results and generalizes well to\nunseen faces, languages, and voices. We comprehensively evaluate our approach\nusing multiple metrics and outperforming the current techniques both\nqualitative and quantitatively. Our work opens up several applications,\nincluding enabling low bandwidth video calls. We release a demo video and\nadditional information at\nhttp://cvit.iiit.ac.in/research/projects/cvit-projects/avfr.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  As one of the largest e-commerce platforms in the world, Taobao's\nrecommendation systems (RSs) serve the demands of shopping for hundreds of\nmillions of customers. Click-Through Rate (CTR) prediction is a core component\nof the RS. One of the biggest characteristics in CTR prediction at Taobao is\nthat there exist multiple recommendation domains where the scales of different\ndomains vary significantly. Therefore, it is crucial to perform cross-domain\nCTR prediction to transfer knowledge from large domains to small domains to\nalleviate the data sparsity issue. However, existing cross-domain CTR\nprediction methods are proposed for static knowledge transfer, ignoring that\nall domains in real-world RSs are continually time-evolving. In light of this,\nwe present a necessary but novel task named Continual Transfer Learning (CTL),\nwhich transfers knowledge from a time-evolving source domain to a time-evolving\ntarget domain. In this work, we propose a simple and effective CTL model called\nCTNet to solve the problem of continual cross-domain CTR prediction at Taobao,\nand CTNet can be trained efficiently. Particularly, CTNet considers an\nimportant characteristic in the industry that models has been continually\nwell-trained for a very long time. So CTNet aims to fully utilize all the\nwell-trained model parameters in both source domain and target domain to avoid\nlosing historically acquired knowledge, and only needs incremental target\ndomain data for training to guarantee efficiency. Extensive offline experiments\nand online A/B testing at Taobao demonstrate the efficiency and effectiveness\nof CTNet. CTNet is now deployed online in the recommender systems of Taobao,\nserving the main traffic of hundreds of millions of active users.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Conditional Neural Processes~(CNPs) bridge neural networks with probabilistic\ninference to approximate functions of Stochastic Processes under meta-learning\nsettings. Given a batch of non-{\\it i.i.d} function instantiations, CNPs are\njointly optimized for in-instantiation observation prediction and\ncross-instantiation meta-representation adaptation within a generative\nreconstruction pipeline. There can be a challenge in tying together such two\ntargets when the distribution of function observations scales to\nhigh-dimensional and noisy spaces. Instead, noise contrastive estimation might\nbe able to provide more robust representations by learning distributional\nmatching objectives to combat such inherent limitation of generative models. In\nlight of this, we propose to equip CNPs by 1) aligning prediction with encoded\nground-truth observation, and 2) decoupling meta-representation adaptation from\ngenerative reconstruction. Specifically, two auxiliary contrastive branches are\nset up hierarchically, namely in-instantiation temporal contrastive\nlearning~({\\tt TCL}) and cross-instantiation function contrastive\nlearning~({\\tt FCL}), to facilitate local predictive alignment and global\nfunction consistency, respectively. We empirically show that {\\tt TCL} captures\nhigh-level abstraction of observations, whereas {\\tt FCL} helps identify\nunderlying functions, which in turn provides more efficient representations.\nOur model outperforms other CNPs variants when evaluating function distribution\nreconstruction and parameter identification across 1D, 2D and high-dimensional\ntime-series.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Traditional systems designed for task oriented dialog utilize knowledge\npresent only in structured knowledge sources to generate responses. However,\nrelevant information required to generate responses may also reside in\nunstructured sources, such as documents. Recent state of the art models such as\nHyKnow and SeKnow aimed at overcoming these challenges make limiting\nassumptions about the knowledge sources. For instance, these systems assume\nthat certain types of information, such as a phone number, is always present in\na structured KB while information about aspects such as entrance ticket prices\nwould always be available in documents.\n  In this paper, we create a modified version of the MutliWOZ based dataset\nprepared by SeKnow to demonstrate how current methods have significant\ndegradation in performance when strict assumptions about the source of\ninformation are removed. Then, in line with recent work exploiting pre-trained\nlanguage models, we fine-tune a BART based model using prompts for the tasks of\nquerying knowledge sources, as well as, for response generation, without making\nassumptions about the information present in each knowledge source. Through a\nseries of experiments, we demonstrate that our model is robust to perturbations\nto knowledge modality (source of information), and that it can fuse information\nfrom structured as well as unstructured knowledge to generate responses.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  In this work, we investigate online mechanisms for trading time-sensitive\nvalued data. We adopt a continuous function $d(t)$ to represent the data value\nfluctuation over time $t$. Our objective is to design an \\emph{online}\nmechanism achieving \\emph{truthfulness} and \\emph{revenue-competitiveness}. We\nfirst prove several lower bounds on the revenue competitive ratios under\nvarious assumptions. We then propose several online truthful auction mechanisms\nfor various adversarial models, such as a randomized observe-then-select\nmechanism $\\mathcal{M}_1$ and prove that it is \\textit{truthful} and\n$\\Theta(\\log n)$-competitive under some assumptions. Then we present an\neffective truthful weighted-selection mechanism $\\mathcal{M'}_W$ by relaxing\nthe assumptions on the sizes of the discount-classes. We prove that it achieves\na competitive ratio $\\Theta(n\\log n)$ for any known non-decreasing discount\nfunction $d(t)$, and the number of buyers in each discount class $n_c \\ge 2$.\nWhen the optimum expected revenue $OPT_1$ can be estimated within a constant\nfactor, i.e. $c_0 \\cdot OPT_1 \\le Z \\le OPT_1 $ for some constant $c_0\n\\in(0,1)$, we propose a truthful online posted-price mechanism that achieves a\nconstant competitive ratio $\\frac{4}{c_0}$. Our extensive numerical evaluations\ndemonstrate that our mechanisms perform very well in most cases.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Parental origin effects play an important role in mammal development and\ndisorder. Case-control mother-child pair genotype data can be used to detect\nparental origin effects and is often convenient to collect in practice. Most\nexisting methods for assessing parental origin effects do not incorporate any\ncovariates, which may be required to control for confounding factors. We\npropose to model the parental origin effects through a logistic regression\nmodel, with predictors including maternal and child genotypes, parental\norigins, and covariates. The parental origins may not be fully inferred from\ngenotypes of a target genetic marker, so we propose to use genotypes of markers\ntightly linked to the target marker to increase inference efficiency. A\ncomputationally robust statistical inference procedure is developed based on a\nmodified profile likelihood in a retrospective way. A computationally feasible\nexpectation-maximization algorithm is devised to estimate all unknown\nparameters involved in the modified profile likelihood. This algorithm differs\nfrom the conventional expectation-maximization algorithm in the sense that it\nis based on a modified instead of the original profile likelihood function. The\nconvergence of the algorithm is established under some mild regularity\nconditions. This expectation-maximization algorithm also allows convenient\nhandling of missing child genotypes. Large sample properties, including weak\nconsistency, asymptotic normality, and asymptotic efficiency, are established\nfor the proposed estimator under some mild regularity conditions. Finite sample\nproperties are evaluated through extensive simulation studies and the\napplication to a real dataset.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Finding an appropriate representation of dynamic activities in the brain is\ncrucial for many downstream applications. Due to its highly dynamic nature,\ntemporally averaged fMRI (functional magnetic resonance imaging) can only\nprovide a narrow view of underlying brain activities. Previous works lack the\nability to learn and interpret the latent dynamics in brain architectures. This\npaper builds an efficient graph neural network model that incorporates both\nregion-mapped fMRI sequences and structural connectivities obtained from DWI\n(diffusion-weighted imaging) as inputs. We find good representations of the\nlatent brain dynamics through learning sample-level adaptive adjacency matrices\nand performing a novel multi-resolution inner cluster smoothing. We also\nattribute inputs with integrated gradients, which enables us to infer (1)\nhighly involved brain connections and subnetworks for each task, (2) temporal\nkeyframes of imaging sequences that characterize tasks, and (3) subnetworks\nthat discriminate between individual subjects. This ability to identify\ncritical subnetworks that characterize signal states across heterogeneous tasks\nand individuals is of great importance to neuroscience and other scientific\ndomains. Extensive experiments and ablation studies demonstrate our proposed\nmethod's superiority and efficiency in spatial-temporal graph signal modeling\nwith insightful interpretations of brain dynamics.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Model-based methods for recommender systems have been studied extensively for\nyears. Modern recommender systems usually resort to 1) representation learning\nmodels which define user-item preference as the distance between their\nembedding representations, and 2) embedding-based Approximate Nearest Neighbor\n(ANN) search to tackle the efficiency problem introduced by large-scale corpus.\nWhile providing efficient retrieval, the embedding-based retrieval pattern also\nlimits the model capacity since the form of user-item preference measure is\nrestricted to the distance between their embedding representations. However,\nfor other more precise user-item preference measures, e.g., preference scores\ndirectly derived from a deep neural network, they are computationally\nintractable because of the lack of an efficient retrieval method, and an\nexhaustive search for all user-item pairs is impractical. In this paper, we\npropose a novel method to extend ANN search to arbitrary matching functions,\ne.g., a deep neural network. Our main idea is to perform a greedy walk with a\nmatching function in a similarity graph constructed from all items. To solve\nthe problem that the similarity measures of graph construction and user-item\nmatching function are heterogeneous, we propose a pluggable adversarial\ntraining task to ensure the graph search with arbitrary matching function can\nachieve fairly high precision. Experimental results in both open source and\nindustry datasets demonstrate the effectiveness of our method. The proposed\nmethod has been fully deployed in the Taobao display advertising platform and\nbrings a considerable advertising revenue increase. We also summarize our\ndetailed experiences in deployment in this paper.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Motivated by investigating multistationarity in biochemical systems, we\naddress saddle-node bifurcations for chemical reaction networks endowed with\ngeneral kinetics. At positive equilibria, we identify structural network\nconditions that guarantee the bifurcation behavior and we develop a method to\nidentify the proper bifurcation parameters. As a relevant example, we\nexplicitly provide such bifurcation parameters for Michaelis-Menten and Hill's\nkinetics. Examples of application include reversible feedback cycles, the\ncentral carbon metabolism of E.Coli, and autocatalytic networks.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  We study discrete allocation problems, as in the textbook notion of an\nexchange economy, but with indivisible goods. The problem is well-known to be\ndifficult. The model is rich enough to encode some of the most pathological\nbargaining configurations in game theory, like the roommate problem. Our\ncontribution is to show the existence of stable allocations (outcomes in the\nweak core, or in the bargaining set) under different sets of assumptions.\nSpecifically, we consider dichotomous preferences, categorical economies, and\ndiscrete TU markets. The paper uses varied techniques, from Scarf's balanced\ngames to a generalization of the TTC algorithm by means of Tarski fixed points.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  In this work we introduce a unit averaging procedure to efficiently recover\nunit-specific parameters in a heterogeneous panel model. The procedure consists\nin estimating the parameter of a given unit using a weighted average of all the\nunit-specific parameter estimators in the panel. The weights of the average are\ndetermined by minimizing an MSE criterion. We analyze the properties of the\nminimum MSE unit averaging estimator in a local heterogeneity framework\ninspired by the literature on frequentist model averaging. The analysis of the\nestimator covers both the cases in which the cross-sectional dimension of the\npanel is fixed and large. In both cases, we obtain the local asymptotic\ndistribution of the minimum MSE unit averaging estimators and of the associated\nweights. A GDP nowcasting application for a panel of European countries\nshowcases the benefits of the procedure.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  To foster usefulness and accountability of machine learning (ML), it is\nessential to explain a model's decisions in addition to evaluating its\nperformance. Accordingly, the field of explainable artificial intelligence\n(XAI) has resurfaced as a topic of active research, offering approaches to\naddress the \"how\" and \"why\" of automated decision-making. Within this domain,\ncounterfactual explanations (CFEs) have gained considerable traction as a\npsychologically grounded approach to generate post-hoc explanations. To do so,\nCFEs highlight what changes to a model's input would have changed its\nprediction in a particular way. However, despite the introduction of numerous\nCFE approaches, their usability has yet to be thoroughly validated at the human\nlevel. Thus, to advance the field of XAI, we introduce the Alien Zoo, an\nengaging, web-based and game-inspired experimental framework. The Alien Zoo\nprovides the means to evaluate usability of CFEs for gaining new knowledge from\nan automated system, targeting novice users in a domain-general context. As a\nproof of concept, we demonstrate the practical efficacy and feasibility of this\napproach in a user study. Our results suggest that users benefit from receiving\nCFEs compared to no explanation, both in terms of objective performance in the\nproposed iterative learning task, and subjective usability. With this work, we\naim to equip research groups and practitioners with the means to easily run\ncontrolled and well-powered user studies to complement their otherwise often\nmore technology-oriented work. Thus, in the interest of reproducible research,\nwe provide the entire code, together with the underlying models and user data.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  We present PMC-Patients, a dataset consisting of 167k patient notes with 3.1M\nrelevant article annotations and 293k similar patient annotations. The patient\nnotes are extracted by identifying certain sections from case reports in PubMed\nCentral, and those with at least CC BY-NC-SA license are re-distributed.\nPatient-article relevance and patient-patient similarity are defined by\ncitation relationships in PubMed. We also perform four tasks with PMC-Patients\nto demonstrate its utility, including Patient Note Recognition (PNR),\nPatient-Patient Similarity (PPS), Patient-Patient Retrieval (PPR), and\nPatient-Article Retrieval (PAR). In summary, PMC-Patients provides the\nlargest-scale patient notes with high quality, diverse conditions, easy access,\nand rich annotations.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Majorana particles are the same as their antiparticle, and their analogues in\ncondensed matter may be a platform for quantum computing. We describe the\nsearch for these modes in semiconductor heterostructures and how disorder is a\nlimiting factor.\n\n\n###\n\n", "completion": " 07"}
{"prompt": "  In this paper, we prove a sharp and strong non-uniqueness for a class of weak\nsolutions to the three-dimensional magneto-hydrodynamic (MHD) system. More\nprecisely, we show that any weak solution $(v,b)\\in L^p_tL^{\\infty}_x$ is\nnon-unique in $L^p_tL^{\\infty}_x$ with $1\\le p<2$, which reveals the strong\nnon-uniqueness, and the sharpness in terms of the classical\nLadyzhenskaya-Prodi-Serrin criteria at endpoint $(2, \\infty)$. Moreover, for\nany $1\\le p<2$ and $\\epsilon>0$, we construct non-Leray-Hopf weak solutions in\n$L^p_tL^{\\infty}_x\\cap L^1_tC^{1-\\epsilon}$. The results of Navier-Stokes\nequations in \\cite{1Cheskidov} imply the sharp non-uniqueness of MHD system\nwith trivial magnetic field $b$. Our result shows the non-uniqueness for any\nweak solution $(v,b)$ including non-trivial magnetic field $b$.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  This paper proposes the MBURST, a novel multimodal solution for audio-visual\nspeech enhancements that consider the most recent neurological discoveries\nregarding pyramidal cells of the prefrontal cortex and other brain regions. The\nso-called burst propagation implements several criteria to address the credit\nassignment problem in a more biologically plausible manner: steering the sign\nand magnitude of plasticity through feedback, multiplexing the feedback and\nfeedforward information across layers through different weight connections,\napproximating feedback and feedforward connections, and linearizing the\nfeedback signals. MBURST benefits from such capabilities to learn correlations\nbetween the noisy signal and the visual stimuli, thus attributing meaning to\nthe speech by amplifying relevant information and suppressing noise.\nExperiments conducted over a Grid Corpus and CHiME3-based dataset show that\nMBURST can reproduce similar mask reconstructions to the multimodal\nbackpropagation-based baseline while demonstrating outstanding energy\nefficiency management, reducing the neuron firing rates to values up to\n\\textbf{$70\\%$} lower. Such a feature implies more sustainable implementations,\nsuitable and desirable for hearing aids or any other similar embedded systems.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We study the upper bounds for $A(n,d)$, the maximum size of codewords with\nlength $n$ and Hamming distance at least $d$. Schrijver studied the Terwilliger\nalgebra of the Hamming scheme and proposed a semidefinite program to bound\n$A(n, d)$. We derive more sophisticated matrix inequalities based on a split\nTerwilliger algebra to improve Schrijver's semidefinite programming bounds on\n$A(n, d)$. In particular, we improve the semidefinite programming bounds on\n$A(18,4)$ and $A(19, 4)$ to $6551$ and $13087$, respectively.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  We report a strategy to design nanoscale cold-source field-effect transistors\n(CS-FETs) with bias-independent sub-60 mV/dec subthreshold swing (SS). By\nfirst-principles calculations and quantum-transport simulations, we reveal that\nthe energy alignment of density of states (DOS) between the drain and source\nelectrodes is critical to achieving bias-independent SS. By defining \"gate\nwindow\", we propose a device model to demonstrate how similar slopes of the\ndrain DOS falling into the gate window can stabilize the SS under different\nbias. This study underscores the significance of drain DOS engineering in the\ndesign of CS-FETs with bias-independent SS for portable electronic\napplications.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We present SLATE, a sequence labeling approach for extracting tasks from\nfree-form content such as digitally handwritten (or \"inked\") notes on a virtual\nwhiteboard. Our approach allows us to create a single, low-latency model to\nsimultaneously perform sentence segmentation and classification of these\nsentences into task/non-task sentences. SLATE greatly outperforms a baseline\ntwo-model (sentence segmentation followed by classification model) approach,\nachieving a task F1 score of 84.4\\%, a sentence segmentation (boundary\nsimilarity) score of 88.4% and three times lower latency compared to the\nbaseline. Furthermore, we provide insights into tackling challenges of\nperforming NLP on the inking domain. We release both our code and dataset for\nthis novel task.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Natural user interfaces are on the rise. Manufacturers for Augmented,\nVirtual, and Mixed Reality head mounted displays are increasingly integrating\nnew sensors into their consumer grade products, allowing gesture recognition\nwithout additional hardware. This offers new possibilities for bare handed\ninteraction within virtual environments. This work proposes a hand gesture\nauthoring tool for object specific grab gestures allowing virtual objects to be\ngrabbed as in the real world. The presented solution uses template matching for\ngesture recognition and requires no technical knowledge to design and create\ncustom tailored hand gestures. In a user study, the proposed approach is\ncompared with the pinch gesture and the controller for grasping virtual\nobjects. The different grasping techniques are compared in terms of accuracy,\ntask completion time, usability, and naturalness. The study showed that\ngestures created with the proposed approach are perceived by users as a more\nnatural input modality than the others.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  A railway is a complex system comprising multiple infrastructure and rolling\nstock assets. To operate the system safely, reliably, and efficiently, the\ncondition many components needs to be monitored. To automate this process,\ndata-driven fault detection and diagnostics models can be employed. In\npractice, however, the performance of data-driven models can be compromised if\nthe training dataset is not representative of all possible future conditions.\nWe propose to approach this problem by learning a feature representation that\nis, on the one hand, invariant to operating or environmental factors but, on\nthe other hand, sensitive to changes in the asset's health condition. We\nevaluate how contrastive learning can be employed on supervised and\nunsupervised fault detection and diagnostics tasks given real condition\nmonitoring datasets within a railway system - one image dataset from\ninfrastructure assets and one time-series dataset from rolling stock assets.\nFirst, we evaluate the performance of supervised contrastive feature learning\non a railway sleeper defect classification task given a labeled image dataset.\nSecond, we evaluate the performance of unsupervised contrastive feature\nlearning without access to faulty samples on an anomaly detection task given a\nrailway wheel dataset. Here, we test the hypothesis of whether a feature\nencoder's sensitivity to degradation is also sensitive to novel fault patterns\nin the data. Our results demonstrate that contrastive feature learning improves\nthe performance on the supervised classification task regarding sleepers\ncompared to a state-of-the-art method. Moreover, on the anomaly detection task\nconcerning the railway wheels, the detection of shelling defects is improved\ncompared to state-of-the-art methods.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Current global re-localization algorithms are built on top of localization\nand mapping methods and heavily rely on scan matching and direct point cloud\nfeature extraction and therefore are vulnerable in featureless demanding\nenvironments like caves and tunnels. In this article, we propose a novel global\nre-localization framework that: a) does not require an initial guess, like most\nmethods do, while b) it has the capability to offer the top-k candidates to\nchoose from and last but not least provides an event-based re-localization\ntrigger module for enabling, and c) supporting completely autonomous robotic\nmissions. With the focus on subterranean environments with low features, we opt\nto use descriptors based on range images from 3D LiDAR scans in order to\nmaintain the depth information of the environment. In our novel approach, we\nmake use of a state-of-the-art data-driven descriptor extraction framework for\nplace recognition and orientation regression and enhance it with the addition\nof a junction detection module that also utilizes the descriptors for\nclassification purposes.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Faced with changing markets and evolving consumer demands, beef industries\nare investing in grading systems to maximise value extraction throughout their\nentire supply chain. The Meat Standards Australia (MSA) system is a\ncustomer-oriented total quality management system that stands out\ninternationally by predicting quality grades of specific muscles processed by a\ndesignated cooking method. The model currently underpinning the MSA system\nrequires laborious effort to estimate and its prediction performance may be\nless accurate in the presence of unbalanced data sets where many \"muscle x\ncook\" combinations have few observations and/or few predictors of palatability\nare available. This paper proposes a novel predictive method for beef eating\nquality that bridges a spectrum of muscle x cook-specific models. At one\nextreme, each muscle x cook combination is modelled independently; at the other\nextreme a pooled predictive model is obtained across all muscle x cook\ncombinations. Via a data-driven regularization method, we cover all muscle x\ncook-specific models along this spectrum. We demonstrate that the proposed\npredictive method attains considerable accuracy improvements relative to\nindependent or pooled approaches on unique MSA data sets.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  This ongoing study revisits the connotations of \"digital humanists\" and\nexplores the reasons why a researcher does or does not self-identify as a\ndigital humanist. Building on semi-structured interview data collected from\nfourteen researchers and practitioners engaging in digital humanities (DH)\nprojects, this poster illustrates researchers' various understandings of\n\"digital humanist\" as a term and research identity and highlights the\ncomplexity of \"digital humanists\" as a research community. This study\ncontributes to DH scholarship with insights into the collective imaginations of\nthe digital humanist as a research community one decade after the early\nattempts. Findings of this research study also facilitate a more thorough,\ntimely, and dynamic discussion of the major workforce in digital humanities,\npotentially paving the way for future research on labor and collaboration in\nthe DH research domain.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  In this paper we prove that the space $ \\mathbb{P}_p $ of all periodic\nfunction of fundamental period $ p $ is a direct sum of the space $\n\\mathbb{P}_{p/2} $ of periodic functions of fundamental period $ p/2 $ and the\nspace $ \\mathbb{AP}_{p/2} $ of antiperiodic functions of fundamental anti\nperiod $ p/2 $. The decomposition can be continued by applying the\ndecomposition process to the successively raising periodic subspaces. It is\nshown that, under certain condition, a periodic function can be written as a\nconvergent infinite series of anti periodic functions of distinct fundamental\nanti periods. In addition, we characterize the space of all periodic functions\nof period $ p \\in \\mathbb{N} $ in terms of all its periodic and antiperiodic\nsubspaces of integer periods (or anti periods). We show that the elements of a\nsubspace of such a space of periodic functions take a specific form (not\narbitrary) of linear combinations of the shifts of the elements of the given\nspace. Lastly, we introduce a lattice diagram named-periodicity diagram for a\nspace of periodic function of a fixed period $ p \\in \\mathbb{N} $. As a\nparticular example, the periodicity diagram of $ \\mathbb{P}_{12} $ is shown.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  The Surface Enhancement of the IceTop air-shower array will include the\naddition of radio antennas and scintillator panels, co-located with the\nexisting ice-Cherenkov tanks and covering an area of about 1 km$^2$. Together,\nthese will increase the sensitivity of the IceCube Neutrino Observatory to the\nelectromagnetic and muonic components of cosmic-ray-induced air showers at the\nSouth Pole. The inclusion of the radio technique necessitates an expanded set\nof simulation and analysis tools to explore the radio-frequency emission from\nair showers in the 70 MHz to 350 MHz band. In this paper we describe the\nsoftware modules that have been developed to work with time- and\nfrequency-domain information within IceCube's existing software framework,\nIceTray, which is used by the entire IceCube collaboration. The software\nincludes a method by which air-shower simulation, generated using CoREAS, can\nbe reused via waveform interpolation, thus overcoming a significant\ncomputational hurdle in the field.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  First order policy optimization has been widely used in reinforcement\nlearning. It guarantees to find the optimal policy for the state-feedback\nlinear quadratic regulator (LQR). However, the performance of policy\noptimization remains unclear for the linear quadratic Gaussian (LQG) control\nwhere the LQG cost has spurious suboptimal stationary points. In this paper, we\nintroduce a novel perturbed policy gradient (PGD) method to escape a large\nclass of bad stationary points (including high-order saddles). In particular,\nbased on the specific structure of LQG, we introduce a novel reparameterization\nprocedure which converts the iterate from a high-order saddle to a strict\nsaddle, from which standard random perturbations in PGD can escape efficiently.\nWe further characterize the high-order saddles that can be escaped by our\nalgorithm.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Rapid aerial grasping through robots can lead to many applications that\nutilize fast and dynamic picking and placing of objects. Rigid grippers\ntraditionally used in aerial manipulators require high precision and specific\nobject geometries for successful grasping. We propose RAPTOR, a quadcopter\nplatform combined with a custom Fin Ray gripper to enable more flexible\ngrasping of objects with different geometries, leveraging the properties of\nsoft materials to increase the contact surface between the gripper and the\nobjects. To reduce the communication latency, we present a new lightweight\nmiddleware solution based on Fast DDS (Data Distribution Service) as an\nalternative to ROS (Robot Operating System). We show that RAPTOR achieves an\naverage of 83% grasping efficacy in a real-world setting for four different\nobject geometries while moving at an average velocity of 1 m/s during grasping.\nIn a high-velocity setting, RAPTOR supports up to four times the payload\ncompared to previous works. Our results highlight the potential of aerial\ndrones in automated warehouses and other manipulation applications where speed,\nswiftness, and robustness are essential while operating in hard-to-reach\nplaces.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Photonic neuromorphic computing has emerged as a promising avenue toward\nbuilding a low-latency and energy-efficient non-von-Neuman computing system.\nPhotonic spiking neural network (PSNN) exploits brain-like spatiotemporal\nprocessing to realize high-performance neuromorphic computing. However, the\nnonlinear computation of PSNN remains a significant challenging. Here, we\nproposed and fabricated a photonic spiking neuron chip based on an integrated\nFabry-P\\'erot laser with a saturable absorber (FP-SA) for the first time. The\nnonlinear neuron-like dynamics including temporal integration, threshold and\nspike generation, refractory period, and cascadability were experimentally\ndemonstrated, which offers an indispensable fundamental building block to\nconstruct the PSNN hardware. Furthermore, we proposed time-multiplexed spike\nencoding to realize functional PSNN far beyond the hardware integration scale\nlimit. PSNNs with single/cascaded photonic spiking neurons were experimentally\ndemonstrated to realize hardware-algorithm collaborative computing, showing\ncapability in performing classification tasks with supervised learning\nalgorithm, which paves the way for multi-layer PSNN for solving complex tasks.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  The interactions of $\\bar{D}^{(*)} \\Lambda_c - \\bar{D}^{(*)}\\Sigma_c^{(*)}$\nare studied within the framework of a dynamical coupled-channel approach. A\nseries of bound states and resonances with different spin and parity are\ndynamically generated in the hidden charm sector. Four $S$-wave bound states\nare found in the mass range of 4.3 to 4.5 GeV, close to the pentaquark states\nobserved by LHCb. Two of the states have a spin parity of $J^P= 1/2^-$ and the\nother two have $J^P=3/2^-$. In addition, several resonances with different spin\nand parity in higher partial waves are predicted.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  In this paper, we have explored the field equations of f(T, B) gravity as an\nextension of teleparallel gravity in an isotropic and homogeneous space time.\nIn the basic formalism developed, the dynamical parameters are derived by\nincorporating the power law and exponential scale factor function. The models\nare showing accelerating behaviour and approaches to $\\Lambda$CDM at late\ntime.The present value of the equation of state parameter for both the cases\nare obtained to be in accordance with the range provided by cosmological\nobservations. The geometrical parameters and the scalar field reconstruction\nare performed to assess the viability of a late time accelerating Universe.\nFurther the stability of both the models are presented. It has been observed\nthat both the models are parameters dependent. Since most of the geometrically\nmodified theories of gravity are favouring the violation of strong energy\ncondition, we have derived the energy conditions both for the power law and\nexponential model. In both the models, the violation of strong energy condition\nestablished.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  The Chern insulator displays a quantized Hall effect without Landau levels.\nIn a landmark paper in 1988, Haldane showed that a Chern insulator could be\nrealized through complex next-nearest-neighbor hopping in a honeycomb lattice.\nDespite its profound impact on the field of topological physics and recent\nimplementation in cold-atom experiments, the Haldane model has remained elusive\nin solid-state materials. Here, we report the experimental realization of a\nHaldane Chern insulator in AB-stacked MoTe2/WSe2 moir\\'e bilayers, which form a\nhoneycomb moir\\'e lattice with two sublattices residing in different layers. We\nshow that the moir\\'e bilayer filled with two charge particles per unit cell is\na quantum spin Hall (QSH) insulator with a tunable charge gap. Under a small\nout-of-plane magnetic field, it becomes a Chern insulator with Chern number c=1\nfrom magneto-transport studies. The results are qualitatively captured by a\ngeneralized Kane-Mele tight-binding Hamiltonian. The Zeeman field splits the\nQSH insulator into two halves of opposite valley--one with a positive and the\nother a negative moir\\'e band gap. Our study highlights the unique potential of\nsemiconductor moir\\'e materials in engineering topological lattice\nHamiltonians.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Multi-label Text Classification (MLTC) is the task of categorizing documents\ninto one or more topics. Considering the large volumes of data and varying\ndomains of such tasks, fully supervised learning requires manually fully\nannotated datasets which is costly and time-consuming. In this paper, we\npropose BERT-Flow-VAE (BFV), a Weakly-Supervised Multi-Label Text\nClassification (WSMLTC) model that reduces the need for full supervision. This\nnew model (1) produces BERT sentence embeddings and calibrates them using a\nflow model, (2) generates an initial topic-document matrix by averaging results\nof a seeded sparse topic model and a textual entailment model which only\nrequire surface name of topics and 4-6 seed words per topic, and (3) adopts a\nVAE framework to reconstruct the embeddings under the guidance of the\ntopic-document matrix. Finally, (4) it uses the means produced by the encoder\nmodel in the VAE architecture as predictions for MLTC. Experimental results on\n6 multi-label datasets show that BFV can substantially outperform other\nbaseline WSMLTC models in key metrics and achieve approximately 84% performance\nof a fully-supervised model.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  High-amplitude free stream turbulence and surface roughness elements can\nexcite a laminar boundary layer flow sufficiently to cause streamwise oriented\nvortices to develop. These vortices resemble elongated streaks having alternate\nspanwise variations of the streamwise velocity. Downstream, the vortices\n`wobble' through an inviscid secondary instability mechanism and, ultimately,\ntransition to turbulence. We formulate an optimal control algorithm to suppress\nthe growth rate of the streamwise vortex system. Considering a high Reynolds\nnumber asymptotic framework, we reduce the full compressible Navier-Stokes\nequations to the nonlinear compressible boundary region equations (NCBRE). We\nthen implement the method of Lagrange multipliers via an appropriate\ntransformation of the original constrained optimization problem into an\nunconstrained form to obtain the disturbance equations in the form of the\nadjoint compressible boundary region equations (ACBRE) and corresponding\noptimality conditions. Numerical solutions of the ACBRE approach for\nhigh-supersonic and hypersonic flows reveal a significant reduction in the\nkinetic energy and wall shear stress for all considered configurations. We\npresent contour plots to demonstrate the qualitative effect of increased\ncontrol iterations. Our results indicate that the primary vortex instabilities\ngradually flatten in the spanwise direction thanks to the ACBRE algorithm.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In settings from fact-checking to question answering, we frequently want to\nknow whether a collection of evidence (premises) entails a hypothesis. Existing\nmethods primarily focus on the end-to-end discriminative version of this task,\nbut less work has treated the generative version in which a model searches over\nthe space of statements entailed by the premises to constructively derive the\nhypothesis. We propose a system for doing this kind of deductive reasoning in\nnatural language by decomposing the task into separate steps coordinated by a\nsearch procedure, producing a tree of intermediate conclusions that faithfully\nreflects the system's reasoning process. Our experiments on the EntailmentBank\ndataset (Dalvi et al., 2021) demonstrate that the proposed system can\nsuccessfully prove true statements while rejecting false ones. Moreover, it\nproduces natural language explanations with a 17% absolute higher step validity\nthan those produced by an end-to-end T5 model.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Natural language interfaces (NLIs) provide users with a convenient way to\ninteractively analyze data through natural language queries. Nevertheless,\ninteractive data analysis is a demanding process, especially for novice data\nanalysts. When exploring large and complex SQL databases from different\ndomains, data analysts do not necessarily have sufficient knowledge about\ndifferent data tables and application domains. It makes them unable to\nsystematically elicit a series of topically-related and meaningful queries for\ninsight discovery in target domains. We develop a NLI with a step-wise query\nrecommendation module to assist users in choosing appropriate next-step\nexploration actions. The system adopts a data-driven approach to suggest\nsemantically relevant and context-aware queries for application domains of\nusers' interest based on their query logs. Also, the system helps users\norganize query histories and results into a dashboard to communicate the\ndiscovered data insights. With a comparative user study, we show that our\nsystem can facilitate a more effective and systematic data analysis process\nthan a baseline without the recommendation module.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  A diagram of groupoid correspondences is a homomorphism to the bicategory of\n\\'etale groupoid correspondences. We study examples of such diagrams, including\ncomplexes of groups and self-similar higher-rank graphs. We encode the diagram\nin a single groupoid, which we call its groupoid model. The groupoid model is\ndefined so that there is a natural bijection between its actions on a space and\nsuitably defined actions of the diagram. We describe the groupoid model in\nseveral cases, including a complex of groups or a self-similar group. We show\nthat the groupoid model is a bilimit in the bicategory of groupoid\ncorrespondences.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We construct a concrete isomorphism from the permutohedral variety to the\nregular semisimple Hessenberg variety associated to the Hessenberg function\n$h_+(i)=i+1$, $1\\le i\\le n-1$. In the process of defining the isomorphism, we\nintroduce a sequence of varieties which we call the prepermutohedral varieties.\nWe first determine the toric structure of these varieties and compute the Euler\ncharacteristics and the Betti numbers using the theory of toric varieties.\nThen, we describe the cohomology of these varieties. We also find a natural way\nto encode the one-dimensional components of the cohomology using the codes\ndefined by Stembridge. Applying the isomorphisms we constructed, we are also\nable to describe the geometric structure of regular semisimple Hessenberg\nvarieties associated to the Hessenberg function represented by $h_k= (2,3,\n\\cdots, k+1, n,\\cdots,n)$, $1\\le k\\le n-3$. In particular, we are able to write\ndown the cohomology ring of the variety. Finally, we determine the dot\nrepresentation of the permutation group ${\\frak S}_n$ on these Hessenberg\nvarieties.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  Deflectometry as a technical approach to assessing reflective surfaces has\nnow existed for almost 40 years. Different aspects and variations of the method\nhave been studied in multiple theses and research articles, and reviews are\nalso becoming available for certain subtopics. Still a field of active\ndevelopment with many unsolved problems, deflectometry now encompasses a large\nvariety of application domains, hardware setup types, and processing workflows\ndesigned for different purposes, and spans a range from qualitative defect\ninspection of large vehicles to precision measurements of microscopic optics.\nOver these years, many exciting developments have accumulated in the underlying\ntheory, in the systems design, and in the implementation specifics. This\ndiversity of topics is difficult to grasp for experts and non-experts alike and\nmay present an obstacle to a wider acceptance of deflectometry as a useful tool\nin other research fields and in the industry.\n  This paper presents an attempt to summarize the status of deflectometry, and\nto map relations between its notable \"spin-off\" branches. The intention of the\npaper is to provide a common communication basis for practitioners and at the\nsame time to offer a convenient entry point for those interested in learning\nand using the method. The list of references is extensive but definitely not\nexhaustive, introducing some prominent trends and established research groups\nin order to facilitate further self-directed exploration by the reader.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Recasting phenomenological Lagrangians in terms of SM effective field theory\n(SMEFT) provides a valuable means of connecting potential BSM physics at\nmomenta well above the electroweak scale to experimental signatures at lower\nenergies. In this work we jointly fit the Wilson coefficients of SMEFT\noperators as well as the PDFs in an extension of the CT18 global analysis\nframework, obtaining self-consistent constraints to possible BSM physics\neffects. Global fits are boosted with machine-learning techniques in the form\nof neural networks to ensure efficient scans of the full PDF+SMEFT parameter\nspace. We focus on several operators relevant for top-quark pair and jet\nproduction at hadron colliders and obtain constraints on the Wilson\ncoefficients with Lagrange Multiplier scans. We find mild correlations between\nthe extracted Wilson coefficients, PDFs, and other QCD parameters, and see\nindications that these correlations may become more prominent in future\nanalyses based on data of higher precision. This work serves as a new platform\nfor joint analyses of SM and BSM physics based on the CTEQ-TEA framework.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Information-directed sampling (IDS) has revealed its potential as a\ndata-efficient algorithm for reinforcement learning (RL). However, theoretical\nunderstanding of IDS for Markov Decision Processes (MDPs) is still limited. We\ndevelop novel information-theoretic tools to bound the information ratio and\ncumulative information gain about the learning target. Our theoretical results\nshed light on the importance of choosing the learning target such that the\npractitioners can balance the computation and regret bounds. As a consequence,\nwe derive prior-free Bayesian regret bounds for vanilla-IDS which learns the\nwhole environment under tabular finite-horizon MDPs. In addition, we propose a\ncomputationally-efficient regularized-IDS that maximizes an additive form\nrather than the ratio form and show that it enjoys the same regret bound as\nvanilla-IDS. With the aid of rate-distortion theory, we improve the regret\nbound by learning a surrogate, less informative environment. Furthermore, we\nextend our analysis to linear MDPs and prove similar regret bounds for Thompson\nsampling as a by-product.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Avoided crossings of level pairs with opposite slopes can form potential\nenergy curves for the external degree of freedom of quantum particles. We\ninvestigate nonadiabatic decay of metastable states on such avoided crossings\n(MSACs) using diabatic and adiabatic representations. The system is described\nby a single scaled adiabaticity parameter, $V$. The time-independent\ntwo-component Schr\\\"odinger equation is solved in both representations, and the\nnonadiabatic lifetimes of MSACs are determined from a wave-function flux\ncalculation and from the Breit-Wigner formula, leading to four lifetime values\nfor each MSAC. We also solve the time-dependent Schr\\\"odinger equation in both\npictures and derive the MSAC lifetimes from wave-function decay. The sets of\nsix non-perturbative values for the MSAC lifetimes agree well, validating the\napproaches. As the adiabaticity parameter $V$ is increased by about a factor of\nten, the MSAC character transitions from marginally to highly stable, with the\nlifetimes increasing by about ten orders of magnitude. The $\\nu$-dependence of\nthe lifetimes in several regimes is discussed. Time-dependent perturbation\ntheory is found to yield approximate lifetimes that deviate by $\\lesssim 30\\%$\nfrom the non-perturbative results, while predictions based on the\nsemi-classical Landau-Zener tunneling equation are found to be up to a factor\nof twenty off, over the ranges of $V$ and $\\nu$ studied. The results are\nrelevant to numerous atomic and molecular systems with quantum states on\nintersecting, coupled potential energy curves.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Autonomous drones can operate in remote and unstructured environments,\nenabling various real-world applications. However, the lack of effective\nvision-based algorithms has been a stumbling block to achieving this goal.\nExisting systems often require hand-engineered components for state estimation,\nplanning, and control. Such a sequential design involves laborious tuning,\nhuman heuristics, and compounding delays and errors. This paper tackles the\nvision-based autonomous-drone-racing problem by learning deep sensorimotor\npolicies. We use contrastive learning to extract robust feature representations\nfrom the input images and leverage a two-stage learning-by-cheating framework\nfor training a neural network policy. The resulting policy directly infers\ncontrol commands with feature representations learned from raw images, forgoing\nthe need for globally-consistent state estimation, trajectory planning, and\nhandcrafted control design. Our experimental results indicate that our\nvision-based policy can achieve the same level of racing performance as the\nstate-based policy while being robust against different visual disturbances and\ndistractors. We believe this work serves as a stepping-stone toward developing\nintelligent vision-based autonomous systems that control the drone purely from\nimage inputs, like human pilots.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Pomset logic and BV are both logics that extend multiplicative linear logic\n(with Mix) with a third connective that is self-dual and non-commutative.\nWhereas pomset logic originates from the study of coherence spaces and proof\nnets, BV originates from the study of series-parallel orders, cographs, and\nproof systems. Both logics enjoy a cut-admissibility result, but for neither\nlogic can this be done in the sequent calculus. Provability in pomset logic can\nbe checked via a proof net correctness criterion and in BV via a deep inference\nproof system. It has long been conjectured that these two logics are the same.\n  In this paper we show that this conjecture is false. We also investigate the\ncomplexity of the two logics, exhibiting a huge gap between the two. Whereas\nprovability in BV is NP-complete, provability in pomset logic is\n$\\Sigma_2^p$-complete. We also make some observations with respect to possible\nsequent systems for the two logics.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  In the paper, we propose two models of Artificial Intelligence (AI) patents\nin European Union (EU) countries addressing spatial and temporal behaviour. In\nparticular, the models can quantitatively describe the interaction between\ncountries or explain the rapidly growing trends in AI patents. For spatial\nanalysis Poisson regression is used to explain collaboration between a pair of\ncountries measured by the number of common patents. Through Bayesian inference,\nwe estimated the strengths of interactions between countries in the EU and the\nrest of the world. In particular, a significant lack of cooperation has been\nidentified for some pairs of countries.\n  Alternatively, an inhomogeneous Poisson process combined with the logistic\ncurve growth accurately models the temporal behaviour by an accurate trend\nline. Bayesian analysis in the time domain revealed an upcoming slowdown in\npatenting intensity.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Let $\\Bbbk$ be a field of characteristic $p>0$, $V$ a finite-dimensional\n$\\Bbbk$-vector-space, and $G$ a finite $p$-group acting $\\Bbbk$-linearly on\n$V$. Let $S = \\Sym V^*$. We show that $S^G$ is a polynomial ring if and only if\nthe dimension of its singular locus is less than $\\rank_\\Bbbk V^G$. Confirming\na conjecture of Shank-Wehlau-Broer, we show that if $S^G$ is a direct summand\nof $S$, then $S^G$ is a polynomial ring, in the following cases:\n\\begin{enumerate}\n  \\item $\\Bbbk = \\bbF_p$ and $\\rank_\\Bbbk V^G = 4$; or\n  \\item $|G| = p^3$. \\end{enumerate} In order to prove the above result, we\nalso show that if $\\rank_\\Bbbk V^G \\geq \\rank_\\Bbbk V - 2$, then the Hilbert\nideal $\\hilbertIdeal_{G,S}$ is a complete intersection.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  Graph clustering is the task of partitioning a collection of observed\nnetworks into groups of similar networks. Here similarity means networks have a\nsimilar structure or graph topology. To this end, a model-based approach is\ndeveloped, where the networks are modelled by a finite mixture model of\nstochastic block models. Moreover, a computationally efficient clustering\nalgorithm is developed. The procedure is an agglomerative hierarchical\nalgorithm that maximizes the so-called integrated classification likelihood\ncriterion. The bottom-up algorithm consists of successive merges of clusters of\nnetworks. Those merges require a means to match block labels of two stochastic\nblock models to overcome the label-switching problem. This problem is addressed\nwith a new distance measure for the comparison of stochastic block models based\non their graphons. The algorithm provides a cluster hierarchy in form of a\ndendrogram and valuable estimates of all model parameters.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  We present the first Bayesian method for tomographic decomposition of the\nplane-of-sky orientation of the magnetic field with the use of stellar\npolarimetry and distance. This standalone tomographic inversion method presents\nan important step forward in reconstructing the magnetized interstellar medium\n(ISM) in 3D within dusty regions. We develop a model in which the polarization\nsignal from the magnetized and dusty ISM is described by thin layers at various\ndistances. Our modeling makes it possible to infer the mean polarization\n(amplitude and orientation) induced by individual dusty clouds and to account\nfor the turbulence-induced scatter in a generic way. We present a likelihood\nfunction that explicitly accounts for uncertainties in polarization and\nparallax. We develop a framework for reconstructing the magnetized ISM through\nthe maximization of the log-likelihood using a nested sampling method. We test\nour Bayesian inversion method on mock data taking into account realistic\nuncertainties from $Gaia$ and as expected for the optical polarization survey\nPASIPHAE according to the currently planned observing strategy. We demonstrate\nthat our method is effective in recovering the cloud properties as soon as the\npolarization induced by a cloud to its background stars is higher than $\\sim\n0.1\\%$, for the adopted survey exposure time and level of systematic\nuncertainty. Our method makes it possible to recover not only the mean\npolarization properties but also to characterize the intrinsic scatter, thus\nopening ways to characterize ISM turbulence and the magnetic field strength.\nFinally, we apply our method to an existing dataset of starlight polarization\nwith known line-of-sight decomposition, demonstrating agreement with previous\nresults and an improved quantification of uncertainties in cloud properties.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Speech coding facilitates the transmission of speech over low-bandwidth\nnetworks with minimal distortion. Neural-network based speech codecs have\nrecently demonstrated significant improvements in quality over traditional\napproaches. While this new generation of codecs is capable of synthesizing\nhigh-fidelity speech, their use of recurrent or convolutional layers often\nrestricts their effective receptive fields, which prevents them from\ncompressing speech efficiently. We propose to further reduce the bitrate of\nneural speech codecs through the use of pretrained Transformers, capable of\nexploiting long-range dependencies in the input signal due to their inductive\nbias. As such, we use a pretrained Transformer in tandem with a convolutional\nencoder, which is trained end-to-end with a quantizer and a generative\nadversarial net decoder. Our numerical experiments show that supplementing the\nconvolutional encoder of a neural speech codec with Transformer speech\nembeddings yields a speech codec with a bitrate of $600\\,\\mathrm{bps}$ that\noutperforms the original neural speech codec in synthesized speech quality when\ntrained at the same bitrate. Subjective human evaluations suggest that the\nquality of the resulting codec is comparable or better than that of\nconventional codecs operating at three to four times the rate.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  FLRW equations are analyzed in a universe with a cosmic scalar background\nthat is spatially uniform but time-varying. Some solvable scalar potentials to\nthe combined dynamics in such a universe are presented. They are consistent\nwith the scalar dynamics as a consequence of energy momentum conservation.\nCertain potentials are found to provide very good fits to type Ia supernovae\ndata, with the kinetic and potential energies of the scalar providing the\nsource for dark matter and dark energy. The scalar rolls down the potential as\nthe universe expands, with the potential playing the role of a time-varying\ncosmological constant, modeling a scenario recently discussed in the\nliterature.\n\n\n###\n\n", "completion": " 01"}
{"prompt": "  Channel pruning is widely used to reduce the complexity of deep network\nmodels. Recent pruning methods usually identify which parts of the network to\ndiscard by proposing a channel importance criterion. However, recent studies\nhave shown that these criteria do not work well in all conditions. In this\npaper, we propose a novel Feature Shift Minimization (FSM) method to compress\nCNN models, which evaluates the feature shift by converging the information of\nboth features and filters. Specifically, we first investigate the compression\nefficiency with some prevalent methods in different layer-depths and then\npropose the feature shift concept. Then, we introduce an approximation method\nto estimate the magnitude of the feature shift, since it is difficult to\ncompute it directly. Besides, we present a distribution-optimization algorithm\nto compensate for the accuracy loss and improve the network compression\nefficiency. The proposed method yields state-of-the-art performance on various\nbenchmark networks and datasets, verified by extensive experiments. Our codes\nare available at: https://github.com/lscgx/FSM.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  This letter deals with the optimization problems of stochastic switching\nbuffer networks, where the switching law is governed by Markov process. The\ndynamical buffer network is introduced, and its application in modeling the\ncar-sharing network is also presented. To address the nonconvexity for getting\na solution as close-to-the-global-optimal as possible of the optimization\nproblem, we adopt a succinct but effective nonconvex optimization method called\n\\emph{ DC (difference of convex functions) programming}. By resorting to the\nlog-log convexity of a class of nonlinear functions called posynomials, the\noptimization problems can be reduced to DC programming problems. Finally, we\nverify the effectiveness of our results by simulation experiments.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Hexahedral (hex) meshing is a long studied topic in geometry processing with\nmany fascinating and challenging associated problems. Hex meshes vary in\ncomplexity from structured to unstructured depending on application or domain\nof interest. Fully structured meshes require that all interior mesh edges are\nadjacent to exactly four hexes. Edges not satisfying this criteria are\nconsidered singular and indicate an unstructured hex mesh. Singular edges join\ntogether into singular curves that either form closed cycles, end on the mesh\nboundary, or end at a singular node, a complex junction of more than two\nsingular curves. While all hex meshes with singularities are unstructured,\nthose with more complex singular nodes tend to have more distorted elements and\nsmaller scaled Jacobian values. In this work, we study the topology of singular\nnodes. We show that all eight of the most common singular nodes are\ndecomposable into just singular curves. We further show that all singular\nnodes, regardless of edge valence, are locally decomposable. Finally we\ndemonstrate these decompositions on hex meshes, thereby decreasing their\ndistortion and converting all singular nodes into singular curves. With this\ndecomposition, the enigmatic complexity of 3D singular nodes becomes\neffectively 2D.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We study the effect of acoustic phonons on the quantum phase transition in\nthe O($N$) model. We develop a renormalization group analysis near (3+1)\nspace-time dimensions and derive the RG equations using an\n$\\epsilon$-expansion. Our results indicate that when the number of flavors of\nthe underlying O($N$) model exceeds a critical number $N_c=4$, the quantum\ntransition remains second-order of the Wilson-Fisher type while, for $N\\le 4$,\nit is a weakly first-order transition. We characterize this weakly first-order\ntransition by a length-scale $\\xi^*$, below which the behavior appears to be\ncritical. At finite temperatures for $N\\le 4$, a tricritical point separates\nthe weakly first-order and second-order transitions.\n\n\n###\n\n", "completion": " 99"}
{"prompt": "  Many speech coders are based on linear prediction coding (LPC), nevertheless\nwith LPC is not possible to model the nonlinearities present in the speech\nsignal. Because of this there is a growing interest for nonlinear techniques.\nIn this paper we discuss ADPCM schemes with a nonlinear predictor based on\nneural nets, which yields an increase of 1-2.5dB in the SEGSNR over classical\nmethods. This paper will discuss the block-adaptive and sample-adaptive\npredictions.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Recently, Minkowski Tensors (MT) have gained popularity for morphological\nanalysis tasks. As opposed to the scalar Minkowski functionals (MF; in 2D given\nby area, perimeter and Euler characteristic), MT can characterize symmetry and\norientation of a body. This has been used for a variety of tasks, e.g. to\ndetect interstellar bubbles by tracing back the origins of filaments in\nHII-regions, or to search for alignment of structures in the CMB. I present a\nmarching-square-based method for calculating MT and MF on the sphere for maps\nin the Healpix format. MT are calculated for a local neighborhood and can then\nbe summed up/averaged over a larger region, using their additivity property.\nThis provides the possibility of localized analyses looking for CMB\nanisotropies and non-Gaussianities at varying scales.\n\n\n###\n\n", "completion": " 07"}
{"prompt": "  The stripe illumination lies between the illumination in the\nspatial-frequency domain and the point illumination. Although the stripe\nillumination has a periodic structure as the illumination in the\nspatial-frequency domain, light from the stripe illumination can reach deep\nregions in biological tissue since it can be regarded as an array of point\nilluminations. For a pair of a source and a detector, the shape of light paths\nwhich connect the source and detector is called the banana shape. First, we\ninvestigate the depth of the banana. In the case of the zero boundary\ncondition, we found that the depth of the center of the banana is $d_{\\rm\nSD}/(2\\sqrt{2})$, where $d_{\\rm SD}$ is the distance between the source and\ndetector on the boundary. In general, the depth is about $0.3d_{\\rm SD}$ when\n$d_{\\rm SD}\\approx2\\,{\\rm cm}$ and the ratio of refractive indices on the\nboundary is about $1.37$. Next, we perform diffuse optical tomography for the\nstripe illumination against forward data taken by Monte Carlo simulation. We\nconsider an impulse illumination of the shape of a stripe. This time-resolved\nmeasurement is more informative than conventional continuous-wave measurements\nin the spatial-frequency domain.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  To use heterogeneous hardware, programmers must have sufficient technical\nskills to utilize OpenMP, CUDA, and OpenCL. On the basis of this, I have\nproposed environment-adaptive software that enables automatic conversion,\nconfiguration, and high performance operation of once written code, in\naccordance with the hardware. However, although it has been considered to\nconvert the code according to the offload devices, there has been no study\nwhere to place the offloaded applications to satisfy users' requirements of\nprice and response time. In this paper, as a new element of environment-adapted\nsoftware, I examine a method to calculate appropriate locations using linear\nprogramming method. I confirm that applications can be arranged appropriately\nthrough simulations.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We construct families of embedded, singly periodic Karcher--Scherk saddle\ntowers of any genus $g$ in the quotient with any even number $2n>2$ of almost\nparallel Scherk ends. A surface in such a family looks like $n$ parallel planes\nconnected by $n-1+g$ small catenoid necks. In the limit, the family converges\nto an $n$-sheeted vertical plane with $n-1+g$ singular points termed nodes in\nthe quotient. For the nodes to open up into catenoid necks, their locations\nmust satisfy a set of balance equations whose solutions are given by the roots\nof Stieltjes polynomials. In a subsequent paper, we will construct minimal\nsurfaces by gluing saddle towers with catenoid limits of saddle towers along\ntheir wings.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Recent arguments that machine learning (ML) is facing a reproducibility and\nreplication crisis suggest that some published claims in ML research cannot be\ntaken at face value. These concerns inspire analogies to the replication crisis\naffecting the social and medical sciences. They also inspire calls for the\nintegration of statistical approaches to causal inference and predictive\nmodeling. A deeper understanding of what reproducibility concerns in supervised\nML research have in common with the replication crisis in experimental science\nputs the new concerns in perspective, and helps researchers avoid \"the worst of\nboth worlds,\" where ML researchers begin borrowing methodologies from\nexplanatory modeling without understanding their limitations and vice versa. We\ncontribute a comparative analysis of concerns about inductive learning that\narise in causal attribution as exemplified in psychology versus predictive\nmodeling as exemplified in ML. We identify themes that re-occur in reform\ndiscussions, like overreliance on asymptotic theory and non-credible beliefs\nabout real-world data generating processes. We argue that in both fields,\nclaims from learning are implied to generalize outside the specific environment\nstudied (e.g., the input dataset or subject sample, modeling implementation,\netc.) but are often impossible to refute due to undisclosed sources of variance\nin the learning pipeline. In particular, errors being acknowledged in ML expose\ncracks in long-held beliefs that optimizing predictive accuracy using huge\ndatasets absolves one from having to consider a true data generating process or\nformally represent uncertainty in performance claims. We conclude by discussing\nrisks that arise when sources of errors are misdiagnosed and the need to\nacknowledge the role of human inductive biases in learning and reform.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Very young (t $\\lesssim$ 10 Myrs) stars possess strong magnetic fields that\nchannel ionized gas from the interiors of their circumstellar discs to the\nsurface of the star. Upon impacting the stellar surface, the shocked gas\nrecombines and emits hydrogen spectral lines. To characterize the density and\ntemperature of the gas within these accretion streams, we measure equivalent\nwidths of Brackett (Br) 11-20 emission lines detected in 1101 APOGEE spectra of\n326 likely pre-main sequence accretors. For sources with multiple observations,\nwe measure median epoch-to-epoch line strength variations of 10% in Br11 and\n20% in Br20. We also fit the measured line ratios to predictions of radiative\ntransfer models by Kwan & Fischer. We find characteristic best-fit electron\ndensities of $n_e$ = 10$^{11} - 10^{12}$ cm$^{-3}$, and excitation temperatures\nthat are inversely correlated with electron density (from T$\\sim$5000 K for\n$n_e \\sim 10^{12}$ cm$^{-3}$, to T$\\sim$12500 K at $n_e \\sim 10^{11}$\ncm$^{-3}$). These physical parameters are in good agreement with predictions\nfrom modelling of accretion streams that account for the hydrodynamics and\nradiative transfer within the accretion stream. We also present a supplementary\ncatalog of line measurements from 9733 spectra of 4255 Brackett emission line\nsources in the APOGEE DR17 dataset.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  A nonlinear transmisson problem for an elastic full von Karman beam is\nconsidered here. We prove that the system possesses a compact global attractor.\n\n\n###\n\n", "completion": " 09"}
{"prompt": "  We present the first meta-analysis of co-evolutionary learning networks for\ndigital disease surveillance research over last 10 years. In doing so, we show\nthe co-evolution and dynamical changes that occurred in academic research\nrelated to digital disease surveillance for improving accuracy, approach and\nresults. Using dynamic network analysis, we are able to show the incorporation\nof social media-based analytics and algorithms which have been proposed and\nlater improved by other researchers as co-evolutionary learning networks. This\nessentially demonstrates how we improve our research and increase accuracy\nthrough feedback loop for correcting the behaviour of an open system and\nperhaps infer learning patterns, reliability and validity using 10 years\nscientific research in digital disease surveillance.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Large transformer-based pre-trained language models have achieved impressive\nperformance on a variety of knowledge-intensive tasks and can capture factual\nknowledge in their parameters. We argue that storing large amounts of knowledge\nin the model parameters is sub-optimal given the ever-growing amounts of\nknowledge and resource requirements. We posit that a more efficient alternative\nis to provide explicit access to contextually relevant structured knowledge to\nthe model and train it to use that knowledge. We present LM-CORE -- a general\nframework to achieve this -- that allows \\textit{decoupling} of the language\nmodel training from the external knowledge source and allows the latter to be\nupdated without affecting the already trained model. Experimental results show\nthat LM-CORE, having access to external knowledge, achieves significant and\nrobust outperformance over state-of-the-art knowledge-enhanced language models\non knowledge probing tasks; can effectively handle knowledge updates; and\nperforms well on two downstream tasks. We also present a thorough error\nanalysis highlighting the successes and failures of LM-CORE.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  3D point cloud segmentation has made tremendous progress in recent years.\nMost current methods focus on aggregating local features, but fail to directly\nmodel long-range dependencies. In this paper, we propose Stratified Transformer\nthat is able to capture long-range contexts and demonstrates strong\ngeneralization ability and high performance. Specifically, we first put forward\na novel key sampling strategy. For each query point, we sample nearby points\ndensely and distant points sparsely as its keys in a stratified way, which\nenables the model to enlarge the effective receptive field and enjoy long-range\ncontexts at a low computational cost. Also, to combat the challenges posed by\nirregular point arrangements, we propose first-layer point embedding to\naggregate local information, which facilitates convergence and boosts\nperformance. Besides, we adopt contextual relative position encoding to\nadaptively capture position information. Finally, a memory-efficient\nimplementation is introduced to overcome the issue of varying point numbers in\neach window. Extensive experiments demonstrate the effectiveness and\nsuperiority of our method on S3DIS, ScanNetv2 and ShapeNetPart datasets. Code\nis available at https://github.com/dvlab-research/Stratified-Transformer.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  In this paper we address the numerical solution of the quadratic optimal\ntransport problem in its dynamical form, the so-called Benamou-Brenier\nformulation. When solved using interior point methods, the main computational\nbottleneck is the solution of large saddle point linear systems arising from\nthe associated Newton-Raphson scheme. The main purpose of this paper is to\ndesign efficient preconditioners to solve these linear systems via iterative\nmethods. Among the proposed preconditioners, we introduce one based on the\npartial commutation of the operators that compose the dual Schur complement of\nthese saddle point linear systems, which we refer as BB-preconditioner. A\nseries of numerical tests show that the BB-preconditioner is the most efficient\namong those presented, with a CPU-time scaling only slightly more than linearly\nwith respect to the number of unknowns used to discretize the problem.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  We study a query model of computation in which an n-vertex k-hypergraph can\nbe accessed only via its independence oracle or via its colourful independence\noracle, and each oracle query may incur a cost depending on the size of the\nquery. In each of these models, we obtain oracle algorithms to approximately\ncount the hypergraph's edges, and we unconditionally prove that no oracle\nalgorithm for this problem can have significantly smaller worst-case oracle\ncost than our algorithms.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  This report presents the results of the Models and Effective Field Theories\nSubgroup of the Off-Shell Interpretations Task Force in the LHC Higgs Working\nGroup. The main goal of the subgroup was to discuss and advance the potential\nimpact of off-shell Higgs measurements on searches for BSM physics carried out\nin the EFT framework or as benchmark model studies. In the first contribution,\nthe off-shell potential to resolve flat directions in parameter space for\non-shell measurements is studied. Furthermore, the sensitivity of off-shell\nmeasurements to SMEFT dimension-6 operators for the gg $\\to$ ZZ process is\ndiscussed, and studies of explicit models that are testable in off-shell\nproduction are reviewed. In the second contribution, the SMEFT effects in the\noff-shell gluon fusion and electroweak processes are discussed. Subsequently,\nthe computation of integrated and differential effects using SMEFT@NLO and\nMG5_aMC@NLO, or JHUGen and MCFM, is demonstrated. On that basis, a study of the\nprospects of obtaining additional SMEFT constraints - beyond those from\nexisting global fits - by utilising the off-shell process is presented. For\nclarification, a revised introduction, definition and discussion of the Higgs\nbasis parametrisation of the SMEFT is given in the third contribution. In short\nnotes on the SMEFT, the Higgs basis with an additional constraint is discussed\nand relations between the Higgs and Warsaw bases are presented. Lastly, an\noverview of EFT calculations and tools is given.\n\n\n###\n\n", "completion": " 11"}
{"prompt": "  In the first part of this paper we develop some theorems in linear algebra\napplicable to information theory when all random variables involved are linear\nfunctions of the individual bits of a source of independent bits.\n  We say that a collection of subspaces of a vector space are \"coordinated\" if\nthe vector space has a basis such that each subspace is spanned by its\nintersection with the basis. We measure the failure of a collection of\nsubspaces to be coordinated by an invariant that we call the \"discoordination\"\nof the family. We develop some foundational results regarding discoordination.\nIn particular, these results give a number of new formulas involving three\nsubspaces of a vector space.\n  We then apply a number of our results, along with a method of Tian to obtain\nsome new lower bounds in a special case of the basic coded caching problem. In\nterms of the usual notation for these problems, we show that for $N=3$\ndocuments and $K=3$ caches, we have $6M+5R\\ge 11$ for a scheme that achieves\nthe memory-rate pair $(M,R)$, assuming the scheme is linear. We also give a new\ncaching scheme for $N=K=3$ that achieves the pair $(M,R) = (1/2,5/3)$.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  The problem of estimating a linear functional based on observational data is\ncanonical in both the causal inference and bandit literatures. We analyze a\nbroad class of two-stage procedures that first estimate the treatment effect\nfunction, and then use this quantity to estimate the linear functional. We\nprove non-asymptotic upper bounds on the mean-squared error of such procedures:\nthese bounds reveal that in order to obtain non-asymptotically optimal\nprocedures, the error in estimating the treatment effect should be minimized in\na certain weighted $L^2$-norm. We analyze a two-stage procedure based on\nconstrained regression in this weighted norm, and establish its\ninstance-dependent optimality in finite samples via matching non-asymptotic\nlocal minimax lower bounds. These results show that the optimal non-asymptotic\nrisk, in addition to depending on the asymptotically efficient variance,\ndepends on the weighted norm distance between the true outcome function and its\napproximation by the richest function class supported by the sample size.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  The Alaskan landscape has undergone substantial changes in recent decades,\nmost notably the expansion of shrubs and trees across the Arctic. We developed\na dynamic statistical model to quantify the impact of climate change on the\nstructural transformation of ecosystems using remotely sensed imagery. We used\nlatent trajectory processes in a hierarchical framework to model dynamic state\nprobabilities that evolve annually, from which we derived transition\nprobabilities between ecotypes. Our latent trajectory model accommodates\ntemporal irregularity in survey intervals and uses spatio-temporally\nheterogeneous climate drivers to infer rates of land cover transitions. We\ncharacterized multi-scale spatial correlation induced by plot and subplot\narrangement in our study system. We also developed a Polya-Gamma sampling\nstrategy to improve computation. Our model facilitates inference on the\nresponse of ecosystems to shifts in the climate and can be used to predict\nfuture land cover transitions under various climate scenarios.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Post-starburst (PSB) galaxies are defined as having experienced a recent\nburst of star formation, followed by a prompt truncation in further activity.\nIdentifying the mechanism(s) causing a galaxy to experience a post-starburst\nphase therefore provides integral insight into the causes of rapid quenching.\nGalaxy mergers have long been proposed as a possible post-starburst trigger.\nEffectively testing this hypothesis requires a large spectroscopic galaxy\nsurvey to identify the rare PSBs as well as high quality imaging and robust\nmorphology metrics to identify mergers. We bring together these critical\nelements by selecting PSBs from the overlap of the Sloan Digital Sky Survey and\nthe Canada-France Imaging Survey and applying a suite of classification\nmethods: non-parametric morphology metrics such as asymmetry and Gini-M20, a\nconvolutional neural network trained to identify post-merger galaxies, and\nvisual classification. This work is therefore the largest and most\ncomprehensive assessment of the merger fraction of PSBs to date. We find that\nthe merger fraction of PSBs ranges from 19% to 42% depending on the merger\nidentification method and details of the PSB sample selection. These merger\nfractions represent an excess of 3-46x relative to non-PSB control samples. Our\nresults demonstrate that mergers play a significant role in generating PSBs,\nbut that other mechanisms are also required. However, applying our merger\nidentification metrics to known post-mergers in the IllustrisTNG simulation\nshows that ~70% of recent post-mergers (<200 Myr) would not be detected. Thus,\nwe cannot exclude the possibility that nearly all post-starburst galaxies have\nundergone a merger in their recent past.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  We calculate the production of $\\chi_{c}$ and $\\eta_{c}$ by the semi-coherent\nand coherent two-photon interaction in ultra-peripheral heavy ion collisions at\nRelativistic Heavy Ion Collider (RHIC) and Large Hadron Collider (LHC)\nenergies. The differential cross section of transverse momentum distribution\nand rapidity distribution for $AB\\stackrel{\\gamma\\gamma}{\\longrightarrow}AHB$\n(H=$\\chi_{c}$ and $\\eta_{c}$), are estimated by using the equivalent photon\napproximation in ultra-peripheral nucleus-nucleus collisions. The numerical\nresults demonstrate that the experimental study of $\\chi_{c}$ and $\\eta_{c}$ in\nultra-peripheral nucleus-nucleus collisions is feasible at RHIC and LHC\nenergies.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In this paper, we present for the first time comprehensive and detailed\nresults on the correspondence between the extrapolated deep inelastic structure\nfunction $g_1$ of both the proton and the neutron with the same quantity\nmeasured in the nucleon resonance region. We use a QCD parameterization of the\nworld data on DIS spin structure functions, extrapolated into the nucleon\nresonance region and averaged over various intervals in the scaling variable\n$x$. We compare the results with the large data set collected in the\nquark-hadron transition region by the CLAS collaboration, averaged over the\nsame intervals. We present this comparison as a function of the momentum\ntransfer $Q^2$. We find that, depending on the averaging interval and the\nminimum momentum transfer chosen, a clear transition to quark-hadron duality\ncan be observed in both nucleon species. Furthermore, we show, for the first\ntime, the scaling behavior of $g_1$ measured in the resonance region at\nsufficiently high momentum transfer. Our results can be used to quantify the\ndeviations from the applicability of pQCD for data taken at moderate energies,\nand help with extraction of quark distribution functions from such data.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We propose Deep Lossless Image Coding (DLIC), a full resolution learned\nlossless image compression algorithm. Our algorithm is based on a neural\nnetwork combined with an entropy encoder. The neural network performs a density\nestimation on each pixel of the source image. The density estimation is then\nused to code the target pixel, beating FLIF in terms of compression rate.\nSimilar approaches have been attempted. However, long run times make them\nunfeasible for real world applications. We introduce a parallelized GPU based\nimplementation, allowing for encoding and decoding of grayscale, 8-bit images\nin less than one second. Because DLIC uses a neural network to estimate the\nprobabilities used for the entropy coder, DLIC can be trained on domain\nspecific image data. We demonstrate this capability by adapting and training\nDLIC with Magnet Resonance Imaging (MRI) images.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  In 2018, we reported our discovery of a dozen quiescent X-ray binaries in the\ncentral parsec (pc) of the Galaxy (Hailey et al. 2018). In a recent follow-up\npaper (Mori et al. 2021), we published an extended analysis of these sources\nand other X-ray binaries (XRBs) in the central pc and beyond, showing that most\nif not all of the 12 non-thermal sources are likely black hole low-mass X-ray\nbinary (BH-LMXB) candidates. In response, Maccarone et al. 2022 (TM22\nhereafter) argued, primarily on the claim that neutron star low-mass X-ray\nbinaries (NS-LMXBs) often do not have short outburst recurrence times (<~ 10\nyr), that they cannot be excluded as a designation for the 12 quiescent X-ray\nbinary sources. TM22 cites three main factors in their study: (1) X-ray\noutburst data of NS transients detected by RXTE and MAXI, (2) the Galactic\npopulation of NS-LMXBs, and (3) (persistently) quiescent NS-LMXBs in globular\nclusters. We address these arguments of TM22 and correct their\nmisunderstandings of our work and the literature, even though most of these\npoints have already been thoroughly addressed by Mori et al. 2021. We also\ncorrect TM22's assertion that our arguments are based solely on NS transients'\nrecurrence times.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  The increasing complexity of interrelated systems has made the use of\nmultiplex networks an important tool for explaining the nature of relations\nbetween elements in the system. In this paper, we aim at investigating various\naspects of countries' behaviour during the coronavirus pandemic period. By\nmeans of a multiplex network we consider simultaneously stringency index\nvalues, COVID-19 infections and international trade data, in order to detect\nclusters of countries that showed a similar reaction to the pandemic. We\npropose a new methodological approach based on the Estrada communicability for\nidentifying communities on a multiplex network, based on a two-step\noptimization. At first, we determine the optimal inter-layer intensity between\nlevels by minimizing a distance function. Hence, the optimal inter-layer\nintensity is used to detect communities on each layer. Our findings show that\nthe community detection on this multiplex network has greater information power\nthan classical methods for single-layer networks. Our approach better reveals\nclusters on each layer with respect to the application of the same approach on\neach single-layer. Moreover, detected groups in the multiplex case benefit of a\nhigher cohesion, leading to identifying on each layer a lower number of\ncommunities with respect to the ones obtained in the single-layer cases.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Forest formulas that generalize Zimmermann's forest formula in quantum field\ntheory have been obtained for the computation of the antipode in the dual of\nenveloping algebras of pre-Lie algebras. In this work, largely motivated by\nMurua's analysis of the Baker-Campbell-Hausdorff formula, we show that the same\nideas and techniques generalize and provide effective tools to handle\ncomputations in these algebras, which are of utmost importance in numerical\nanalysis and related areas. We illustrate our results by studying the action of\nthe pre-Lie exponential and the Magnus operator in the free pre-Lie algebra and\nin a pre-Lie algebra of words originating in free probability. The latter\nexample provides combinatorial formulas relating the different brands of\ncumulants in non-commutative probability.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In this paper, we carry out a semi-analytic general relativistic study of a\nGamma-Ray Bursts (GRB) jet that is breaking out of a cocoon or stellar\nenvelope. We solve hydrodynamic equations with the relativistic equation of\nstate that takes care of fluid composition. In short GRBs, a general\nrelativistic approach is required to account for curved spacetime in strong\ngravity. The piercing of the jet through the cocoon resembles a de Laval nozzle\nand the jet may go through recollimation shock transitions. We show that the\npossibility of shock transition and the shock properties are sensitive to the\nmatter composition and the cocoon strength. Obtained Lorentz factors in\nthermally driven jets comfortably reach a few $\\times$10.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Many important phenomena in quantum devices are dynamic, meaning that they\ncannot be studied using time-averaged measurements alone. Experiments that\nmeasure such transient effects are collectively known as fast readout. One of\nthe most useful techniques in fast electrical readout is radio-frequency\nreflectometry, which can measure changes in impedance (both resistive and\nreactive) even when their duration is extremely short, down to a microsecond or\nless. Examples of reflectometry experiments, some of which have been realised\nand others so far only proposed, include projective measurements of qubits and\nMajorana devices for quantum computing, real-time measurements of mechanical\nmotion and detection of non-equilibrium temperature fluctuations. However, all\nof these experiments must overcome the central challenge of fast readout: the\nlarge mismatch between the typical impedance of quantum devices (set by the\nresistance quantum) and of transmission lines (set by the impedance of free\nspace). Here, we review the physical principles of radio-frequency\nreflectometry and its close cousins, measurements of radio-frequency\ntransmission and emission. We explain how to optimise the speed and sensitivity\nof a radio-frequency measurement, and how to incorporate new tools such as\nsuperconducting circuit elements and quantum-limited amplifiers into advanced\nradio-frequency experiments. Our aim is three-fold: to introduce the readers to\nthe technique, to review the advances to date and to motivate new experiments\nin fast quantum device dynamics. Our intended audience includes\nexperimentalists in the field of quantum electronics who want to implement\nradio-frequency experiments or improve them, together with physicists in\nrelated fields who want to understand how the most important radio-frequency\nmeasurements work.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  In a convolution neural network, a composition of linear scalar product,\nnon-linear activation function and maximum pooling computations are intensively\ninvoked. As such, to design and implement privacy-preserving, high efficiency\nmachine learning mechanisms, one highly demands a practical crypto tool for\nsecure arithmetic computations. SPDZ, an interesting framework of secure\nmulti-party computations is a promising technique deployed for industry-scale\nmachine learning development if one is able to generate Beaver (multiplication)\ntriple offline efficiently. This paper studies secure yet efficient Beaver\ntriple generators leveraging privacy-preserving scalar product protocols which\nin turn can be constructed from additive-only homomorphic encryptions(AHEs).\nDifferent from the state-of-the-art solutions, where a party first splits her\nprivate input into a shared vector and then invokes an AHE to compute scalar\nproduct of the shared vectors managed by individual MPC server, we formalize\nBeaver triple generators in the context of 2-party shared scalar product\nprotocol and then dispense the generated shares to MPC servers. As such, the\nprotocol presented in this paper can be viewed as a dual construction of the\nstate-of-the-art AHE based solutions. Furthermore, instead of applying the\nPaillier encryption as a basis of our previous constructions or inheriting from\nsomewhat homomorphic encryptions, we propose an alternative construction of AHE\nfrom polynomial ring learning with error (RLWE) which results in an efficient\nimplementation of Beaver triple generators.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Previous gait phase detection as convolutional neural network (CNN) based\nclassification task requires cumbersome manual setting of time delay or heavy\noverlapped sliding windows to accurately classify each phase under different\ntest cases, which is not suitable for streaming Inertial-Measurement-Unit (IMU)\nsensor data and fails to adapt to different scenarios. This paper presents a\nsegmentation based gait phase detection with only a single six-axis IMU sensor,\nwhich can easily adapt to both walking and running at various speeds. The\nproposed segmentation uses CNN with gait phase aware receptive field setting\nand IMU oriented processing order, which can fit to high sampling rate of IMU\nup to 1000Hz for high accuracy and low sampling rate down to 20Hz for real time\ncalculation. The proposed model on the 20Hz sampling rate data can achieve\naverage error of 8.86 ms in swing time, 9.12 ms in stance time and 96.44\\%\naccuracy of gait phase detection and 99.97\\% accuracy of stride detection. Its\nreal-time implementation on mobile phone only takes 36 ms for 1 second length\nof sensor data.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  The era of fast radio bursts (FRBs) was open in 2007, when a very bright\nradio pulse of unknown origin was discovered occasionally in the archival data\nof Parkes Telescope. Over the past fifteen years, this mysterious phenomenon\nhave caught substantial attention among the scientific community and become one\nof the hottest topic in high-energy astrophysics. The total number of events\nhas a dramatic increase to a few hundred recently, benefiting from new\ndedicated surveys and improved observational techniques. Our understanding of\nthese bursts has been undergoing a revolutionary growth with observational\nbreakthroughs announced consistently. In this chapter, we will give a\ncomprehensive introduction of FRBs, including the latest progress. Starting\nfrom the basics, we will go through population study, inherent physical\nmechanism, and all the way to the application in cosmology. Plenty of open\nquestions exist right now and there is more surprise to come in this active\nyoung field.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Scanning tunneling and atomic force microscopies (STM/nc-AFM) are rapidly\nprogressing to offer unprecedented spatial resolution of a diverse array of\nchemical species. In particular, they are employed to characterize on-surface\nchemical reactions by directly examining precursors and products. Chiral\neffects and self-assembled structures can also be investigated. This open\nsource, modular, python based scheme automates the categorization of a variety\nof molecules present in medium sized (10$\\times$10 to 100$\\times$100 nm)\nscanned probe images.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Blockchain systems based on a reusable resource, such as proof-of-stake\n(PoS), provide weaker security guarantees than those based on proof-of-work.\nSpecifically, they are vulnerable to long-range attacks, where an adversary can\ncorrupt prior participants in order to rewrite the full history of the chain.\nTo prevent this attack on a PoS chain, we propose a protocol that checkpoints\nthe state of the PoS chain to a proof-of-work blockchain such as Bitcoin. Our\ncheckpointing protocol hence does not rely on any central authority. Our work\nuses Schnorr signatures and leverages Bitcoin recent Taproot upgrade, allowing\nus to create a checkpointing transaction of constant size. We argue for the\nsecurity of our protocol and present an open-source implementation that was\ntested on the Bitcoin testnet.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Vision-based autonomous navigation systems rely on fast and accurate object\ndetection algorithms to avoid obstacles. Algorithms and sensors designed for\nsuch systems need to be computationally efficient, due to the limited energy of\nthe hardware used for deployment. Biologically inspired event cameras are a\ngood candidate as a vision sensor for such systems due to their speed, energy\nefficiency, and robustness to varying lighting conditions. However, traditional\ncomputer vision algorithms fail to work on event-based outputs, as they lack\nphotometric features such as light intensity and texture. In this work, we\npropose a novel technique that utilizes the temporal information inherently\npresent in the events to efficiently detect moving objects. Our technique\nconsists of a lightweight spiking neural architecture that is able to separate\nevents based on the speed of the corresponding objects. These separated events\nare then further grouped spatially to determine object boundaries. This method\nof object detection is both asynchronous and robust to camera noise. In\naddition, it shows good performance in scenarios with events generated by\nstatic objects in the background, where existing event-based algorithms fail.\nWe show that by utilizing our architecture, autonomous navigation systems can\nhave minimal latency and energy overheads for performing object detection.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  New experiments that target the B-mode polarization signals in the Cosmic\nMicrowave Background require more sensitivity, more detectors, and thus\nlarger-aperture millimeter-wavelength telescopes, than previous experiments.\nThese larger apertures require ever larger vacuum windows to house cryogenic\noptics. Scaling up conventional vacuum windows, such as those made of High\nDensity Polyethylene (HDPE), require a corresponding increase in the thickness\nof the window material to handle the extra force from the atmospheric pressure.\nThicker windows cause more transmission loss at ambient temperatures,\nincreasing optical loading and decreasing sensitivity. We have developed the\nuse of woven High Modulus Polyethylene (HMPE), a material 100 times stronger\nthan HDPE, to manufacture stronger, thinner windows using a pressurized hot\nlamination process. We discuss the development of a specialty autoclave for\ngenerating thin laminate vacuum windows and the optical and mechanical\ncharacterization of full scale science grade windows, with the goal of\ndeveloping a new window suitable for BICEP Array cryostats and for future CMB\napplications.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Hybrid stochastic differential equations are a useful tool to model\ncontinuously varying stochastic systems which are modulated by a random\nenvironment that may depend on the system state itself. In this paper, we\nestablish the pathwise convergence of the solutions to hybrid stochastic\ndifferential equations via space-grid discretizations. While time-grid\ndiscretizations are a classical approach for simulation purposes, our\nspace-grid discretization provides a link with multi-regime Markov modulated\nBrownian motions, leading to computational tractability. We exploit our\nconvergence result to obtain efficient approximations to first passage\nprobabilities and expected occupation times of the solutions hybrid stochastic\ndifferential equations, results which are the first of their kind for such a\nrobust framework. We finally illustrate the performance of the resulting\napproximations in numerical examples.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Accurate estimation of Intrinsic Dimensionality (ID) is of crucial importance\nin many data mining and machine learning tasks, including dimensionality\nreduction, outlier detection, similarity search and subspace clustering.\nHowever, since their convergence generally requires sample sizes (that is,\nneighborhood sizes) on the order of hundreds of points, existing ID estimation\nmethods may have only limited usefulness for applications in which the data\nconsists of many natural groups of small size. In this paper, we propose a\nlocal ID estimation strategy stable even for `tight' localities consisting of\nas few as 20 sample points. The estimator applies MLE techniques over all\navailable pairwise distances among the members of the sample, based on a recent\nextreme-value-theoretic model of intrinsic dimensionality, the Local Intrinsic\nDimension (LID). Our experimental results show that our proposed estimation\ntechnique can achieve notably smaller variance, while maintaining comparable\nlevels of bias, at much smaller sample sizes than state-of-the-art estimators.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  A new two-dimensional procedure for extrapolation of the values of matter,\nneutron, and proton radii obtained in no-core shell model (NCSM) calculations\nto infinite size of its basis is proposed. A relationship between the radii is\nused as an additional test. Together with the JISP16 potential, which is\nfrequently used in NCSM calculations of the radii, the Daejeon16 potential is\napplied for these purposes for the first time. Halo nucleus 6He is the object\nof studies. The small spread of radii values, successful testing using\nrelationship between the values of these three radii, and reasonable agreement\nbetween the obtained results and experimental data as well as the results of\nother advanced ab initio calculations demonstrate the high efficiency of the\ndeveloped approach and, therefore, good prospects for its application. The\nperformed investigations and analysis of the results of other studies indicate\nthat the halo of 6He has a large size 0.7 - 0.8 fm.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  The dichromatic number of a digraph is the minimum size of a partition of its\nvertices into acyclic induced subgraphs. Given a class of digraphs $\\mathcal\nC$, a digraph $H$ is a hero in $\\mc C$ if $H$-free digraphs of $\\mathcal C$\nhave bounded dichromatic number. In a seminal paper, Berger at al. give a\nsimple characterization of all heroes in tournaments. In this paper, we give a\nsimple proof that heroes in quasi-transitive oriented graphs are the same as\nheroes in tournaments. We also prove that it is not the case in the class of\noriented multipartite graphs, disproving a conjecture of Aboulker, Charbit and\nNaserasr. We also give a full characterisation of heroes in oriented complete\nmultipartite graphs up to the status of a single tournament on $6$ vertices.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  Multi-player multi-armed bandits (MMAB) study how decentralized players\ncooperatively play the same multi-armed bandit so as to maximize their total\ncumulative rewards. Existing MMAB models mostly assume when more than one\nplayer pulls the same arm, they either have a collision and obtain zero\nrewards, or have no collision and gain independent rewards, both of which are\nusually too restrictive in practical scenarios. In this paper, we propose an\nMMAB with shareable resources as an extension to the collision and\nnon-collision settings. Each shareable arm has finite shareable resources and a\n\"per-load\" reward random variable, both of which are unknown to players. The\nreward from a shareable arm is equal to the \"per-load\" reward multiplied by the\nminimum between the number of players pulling the arm and the arm's maximal\nshareable resources. We consider two types of feedback: sharing demand\ninformation (SDI) and sharing demand awareness (SDA), each of which provides\ndifferent signals of resource sharing. We design the DPE-SDI and SIC-SDA\nalgorithms to address the shareable arm problem under these two cases of\nfeedback respectively and prove that both algorithms have logarithmic regrets\nthat are tight in the number of rounds. We conduct simulations to validate both\nalgorithms' performance and show their utilities in wireless networking and\nedge computing.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  In this paper, we present our submission to Shared Metrics Task: RoBLEURT\n(Robustly Optimizing the training of BLEURT). After investigating the recent\nadvances of trainable metrics, we conclude several aspects of vital importance\nto obtain a well-performed metric model by: 1) jointly leveraging the\nadvantages of source-included model and reference-only model, 2) continuously\npre-training the model with massive synthetic data pairs, and 3) fine-tuning\nthe model with data denoising strategy. Experimental results show that our\nmodel reaching state-of-the-art correlations with the WMT2020 human annotations\nupon 8 out of 10 to-English language pairs.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Technological advances in holography, robotics, and 3D printing are starting\nto realize the vision of a holodeck. These immersive 3D displays must address\nuser safety from the start to be viable. A holodeck's safety challenges are\nnovel because its applications will involve explicit physical interactions\nbetween humans and synthesized 3D objects and experiences in real-time. This\npioneering paper first proposes research directions for modeling safety in\nfuture holodeck applications from traditional physical human-robot interaction\nmodeling. Subsequently, we propose a test-bed to enable safety validation of\nphysical human-robot interaction based on existing augmented reality and\nvirtual simulation technology.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  News articles both shape and reflect public opinion across the political\nspectrum. Analyzing them for social bias can thus provide valuable insights,\nsuch as prevailing stereotypes in society and the media, which are often\nadopted by NLP models trained on respective data. Recent work has relied on\nword embedding bias measures, such as WEAT. However, several representation\nissues of embeddings can harm the measures' accuracy, including low-resource\nsettings and token frequency differences. In this work, we study what kind of\nembedding algorithm serves best to accurately measure types of social bias\nknown to exist in US online news articles. To cover the whole spectrum of\npolitical bias in the US, we collect 500k articles and review psychology\nliterature with respect to expected social bias. We then quantify social bias\nusing WEAT along with embedding algorithms that account for the aforementioned\nissues. We compare how models trained with the algorithms on news articles\nrepresent the expected social bias. Our results suggest that the standard way\nto quantify bias does not align well with knowledge from psychology. While the\nproposed algorithms reduce the~gap, they still do not fully match the\nliterature.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Most pregnancies and births result in a good outcome, but complications are\nnot uncommon and when they do occur, they can be associated with serious\nimplications for mothers and babies. Predictive modeling has the potential to\nimprove outcomes through better understanding of risk factors, heightened\nsurveillance, and more timely and appropriate interventions, thereby helping\nobstetricians deliver better care. For three types of complications we identify\nand study the most important risk factors using Explainable Boosting Machine\n(EBM), a glass box model, in order to gain intelligibility: (i) Severe Maternal\nMorbidity (SMM), (ii) shoulder dystocia, and (iii) preterm preeclampsia. While\nusing the interpretability of EBM's to reveal surprising insights into the\nfeatures contributing to risk, our experiments show EBMs match the accuracy of\nother black-box ML methods such as deep neural nets and random forests.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Vascular segmentation extracts blood vessels from images and serves as the\nbasis for diagnosing various diseases, like ophthalmic diseases.\nOphthalmologists often require high-resolution segmentation results for\nanalysis, which leads to super-computational load by most existing methods. If\nbased on low-resolution input, they easily ignore tiny vessels or cause\ndiscontinuity of segmented vessels. To solve these problems, the paper proposes\nan algorithm named SuperVessel, which gives out high-resolution and accurate\nvessel segmentation using low-resolution images as input. We first take\nsuper-resolution as our auxiliary branch to provide potential high-resolution\ndetail features, which can be deleted in the test phase. Secondly, we propose\ntwo modules to enhance the features of the interested segmentation region,\nincluding an upsampling with feature decomposition (UFD) module and a feature\ninteraction module (FIM) with a constraining loss to focus on the interested\nfeatures. Extensive experiments on three publicly available datasets\ndemonstrate that our proposed SuperVessel can segment more tiny vessels with\nhigher segmentation accuracy IoU over 6%, compared with other state-of-the-art\nalgorithms. Besides, the stability of SuperVessel is also stronger than other\nalgorithms. We will release the code after the paper is published.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Mathematical modeling of fluid flow in a porous medium is usually described\nby a continuity equation and a chosen constitutive law. The latter, depending\non the problem at hand, may be a nonlinear relation between the fluid's\npressure gradient and velocity. The actual shape of this relation is normally\nchosen at the outset of the problem, even though, in practice, the fluid may\nexperience velocities outside of its range of applicability. We propose here an\nadaptive model, so that the most appropriate law is locally selected depending\non the computed velocity. From the analytical point of view, we show\nwell-posedness of the problem when the law is monotone in velocity and show\nexistence in one space dimension otherwise. From the computational point of\nview, we present a new approach based on regularizing via mollification the\nunderlying dissipation, i.e., the power lost by the fluid to the porous medium\nthrough drag. The resulting regularization is shown to converge to the original\nproblem using $\\Gamma$-convergence on the dissipation in the monotone case.\nThis approach gives rise to a variational numerical scheme which applies to\nvery general problems and which we validate on three test cases.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  Language model fusion helps smart assistants recognize words which are rare\nin acoustic data but abundant in text-only corpora (typed search logs).\nHowever, such corpora have properties that hinder downstream performance,\nincluding being (1) too large, (2) beset with domain-mismatched content, and\n(3) heavy-headed rather than heavy-tailed (excessively many duplicate search\nqueries such as \"weather\"). We show that three simple strategies for selecting\nlanguage modeling data can dramatically improve rare-word recognition without\nharming overall performance. First, to address the heavy-headedness, we\ndownsample the data according to a soft log function, which tunably reduces\nhigh frequency (head) sentences. Second, to encourage rare-word exposure, we\nexplicitly filter for words rare in the acoustic data. Finally, we tackle\ndomain-mismatch via perplexity-based contrastive selection, filtering for\nexamples matched to the target domain. We down-select a large corpus of web\nsearch queries by a factor of 53x and achieve better LM perplexities than\nwithout down-selection. When shallow-fused with a state-of-the-art, production\nspeech engine, our LM achieves WER reductions of up to 24% relative on\nrare-word sentences (without changing overall WER) compared to a baseline LM\ntrained on the raw corpus. These gains are further validated through favorable\nside-by-side evaluations on live voice search traffic.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  The advent of Cloud Computing enabled the proliferation of IoT applications\nfor smart environments. However, the distance of these resources makes them\nunsuitable for delay-sensitive applications. Hence, Fog Computing has emerged\nto provide such capabilities in proximity to end devices through distributed\nresources. These limited resources can collaborate to serve distributed IoT\napplication workflows using the concept of stateless micro Fog service\nreplicas, which provides resiliency and maintains service availability in the\nface of failures. Load balancing supports this collaboration by optimally\nassigning workloads to appropriate services, i.e., distributing the load among\nFog nodes to fairly utilize compute and network resources and minimize\nexecution delays. In this paper, we propose using ELECTRE, a Multi-Criteria\nDecision Analysis (MCDA) approach, to efficiently balance the load in Fog\nenvironments. We considered multiple objectives to make service selection\ndecisions, including compute and network load information. We evaluate our\napproach in a realistic unbalanced topological setup with heterogeneous\nworkload requirements. To the best of our knowledge, this is the first time\nELECTRE-based methods are used to balance the load in Fog environments. Through\nsimulations, we compared the performance of our proposed approach with\ntraditional baseline methods that are commonly used in practice, namely random,\nRound-Robin, nearest node, and fastest service selection algorithms. In terms\nof the overall system performance, our approach outperforms these methods with\nup to 67% improvement.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  This paper presents a new algorithm for the parallel in time (PiT) numerical\nsimulation of time dependent partial/ordinary differential equations. We\npropose a reliable alternative to the well know parareal in time algorithm, by\nformulating the parallel in time problem algebraically and solve it using an\nadapted Bi-Conjugate gradient stabilized method. The proposed Parallel in time\nStable Bi-Conjugate algorithm (PiTSBiCG) has a great potential in stabilizing\nthe parallel resolution for a variety of problems. In this work, we describe\nthe mathematical approach to the new algorithm and provide numerical evidences\nthat show its superiority to the standard parareal method.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  The access to activity of subcortical structures offers unique opportunity\nfor building intention dependent brain-computer interfaces, renders abundant\noptions for exploring a broad range of cognitive phenomena in the realm of\naffective neuroscience including complex decision making processes and the\neternal free-will dilemma and facilitates diagnostics of a range of\nneurological deceases. So far this was possible only using bulky, expensive and\nimmobile fMRI equipment. Here we present an interpretable domain grounded\nsolution to recover the activity of several subcortical regions from the\nmultichannel EEG data and demonstrate up to 60% correlation between the actual\nsubcortical blood oxygenation level dependent sBOLD signal and its EEG-derived\ntwin. Then, using the novel and theoretically justified weight interpretation\nmethodology we recover individual spatial and time-frequency patterns of scalp\nEEG predictive of the hemodynamic signal in the subcortical nuclei. The\ndescribed results not only pave the road towards wearable subcortical activity\nscanners but also showcase an automatic knowledge discovery process facilitated\nby deep learning technology in combination with an interpretable domain\nconstrained architecture and the appropriate downstream task.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Despite having the potential to provide significant insights into tactical\npreparations for future matches, very few studies have considered the spatial\ntrends of team attacking possessions in rugby league. Those which have\nconsidered these trends have used grid based aggregation methods, which provide\na discrete understanding of rugby league match play but may fail to provide a\ncomplete understanding of the spatial trends of attacking possessions due to\nthe dynamic nature of the sport. In this study, we use Kernel Density\nEstimation (KDE) to provide a continuous understanding of the spatial trends of\nattacking possessions in rugby league on a team by team basis. We use the\nWasserstein distance to understand the differences between teams (i.e. using\nall of each team's data) and within teams (i.e. using a single team's data\nagainst different opponents). Our results show that KDEs are able to provide\ninteresting tactical insights at the between team level. Furthermore, at the\nwithin team level, the results are able to show patterns of spatial trends for\nattacking teams, which are present against some opponents but not others. The\nresults could help sports practitioners to understand opposition teams'\nprevious performances and prepare tactical strategies for matches against them.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  We study the Cauchy problem for the Schr\\\"odinger-improved Boussinesq system\nin a two dimensional domain. Under natural assumptions on the data without\nsmallness, we prove the existence and uniqueness of global strong solutions.\nMoreover, we consider the vanishing \"improvement\" limit of global solutions as\nthe coefficient of the linear term of the highest order in the equation of ion\nsound waves tends to zero. Under the same smallness assumption on the data as\nin the Zakharov case, solutions in the vanishing \"improvement\" limit are shown\nto satisfy the Zakharov system.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Good research data management is essential in modern-day lab work. Various\nsolutions exist that are either highly specific or need a significant effort to\nbe customized appropriately. This paper presents an integrated solution for\nindividuals and small groups of researchers in data-driven deductive research.\nOur electronic lab book generates itself out of notes and files, which are\ngenerated by one or several experiments. The generated electronic lab book is\nthen presented on a Django-based website. The automated gathering of metadata\nsignificantly reduces the documentation effort for the lab worker and prevents\nhuman error in the repetitive task of manually entering basic meta-data. The\nskilled user can quickly adapt the electronic lab book software to his needs\nbecause the software employs widely used open-source software libraries with\nactive communities and excellent documentation.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Quantum Chaos has originally emerged as the field which studies how the\nproperties of classical chaotic systems arise in their quantum counterparts.\nThe growing interest in quantum many-body systems, with no obvious classical\nmeaning has led to consider time-dependent quantities that can help to\ncharacterize and redefine Quantum Chaos. This article reviews the prominent\nrole that the out of time ordered correlator (OTOC) plays to achieve such goal.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  In this contribution we have collected some facts about Killing and\nKilling-Yano tensors that we feel are of general interest for researchers\nworking on problems that rely on differential geometry. We also include some of\nour recent studies pertaining to currents, charges and (super)invariants for\nparticles and tensionless strings.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Dilatons (and moduli) couple to the masses and coupling constants of ordinary\nmatter, and these quantities are fixed by the local value of the dilaton field.\nIf, in addition, the dilaton with mass $m_\\phi$ contributes to the cosmic dark\nmatter density, then such quantities oscillate in time at the dilaton Compton\nfrequency. We show how these oscillations lead to broadening and shifting of\nthe Voigt profile of the Ly$\\alpha$ forest, in a manner that is correlated with\nthe local dark matter density. We further show how tomographic methods allow\nthe effect to be reconstructed by observing the Ly$\\alpha$ forest spectrum of\ndistant quasars. We then simulate a large number of quasar lines of sight using\nthe lognormal density field, and forecast the ability of future astronomical\nsurveys to measure this effect. We find that in the ultra low mass range\n$10^{-32}\\text{ eV}\\leq m_\\phi\\leq 10^{-28}\\text{ eV}$ upcoming observations\ncan improve over existing limits to the dilaton electron mass and fine\nstructure constant couplings set by fifth force searches by up to five orders\nof magnitude. Our projected limits apply assuming that the ultralight dilaton\nmakes up a few percent of the dark matter density, consistent with upper limits\nset by the cosmic microwave background anisotropies.\n\n\n###\n\n", "completion": " 06"}
{"prompt": "  We prove the following formula for the ground state energy density of a\ndilute Bose gas with density $\\rho$ in $2$ dimensions in the thermodynamic\nlimit \\begin{align*} e^{\\rm{2D}}(\\rho) = 4\\pi \\rho^2 Y\\left(1 - Y \\vert \\log Y\n\\vert + \\left( 2\\Gamma + \\frac{1}{2} + \\log(\\pi) \\right) Y \\right) + o(\\rho^2\nY^{2}). \\end{align*} Here $Y= |\\log(\\rho a^2)|^{-1}$ and $a$ is the scattering\nlength of the two-body potential. This result in $2$ dimensions corresponds to\nthe famous Lee-Huang-Yang formula in $3$ dimensions. The proof is valid for\nessentially all positive potentials with finite scattering length, in\nparticular it covers the crucial case of the hard core potential.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  In this paper, based on some prior estimates, we show that the essential\nspectrum $\\lambda=0$ is a bifurcation point for an superlinear elliptic\nequation with only local conditions, which generalizes a series of earlier\nresults on an open problem proposed by C. A. Stuart in 1983 [Lecture Notes in\nMathematics, 1017].\n\n\n###\n\n", "completion": " 03"}
{"prompt": "  Recent theoretical work has highlighted that quantizing a superconducting\ncircuit in the presence of time-dependent flux $\\Phi(t)$ generally produces\nHamiltonian terms proportional to $d\\Phi/dt$ unless a special allocation of the\nflux across inductive terms is chosen. Here, we present an experiment probing\nthe effects of a fast flux ramp applied to a heavy-fluxonium circuit. The\nexperiment confirms that na\\\"ive omission of the $d\\Phi/dt$ term leads to\ntheoretical predictions inconsistent with experimental data. Experimental data\nare fully consistent with recent theory that includes the derivative term or\nequivalently uses \"irrotational variables\" that uniquely allocate the flux to\nproperly eliminate the $d\\Phi/dt$ term.\n\n\n###\n\n", "completion": " 19"}
{"prompt": "  Circadian rhythms are a process of the sleep-wake cycle that regulates the\nphysical, mental and behavioural changes in all living beings with a period of\nroughly 24 h. Wearable accelerometers are typically used in livestock\napplications to record animal movement from which we can estimate the activity\ntype. Here, we use the overall movement recorded by accelerometers worn on the\nnecks of newborn calves for a period of 8 weeks. From the movement data, we\ncalculate 24 h periodicity intensities corresponding to circadian rhythms, from\na 7-day window that slides through up to 8-weeks of data logging. The strength\nor intensity of the 24 h periodicity is computed at intervals as the calves\nbecome older, which is an indicator of individual calf welfare. We observe that\nthe intensities of these 24 h periodicities for individual calves, derived from\nmovement data, increase and decrease synchronously in a herd of 19 calves. Our\nresults show that external factors affecting the welfare of the herd can be\nobserved by processing and visualising movement data in this way and our method\nreveals insights that are not observable from movement data alone.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  The Expectation-Maximization (EM) algorithm has been predominantly used to\napproximate the maximum likelihood estimation of the location-scale Gaussian\nmixtures. However, when the models are over-specified, namely, the chosen\nnumber of components to fit the data is larger than the unknown true number of\ncomponents, EM needs a polynomial number of iterations in terms of the sample\nsize to reach the final statistical radius; this is computationally expensive\nin practice. The slow convergence of EM is due to the missing of the locally\nstrong convexity with respect to the location parameter on the negative\npopulation log-likelihood function, i.e., the limit of the negative sample\nlog-likelihood function when the sample size goes to infinity. To efficiently\nexplore the curvature of the negative log-likelihood functions, by specifically\nconsidering two-component location-scale Gaussian mixtures, we develop the\nExponential Location Update (ELU) algorithm. The idea of the ELU algorithm is\nthat we first obtain the exact optimal solution for the scale parameter and\nthen perform an exponential step-size gradient descent for the location\nparameter. We demonstrate theoretically and empirically that the ELU iterates\nconverge to the final statistical radius of the models after a logarithmic\nnumber of iterations. To the best of our knowledge, it resolves the\nlong-standing open question in the literature about developing an optimization\nalgorithm that has optimal statistical and computational complexities for\nsolving parameter estimation even under some specific settings of the\nover-specified Gaussian mixture models.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Mixed Sample Regularization (MSR), such as MixUp or CutMix, is a powerful\ndata augmentation strategy to generalize convolutional neural networks.\nPrevious empirical analysis has illustrated an orthogonal performance gain\nbetween MSR and the conventional offline Knowledge Distillation (KD). To be\nmore specific, student networks can be enhanced with the involvement of MSR in\nthe training stage of the sequential distillation. Yet, the interplay between\nMSR and online knowledge distillation, a stronger distillation paradigm, where\nan ensemble of peer students learn mutually from each other, remains\nunexplored. To bridge the gap, we make the first attempt at incorporating\nCutMix into online distillation, where we empirically observe a significant\nimprovement. Encouraged by this fact, we propose an even stronger MSR\nspecifically for online distillation, named as Cut^nMix. Furthermore, a novel\nonline distillation framework is designed upon Cut^nMix, to enhance the\ndistillation with feature level mutual learning and a self-ensemble teacher.\nComprehensive evaluations on CIFAR10 and CIFAR100 with six network\narchitectures show that our approach can consistently outperform\nstate-of-the-art distillation methods.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  Full waveform inversion (FWI) is one of a family of methods that allows the\nreconstruction of earth subsurface parameters from measurements of waves at or\nnear the surface. This is a numerical optimization problem that uses the whole\nwaveform information of all arrivals to update the subsurface parameters that\ngovern seismic wave propagation. We apply FWI in the multi-scale approach on\ntwo well-known benchmarks: Marmousi and 2004 BP velocity model. For the forward\nmodeling, we use an RBF-FD solver on hexagonal grids and quasi-optimal shape\nparameters.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  The Sinkhorn operator has recently experienced a surge of popularity in\ncomputer vision and related fields. One major reason is its ease of integration\ninto deep learning frameworks. To allow for an efficient training of respective\nneural networks, we propose an algorithm that obtains analytical gradients of a\nSinkhorn layer via implicit differentiation. In comparison to prior work, our\nframework is based on the most general formulation of the Sinkhorn operator. It\nallows for any type of loss function, while both the target capacities and cost\nmatrices are differentiated jointly. We further construct error bounds of the\nresulting algorithm for approximate inputs. Finally, we demonstrate that for a\nnumber of applications, simply replacing automatic differentiation with our\nalgorithm directly improves the stability and accuracy of the obtained\ngradients. Moreover, we show that it is computationally more efficient,\nparticularly when resources like GPU memory are scarce.\n\n\n###\n\n", "completion": " 20"}
{"prompt": "  A well known conjecture of Burr and Erdos asserts that the Ramsey number\n$r(Q_n)$ of the hypercube $Q_n$ on $2^n$ vertices is of the order $O(2^n)$. In\nthis paper, we show that $r(Q_n)=O(2^{2n-c n})$ for a universal constant $c>0$,\nimproving upon the previous best known bound $r(Q_n)=O(2^{2n})$, due to Conlon,\nFox and Sudakov.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  We present a CO(3-2) study of four systems composed of six (ultra) luminous\ninfrared galaxies (U/LIRGs), located at 0.28 < z < 0.44, that straddle the\ntransition region between regular star forming galaxies and starbursts. These\ngalaxies benefit from previous multi-wavelength analysis allowing in depth\nexploration of an understudied population of U/LIRGs at a time when the\nuniverse is experiencing a rapid decline in star formation rate density. We\ndetect CO(3-2) emission in four targets and these galaxies fall between the\nloci of regular star forming galaxies and starbursts on the Kennicutt-Schmidtt\nrelation. Compared to low luminosity LIRGs and high luminosity ULIRGs at\nsimilar redshifts, we find they all have similar molecular gas budgets with the\ndifference in their star formation rates (SFR) driven by the star formation\nefficiency (SFE). This suggests that at these redshifts large molecular gas\nreservoirs must coincide with an increased SFE to transition a galaxy into the\nstarburst regime. We studied the structure and kinematics and found our four\ndetections are either interacting or have disturbed morphology which may be\ndriving the SFE. One of the CO(3-2) non-detections has a strong continuum\ndetection, and has been previously observed in H$\\alpha$, suggesting an unusual\ninterstellar medium for a ULIRG. We conclude that our sample of transitioning\nU/LIRGs fill the gap between regular star forming galaxies and starbursts,\nsuggest a continuous change in SFE between these two populations and the\nincreased SFE may be driven by morphology and differing stages of interaction.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Random walks simulate the randomness of objects, and are key instruments in\nvarious fields such as computer science, biology and physics. The counter part\nof classical random walks in quantum mechanics are the quantum walks. Quantum\nwalk algorithms provide an exponential speedup over classical algorithms.\nClassical and quantum random walks can be applied in social network analysis,\nand can be used to define specific centrality metrics in terms of node\noccupation on single-layer and multilayer networks. In this paper, we applied\nthese new centrality measures to three real criminal networks derived from an\nanti-mafia operation named Montagna and a multilayer network derived from them.\nOur aim is to (i) identify leaders in our criminal networks, (ii) study the\ndependence between these centralities and the degree, (iii) compare the results\nobtained for the real multilayer criminal network with those of a synthetic\nmultilayer network which replicates its structure.\n\n\n###\n\n", "completion": " 10"}
{"prompt": "  We introduce a family of models, which we name matrix models associated with\nchildren's drawings -- the so-called dessin d'enfant. Dessins d'enfant are\ngraphs of a special kind drawn on a closed connected orientable surface (in the\nsky). The vertices of such a graph are small disks that we call stars. We\nattach random matrices to the edges of the graph and get multimatrix models.\nAdditionally, to the stars we attach source matrices. They play the role of\nfree parameters or model coupling constants. The answers for our integrals are\nexpressed through quantities that we call the \"spectrum of stars.\" The answers\nmay also include some combinatorial numbers, such as Hurwitz numbers or\ncharacters from group representation theory.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  This article concerns a question asked by M. V. Nori on homotopy of sections\nof Projective modules defined on the polynomial algebra over a smooth affine\ndomain $R$. While this question has an affirmative answer, it is known that the\nassertion does not hold if: (1) $\\dim(R)=2$; or (2) $d\\geq 3$ but $R$ is not\nsmooth. We first prove that an affirmative answer can be given for $\\dim(R)=2$\nwhen $R$ is an $\\bar{\\mathbb{F}}_p$-algebra. Next, for $d\\geq 3$ we find the\nprecise obstruction for the failure in the singular case. Further, we improve a\nresult of Mandal (related to Nori's question) in the case when the ring $A$ is\nan affine $\\bar{\\mathbb{F}}_p$-algebra of dimension $d$. We apply this\nimprovement to define the $n$-th Euler class group $E^n(A)$, where $2n\\ge d+2.$\nMoreover, if $A$ is smooth, we associate to a unimodular row $v$ of length\n$n+1$ its Euler class $e(v)\\in E^n(A)$ and show that the corresponding stably\nfree module, say, $P(v)$ has a unimodular element if and only if $e(v)$\nvanishes in $E^n(A)$.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  Nonzero mean value of phonon angular momentum (PAM) in chiral materials can\nbe generated when a temperature gradient is applied. We find that both diagonal\nand off-diagonal terms of PAM contribute to mean PAM by using the Kubo formula\nwhere both diagonal and off-diagonal elements of the heat current operator are\nconsidered. The calculation results show that the off-diagonal term is dominant\nwhen the phonon scattering is strong enough. This finding reveals that the\nquantum transition between different phonon modes induced by temperature\ngradient strongly affects the local atomic rotation. Our discovery provides an\nexplanation of the recently observed chiral phonon activated spin Seebeck\neffect.\n\n\n###\n\n", "completion": " 12"}
{"prompt": "  Solid body tides provide key information on the interior structure,\nevolution, and origin of the planetary bodies. Our Solar system harbours a very\ndiverse population of planetary bodies, including those composed of rock, ice,\ngas, or a mixture of all. While a rich arsenal of geophysical methods has been\ndeveloped over several years to infer knowledge about the interior of the\nEarth, the inventory of tools to investigate the interiors of other\nSolar-system bodies remains limited. With seismic data only available for the\nEarth, the Moon, and Mars, geodetic measurements, including the observation of\nthe tidal response, have become especially valuable and therefore, has played\nan important role in understanding the interior and history of several Solar\nsystem bodies. To use tidal response measurements as a means to obtain\nconstraints on the interior structure of planetary bodies, appropriate\nunderstanding of the viscoelastic reaction of the materials from which the\nplanets are formed is needed. Here, we review the fundamental aspects of the\ntidal modeling and the information on the present-day interior properties and\nevolution of several planets and moons based on studying their tidal response.\nWe begin with an outline of the theory of viscoelasticity and tidal response.\nNext, we proceed by discussing the information on the tidal response and the\ninferred structure of Mercury, Venus, Mars and its moons, the Moon, and the\nlargest satellites of giant planets, obtained from the analysis of the data\nthat has been provided by space missions. We also summarise the upcoming\npossibilities offered by the currently planned missions.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  This article is a continuation of our investigations in the function space\n$C(X)$ with respect to the topology $\\tau^s_\\mathfrak{B}$ of strong uniform\nconvergence on $\\mathfrak{B}$ in line of (Chandra et al. 2020 \\cite{dcpdsd} and\nDas et al. 2022 \\cite{pddcsd-3}) using the idea of strong uniform convergence\n(Beer and Levi, 2009 \\cite{bl}) on a bornology. First we focus on the notion of\ntightness property of $(C(X),\\tau^s_\\mathfrak{B})$ and some of its variations\nsuch as supertightness, Id-fan tightness and $T$-tightness. Certain situations\nare discussed when $C(X)$ is a {\\rm k}-space with respect to the topology\n$\\tau^s_\\mathfrak{B}$. Next the notions of strong $\\mathfrak{B}$-open game and\n$\\gamma_{\\mathfrak{B}^s}$-open game on $X$ are introduced and some of its\nconsequences are investigated. Finally, we consider discretely selective\nproperty and related games. On $(C(X),\\tau^s_\\mathfrak{B})$ several\ninteractions between topological games related to discretely selective\nproperty, the Gruenhage game on $(C(X),\\tau^s_\\mathfrak{B})$ and certain games\non $X$ are presented.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Ivlev's pioneering work started in the 1970's showed a new and promissory way\nin the study of modal logic from the perspective of many-valued logics.\nContinuing our previous work on Ivlev-like non-normal modal logics with\nnon-deterministic semantics, we present in this paper tableau systems for Tm,\nS4m and S5m, the non-normal versions of T, S4 and S5, respectively, as well as\nfor their corresponding first-order extensions Tm*, S4m* and S5m*.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Few-shot learning (FSL), purposing to resolve the problem of data-scarce, has\nattracted considerable attention in recent years. A popular FSL framework\ncontains two phases: (i) the pre-train phase employs the base data to train a\nCNN-based feature extractor. (ii) the meta-test phase applies the frozen\nfeature extractor to novel data (novel data has different categories from base\ndata) and designs a classifier for recognition. To correct few-shot data\ndistribution, researchers propose Semi-Supervised Few-Shot Learning (SSFSL) by\nintroducing unlabeled data. Although SSFSL has been proved to achieve\noutstanding performances in the FSL community, there still exists a fundamental\nproblem: the pre-trained feature extractor can not adapt to the novel data\nflawlessly due to the cross-category setting. Usually, large amounts of noises\nare introduced to the novel feature. We dub it as Feature-Extractor-Maladaptive\n(FEM) problem. To tackle FEM, we make two efforts in this paper. First, we\npropose a novel label prediction method, Isolated Graph Learning (IGL). IGL\nintroduces the Laplacian operator to encode the raw data to graph space, which\nhelps reduce the dependence on features when classifying, and then project\ngraph representation to label space for prediction. The key point is that: IGL\ncan weaken the negative influence of noise from the feature representation\nperspective, and is also flexible to independently complete training and\ntesting procedures, which is suitable for SSFSL. Second, we propose Graph\nCo-Training (GCT) to tackle this challenge from a multi-modal fusion\nperspective by extending the proposed IGL to the co-training framework. GCT is\na semi-supervised method that exploits the unlabeled samples with two modal\nfeatures to crossly strengthen the IGL classifier.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We formulate a phenomenological model to study the power applied by a cyclist\non a velodrome -- for individual timetrials -- taking into account the\nstraights, circular arcs, connecting transition curves, and banking. The\ndissipative forces we consider are air resistance, rolling resistance, lateral\nfriction and drivetrain resistance. Also, in general, the power is used to\nincrease the kinetic and potential energy. However, to model a steady ride --\nas expected for individual timetrials -- we assume a constant centre-of-mass\nspeed and allow the cadence and power to vary during a lap. Hence, the only\nmechanical energy to consider is the increase of potential energy due to\nraising the centre of mass upon exiting each curve. Following derivations and\njustifications of expressions that constitute this mathematical model, we\npresent a numerical example. We show that, as expected, the cadence and power\nvary only slightly during a steady ride. Also, we examine changes in the\nrequired average power per lap due to modifications of various quantities, such\nas air density at a velodrome, laptime and several others, as well as the model\nsensitivity to input errors. Such an examination is of immediate use in\nstrategizing the performance for individual pursuits and the Hour Record, as\nwell as in evaluating the reliability of model predictions.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Rare genetic disorders affect more than 6% of the global population. Reaching\na diagnosis is challenging because rare disorders are very diverse. Many\ndisorders have recognizable facial features that are hints for clinicians to\ndiagnose patients. Previous work, such as GestaltMatcher, utilized\nrepresentation vectors produced by a DCNN similar to AlexNet to match patients\nin high-dimensional feature space to support \"unseen\" ultra-rare disorders.\nHowever, the architecture and dataset used for transfer learning in\nGestaltMatcher have become outdated. Moreover, a way to train the model for\ngenerating better representation vectors for unseen ultra-rare disorders has\nnot yet been studied. Because of the overall scarcity of patients with\nultra-rare disorders, it is infeasible to directly train a model on them.\nTherefore, we first analyzed the influence of replacing GestaltMatcher DCNN\nwith a state-of-the-art face recognition approach, iResNet with ArcFace.\nAdditionally, we experimented with different face recognition datasets for\ntransfer learning. Furthermore, we proposed test-time augmentation, and model\nensembles that mix general face verification models and models specific for\nverifying disorders to improve the disorder verification accuracy of unseen\nultra-rare disorders. Our proposed ensemble model achieves state-of-the-art\nperformance on both seen and unseen disorders.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Most computer algebra systems (CAS) support symbolic integration as core\nfunctionality. The majority of the integration packages use a combination of\nheuristic algebraic and rule-based (integration table) methods. In this paper,\nwe present a hybrid (symbolic-numeric) methodology to calculate the indefinite\nintegrals of univariate expressions. The primary motivation for this work is to\nadd symbolic integration functionality to a modern CAS (the symbolic\nmanipulation packages of SciML, the Scientific Machine Learning ecosystem of\nthe Julia programming language), which is mainly designed toward numerical and\nmachine learning applications and has a different set of features than\ntraditional CAS. The symbolic part of our method is based on the combination of\ncandidate terms generation (borrowed from the Homotopy operators theory) with\nrule-based expression transformations provided by the underlying CAS. The\nnumeric part is based on sparse-regression, a component of Sparse\nIdentification of Nonlinear Dynamics (SINDy) technique. We show that this\nsystem can solve a large variety of common integration problems using only a\nfew dozen basic integration rules.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Neutron captures and delayed decays of reaction products are common sources\nof backgrounds in ultra-rare event searches. In this work, we studied\n$^{13}$C($\\alpha,n)^{16}$O reactions induced by $\\alpha$-particles emitted\nwithin the calibration sources of the \\textsc{Majorana Demonstrator}. These\nsources are thorium-based calibration standards enclosed in carbon-rich\nmaterials. The reaction rate was estimated by using the 6129-keV $\\gamma$-rays\nemitted from the excited $^{16}$O states that are populated when the incoming\n$\\alpha$-particles exceed the reaction Q-value. Thanks to the excellent energy\nperformance of the \\textsc{Demonstrator}'s germanium detectors, these\ncharacteristic photons can be clearly observed in the calibration data.\nFacilitated by \\textsc{Geant4} simulations, a comparison between the observed\n6129-keV photon rates and predictions by a TALYS-based software was performed.\nThe measurements and predictions were found to be consistent, albeit with large\nstatistical uncertainties. This agreement provides support for background\nprojections from ($\\alpha,n$)-reactions in future double-beta decay search\nefforts.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  We present a brief introduction to the Dyson-Schwinger equations (DSEs)\napproach to hadron and high-energy physics. In particular, how this formalism\nis applied to calculate the electromagnetic form factors $\\gamma^* \\gamma^* \\to\n\\textbf{P}^0$ and $\\gamma^* \\textbf{P}^\\pm \\to \\textbf{P}^\\pm$ (with\n$\\textbf{P}^\\pm$ and $\\textbf{P}^0$ charged and neutral ground-state\npseudoscalar mesons, respectively) is discussed. Subsequently, the\ncorresponding contributions of those form factors to the muon anomalous\nmagnetic moment ($g-2$) are estimated. We look forward to promoting the DSE\napproach to address theoretical aspects of the muon $g-2$, highlighting some\ncalculations that could be carried out in the future.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  In this paper, we propose a novel end-to-end user-defined keyword spotting\nmethod that utilizes linguistically corresponding patterns between speech and\ntext sequences. Unlike previous approaches requiring speech keyword enrollment,\nour method compares input queries with an enrolled text keyword sequence. To\nplace the audio and text representations within a common latent space, we adopt\nan attention-based cross-modal matching approach that is trained in an\nend-to-end manner with monotonic matching loss and keyword classification loss.\nWe also utilize a de-noising loss for the acoustic embedding network to improve\nrobustness in noisy environments. Additionally, we introduce the LibriPhrase\ndataset, a new short-phrase dataset based on LibriSpeech for efficiently\ntraining keyword spotting models. Our proposed method achieves competitive\nresults on various evaluation sets compared to other single-modal and\ncross-modal baselines.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  Doped Mott insulators exhibit some of the most intriguing quantum phases of\nmatter, including quantum spin-liquids, unconventional superconductors, and\nnon-Fermi liquid metals. Such phases often arise when itinerant electrons are\nclose to a Mott insulating state, and thus experience strong spatial\ncorrelations. Proximity between different layers of van der Waals\nheterostructures naturally realizes a platform for experimentally studying the\nrelationship between localized, correlated electrons and itinerant electrons.\nHere, we explore this relationship by studying the magnetic landscape of\n4Hb-TaS2, which realizes an alternate stack of a candidate spin liquid and a\nsuperconductor. We report on a spontaneous vortex phase whose vortex density\ncan be trained in the normal state. We show that time reversal symmetry is\nbroken above Tc, indicating the presence of a magnetic phase independent of the\nsuperconductor. Strikingly, this phase does not generate detectable magnetic\nsignals. We use scanning superconducting quantum interference device (SQUID)\nmicroscopy to show that it is incompatible with ferromagnetic ordering. The\ndiscovery of this new form of hidden magnetism illustrates how combining\nsuperconductivity with a strongly correlated system can lead to new, unexpected\nphysics.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Partial maximum distance separable (PMDS) codes are a kind of erasure codes\nwhere the nodes are divided into multiple groups with each forming an MDS code\nwith a smaller code length, thus they allow repairing a failed node with only a\nfew helper nodes and can correct all erasure patterns that are\ninformation-theoretically correctable. However, the repair of a failed node of\nPMDS codes still requires a large amount of communication if the group size is\nlarge. Recently, PMDS array codes with each local code being an MSR code were\nintroduced to reduce the repair bandwidth further. However, they require\nextensive rebuilding access and unavoidably a significant sub packetization\nlevel. In this paper, we first propose two constructions of PMDS array codes\nwith two global parities that have smaller sub-packetization levels and much\nsmaller finite fields than the existing one. One construction can support an\narbitrary number of local parities and has $(1+\\epsilon)$-optimal repair\nbandwidth (i.e., $(1+\\epsilon)$ times the optimal repair bandwidth), while the\nother one is limited to two local parities but has significantly smaller\nrebuilding access and its sub packetization level is only $2$. In addition, we\npresent a construction of PMDS array code with three global parities, which has\na smaller sub-packetization level as well as $(1+\\epsilon)$-optimal repair\nbandwidth, the required finite field is significantly smaller than existing\nones.\n\n\n###\n\n", "completion": " 13"}
{"prompt": "  Hybrid excitations of light and matter, namely, polaritons, in the\nultrastrong coupling regime have been intensively investigated to explore novel\nmaterial functions and realize coherent control of material properties by\noptical means. However, realization of ultrastrong coupling in a-few-electron\nsystems has been challenging, because the electronic dipole moment decreases\nwith decreasing electron numbers in the system. Here, we fabricate a\ngate-defined quantum dot (QD) in the vicinity of a gap of a terahertz (THz)\nsplit-ring resonator (SRR). By illuminating the system with external THz\nradiation, the QD shows a current change whose spectrum exhibits anti-crossing\nbehavior between the resonant excitation of the quantized electronic states and\nthe resonance mode of the SRR. Our result indicates that, owing to the field\nenhancement by the THz SRR, the system enters the ultrastrong coupling regime\neven when only a few electrons reside in the QD.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  Wireless communication offers many benefits for control such as substantially\nreduced deployment costs, higher flexibility, as well as easier data access. It\nis thus not surprising that smart and wireless sensors and actuators are\nincreasingly used in industry. With these enhanced possibilities, exciting new\ntechnologies such as Control-as-a-Service arise, where (for example) controller\ndesign or tuning based on input-output-data can be outsourced to a cloud or\nmobile device. This implies, however, that sensitive plant information may\nbecome available to service providers or, possibly, attackers.\n  Against this background, we focus on privacy-preserving optimal PID tuning\nas-a-Service here. In particular, we combine homomorphic encryption with\nextremum seeking in order to provide a purely data-driven and confidential\ntuning algorithm. The encrypted realization requires several adaptions of\nestablished extremum seekers. These encompass relative parameter updates,\nstochastic gradient approximations, and a normalized objective function. As a\nresult, and as illustrated by various numerical examples, the proposed\nencrypted extremum seeker is able to tune PID controllers for a wide variety of\nplants without being too conservative.\n\n\n###\n\n", "completion": " 18"}
{"prompt": "  We solve the Wheeler-DeWitt equation for the planar AdS-Schwarzschild\ninterior in a minisuperspace approximation involving the volume and spatial\nanisotropy of the interior. A Gaussian wavepacket is constructed that is peaked\non the classical interior solution. Simple observables are computed using this\nwavepacket, demonstrating the freedom to a choose a relational notion of\n`clock' in the interior and characterizing the approach to the spacelike\nsingularity. The Wheeler-DeWitt equation may be extended out through the\nhorizon, where it describes the holographic renormalization group flow of the\nblack hole exterior. This amounts to the Hamilton-Jacobi evolution of the\nmetric component $g_{tt}$ from positive interior values to negative exterior\nvalues. The interior Gaussian wavepacket is shown to evolve into the Lorentizan\npartition function of the boundary conformal field theory over a microcanonical\nenergy window.\n\n\n###\n\n", "completion": " 17"}
{"prompt": "  We present our current understanding of the formation and early evolution of\nprotostars, protoplanetary disks, and the driving of outflows as dictated by\nthe interplay of magnetic fields and partially ionized gas in molecular cloud\ncores. In recent years, the field has witnessed enormous development through\nsub-millimeter observations which in turn have constrained models of protostar\nformation. As a result of these observations % that the observations provided,\nthe state-of-the-art theoretical understanding of the formation and evolution\nof young stellar objects is described. In particular, we emphasize the\nimportance of the coupling, decoupling, and re-coupling between weakly ionized\ngas and the magnetic field on appropriate scales. This highlights the complex\nand intimate relationship between gravitational collapse and magnetic fields in\nyoung protostars.\n\n\n###\n\n", "completion": " 14"}
{"prompt": "  We consider a variant of the prize collecting Steiner tree problem in which\nwe are given a \\emph{directed graph} $D=(V,A)$, a monotone submodular prize\nfunction $p:2^V \\rightarrow \\mathbb{R}^+ \\cup \\{0\\}$, a cost function $c:V\n\\rightarrow \\mathbb{Z}^{+}$, a root vertex $r \\in V$, and a budget $B$. The aim\nis to find an out-subtree $T$ of $D$ rooted at $r$ that costs at most $B$ and\nmaximizes the prize function. We call this problem \\emph{Directed Rooted\nSubmodular Tree} (\\textbf{DRSO}).\n  Very recently, Ghuge and Nagarajan [SODA\\ 2020] gave an optimal\nquasi-polynomial-time $O\\left(\\frac{\\log n'}{\\log \\log\nn'}\\right)$-approximation algorithm, where $n'$ is the number of vertices in an\noptimal solution, for the case in which the costs are associated to the edges.\n  In this paper, we give a polynomial-time algorithm for \\textbf{DRSO} that\nguarantees an approximation factor of $O(\\sqrt{B}/\\epsilon^3)$ at the cost of a\nbudget violation of a factor $1+\\epsilon$, for any $\\epsilon \\in (0,1]$. The\nsame result holds for the edge-cost case, to the best of our knowledge this is\nthe first polynomial-time approximation algorithm for this case. We further\nshow that the unrooted version of \\textbf{DRSO} can be approximated to a factor\nof $O(\\sqrt{B})$ without budget violation, which is an improvement over the\nfactor $O(\\Delta \\sqrt{B})$ given in~[Kuo et al.\\ IEEE/ACM\\ Trans.\\ Netw.\\\n2015] for the undirected and unrooted case, where $\\Delta$ is the maximum\ndegree of the graph. Finally, we provide some new/improved approximation bounds\nfor several related problems, including the additive-prize version of\n\\textbf{DRSO}, the maximum budgeted connected set cover problem, and the\nbudgeted sensor cover problem.\n\n\n###\n\n", "completion": " 21"}
{"prompt": "  HDSDP is a numerical software solving the semidefinite programming problems.\nThe main framework of HDSDP resembles the dual-scaling interior point solver\nDSDP[2] and several new features, especially a dual method based on the\nsimplified homogeneous self-dual embedding, have been implemented. The\nembedding enhances stability of dual method and several new heuristics and\ncomputational techniques are designed to accelerate its convergence. HDSDP aims\nto show how dual-scaling algorithms benefit from the self-dual embedding and it\nis developed in parallel to DSDP5.8. Numerical experiments over several\nclassical benchmark datasets exhibit its robustness and efficiency, and\nparticularly its advantages on SDP instances featuring low-rank structure and\nsparsity. The pre-built binary of HDSDP is currently freely available at\nhttps://github.com/COPT-Public/HDSDP.\n\n\n###\n\n", "completion": " 22"}
{"prompt": "  This paper addresses the following question: given a topological quantum\nfield theory on $\\mathbb R^n$ built from an action functional, when is it\npossible to globalize the theory so that it makes sense on an arbitrary smooth\noriented $n$-manifold? We study a broad class of topological field theories --\nthose of AKSZ type -- and obtain an explicit condition for the vanishing of the\nframing anomaly, i.e., the obstruction to performing this globalization\nprocedure. We also interpret our results in terms of identifying the\nobservables as an algebra over the framed little $n$-disks operad. Our analysis\nuses the BV formalism for perturbative field theory and the notion of\nfactorization homology.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  Persistent currents in annular geometries have played an important role in\ndisclosing the quantum phase coherence of superconductors and mesoscopic\nelectronic systems. Ultracold atomic gases in multiply connected traps also\nexhibit long-lived supercurrents, and have attracted much interest both for\nfundamental studies of superfluid dynamics and as prototypes for atomtronic\ncircuits. Here, we report on the realization of supercurrents in homogeneous,\ntunable fermionic rings. We gain exquisite, rapid control over quantized\npersistent currents in all regimes of the BCS-BEC crossover through a universal\nphase-imprinting technique, attaining on-demand circulations $w$ as high as 8.\nHigh-fidelity read-out of the superfluid circulation state is achieved by\nexploiting an interferometric protocol, which also yields local information\nabout the superfluid phase around the ring. In the absence of externally\nintroduced perturbations, we find the induced metastable supercurrents to be as\nlong-lived as the atomic sample. Conversely, we trigger and inspect the\nsupercurrent decay by inserting a single small obstacle within the ring. For\ncirculations higher than a critical value, the quantized current is observed to\ndissipate via the emission of vortices, i.e., quantized phase slips, which we\ndirectly image, in good agreement with numerical simulations. The critical\ncirculation at which the superflow becomes unstable is found to depend starkly\non the interaction strength, taking its maximum value for the unitary Fermi\ngas. Our results demonstrate fast and accurate control of quantized collective\nexcitations in a macroscopic quantum system, and establish strongly interacting\nfermionic superfluids as excellent candidates for atomtronic applications.\n\n\n###\n\n", "completion": " 16"}
{"prompt": "  Interesting discrepancies in cosmological parameters are challenging the\nsuccess of the $\\Lambda$CDM model. Direct measurements of the Hubble constant\n$H_0$ using Cepheid variables and supernovae turn out to be higher than\ninferred from the Cosmic Microwave Background (CMB). Weak galaxy lensing\nsurveys consistently report values of the strength of matter clustering\n$\\sigma_8$ lower than values derived from the CMB in the context of\n$\\Lambda$CDM. In this paper we address these discrepancies in cosmological\nparameters by considering Dark Energy (DE) as a fluid with evolving equation of\nstate $w_{\\mathrm{de}}(z)$, constant sound speed squared\n$\\hat{c}_{\\mathrm{s}}^{2}$, and vanishing anisotropic stress $\\sigma$. Our\n$w_{\\mathrm{de}}(z)$ is derived from the Holographic Principle and can\nconsecutively exhibit radiation-like, matter-like, and DE-like behaviour, thus\naffecting the sound horizon and the comoving angular diameter distance, hence\n$H_0$. Here we show DE sound speed plays a part in the matter clustering\nbehaviour through its effect on the evolution of the gravitational potential.\nWe compute cosmological constraints using several data set combinations\nincluding primary CMB, CMB lensing, redshift-space-distortions, local\ndistance-ladder, supernovae, and baryon acoustic oscillations. In our analysis\nwe marginalise over $\\hat{c}_{\\mathrm{s}}^{2}$ and find\n$\\hat{c}_{\\mathrm{s}}^{2}=1$ is excluded at $\\gtrsim 3\\sigma$. For our baseline\nresult including the whole data set we found $H_0$ and $\\sigma_8$ in good\nagreement (within $\\approx 2\\sigma$) with low redshift probes. Our constraint\nfor the baryon energy density $\\omega_{\\rm{b}}$ is however in $\\approx 3\\sigma$\ntension with BBN constraints. We conclude evolving DE also having non-standard\nclustering properties [e.g., $\\hat{c}_{\\mathrm{s}}^{2}(z,k)$] might be relevant\nfor the solution of current discrepancies in cosmological parameters.\n\n\n###\n\n", "completion": " 15"}
{"prompt": "  In this paper we study admissible extensions of several theories T of reverse\nmathematics. The idea is that in such an extension the structure M = (N,S,\\in)\nof the natural numbers N and collection of sets of natural numbers S has to\nobey the axioms of T while simultaneously one also has a set-theoretic world\nwith transfinite levels erected on top of M governed by the axioms of\nKripke-Platek set theory, KP.\n\n\n###\n\n", "completion": " 08"}
{"prompt": "  I present an overview of recent developments in the microscopic description\nof the quark-gluon plasma. I will concentrate on medium-induced emission and\ntransverse momentum broadening. These are two key ingredients of the theory of\njet modifications in the QCD medium and of the kinetic theory used for\ntransport and thermalisation. The main focus is on progress towards a better\nunderstanding of theory and of its uncertainties.\n\n\n###\n\n", "completion": " 99"}
